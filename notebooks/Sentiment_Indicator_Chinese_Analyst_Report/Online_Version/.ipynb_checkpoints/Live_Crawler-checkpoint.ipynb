{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "import pickle\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import sqlalchemy as sq\n",
    "import os\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import *\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.proxy import Proxy, ProxyType\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crawler_machine:\n",
    "    def __init__(self,conn,build_db_html = False):\n",
    "        self.conn_html = conn\n",
    "        if build_db_html:\n",
    "            self.build_html_db()\n",
    "    def build_html_db(self):\n",
    "        # Function: Set up a database to store accuracy with the following setting. \n",
    "        # Note that: All functions in this class will follow this setting, pls set up ur database accordingly to avoid error\n",
    "        self.conn_html.execute('CREATE TABLE `Alternative_DB`.`html`(`url` VARCHAR(750) NOT NULL,`id` INT NOT NULL AUTO_INCREMENT,`company` VARCHAR(30) NULL,`type` VARCHAR(45) NULL,`title` TINYTEXT NULL,`html` MEDIUMTEXT NULL,PRIMARY KEY (`url`),KEY(`id`));')\n",
    "    \n",
    "    def raw_crawl_func(self,driver,crawl_type,analyst_company, news_type,website_link,keyword_report = 'All',\n",
    "                             xpath = None,tag_element = None,keyword_next_page =None,keyword_filter = [],exclude_list=[]):\n",
    "        \n",
    "        # Function: This function will crawl data from the given page and it will stop crawling when we reach the url that is already in database\n",
    "        # Inputs: Wait time is seconds to wait for driver to initiate, website_link is the index page link\n",
    "        # keyword_report is to select all reports that contain keyword\n",
    "        # If keyword_report is All, then xpath and tag_element for the all report links must be given in order to locate them\n",
    "        # keyword_filter is the keyword must be contained in the title if not we will filter it out\n",
    "        \n",
    "         \n",
    "        result = self.conn_html.execute(\"SHOW TABLES LIKE 'html';\")\n",
    "        \n",
    "        if  not result.first():\n",
    "            driver.close()\n",
    "            raise Exception('Database not exist, please use build_html_db function')\n",
    "        \n",
    "        \n",
    "        # Record we have proceed how many links we have crawled\n",
    "        record_page = 0\n",
    "        crawled_data =0 \n",
    "        crawled_link = []\n",
    "        \n",
    "        # Record the website firstpage\n",
    "        current_page = 1\n",
    "        current_website_link = website_link\n",
    "        \n",
    "        print('Start Crawling Report from {}'.format(analyst_company))\n",
    "    \n",
    "    \n",
    "        driver.execute_script(\"window.open('');\")\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        \n",
    "        type_lst = ['manual_num_crawl', 'auto_click_crawl', 'auto_link_crawl','same_page_click']\n",
    "        if crawl_type not in type_lst:\n",
    "            driver.quit()\n",
    "            raise Exception('crawl_type can only be manual_num_crawl, auto_click_crawl, auto_link_crawl,same_page_click')\n",
    "        try:\n",
    "            \n",
    "            while True:\n",
    "                SCROLL_PAUSE_TIME = 2.5\n",
    "\n",
    "                # Get scroll height\n",
    "                last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "                while True:\n",
    "                # Scroll down to bottom\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "                # Wait to load page\n",
    "                    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "                # Calculate new scroll height and compare with last scroll height\n",
    "                    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                    if new_height == last_height:\n",
    "                        break\n",
    "                    last_height = new_height\n",
    "                    \n",
    "                if keyword_report!= 'All':\n",
    "                \n",
    "                # Check if we have particular report type we want to extract:\n",
    "                    if type(keyword_report)!= str:\n",
    "                        raise Exception('Error : keyword_report can only be one keyword and the type should be string')\n",
    "                    else:\n",
    "                        total_link = driver.find_elements_by_partial_link_text(keyword_report)\n",
    "                else:\n",
    "                    if xpath == None or tag_element == None:\n",
    "                        raise Exception('Error : class_type cannot be none, have to key in class name if u choose for All link option, if not pls enter keyword_report')\n",
    "                    else:\n",
    "                        temp = driver.find_element_by_xpath(xpath)\n",
    "                        total_link = temp.find_elements_by_tag_name(tag_element)\n",
    "                        \n",
    "                # Now select potentail links for report type we are interested in the current page\n",
    "            \n",
    "                if keyword_filter == 'All':\n",
    "                    filter_link = list(set(total_link))\n",
    "                else:\n",
    "                    selected_link = []\n",
    "                    for keyword in keyword_filter:\n",
    "                        current_link = driver.find_elements_by_partial_link_text(keyword)\n",
    "                        selected_link = list(set().union(selected_link,current_link))\n",
    "                    filter_link = list(set(selected_link) & set(total_link))\n",
    "                \n",
    "                # Filter out link that contains keyword we don't want\n",
    "                \n",
    "                kickout_link = [] \n",
    "                for keyword in exclude_list:\n",
    "                        current_link = driver.find_elements_by_partial_link_text(keyword)\n",
    "                        kickout_link = list(set().union(kickout_link,current_link))\n",
    "                        \n",
    "                for kickout in kickout_link:\n",
    "                    filter_link.remove(kickout)\n",
    "            \n",
    "                for link in filter_link:\n",
    "                    \n",
    "                    # This is to check whether the link is crawled. Note that this is for same_page_click type\n",
    "                    if link in crawled_link:\n",
    "                        continue\n",
    "                    # Crawl url,html content, title and update to database\n",
    "                \n",
    "                    new_input = {}\n",
    "                    new_input['title'] = [link.text[:50]]\n",
    "                    new_input['company'] = [analyst_company]\n",
    "                    new_input['type'] = [news_type]\n",
    "                    new_input['url'] = [link.get_attribute(\"href\")]\n",
    "                    \n",
    "                    temp = link.get_attribute(\"href\")\n",
    "                    driver.switch_to.window(driver.window_handles[1])\n",
    "                    driver.get(temp)              \n",
    "                    time.sleep(5)\n",
    "                    \n",
    "                    new_input['html'] = [str(BeautifulSoup(driver.page_source, \"html.parser\"))]\n",
    "                    driver.switch_to.window(driver.window_handles[0])\n",
    "                \n",
    "                \n",
    "                    df_input = pd.DataFrame(new_input)\n",
    "                    df_input.to_sql(name='html', con=self.conn_html, if_exists='append',index=False)\n",
    "                    crawled_data+=1\n",
    "                \n",
    "                \n",
    "                print('Link crawled : ',crawled_data)\n",
    "                record_page +=1\n",
    "                #Check condition whehter to go to next page\n",
    "            \n",
    "            \n",
    "                if keyword_next_page and crawl_type == 'auto_link_crawl':\n",
    "                    \n",
    "                    next_page_link = driver.find_elements_by_partial_link_text(keyword_next_page)\n",
    "                \n",
    "                    # Check whether there is next page to go\n",
    "                    if next_page_link:\n",
    "                        page_link_check = next_page_link[0].get_attribute(\"href\")\n",
    "                        \n",
    "                        if ('void' in page_link_check) or (page_link_check == None):\n",
    "                            break\n",
    "                        elif page_link_check == current_website_link:\n",
    "                            break\n",
    "                        else:\n",
    "                            driver.get(page_link_check)\n",
    "                            current_website_link = page_link_check\n",
    "                    else:\n",
    "                        break\n",
    "                elif keyword_next_page and crawl_type == 'manual_num_crawl':\n",
    "                    current_page +=1\n",
    "                    temp_next = driver.find_element_by_xpath(keyword_next_page)\n",
    "                    next_page_link = temp_next.find_elements_by_partial_link_text(str(current_page))\n",
    "                    # Check whether there is next page to go\n",
    "                    if next_page_link:\n",
    "                        page_link_check = next_page_link[0].click()\n",
    "                    else:\n",
    "                        break\n",
    "                elif keyword_next_page and (crawl_type == 'auto_click_crawl' or crawl_type == 'same_page_click'):\n",
    "                    next_page_link = driver.find_elements_by_partial_link_text(keyword_next_page)\n",
    "                    if crawl_type == 'same_page_click':\n",
    "                        crawled_link += filter_link\n",
    "                    # Check whether there is next page to go\n",
    "                    if next_page_link:\n",
    "                        current_website_link = driver.current_url\n",
    "                        page_link_check = next_page_link[0].click()\n",
    "                        time.sleep(5)\n",
    "                    else:\n",
    "                        break\n",
    "                else:\n",
    "                    break\n",
    "        except Exception as e: \n",
    "            if 'Duplicate entry' in str(e):\n",
    "                print('Completed')\n",
    "                print('Link crawled : ',crawled_data)\n",
    "            \n",
    "            else:   \n",
    "                print('Program Died at Page '+str(record_page))\n",
    "                print('reason is : ')\n",
    "                print(e)\n",
    "                \n",
    "            driver.quit()\n",
    "            return \n",
    "        \n",
    "        driver.quit()\n",
    "        print(\"Completed\")\n",
    "        print('Link crawled : ',crawled_data)\n",
    "    \n",
    "    def crawl(self,wait_time,website_link,webdriver_link):\n",
    "        \n",
    "        \n",
    "        pre_click = False\n",
    "        keyword_filter = ['铜','铅','锌','镍','铝','锡','有色'] \n",
    "        exclude_list=[]\n",
    "        \n",
    "        if website_link == 'http://www.dlqh.com/page-1-4.php':\n",
    "            analyst_company = '大陆'\n",
    "            news_type = 'Weekly'\n",
    "            keyword_report = '周报'\n",
    "            keyword_next_page = None \n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            crawl_type = 'auto_link_crawl'\n",
    "        \n",
    "        elif website_link == 'http://www.cnhtqh.com.cn/list/664/1.shtml?id=jsqh':\n",
    "            analyst_company = '恒泰'\n",
    "            news_type = 'Weekly'\n",
    "            keyword_report = 'All'\n",
    "            keyword_next_page = '下一页' \n",
    "            xpath = \"//div[@class='kf_jynews']\"\n",
    "            tag_element = 'a'\n",
    "            crawl_type = 'auto_link_crawl'\n",
    "        \n",
    "        elif website_link == 'http://www.bocifco.com/Category_86/Index.aspx':\n",
    "            analyst_company = '中银'\n",
    "            news_type = 'Weekly'\n",
    "            keyword_report = '周报'\n",
    "            keyword_next_page = '下一页' \n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            crawl_type = 'auto_link_crawl'\n",
    "        elif website_link == 'http://www.xzfutures.com/deeconomic.html':\n",
    "            analyst_company = '兴证'\n",
    "            news_type = 'Weekly'\n",
    "            keyword_report = '精要'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = '下一页' \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "            keyword_filter = 'All'\n",
    "        elif website_link == 'http://www.xzfutures.com/deeconomic_cid_119.html':\n",
    "            analyst_company = '兴证'\n",
    "            news_type = 'Weekly'\n",
    "            keyword_report = '周报'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = '下一页' \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "        \n",
    "        elif website_link == 'https://www.mfc.com.cn/research.html':\n",
    "            pre_click = True\n",
    "            locate_action = \"//div[@class='screen']\"\n",
    "            click_action=[\"//a[contains(text(), '常规')]\",\"//a[contains(text(), '金属')]\"]\n",
    "            \n",
    "            analyst_company = '美尔雅'\n",
    "            news_type = 'Weekly'\n",
    "            keyword_report = '周报'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = '加载更多' \n",
    "            crawl_type = 'same_page_click'\n",
    "        elif website_link == 'http://www.gzjkqh.com/czjy/list_36.aspx':\n",
    "            analyst_company = '广金'\n",
    "            news_type = 'Daily'           \n",
    "            keyword_report = '种操作建议'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = '>' \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "            keyword_filter = 'All'\n",
    "        \n",
    "        elif website_link == 'http://www.shqhgs.com/lists/Dailystudy/p/1.html':\n",
    "            analyst_company = '神华'\n",
    "            news_type = 'Daily'\n",
    "            keyword_report = '行情资信'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = '下一页' \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "            keyword_filter = 'All'\n",
    "        elif website_link == 'http://www.zcqh.com/zcyj_z.php?name=%E6%AF%8F%E6%97%A5%E6%97%A9%E6%8A%A5&page=1':\n",
    "            analyst_company = '中财'\n",
    "            news_type = 'Daily'\n",
    "            keyword_report = '晨会焦点'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = '下一页' \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "            keyword_filter = 'All'\n",
    "            \n",
    "        elif website_link == 'http://www.tqfutures.com/zpts/list_14.html':\n",
    "            analyst_company = '中投'\n",
    "            news_type = 'Morning'\n",
    "            keyword_report = '早盘分析'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = '下一页' \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "            keyword_filter = 'All'\n",
    "            \n",
    "        elif website_link == 'http://www.shcifco.com/html/yanjiuzhongxin/shishikuaixun/weipantishi/':\n",
    "            analyst_company = '上海中期'\n",
    "            news_type = 'After Market'\n",
    "            keyword_report = '尾盘研发观点'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = '下一页' \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "            keyword_filter = 'All'\n",
    "            \n",
    "        elif website_link == 'https://www.dyqh.info/research/researchreport/8/2?tag=1':\n",
    "            analyst_company = '大越'\n",
    "            news_type = 'Daily'\n",
    "            keyword_report = '每日评论'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = '下一页' \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "        elif website_link == 'http://www.xzfutures.com/deeconomic_cid_107.html':\n",
    "            analyst_company = '兴证'\n",
    "            news_type = 'After Market'\n",
    "            keyword_report = '研发盘末提示'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = '下一页' \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "            keyword_filter = 'All'    \n",
    "        \n",
    "        elif website_link == 'https://www.rdqh.com/content/index/115?page=1':\n",
    "            analyst_company = '瑞达'\n",
    "            news_type = 'Daily'\n",
    "            keyword_report = '瑞达期货'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = '下一页' \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "            \n",
    "        elif website_link == 'http://www.jtqh.cn/yfzx_1.asp?fl=1&lm=2&pz=%CD%AD':\n",
    "            analyst_company = '锦泰'\n",
    "            news_type = 'Morning'\n",
    "            keyword_report = '铜市早评'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = '下一页' \n",
    "            crawl_type = 'auto_click_crawl'\n",
    "            keyword_filter = 'All'\n",
    "            \n",
    "        elif website_link == 'http://www.sdfutures.com.cn/a/sdyanjiu/jinshu/ribao/list_151_1.html':\n",
    "            analyst_company = '盛达'\n",
    "            news_type = 'Daily'\n",
    "            keyword_report = '盛达期货'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = '下一页' \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "            keyword_filter = 'All'\n",
    "        elif website_link == 'http://www.guosenqh.com.cn/main/yjzx/zp/zp_metal/index.shtml':\n",
    "            analyst_company = '国信'\n",
    "            news_type = 'Morning'\n",
    "            keyword_report = '早评'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = '下一页' \n",
    "            crawl_type = 'auto_click_crawl'\n",
    "        elif website_link == 'http://www.gtaxqh.com/html/RESEARCH_SERVICES/pzbg/ysjgjs/':\n",
    "            analyst_company = '国投'\n",
    "            news_type = 'Morning'\n",
    "            keyword_report = '晨报'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = '下一页' \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "        \n",
    "        elif website_link == 'http://www.cnhtqh.com.cn/list/654/1.shtml?id=cjzbc':\n",
    "            analyst_company = '恒泰'\n",
    "            news_type = 'Morning'\n",
    "            keyword_report = '早盘精要'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = '下一页' \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "            keyword_filter = 'All'\n",
    "        elif website_link == 'http://www.shcifco.com/html/yanjiuzhongxin/shishikuaixun/qishizaobanche/':\n",
    "            analyst_company = '上海中期'\n",
    "            news_type = 'Morning'\n",
    "            keyword_report = '早盘研发'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = '下一页' \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "            keyword_filter = 'All'\n",
    "        \n",
    "        elif website_link == 'https://www.dyqh.info/research/researchreport/6/0?tag=1':\n",
    "            analyst_company = '大越'\n",
    "            news_type = 'Daily'\n",
    "            keyword_report = '交易内参'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = '下一页' \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "            keyword_filter = 'All'\n",
    "        \n",
    "        elif website_link == 'http://www.xzfutures.com/deeconomic_page_1.html?cid=114':\n",
    "            analyst_company = '兴证'\n",
    "            news_type = 'Daily'\n",
    "            keyword_report = '日报'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = '下一页' \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "        \n",
    "        elif website_link == 'http://www.gzf2010.com.cn/ResearchCenter.aspx?c=220102&page=1':\n",
    "            analyst_company = '广州期货'\n",
    "            news_type = 'Daily'\n",
    "            keyword_report = 'All'\n",
    "            xpath = \"//div[@class='r right right_all']//ul\"\n",
    "            tag_element = 'a'\n",
    "            keyword_next_page = '下一页' \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "        elif website_link == 'http://www.jxgsqh.com/News_list.aspx?Sort_Id=634&Mid=629':\n",
    "            analyst_company = '国盛'\n",
    "            news_type = 'Daily'\n",
    "            keyword_report = 'All'\n",
    "            xpath = \"//div[@class='ny_ri_n']//ul\"\n",
    "            tag_element = 'a'\n",
    "            keyword_next_page = '下一页' \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "        elif website_link == 'http://www.hongyuanqh.com/hyqhnew/hyyj/more_index.jsp?1=1&oneMenuId=000200010015&twoMenuId=0002000100150001&threeMenuid=00020001001500010002&classId=000200010015000100020004&productid=100':\n",
    "            analyst_company = '宏源'\n",
    "            news_type = 'Morning'\n",
    "            keyword_report = '有色早评'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = '下一页' \n",
    "            crawl_type = 'auto_click_crawl'\n",
    "        elif website_link == 'http://www.hhqh.com.cn/?pcyear=10-24-13':\n",
    "            analyst_company = '和合'\n",
    "            news_type = 'Morning'\n",
    "            keyword_report = '和合期货'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = '下一页' \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "            keyword_filter = ['铜','铅','锌','镍','铝','锡','有色','早盘提示']\n",
    "        \n",
    "        elif website_link == 'http://www.bhfcc.com/research_page_1.html?pid=88':\n",
    "            analyst_company = '渤海'\n",
    "            news_type = 'Morning'\n",
    "            keyword_report = '早盘提示'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = '下一页' \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "        elif website_link == 'https://www.thanf.com/list-83.html':\n",
    "            analyst_company = '天风'\n",
    "            news_type = 'Daily'\n",
    "            keyword_report = 'All'\n",
    "            xpath = \"//div[@class='service-index ']\"\n",
    "            tag_element = 'a'\n",
    "            keyword_next_page = '»' \n",
    "            crawl_type = 'auto_click_crawl'\n",
    "        \n",
    "        elif website_link == 'http://www.bocifco.com/Category_28/Index.aspx':\n",
    "            analyst_company = '中银'\n",
    "            news_type = 'Daily'\n",
    "            keyword_report = '日报'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = '下一页' \n",
    "            crawl_type = 'auto_click_crawl'\n",
    "        \n",
    "        elif website_link == 'http://www.ftol.com.cn/main/yfzx/rcbg/rcbg/zaoping/index.shtml':\n",
    "            analyst_company = 'Holly'\n",
    "            news_type = 'Morning'\n",
    "            keyword_report = '金属早评'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = \"//div[@class='page_footer']\" \n",
    "            crawl_type = 'manual_num_crawl'\n",
    "            keyword_filter = 'All'\n",
    "            exclude_list = ['黑色金属早评']\n",
    "        elif website_link == 'https://www.cnzsqh.com/cms/column/index?id=116':\n",
    "            analyst_company = '浙商'\n",
    "            news_type = 'Morning'\n",
    "            keyword_report = '留单建议'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = \"»\" \n",
    "            crawl_type = 'auto_click_crawl'\n",
    "            keyword_filter = 'All'\n",
    "        \n",
    "        elif website_link == 'http://www.fnqh.com.cn/content/index/85':\n",
    "            analyst_company = '福能'\n",
    "            news_type = 'Morning'\n",
    "            keyword_report = '早报'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = \"»\" \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "        \n",
    "        elif website_link == 'http://www.xzfutures.com/deeconomic_cid_106.html':\n",
    "            analyst_company = '兴证'\n",
    "            news_type = 'Morning'\n",
    "            keyword_report = '中心早评'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = \"下一页\" \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "            keyword_filter = 'All'\n",
    "        \n",
    "        elif website_link == 'http://www.gzf2010.com.cn/ResearchCenter.aspx?c=220101':\n",
    "            analyst_company = '广州期货'\n",
    "            news_type = 'Morning'\n",
    "            keyword_report = 'All'\n",
    "            xpath = \"//div[@class='r right right_all']//ul\"\n",
    "            tag_element = \"a\"\n",
    "            keyword_next_page = \"下一页\" \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "            keyword_filter = 'All'\n",
    "            \n",
    "        elif website_link == 'http://www.hlqh.com/article_cat.php?id=96&t_id=96':\n",
    "            analyst_company = '华联'\n",
    "            news_type = 'Morning'\n",
    "            keyword_report = '研究所日评'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = \"下一页\" \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "            keyword_filter = 'All'\n",
    "        \n",
    "        elif website_link == 'https://www.btqh.com/index.php?m=content&c=index&a=lists&catid=56':\n",
    "            analyst_company = '倍特'\n",
    "            news_type = 'Daily'\n",
    "            keyword_report = 'All'\n",
    "            xpath = \"//ul[@class='fxd-text']\"\n",
    "            tag_element = 'a'\n",
    "            keyword_next_page = \">\" \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "            \n",
    "        elif website_link == 'http://www.szjhqh.com/index.php?s=news&c=category&id=10':\n",
    "            analyst_company = '金汇'\n",
    "            news_type = 'Daily'\n",
    "            keyword_report = '有色板块'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = \"下一页\" \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "            keyword_filter = 'All'\n",
    "        \n",
    "        elif website_link == 'https://www.htfc.com/main/yjzx/yjbg/index.shtml':\n",
    "            analyst_company = '华泰'\n",
    "            news_type = 'Daily'\n",
    "            keyword_report = '日报'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = \"下一页\" \n",
    "            crawl_type = 'auto_click_crawl'\n",
    "            pre_click = True\n",
    "            locate_action = \"//div[@class='market_box']\"\n",
    "            click_action=[\"//a[contains(text(), '日报')]\",\"//a[contains(text(), '金属')]\"]\n",
    "        \n",
    "        elif website_link == 'http://www.guosenqh.com.cn/main/yjzx/rp/rp_metal/index.shtml':\n",
    "            analyst_company = '国信'\n",
    "            news_type = 'Daily'\n",
    "            keyword_report = '日评'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = \"下一页\" \n",
    "            crawl_type = 'auto_click_crawl'\n",
    "\n",
    "        elif website_link == 'http://www.shcifco.com/html/yanjiuzhongxin/shishikuaixun/panzhongshidian/':\n",
    "            analyst_company = '上海中期'\n",
    "            news_type = 'After Market'\n",
    "            keyword_report = '午间评述'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = \"下一页\" \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "            keyword_filter = 'All'\n",
    "        \n",
    "        elif website_link == 'http://www.gtaxqh.com/html/RESEARCH_SERVICES/zhlcb/mrsp/':\n",
    "            analyst_company = '国投安信'\n",
    "            news_type = 'After Market'\n",
    "            keyword_report = '货每日收评'\n",
    "            xpath = None\n",
    "            tag_element = None\n",
    "            keyword_next_page = \"下一页\" \n",
    "            crawl_type = 'auto_link_crawl'\n",
    "            keyword_filter = 'All'\n",
    "        else:\n",
    "            print('Website not in the class, please add under crawl function')\n",
    "            return\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Load the Chrome Driver\n",
    "        driver = webdriver.Chrome(webdriver_link)\n",
    "        print('init driver')\n",
    "\n",
    "        # Open the website firstpage\n",
    "        driver.get(website_link)\n",
    "        print('Load Page')\n",
    "        time.sleep(wait_time)\n",
    "        \n",
    "        #Pre Click\n",
    "        if pre_click:\n",
    "            temp= driver.find_element_by_xpath(locate_action)\n",
    "            for action in click_action: \n",
    "                temp.find_element_by_xpath(action).click()\n",
    "                time.sleep(5)\n",
    "                \n",
    "        self.raw_crawl_func(driver,crawl_type,analyst_company, news_type,website_link,\n",
    "                            keyword_report,xpath = xpath,tag_element = tag_element,\n",
    "                            keyword_next_page =keyword_next_page,keyword_filter=keyword_filter,exclude_list=exclude_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "website_link_lst =[]\n",
    "website_link_lst.append('http://www.dlqh.com/page-1-4.php')\n",
    "website_link_lst.append('http://www.cnhtqh.com.cn/list/664/1.shtml?id=jsqh')\n",
    "website_link_lst.append('http://www.bocifco.com/Category_86/Index.aspx')\n",
    "website_link_lst.append('http://www.xzfutures.com/deeconomic.html')\n",
    "website_link_lst.append('http://www.xzfutures.com/deeconomic_cid_119.html')\n",
    "website_link_lst.append('https://www.mfc.com.cn/research.html')\n",
    "website_link_lst.append('http://www.gzjkqh.com/czjy/list_36.aspx')\n",
    "website_link_lst.append('http://www.shqhgs.com/lists/Dailystudy/p/1.html')\n",
    "website_link_lst.append('http://www.zcqh.com/zcyj_z.php?name=%E6%AF%8F%E6%97%A5%E6%97%A9%E6%8A%A5&page=1')\n",
    "website_link_lst.append('http://www.tqfutures.com/zpts/list_14.html')\n",
    "website_link_lst.append('http://www.shcifco.com/html/yanjiuzhongxin/shishikuaixun/weipantishi/')\n",
    "website_link_lst.append('https://www.dyqh.info/research/researchreport/8/2?tag=1')\n",
    "website_link_lst.append('http://www.xzfutures.com/deeconomic_cid_107.html')\n",
    "website_link_lst.append('https://www.rdqh.com/content/index/115?page=1')\n",
    "website_link_lst.append('http://www.jtqh.cn/yfzx_1.asp?fl=1&lm=2&pz=%CD%AD')\n",
    "website_link_lst.append('http://www.sdfutures.com.cn/a/sdyanjiu/jinshu/ribao/list_151_1.html')\n",
    "website_link_lst.append('http://www.guosenqh.com.cn/main/yjzx/zp/zp_metal/index.shtml')\n",
    "website_link_lst.append('http://www.gtaxqh.com/html/RESEARCH_SERVICES/pzbg/ysjgjs/')\n",
    "website_link_lst.append('http://www.cnhtqh.com.cn/list/654/1.shtml?id=cjzbc')\n",
    "website_link_lst.append('http://www.shcifco.com/html/yanjiuzhongxin/shishikuaixun/qishizaobanche/')\n",
    "website_link_lst.append('https://www.dyqh.info/research/researchreport/6/0?tag=1')\n",
    "website_link_lst.append('http://www.xzfutures.com/deeconomic_page_1.html?cid=114')\n",
    "website_link_lst.append('http://www.gzf2010.com.cn/ResearchCenter.aspx?c=220102&page=1')\n",
    "website_link_lst.append('http://www.jxgsqh.com/News_list.aspx?Sort_Id=634&Mid=629')\n",
    "website_link_lst.append('http://www.hongyuanqh.com/hyqhnew/hyyj/more_index.jsp?1=1&oneMenuId=000200010015&twoMenuId=0002000100150001&threeMenuid=00020001001500010002&classId=000200010015000100020004&productid=100')\n",
    "website_link_lst.append('http://www.hhqh.com.cn/?pcyear=10-24-13')\n",
    "website_link_lst.append('http://www.bhfcc.com/research_page_1.html?pid=88')\n",
    "website_link_lst.append('https://www.thanf.com/list-83.html')\n",
    "website_link_lst.append('http://www.bocifco.com/Category_28/Index.aspx')\n",
    "website_link_lst.append('http://www.ftol.com.cn/main/yfzx/rcbg/rcbg/zaoping/index.shtml')\n",
    "website_link_lst.append('https://www.cnzsqh.com/cms/column/index?id=116')\n",
    "website_link_lst.append('http://www.fnqh.com.cn/content/index/85')\n",
    "website_link_lst.append('http://www.xzfutures.com/deeconomic_cid_106.html')\n",
    "website_link_lst.append('http://www.gzf2010.com.cn/ResearchCenter.aspx?c=220101')\n",
    "website_link_lst.append('http://www.hlqh.com/article_cat.php?id=96&t_id=96')\n",
    "website_link_lst.append('https://www.btqh.com/index.php?m=content&c=index&a=lists&catid=56')\n",
    "website_link_lst.append('http://www.szjhqh.com/index.php?s=news&c=category&id=10')\n",
    "website_link_lst.append('https://www.htfc.com/main/yjzx/yjbg/index.shtml')\n",
    "website_link_lst.append('http://www.guosenqh.com.cn/main/yjzx/rp/rp_metal/index.shtml')\n",
    "website_link_lst.append('http://www.gtaxqh.com/html/RESEARCH_SERVICES/zhlcb/mrsp/')\n",
    "website_link_lst.append('http://www.shcifco.com/html/yanjiuzhongxin/shishikuaixun/panzhongshidian/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sq.create_engine(\"mysql+pymysql://root:next++4e@localhost/Alternative_DB?host=localhost?port=3306\")\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler = Crawler_machine(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.gtaxqh.com/html/RESEARCH_SERVICES/zhlcb/mrsp/'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webdriver_link = '/home/liangchen/4e/Alternative Data/chromedriver'\n",
    "wait_time = 2.5\n",
    "website_link = website_link_lst[-2]\n",
    "website_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init driver\n",
      "Load Page\n",
      "Start Crawling Report from 国投安信\n",
      "Completed\n",
      "Link crawled :  0\n"
     ]
    }
   ],
   "source": [
    "crawler.crawl(wait_time,website_link,webdriver_link)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
