{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      " \"Already loaded SinglePackageAl version * 19.04.6 * \"\n",
      "\n",
      "\n",
      "[1]\n",
      " \"Detaching it\"\n",
      "\n",
      "\n",
      "[1]\n",
      " \"Also unloading with devtools:\"\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "[1]\n",
      " \"SinglePackageAl loaded. Attaching version 19.04.6\"\n",
      "\n",
      "\n",
      "[1]\n",
      " \"Loaded AlphienData\"\n",
      "\n",
      "\n",
      "[1]\n",
      " \"Loaded AlphienTechnicalAnalysis\"\n",
      "\n",
      "\n",
      "[1]\n",
      " \"Loaded AlphienFundamental\"\n",
      "\n",
      "\n",
      "[1]\n",
      " \"Loaded AlphienBaseMetals\"\n",
      "\n",
      "\n",
      "[1]\n",
      " \"Loaded AlphienOption\"\n",
      "\n",
      "\n",
      "send2Log: Your working directory is: /home/chanmingwei\n",
      " \n",
      "\n",
      "\n",
      "/home/chanmingwei/NEXT/4EBaseMetal/code/utils\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import json\n",
    "from copy import copy\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import rpy2.robjects as robjects\n",
    "import pandas as pd\n",
    "robjects.r('.sourceAlfunction()')\n",
    "print(sys.path[0])\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(sys.path[0], 'NEXT/4EBaseMetal/code/utils')))\n",
    "read_data = importlib.import_module(\"read_data\")\n",
    "construct_data = importlib.import_module(\"construct_data\")\n",
    "transform_data = importlib.import_module(\"transform_data\")\n",
    "normalize_feature = importlib.import_module(\"normalize_feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h5_function(date_range,ground_truth):\n",
    "    h = 5\n",
    "    time_series = None\n",
    "    rgetSecurity = robjects.r('getSecurity')\n",
    "    rindex = robjects.r('index')\n",
    "    rgetGenOHLCV = robjects.r('getGenOHLCV')\n",
    "    gt_data = rgetSecurity(securityName=ground_truth,zoom=date_range)\n",
    "    gt_index = rindex(gt_data)\n",
    "    extra_data = None\n",
    "    extra_index = None\n",
    "    if ground_truth == \"LMAHDY Comdty\":\n",
    "        lag = 20\n",
    "        norm_ex = \"v1\"\n",
    "        norm_volume = \"v1\"\n",
    "        norm_3m_spread = \"v1\"\n",
    "        extra_data = robjects.r('getGenOHLCV(\"PA\",zoom = \\\"'+date_range+'\\\")[,3]')\n",
    "        extra_index = rindex(extra_data)\n",
    "    elif ground_truth == \"LMPBDY Comdty\":\n",
    "        lag = 10\n",
    "        norm_ex = \"v1\"\n",
    "        norm_volume = \"v1\"\n",
    "        norm_3m_spread = \"v1\"\n",
    "        extra_data = robjects.r('getGenOHLCV(\"PL\",zoom = \\\"'+date_range+'\\\")[,6]')\n",
    "        extra_index = rindex(extra_data)\n",
    "    elif ground_truth == \"LMNIDY Comdty\":\n",
    "        lag = 5\n",
    "        norm_ex = \"v1\"\n",
    "        norm_volume = \"v1\"\n",
    "        norm_3m_spread = \"v1\"\n",
    "        extra_data = robjects.r('getGenOHLCV(\"PA\",zoom = \\\"'+date_range+'\\\")[,1]')\n",
    "        extra_index = rindex(extra_data)\n",
    "    elif ground_truth == \"LMZSDY Comdty\":\n",
    "        lag = 40\n",
    "        norm_ex = \"v1\"\n",
    "        norm_volume = \"v1\"\n",
    "        norm_3m_spread = \"v1\"\n",
    "        extra_data = rgetSecurity(securityName= \"LMCADY Comdty\", zoom = date_range)\n",
    "        extra_index = rindex(extra_data)\n",
    "    elif ground_truth == \"LMSNDY Comdty\":\n",
    "        lag = 5\n",
    "        norm_ex = \"v1\"\n",
    "        norm_volume = \"v1\"\n",
    "        norm_3m_spread = \"v1\"\n",
    "        extra_data = robjects.r('getGenOHLCV(\"PBLcl\",zoom = \\\"'+date_range+'\\\")[,3]')\n",
    "        extra_index = rindex(extra_data)\n",
    "    elif ground_truth == \"LMCADY Comdty\":\n",
    "        lag = 40\n",
    "        norm_ex = \"v1\"\n",
    "        norm_volume = \"v1\"\n",
    "        norm_3m_spread = \"v1\"\n",
    "        extra_data = robjects.r('getGenOHLCV(\"PA\",zoom = \\\"'+date_range+'\\\")[,5]')\n",
    "        extra_index = rindex(extra_data)\n",
    "    else:\n",
    "        print(\"ground truth val out of bounds!\")\n",
    "        return None\n",
    "    gt_data_list = []\n",
    "    gt_index_list = []\n",
    "    extra_data_list = []\n",
    "    extra_index_list = []\n",
    "    for i in range(len(gt_index)):\n",
    "        gt_index_list.append(gt_index[i])\n",
    "    for i in range(len(gt_data)):\n",
    "        gt_data_list.append(gt_data[i])\n",
    "    for i in range(len(extra_index)):\n",
    "        extra_index_list.append(extra_index[i])\n",
    "    for i in range(len(extra_data)):\n",
    "        extra_data_list.append(extra_data[i])\n",
    "    start_date= min(gt_index_list[0],extra_index_list[0])\n",
    "    end_date =max(gt_index_list[-1],extra_index_list[-1])\n",
    "    if ground_truth == \"LMAHDY Comdty\":\n",
    "        gt_dict={'time':gt_index_list,'LME_Al_Spot':gt_data_list}\n",
    "        extra_dict = {'time':extra_index_list+86400*np.ones(len(extra_index_list)), 'COMEX_PA_lag1_Low':extra_data_list}\n",
    "    elif ground_truth == \"LMPBDY Comdty\":\n",
    "        gt_dict={'time':gt_index_list,'LME_Le_Spot':gt_data_list}\n",
    "        extra_dict = {'time':extra_index_list+86400*np.ones(len(extra_index_list)), 'COMEX_PL_lag1_OI':extra_data_list}\n",
    "    elif ground_truth == \"LMNIDY Comdty\":\n",
    "        gt_dict={'time':gt_index_list,'LME_Ni_Spot':gt_data_list}\n",
    "        extra_dict = {'time':extra_index_list+86400*np.ones(len(extra_index_list)), 'COMEX_PA_lag1_Open':extra_data_list}\n",
    "    elif ground_truth == \"LMZSDY Comdty\":\n",
    "        gt_dict={'time':gt_index_list,'LME_Zi_Spot':gt_data_list}\n",
    "        extra_dict = {'time':extra_index_list, 'LME_Co_Spot':extra_data_list}\n",
    "    elif ground_truth == \"LMSNDY Comdty\":\n",
    "        gt_dict={'time':gt_index_list,'LME_Ti_Spot':gt_data_list}\n",
    "        extra_dict = {'time':extra_index_list, 'SHFE_Le_Low':extra_data_list}\n",
    "    elif ground_truth == \"LMCADY Comdty\":\n",
    "        gt_dict={'time':gt_index_list,'LME_Co_Spot':gt_data_list}\n",
    "        extra_dict = {'time':extra_index_list+86400*np.ones(len(extra_index_list)), 'COMEX_PA_lag1_Volume':extra_data_list}\n",
    "    else:\n",
    "        print(\"ground truth val out of bounds!\")\n",
    "        return None\n",
    "    gt_dataframe = pd.DataFrame(gt_dict)\n",
    "    extra_dataframe = pd.DataFrame(extra_dict)\n",
    "#     print(isinstance(extra_dataframe, pd.DataFrame))\n",
    "    time_series = pd.DataFrame.merge(gt_dataframe,extra_dataframe,how ='outer', on = 'time')\n",
    "    time_series.set_index('time')\n",
    "#     print(time_series['time'])\n",
    "    time_series = time_series.drop('time',axis = 1)\n",
    "    \n",
    "\n",
    "#     print(time_series)\n",
    "    \n",
    "    #Processing data\n",
    "    time_series = read_data.process_missing_value_v3(time_series,np.min([lag,10]))\n",
    "    org_cols = time_series.columns.values.tolist()\n",
    "    print(\"Normalizing\")\n",
    "\n",
    "    #Normalize and generate technical indications\n",
    "    norm_params = construct_data.normalize(time_series,vol_norm = norm_volume, spot_spread_norm=norm_3m_spread,ex_spread_norm = norm_ex)\n",
    "    time_series = copy(norm_params[\"val\"])\n",
    "    del norm_params[\"val\"]\n",
    "    time_series = construct_data.technical_indication(time_series)\n",
    "    cols = time_series.columns.values.tolist()\n",
    "    for col in cols:\n",
    "        if \"_Volume\" in col or \"_OI\" in col or \"CNYUSD\" in col:\n",
    "            time_series = time_series.drop(col,axis = 1)\n",
    "            org_cols.remove(col)\n",
    "    print(time_series.columns.values.tolist())\n",
    "    curr = \"\"\n",
    "    if ground_truth == \"LMAHDY Comdty\":\n",
    "        curr = \"Al\"\n",
    "    elif ground_truth == \"LMPBDY Comdty\":\n",
    "        curr = \"Le\"\n",
    "    elif ground_truth == \"LMNIDY Comdty\":\n",
    "        curr = \"Ni\"\n",
    "    elif ground_truth == \"LMZSDY Comdty\":\n",
    "        curr = \"Zi\"\n",
    "    elif ground_truth == \"LMSNDY Comdty\":\n",
    "        curr = \"Ti\"\n",
    "    elif ground_truth == \"LMCADY Comdty\":\n",
    "        curr = \"Co\"\n",
    "    else:\n",
    "        print(\"ground truth val out of bounds!\")\n",
    "        return None\n",
    "#     print(time.series.columns.values)\n",
    "    norm_data = copy(normalize_feature.log_1d_return(time_series,org_cols))\n",
    "    norm_data = read_data.process_missing_value_v3(norm_data,10)\n",
    "    to_be_predicted = norm_data[\"LME_\"+curr+\"_Spot\"]\n",
    "    if h > 1:\n",
    "        for i in range(h-1):\n",
    "            to_be_predicted = to_be_predicted + norm_data[\"LME_\"+curr+\"_Spot\"].shift(-i-1)\n",
    "    gt = (to_be_predicted > 0).shift(-1)\n",
    "\n",
    "    start_index = 0\n",
    "    if start_index < lag - 1:\n",
    "        start_index = lag - 1\n",
    "    end_index = len(norm_data)-1\n",
    "    assert end_index >= lag - 1\n",
    "\n",
    "    X_te, y_te = construct_data.construct(norm_data, gt, start_index, end_index, lag, \"log_1d_return\")\n",
    "    X_te = transform_data.flatten(X_te)\n",
    "    y_te = y_te*2 - 1\n",
    "\n",
    "    #load model\n",
    "    model = joblib.load(\"NEXT/LME_\"+curr+\"_Spot_h\"+str(h)+\"_n1.joblib\")\n",
    "\n",
    "    prediction = model.predict(X_te).reshape(X_te.shape[0],1)\n",
    "\n",
    "\n",
    "    total_no = prediction.shape[0]\n",
    "    no_true = sum(np.equal(prediction,y_te))\n",
    "    no_TT = sum(np.multiply(prediction+1,y_te+1))/4\n",
    "    no_FF = sum(np.multiply(prediction - 1,y_te - 1))/4\n",
    "    no_TF = -sum(np.multiply(prediction + 1,y_te - 1))/4\n",
    "    no_FT = -sum(np.multiply(prediction - 1,y_te + 1))/4\n",
    "\n",
    "    #some basic statistics, to identify whether our model is more prone to which type of error.\n",
    "    print(\"Overall Accuracy:%d\",no_true/total_no )\n",
    "    print(\"TT:%d\", no_TT)\n",
    "    print(\"TF:%d\", no_TF)\n",
    "    print(\"FT:%d\", no_FT)\n",
    "    print(\"FF:%d\", no_FF)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send2Log: Fetching generic for PA1I\n",
      " \n",
      "\n",
      "\n",
      "Normalizing\n",
      "['LME_Ni_Spot', 'COMEX_PA_lag1_Open']\n",
      "Overall Accuracy:%d [0.67]\n",
      "TT:%d [20.]\n",
      "TF:%d [13.]\n",
      "FT:%d [53.]\n",
      "FF:%d [114.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chanmingwei/.local/lib/python3.5/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "LMNIDY = h5_function(\"2015-01-06::2016-01-05\",\"LMNIDY Comdty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send2Log: Fetching generic for PA1I\n",
      " \n",
      "\n",
      "\n",
      "Normalizing\n",
      "['LME_Co_Spot']\n",
      "Overall Accuracy:%d [0.64848485]\n",
      "TT:%d [8.]\n",
      "TF:%d [7.]\n",
      "FT:%d [51.]\n",
      "FF:%d [99.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chanmingwei/.local/lib/python3.5/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "LMCADY = h5_function(\"2015-01-06::2016-01-05\",\"LMCADY Comdty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send2Log: Fetching generic for PA1I\n",
      " \n",
      "\n",
      "\n",
      "Normalizing\n",
      "['LME_Al_Spot', 'COMEX_PA_lag1_Low']\n",
      "Overall Accuracy:%d [0.56756757]\n",
      "TT:%d [40.]\n",
      "TF:%d [44.]\n",
      "FT:%d [36.]\n",
      "FF:%d [65.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chanmingwei/.local/lib/python3.5/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "LMAHDY = h5_function(\"2015-01-06::2016-01-05\",\"LMAHDY Comdty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send2Log: Fetching generic for PL1S\n",
      " \n",
      "\n",
      "\n",
      "Normalizing\n",
      "Normalizing OI:COMEX_PL_lag1_OI=>COMEX_PL_lag1_nOI\n",
      "['LME_Le_Spot', 'COMEX_PL_lag1_nOI']\n",
      "Overall Accuracy:%d [0.64021164]\n",
      "TT:%d [15.]\n",
      "TF:%d [2.]\n",
      "FT:%d [66.]\n",
      "FF:%d [106.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chanmingwei/.local/lib/python3.5/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "LMPBDY = h5_function(\"2015-01-06::2016-01-05\",\"LMPBDY Comdty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing\n",
      "['LME_Zi_Spot', 'LME_Co_Spot']\n",
      "Overall Accuracy:%d [0.5399061]\n",
      "TT:%d [42.]\n",
      "TF:%d [66.]\n",
      "FT:%d [32.]\n",
      "FF:%d [73.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chanmingwei/.local/lib/python3.5/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "LMZSDY = h5_function(\"2015-01-06::2016-01-05\",\"LMZSDY Comdty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send2Log: Fetching generic for PBL1C\n",
      " \n",
      "\n",
      "\n",
      "Normalizing\n",
      "['LME_Ti_Spot', 'SHFE_Le_Low']\n",
      "Overall Accuracy:%d [0.66666667]\n",
      "TT:%d [19.]\n",
      "TF:%d [7.]\n",
      "FT:%d [71.]\n",
      "FF:%d [137.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chanmingwei/.local/lib/python3.5/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "LMSNDY = h5_function(\"2015-01-06::2016-01-05\",\"LMSNDY Comdty\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
