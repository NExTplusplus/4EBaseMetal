
		{"drop_out": 0.6, "drop_out_mc": 0.05, "repeat_mc": 50, "hidden": 20, "embedding_size": 5, "batch": 512, "lag": 3}
{'generate_norm_params': 'v1', 'generate_tech_params': 'v3', 'generate_strat_params': None, 'generate_SD_params': 'v1', 'deal_with_abnormal_value': 'v2', 'labelling': 'v3', 'process_missing_value': 'v1', 'strategy_signal': None, 'normalize_without_1d_return': 'v1', 'technical_indication': 'v4', 'supply_and_demand': None, 'remove_unused_columns': 'v6', 'price_normalization': 'v3', 'scaling': None, 'construct': 'v4'}
LME_Co_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6798 6798 6798
1.8562728 -0.6288155 0.09756618 -0.123651974
Validation: 756 756 756
Testing: 774 774 774
pre-processing time: 0.00032806396484375
the split date is 2009-07-01
net initializing with time: 0.03630828857421875
preparing training and testing date with time: 4.76837158203125e-07
current epoch: 1
train loss is 0.483695
average val loss: 0.426696, accuracy: 0.4267
average test loss: 0.425899, accuracy: 0.4259
case acc: 0.3632601
case acc: 0.5070758
case acc: 0.4013899
case acc: 0.2634799
case acc: 0.5800089
case acc: 0.44017828
top acc: 0.3720 ::: bot acc: 0.3549
top acc: 0.5190 ::: bot acc: 0.4951
top acc: 0.4162 ::: bot acc: 0.3857
top acc: 0.2744 ::: bot acc: 0.2523
top acc: 0.5921 ::: bot acc: 0.5685
top acc: 0.4508 ::: bot acc: 0.4290
current epoch: 2
train loss is 0.179137
average val loss: 0.080893, accuracy: 0.0806
average test loss: 0.081275, accuracy: 0.0817
case acc: 0.08079625
case acc: 0.058046076
case acc: 0.038134474
case acc: 0.17378625
case acc: 0.130099
case acc: 0.009373699
top acc: 0.0717 ::: bot acc: 0.0894
top acc: 0.0698 ::: bot acc: 0.0462
top acc: 0.0233 ::: bot acc: 0.0536
top acc: 0.1632 ::: bot acc: 0.1847
top acc: 0.1421 ::: bot acc: 0.1184
top acc: 0.0083 ::: bot acc: 0.0144
current epoch: 3
train loss is 0.127991
average val loss: 0.084725, accuracy: 0.0851
average test loss: 0.084673, accuracy: 0.0848
case acc: 0.021209814
case acc: 0.108990945
case acc: 0.023052592
case acc: 0.107314914
case acc: 0.18886112
case acc: 0.059538674
top acc: 0.0121 ::: bot acc: 0.0299
top acc: 0.1207 ::: bot acc: 0.0972
top acc: 0.0374 ::: bot acc: 0.0097
top acc: 0.0971 ::: bot acc: 0.1179
top acc: 0.2008 ::: bot acc: 0.1771
top acc: 0.0704 ::: bot acc: 0.0482
current epoch: 4
train loss is 0.115230
average val loss: 0.095543, accuracy: 0.0956
average test loss: 0.095065, accuracy: 0.0950
case acc: 0.012262509
case acc: 0.13949485
case acc: 0.054198064
case acc: 0.07356819
case acc: 0.20259954
case acc: 0.08761319
top acc: 0.0206 ::: bot acc: 0.0050
top acc: 0.1513 ::: bot acc: 0.1277
top acc: 0.0700 ::: bot acc: 0.0381
top acc: 0.0636 ::: bot acc: 0.0840
top acc: 0.2146 ::: bot acc: 0.1908
top acc: 0.0986 ::: bot acc: 0.0763
current epoch: 5
train loss is 0.094734
average val loss: 0.073103, accuracy: 0.0736
average test loss: 0.072930, accuracy: 0.0733
case acc: 0.02858554
case acc: 0.09447545
case acc: 0.018507823
case acc: 0.11043751
case acc: 0.1435728
case acc: 0.04393645
top acc: 0.0195 ::: bot acc: 0.0375
top acc: 0.1063 ::: bot acc: 0.0826
top acc: 0.0320 ::: bot acc: 0.0073
top acc: 0.1006 ::: bot acc: 0.1208
top acc: 0.1557 ::: bot acc: 0.1318
top acc: 0.0550 ::: bot acc: 0.0326
current epoch: 6
train loss is 0.090805
average val loss: 0.069203, accuracy: 0.0697
average test loss: 0.068993, accuracy: 0.0692
case acc: 0.025537502
case acc: 0.09050072
case acc: 0.021991663
case acc: 0.103968054
case acc: 0.12892967
case acc: 0.044298284
top acc: 0.0164 ::: bot acc: 0.0344
top acc: 0.1024 ::: bot acc: 0.0786
top acc: 0.0366 ::: bot acc: 0.0087
top acc: 0.0941 ::: bot acc: 0.1144
top acc: 0.1410 ::: bot acc: 0.1171
top acc: 0.0554 ::: bot acc: 0.0329
current epoch: 7
train loss is 0.086883
average val loss: 0.067116, accuracy: 0.0675
average test loss: 0.066865, accuracy: 0.0669
case acc: 0.017592123
case acc: 0.09311255
case acc: 0.03044725
case acc: 0.093484774
case acc: 0.11817701
case acc: 0.048564505
top acc: 0.0087 ::: bot acc: 0.0264
top acc: 0.1050 ::: bot acc: 0.0813
top acc: 0.0461 ::: bot acc: 0.0152
top acc: 0.0836 ::: bot acc: 0.1039
top acc: 0.1302 ::: bot acc: 0.1064
top acc: 0.0597 ::: bot acc: 0.0372
current epoch: 8
train loss is 0.080046
average val loss: 0.061280, accuracy: 0.0617
average test loss: 0.061001, accuracy: 0.0611
case acc: 0.02072857
case acc: 0.08457719
case acc: 0.02911865
case acc: 0.09440319
case acc: 0.0962049
case acc: 0.04141437
top acc: 0.0116 ::: bot acc: 0.0297
top acc: 0.0965 ::: bot acc: 0.0727
top acc: 0.0448 ::: bot acc: 0.0140
top acc: 0.0846 ::: bot acc: 0.1048
top acc: 0.1082 ::: bot acc: 0.0844
top acc: 0.0525 ::: bot acc: 0.0300
current epoch: 9
train loss is 0.071560
average val loss: 0.055059, accuracy: 0.0555
average test loss: 0.054754, accuracy: 0.0549
case acc: 0.025388952
case acc: 0.07370845
case acc: 0.026273891
case acc: 0.09653907
case acc: 0.073942035
case acc: 0.03346207
top acc: 0.0162 ::: bot acc: 0.0344
top acc: 0.0857 ::: bot acc: 0.0619
top acc: 0.0418 ::: bot acc: 0.0115
top acc: 0.0868 ::: bot acc: 0.1070
top acc: 0.0860 ::: bot acc: 0.0621
top acc: 0.0447 ::: bot acc: 0.0219
current epoch: 10
train loss is 0.067591
average val loss: 0.049901, accuracy: 0.0503
average test loss: 0.049578, accuracy: 0.0497
case acc: 0.026921287
case acc: 0.065244764
case acc: 0.025790613
case acc: 0.09534391
case acc: 0.0558321
case acc: 0.029200299
top acc: 0.0178 ::: bot acc: 0.0360
top acc: 0.0772 ::: bot acc: 0.0534
top acc: 0.0414 ::: bot acc: 0.0111
top acc: 0.0857 ::: bot acc: 0.1057
top acc: 0.0679 ::: bot acc: 0.0440
top acc: 0.0404 ::: bot acc: 0.0177
current epoch: 11
train loss is 0.063514
average val loss: 0.047211, accuracy: 0.0476
average test loss: 0.046869, accuracy: 0.0469
case acc: 0.021561187
case acc: 0.064766265
case acc: 0.031418283
case acc: 0.0876184
case acc: 0.04478373
case acc: 0.031418942
top acc: 0.0124 ::: bot acc: 0.0306
top acc: 0.0768 ::: bot acc: 0.0529
top acc: 0.0474 ::: bot acc: 0.0159
top acc: 0.0780 ::: bot acc: 0.0980
top acc: 0.0568 ::: bot acc: 0.0329
top acc: 0.0426 ::: bot acc: 0.0199
current epoch: 12
train loss is 0.059850
average val loss: 0.046210, accuracy: 0.0464
average test loss: 0.045823, accuracy: 0.0457
case acc: 0.01303568
case acc: 0.069105975
case acc: 0.040819135
case acc: 0.07621268
case acc: 0.03819292
case acc: 0.037131906
top acc: 0.0050 ::: bot acc: 0.0215
top acc: 0.0811 ::: bot acc: 0.0572
top acc: 0.0571 ::: bot acc: 0.0247
top acc: 0.0666 ::: bot acc: 0.0865
top acc: 0.0503 ::: bot acc: 0.0263
top acc: 0.0483 ::: bot acc: 0.0256
current epoch: 13
train loss is 0.055354
average val loss: 0.045717, accuracy: 0.0458
average test loss: 0.045235, accuracy: 0.0450
case acc: 0.0076691792
case acc: 0.07171871
case acc: 0.049492624
case acc: 0.06474087
case acc: 0.033994336
case acc: 0.042522445
top acc: 0.0048 ::: bot acc: 0.0136
top acc: 0.0838 ::: bot acc: 0.0598
top acc: 0.0659 ::: bot acc: 0.0331
top acc: 0.0552 ::: bot acc: 0.0750
top acc: 0.0460 ::: bot acc: 0.0223
top acc: 0.0537 ::: bot acc: 0.0310
current epoch: 14
train loss is 0.053362
average val loss: 0.046847, accuracy: 0.0468
average test loss: 0.046180, accuracy: 0.0460
case acc: 0.007459905
case acc: 0.07361378
case acc: 0.059040047
case acc: 0.051059496
case acc: 0.035131764
case acc: 0.04949126
top acc: 0.0128 ::: bot acc: 0.0060
top acc: 0.0857 ::: bot acc: 0.0617
top acc: 0.0755 ::: bot acc: 0.0427
top acc: 0.0415 ::: bot acc: 0.0613
top acc: 0.0472 ::: bot acc: 0.0234
top acc: 0.0607 ::: bot acc: 0.0380
current epoch: 15
train loss is 0.051488
average val loss: 0.047356, accuracy: 0.0474
average test loss: 0.046600, accuracy: 0.0464
case acc: 0.009903169
case acc: 0.07160697
case acc: 0.065578744
case acc: 0.03890464
case acc: 0.038333446
case acc: 0.05427339
top acc: 0.0176 ::: bot acc: 0.0038
top acc: 0.0837 ::: bot acc: 0.0597
top acc: 0.0821 ::: bot acc: 0.0492
top acc: 0.0294 ::: bot acc: 0.0492
top acc: 0.0504 ::: bot acc: 0.0265
top acc: 0.0655 ::: bot acc: 0.0428
current epoch: 16
train loss is 0.049351
average val loss: 0.047529, accuracy: 0.0475
average test loss: 0.046731, accuracy: 0.0466
case acc: 0.011844119
case acc: 0.06700035
case acc: 0.070207626
case acc: 0.027186941
case acc: 0.045405347
case acc: 0.058069065
top acc: 0.0203 ::: bot acc: 0.0043
top acc: 0.0791 ::: bot acc: 0.0550
top acc: 0.0868 ::: bot acc: 0.0538
top acc: 0.0182 ::: bot acc: 0.0372
top acc: 0.0575 ::: bot acc: 0.0336
top acc: 0.0693 ::: bot acc: 0.0466
current epoch: 17
train loss is 0.044253
average val loss: 0.038740, accuracy: 0.0388
average test loss: 0.038174, accuracy: 0.0380
case acc: 0.0070858197
case acc: 0.04599661
case acc: 0.05863647
case acc: 0.030267581
case acc: 0.039463494
case acc: 0.046280794
top acc: 0.0066 ::: bot acc: 0.0118
top acc: 0.0581 ::: bot acc: 0.0340
top acc: 0.0752 ::: bot acc: 0.0422
top acc: 0.0211 ::: bot acc: 0.0404
top acc: 0.0516 ::: bot acc: 0.0276
top acc: 0.0575 ::: bot acc: 0.0348
current epoch: 18
train loss is 0.040719
average val loss: 0.031501, accuracy: 0.0317
average test loss: 0.031100, accuracy: 0.0310
case acc: 0.017931905
case acc: 0.022976935
case acc: 0.0445001
case acc: 0.03522818
case acc: 0.032504585
case acc: 0.03299976
top acc: 0.0088 ::: bot acc: 0.0270
top acc: 0.0349 ::: bot acc: 0.0113
top acc: 0.0611 ::: bot acc: 0.0282
top acc: 0.0257 ::: bot acc: 0.0456
top acc: 0.0445 ::: bot acc: 0.0208
top acc: 0.0442 ::: bot acc: 0.0215
current epoch: 19
train loss is 0.037372
average val loss: 0.025884, accuracy: 0.0262
average test loss: 0.025841, accuracy: 0.0259
case acc: 0.033925507
case acc: 0.008899788
case acc: 0.02852129
case acc: 0.04277959
case acc: 0.02249728
case acc: 0.018619798
top acc: 0.0247 ::: bot acc: 0.0431
top acc: 0.0115 ::: bot acc: 0.0125
top acc: 0.0446 ::: bot acc: 0.0133
top acc: 0.0332 ::: bot acc: 0.0531
top acc: 0.0340 ::: bot acc: 0.0116
top acc: 0.0294 ::: bot acc: 0.0080
current epoch: 20
train loss is 0.036543
average val loss: 0.025553, accuracy: 0.0260
average test loss: 0.026017, accuracy: 0.0262
case acc: 0.048218444
case acc: 0.021710144
case acc: 0.01587098
case acc: 0.05170034
case acc: 0.010291741
case acc: 0.009133472
top acc: 0.0389 ::: bot acc: 0.0574
top acc: 0.0104 ::: bot acc: 0.0333
top acc: 0.0287 ::: bot acc: 0.0071
top acc: 0.0421 ::: bot acc: 0.0621
top acc: 0.0182 ::: bot acc: 0.0066
top acc: 0.0154 ::: bot acc: 0.0075
current epoch: 21
train loss is 0.037704
average val loss: 0.028369, accuracy: 0.0291
average test loss: 0.029293, accuracy: 0.0296
case acc: 0.054900702
case acc: 0.032351673
case acc: 0.012120112
case acc: 0.05715696
case acc: 0.012012809
case acc: 0.0088678
top acc: 0.0456 ::: bot acc: 0.0641
top acc: 0.0204 ::: bot acc: 0.0443
top acc: 0.0193 ::: bot acc: 0.0138
top acc: 0.0476 ::: bot acc: 0.0676
top acc: 0.0052 ::: bot acc: 0.0213
top acc: 0.0076 ::: bot acc: 0.0152
current epoch: 22
train loss is 0.037773
average val loss: 0.029877, accuracy: 0.0306
average test loss: 0.030887, accuracy: 0.0311
case acc: 0.053882007
case acc: 0.033040114
case acc: 0.012065904
case acc: 0.058301907
case acc: 0.020404974
case acc: 0.009189839
top acc: 0.0445 ::: bot acc: 0.0631
top acc: 0.0211 ::: bot acc: 0.0450
top acc: 0.0168 ::: bot acc: 0.0164
top acc: 0.0487 ::: bot acc: 0.0687
top acc: 0.0092 ::: bot acc: 0.0319
top acc: 0.0065 ::: bot acc: 0.0163
current epoch: 23
train loss is 0.036641
average val loss: 0.029471, accuracy: 0.0302
average test loss: 0.030448, accuracy: 0.0307
case acc: 0.049991325
case acc: 0.029615078
case acc: 0.01205706
case acc: 0.057290353
case acc: 0.026488237
case acc: 0.008764091
top acc: 0.0406 ::: bot acc: 0.0593
top acc: 0.0178 ::: bot acc: 0.0415
top acc: 0.0169 ::: bot acc: 0.0162
top acc: 0.0478 ::: bot acc: 0.0676
top acc: 0.0146 ::: bot acc: 0.0383
top acc: 0.0079 ::: bot acc: 0.0148
current epoch: 24
train loss is 0.035807
average val loss: 0.028091, accuracy: 0.0288
average test loss: 0.029037, accuracy: 0.0293
case acc: 0.045304276
case acc: 0.023123242
case acc: 0.012038197
case acc: 0.055327274
case acc: 0.031278033
case acc: 0.008493673
top acc: 0.0358 ::: bot acc: 0.0546
top acc: 0.0117 ::: bot acc: 0.0348
top acc: 0.0178 ::: bot acc: 0.0154
top acc: 0.0458 ::: bot acc: 0.0657
top acc: 0.0192 ::: bot acc: 0.0432
top acc: 0.0094 ::: bot acc: 0.0133
current epoch: 25
train loss is 0.035430
average val loss: 0.024443, accuracy: 0.0252
average test loss: 0.025209, accuracy: 0.0253
case acc: 0.036546014
case acc: 0.01028075
case acc: 0.01283705
case acc: 0.050243836
case acc: 0.033657953
case acc: 0.00845915
top acc: 0.0271 ::: bot acc: 0.0459
top acc: 0.0052 ::: bot acc: 0.0188
top acc: 0.0224 ::: bot acc: 0.0109
top acc: 0.0407 ::: bot acc: 0.0606
top acc: 0.0216 ::: bot acc: 0.0456
top acc: 0.0127 ::: bot acc: 0.0100
current epoch: 26
train loss is 0.035568
average val loss: 0.023451, accuracy: 0.0236
average test loss: 0.023475, accuracy: 0.0231
case acc: 0.011958442
case acc: 0.028998138
case acc: 0.027637405
case acc: 0.028657347
case acc: 0.0210547
case acc: 0.020323815
top acc: 0.0043 ::: bot acc: 0.0204
top acc: 0.0409 ::: bot acc: 0.0171
top acc: 0.0439 ::: bot acc: 0.0124
top acc: 0.0196 ::: bot acc: 0.0387
top acc: 0.0097 ::: bot acc: 0.0327
top acc: 0.0313 ::: bot acc: 0.0094
current epoch: 27
train loss is 0.036496
average val loss: 0.048058, accuracy: 0.0480
average test loss: 0.046944, accuracy: 0.0469
case acc: 0.034602113
case acc: 0.08228344
case acc: 0.07071135
case acc: 0.017504558
case acc: 0.016358199
case acc: 0.06000747
top acc: 0.0441 ::: bot acc: 0.0252
top acc: 0.0942 ::: bot acc: 0.0703
top acc: 0.0876 ::: bot acc: 0.0542
top acc: 0.0262 ::: bot acc: 0.0088
top acc: 0.0272 ::: bot acc: 0.0069
top acc: 0.0713 ::: bot acc: 0.0485
current epoch: 28
train loss is 0.046207
average val loss: 0.100130, accuracy: 0.1001
average test loss: 0.098912, accuracy: 0.0989
case acc: 0.085026056
case acc: 0.13565361
case acc: 0.12305606
case acc: 0.07364717
case acc: 0.067295074
case acc: 0.10879647
top acc: 0.0946 ::: bot acc: 0.0756
top acc: 0.1476 ::: bot acc: 0.1237
top acc: 0.1399 ::: bot acc: 0.1066
top acc: 0.0831 ::: bot acc: 0.0633
top acc: 0.0794 ::: bot acc: 0.0553
top acc: 0.1201 ::: bot acc: 0.0973
current epoch: 29
train loss is 0.065249
average val loss: 0.059405, accuracy: 0.0594
average test loss: 0.058160, accuracy: 0.0581
case acc: 0.036598288
case acc: 0.077607505
case acc: 0.0812916
case acc: 0.043455236
case acc: 0.04286154
case acc: 0.06706272
top acc: 0.0462 ::: bot acc: 0.0271
top acc: 0.0896 ::: bot acc: 0.0656
top acc: 0.0981 ::: bot acc: 0.0648
top acc: 0.0530 ::: bot acc: 0.0330
top acc: 0.0549 ::: bot acc: 0.0308
top acc: 0.0784 ::: bot acc: 0.0556
current epoch: 30
train loss is 0.039271
average val loss: 0.045576, accuracy: 0.0455
average test loss: 0.044428, accuracy: 0.0442
case acc: 0.01238577
case acc: 0.03767722
case acc: 0.06309879
case acc: 0.042372312
case acc: 0.05645158
case acc: 0.05334157
top acc: 0.0213 ::: bot acc: 0.0044
top acc: 0.0497 ::: bot acc: 0.0257
top acc: 0.0799 ::: bot acc: 0.0466
top acc: 0.0519 ::: bot acc: 0.0320
top acc: 0.0686 ::: bot acc: 0.0444
top acc: 0.0647 ::: bot acc: 0.0419
current epoch: 31
train loss is 0.024291
average val loss: 0.028404, accuracy: 0.0286
average test loss: 0.028058, accuracy: 0.0278
case acc: 0.026849285
case acc: 0.015055726
case acc: 0.029254047
case acc: 0.023294445
case acc: 0.048836015
case acc: 0.02375766
top acc: 0.0173 ::: bot acc: 0.0363
top acc: 0.0056 ::: bot acc: 0.0258
top acc: 0.0456 ::: bot acc: 0.0138
top acc: 0.0325 ::: bot acc: 0.0135
top acc: 0.0609 ::: bot acc: 0.0368
top acc: 0.0350 ::: bot acc: 0.0126
current epoch: 32
train loss is 0.042386
average val loss: 0.057863, accuracy: 0.0578
average test loss: 0.059071, accuracy: 0.0591
case acc: 0.101858646
case acc: 0.100670524
case acc: 0.046109688
case acc: 0.045764953
case acc: 0.014149329
case acc: 0.046149105
top acc: 0.0923 ::: bot acc: 0.1113
top acc: 0.0887 ::: bot acc: 0.1126
top acc: 0.0295 ::: bot acc: 0.0625
top acc: 0.0363 ::: bot acc: 0.0561
top acc: 0.0053 ::: bot acc: 0.0246
top acc: 0.0348 ::: bot acc: 0.0576
current epoch: 33
train loss is 0.083648
average val loss: 0.055299, accuracy: 0.0553
average test loss: 0.056519, accuracy: 0.0565
case acc: 0.09460885
case acc: 0.08973762
case acc: 0.04425239
case acc: 0.05009516
case acc: 0.018315578
case acc: 0.04220482
top acc: 0.0850 ::: bot acc: 0.1040
top acc: 0.0778 ::: bot acc: 0.1017
top acc: 0.0277 ::: bot acc: 0.0606
top acc: 0.0406 ::: bot acc: 0.0604
top acc: 0.0077 ::: bot acc: 0.0296
top acc: 0.0309 ::: bot acc: 0.0536
current epoch: 34
train loss is 0.057151
average val loss: 0.027887, accuracy: 0.0283
average test loss: 0.029114, accuracy: 0.0294
case acc: 0.056326594
case acc: 0.03571942
case acc: 0.016130181
case acc: 0.034220587
case acc: 0.0171453
case acc: 0.016814938
top acc: 0.0467 ::: bot acc: 0.0658
top acc: 0.0238 ::: bot acc: 0.0477
top acc: 0.0069 ::: bot acc: 0.0288
top acc: 0.0249 ::: bot acc: 0.0446
top acc: 0.0070 ::: bot acc: 0.0282
top acc: 0.0069 ::: bot acc: 0.0276
current epoch: 35
train loss is 0.031300
average val loss: 0.016318, accuracy: 0.0169
average test loss: 0.016881, accuracy: 0.0170
case acc: 0.02886049
case acc: 0.009745607
case acc: 0.01424386
case acc: 0.024257919
case acc: 0.016677747
case acc: 0.00848904
top acc: 0.0192 ::: bot acc: 0.0383
top acc: 0.0171 ::: bot acc: 0.0068
top acc: 0.0258 ::: bot acc: 0.0082
top acc: 0.0155 ::: bot acc: 0.0343
top acc: 0.0067 ::: bot acc: 0.0277
top acc: 0.0131 ::: bot acc: 0.0098
current epoch: 36
train loss is 0.029720
average val loss: 0.024435, accuracy: 0.0242
average test loss: 0.023622, accuracy: 0.0233
case acc: 0.007081501
case acc: 0.031880602
case acc: 0.03769343
case acc: 0.010631762
case acc: 0.01956326
case acc: 0.0326535
top acc: 0.0108 ::: bot acc: 0.0083
top acc: 0.0438 ::: bot acc: 0.0199
top acc: 0.0543 ::: bot acc: 0.0217
top acc: 0.0177 ::: bot acc: 0.0051
top acc: 0.0309 ::: bot acc: 0.0090
top acc: 0.0440 ::: bot acc: 0.0211
current epoch: 37
train loss is 0.023424
average val loss: 0.015066, accuracy: 0.0150
average test loss: 0.014906, accuracy: 0.0146
case acc: 0.01769678
case acc: 0.0104608955
case acc: 0.021469172
case acc: 0.007179898
case acc: 0.0136349145
case acc: 0.016901953
top acc: 0.0083 ::: bot acc: 0.0271
top acc: 0.0193 ::: bot acc: 0.0048
top acc: 0.0369 ::: bot acc: 0.0077
top acc: 0.0082 ::: bot acc: 0.0117
top acc: 0.0236 ::: bot acc: 0.0059
top acc: 0.0277 ::: bot acc: 0.0065
current epoch: 38
train loss is 0.021520
average val loss: 0.013585, accuracy: 0.0137
average test loss: 0.013660, accuracy: 0.0136
case acc: 0.023391098
case acc: 0.008875945
case acc: 0.017095359
case acc: 0.007242443
case acc: 0.012610769
case acc: 0.012290709
top acc: 0.0138 ::: bot acc: 0.0329
top acc: 0.0121 ::: bot acc: 0.0118
top acc: 0.0308 ::: bot acc: 0.0068
top acc: 0.0074 ::: bot acc: 0.0125
top acc: 0.0221 ::: bot acc: 0.0059
top acc: 0.0217 ::: bot acc: 0.0047
current epoch: 39
train loss is 0.023048
average val loss: 0.016312, accuracy: 0.0165
average test loss: 0.016164, accuracy: 0.0161
case acc: 0.021236544
case acc: 0.009189468
case acc: 0.018324329
case acc: 0.009630162
case acc: 0.022320101
case acc: 0.01560468
top acc: 0.0116 ::: bot acc: 0.0307
top acc: 0.0089 ::: bot acc: 0.0151
top acc: 0.0328 ::: bot acc: 0.0067
top acc: 0.0160 ::: bot acc: 0.0054
top acc: 0.0339 ::: bot acc: 0.0112
top acc: 0.0262 ::: bot acc: 0.0056
current epoch: 40
train loss is 0.024782
average val loss: 0.020692, accuracy: 0.0210
average test loss: 0.020526, accuracy: 0.0205
case acc: 0.024712423
case acc: 0.01700397
case acc: 0.016310766
case acc: 0.013102792
case acc: 0.034826066
case acc: 0.017127024
top acc: 0.0151 ::: bot acc: 0.0342
top acc: 0.0069 ::: bot acc: 0.0280
top acc: 0.0297 ::: bot acc: 0.0069
top acc: 0.0209 ::: bot acc: 0.0060
top acc: 0.0469 ::: bot acc: 0.0229
top acc: 0.0280 ::: bot acc: 0.0067
current epoch: 41
train loss is 0.037139
average val loss: 0.050517, accuracy: 0.0504
average test loss: 0.051723, accuracy: 0.0518
case acc: 0.084409125
case acc: 0.08934484
case acc: 0.046428148
case acc: 0.042444184
case acc: 0.012030357
case acc: 0.036081154
top acc: 0.0748 ::: bot acc: 0.0939
top acc: 0.0774 ::: bot acc: 0.1013
top acc: 0.0297 ::: bot acc: 0.0629
top acc: 0.0330 ::: bot acc: 0.0528
top acc: 0.0051 ::: bot acc: 0.0215
top acc: 0.0247 ::: bot acc: 0.0475
current epoch: 42
train loss is 0.072812
average val loss: 0.058252, accuracy: 0.0582
average test loss: 0.059480, accuracy: 0.0595
case acc: 0.088448696
case acc: 0.09185998
case acc: 0.054446775
case acc: 0.05656376
case acc: 0.023551779
case acc: 0.04183966
top acc: 0.0788 ::: bot acc: 0.0980
top acc: 0.0799 ::: bot acc: 0.1038
top acc: 0.0375 ::: bot acc: 0.0710
top acc: 0.0471 ::: bot acc: 0.0669
top acc: 0.0119 ::: bot acc: 0.0354
top acc: 0.0305 ::: bot acc: 0.0533
current epoch: 43
train loss is 0.058562
average val loss: 0.028874, accuracy: 0.0290
average test loss: 0.030106, accuracy: 0.0302
case acc: 0.048582364
case acc: 0.037117016
case acc: 0.021863965
case acc: 0.03824467
case acc: 0.020596065
case acc: 0.0146508785
top acc: 0.0390 ::: bot acc: 0.0581
top acc: 0.0252 ::: bot acc: 0.0490
top acc: 0.0083 ::: bot acc: 0.0368
top acc: 0.0287 ::: bot acc: 0.0486
top acc: 0.0094 ::: bot acc: 0.0323
top acc: 0.0053 ::: bot acc: 0.0251
current epoch: 44
train loss is 0.032116
average val loss: 0.024215, accuracy: 0.0247
average test loss: 0.025348, accuracy: 0.0257
case acc: 0.032789044
case acc: 0.0092411395
case acc: 0.014918433
case acc: 0.042926323
case acc: 0.041752238
case acc: 0.012680251
top acc: 0.0231 ::: bot acc: 0.0423
top acc: 0.0085 ::: bot acc: 0.0154
top acc: 0.0078 ::: bot acc: 0.0266
top acc: 0.0334 ::: bot acc: 0.0533
top acc: 0.0297 ::: bot acc: 0.0538
top acc: 0.0045 ::: bot acc: 0.0226
current epoch: 45
train loss is 0.029720
average val loss: 0.036300, accuracy: 0.0362
average test loss: 0.035410, accuracy: 0.0352
case acc: 0.02903155
case acc: 0.068304844
case acc: 0.048699435
case acc: 0.012736637
case acc: 0.008782422
case acc: 0.04357772
top acc: 0.0387 ::: bot acc: 0.0196
top acc: 0.0802 ::: bot acc: 0.0564
top acc: 0.0655 ::: bot acc: 0.0322
top acc: 0.0205 ::: bot acc: 0.0058
top acc: 0.0141 ::: bot acc: 0.0100
top acc: 0.0549 ::: bot acc: 0.0321
current epoch: 46
train loss is 0.045078
average val loss: 0.079084, accuracy: 0.0791
average test loss: 0.077846, accuracy: 0.0778
case acc: 0.06982299
case acc: 0.11053817
case acc: 0.09149234
case acc: 0.059549574
case acc: 0.05128458
case acc: 0.08438973
top acc: 0.0794 ::: bot acc: 0.0603
top acc: 0.1225 ::: bot acc: 0.0986
top acc: 0.1083 ::: bot acc: 0.0750
top acc: 0.0691 ::: bot acc: 0.0491
top acc: 0.0633 ::: bot acc: 0.0393
top acc: 0.0958 ::: bot acc: 0.0729
current epoch: 47
train loss is 0.053658
average val loss: 0.032372, accuracy: 0.0323
average test loss: 0.031206, accuracy: 0.0310
case acc: 0.013936964
case acc: 0.04173435
case acc: 0.041324362
case acc: 0.024376215
case acc: 0.028170643
case acc: 0.036720518
top acc: 0.0230 ::: bot acc: 0.0055
top acc: 0.0537 ::: bot acc: 0.0298
top acc: 0.0581 ::: bot acc: 0.0250
top acc: 0.0337 ::: bot acc: 0.0144
top acc: 0.0400 ::: bot acc: 0.0164
top acc: 0.0481 ::: bot acc: 0.0252
current epoch: 48
train loss is 0.024969
average val loss: 0.020792, accuracy: 0.0210
average test loss: 0.020373, accuracy: 0.0202
case acc: 0.014117786
case acc: 0.008851406
case acc: 0.021160768
case acc: 0.01976139
case acc: 0.036699157
case acc: 0.020860543
top acc: 0.0054 ::: bot acc: 0.0232
top acc: 0.0113 ::: bot acc: 0.0126
top acc: 0.0366 ::: bot acc: 0.0076
top acc: 0.0288 ::: bot acc: 0.0104
top acc: 0.0487 ::: bot acc: 0.0246
top acc: 0.0320 ::: bot acc: 0.0099
current epoch: 49
train loss is 0.025063
average val loss: 0.025838, accuracy: 0.0258
average test loss: 0.026676, accuracy: 0.0269
case acc: 0.051577576
case acc: 0.049131904
case acc: 0.01874577
case acc: 0.009908229
case acc: 0.019582756
case acc: 0.012627996
top acc: 0.0419 ::: bot acc: 0.0611
top acc: 0.0372 ::: bot acc: 0.0611
top acc: 0.0069 ::: bot acc: 0.0328
top acc: 0.0043 ::: bot acc: 0.0183
top acc: 0.0309 ::: bot acc: 0.0090
top acc: 0.0045 ::: bot acc: 0.0225
current epoch: 50
train loss is 0.053607
average val loss: 0.073760, accuracy: 0.0737
average test loss: 0.074992, accuracy: 0.0750
case acc: 0.10495375
case acc: 0.110980526
case acc: 0.07062292
case acc: 0.06460205
case acc: 0.037149873
case acc: 0.06160867
top acc: 0.0953 ::: bot acc: 0.1145
top acc: 0.0990 ::: bot acc: 0.1229
top acc: 0.0537 ::: bot acc: 0.0872
top acc: 0.0551 ::: bot acc: 0.0750
top acc: 0.0251 ::: bot acc: 0.0492
top acc: 0.0502 ::: bot acc: 0.0731
LME_Co_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6810 6810 6810
1.8562728 -0.6288155 0.08104724 -0.1112376
Validation: 762 762 762
Testing: 744 744 744
pre-processing time: 0.0003337860107421875
the split date is 2010-01-01
net initializing with time: 1.694878101348877
preparing training and testing date with time: 2.384185791015625e-07
current epoch: 1
train loss is 0.186677
average val loss: 0.047312, accuracy: 0.0470
average test loss: 0.047085, accuracy: 0.0470
case acc: 0.015460459
case acc: 0.026191762
case acc: 0.053183176
case acc: 0.014659184
case acc: 0.045605764
case acc: 0.12679973
top acc: 0.0122 ::: bot acc: 0.0244
top acc: 0.0401 ::: bot acc: 0.0150
top acc: 0.0758 ::: bot acc: 0.0321
top acc: 0.0247 ::: bot acc: 0.0119
top acc: 0.0609 ::: bot acc: 0.0315
top acc: 0.1453 ::: bot acc: 0.1083
current epoch: 2
train loss is 0.073040
average val loss: 0.069266, accuracy: 0.0691
average test loss: 0.069948, accuracy: 0.0702
case acc: 0.11416012
case acc: 0.07930239
case acc: 0.054648906
case acc: 0.09511296
case acc: 0.061692677
case acc: 0.016515534
top acc: 0.0995 ::: bot acc: 0.1294
top acc: 0.0655 ::: bot acc: 0.0908
top acc: 0.0326 ::: bot acc: 0.0755
top acc: 0.0786 ::: bot acc: 0.1112
top acc: 0.0466 ::: bot acc: 0.0754
top acc: 0.0298 ::: bot acc: 0.0078
current epoch: 3
train loss is 0.066096
average val loss: 0.135524, accuracy: 0.1355
average test loss: 0.136278, accuracy: 0.1363
case acc: 0.1803905
case acc: 0.14695054
case acc: 0.12725574
case acc: 0.16380292
case acc: 0.13127872
case acc: 0.067982264
top acc: 0.1660 ::: bot acc: 0.1954
top acc: 0.1332 ::: bot acc: 0.1587
top acc: 0.1056 ::: bot acc: 0.1480
top acc: 0.1478 ::: bot acc: 0.1797
top acc: 0.1164 ::: bot acc: 0.1448
top acc: 0.0506 ::: bot acc: 0.0853
current epoch: 4
train loss is 0.082180
average val loss: 0.144739, accuracy: 0.1447
average test loss: 0.145373, accuracy: 0.1454
case acc: 0.18415299
case acc: 0.1525907
case acc: 0.13784096
case acc: 0.1743503
case acc: 0.13867983
case acc: 0.08462502
top acc: 0.1699 ::: bot acc: 0.1990
top acc: 0.1389 ::: bot acc: 0.1645
top acc: 0.1165 ::: bot acc: 0.1585
top acc: 0.1585 ::: bot acc: 0.1902
top acc: 0.1240 ::: bot acc: 0.1520
top acc: 0.0675 ::: bot acc: 0.1016
current epoch: 5
train loss is 0.090982
average val loss: 0.120296, accuracy: 0.1203
average test loss: 0.120869, accuracy: 0.1209
case acc: 0.15452436
case acc: 0.1247914
case acc: 0.114167504
case acc: 0.15259276
case acc: 0.11248938
case acc: 0.06664503
top acc: 0.1403 ::: bot acc: 0.1693
top acc: 0.1111 ::: bot acc: 0.1367
top acc: 0.0929 ::: bot acc: 0.1348
top acc: 0.1368 ::: bot acc: 0.1684
top acc: 0.0980 ::: bot acc: 0.1258
top acc: 0.0496 ::: bot acc: 0.0835
current epoch: 6
train loss is 0.099460
average val loss: 0.048580, accuracy: 0.0485
average test loss: 0.049441, accuracy: 0.0497
case acc: 0.07619375
case acc: 0.04844385
case acc: 0.04159837
case acc: 0.080773555
case acc: 0.03820009
case acc: 0.0128269885
top acc: 0.0619 ::: bot acc: 0.0910
top acc: 0.0348 ::: bot acc: 0.0603
top acc: 0.0202 ::: bot acc: 0.0623
top acc: 0.0648 ::: bot acc: 0.0967
top acc: 0.0237 ::: bot acc: 0.0516
top acc: 0.0152 ::: bot acc: 0.0188
current epoch: 7
train loss is 0.061838
average val loss: 0.070955, accuracy: 0.0709
average test loss: 0.071503, accuracy: 0.0715
case acc: 0.094453335
case acc: 0.06849355
case acc: 0.06610661
case acc: 0.103910685
case acc: 0.06039092
case acc: 0.035643127
top acc: 0.0801 ::: bot acc: 0.1093
top acc: 0.0548 ::: bot acc: 0.0803
top acc: 0.0447 ::: bot acc: 0.0869
top acc: 0.0878 ::: bot acc: 0.1198
top acc: 0.0460 ::: bot acc: 0.0737
top acc: 0.0190 ::: bot acc: 0.0524
current epoch: 8
train loss is 0.059631
average val loss: 0.077883, accuracy: 0.0779
average test loss: 0.078366, accuracy: 0.0784
case acc: 0.09634885
case acc: 0.07221636
case acc: 0.07400643
case acc: 0.110444464
case acc: 0.06586619
case acc: 0.05125758
top acc: 0.0820 ::: bot acc: 0.1111
top acc: 0.0586 ::: bot acc: 0.0840
top acc: 0.0526 ::: bot acc: 0.0949
top acc: 0.0944 ::: bot acc: 0.1264
top acc: 0.0515 ::: bot acc: 0.0791
top acc: 0.0342 ::: bot acc: 0.0682
current epoch: 9
train loss is 0.051906
average val loss: 0.086120, accuracy: 0.0861
average test loss: 0.086527, accuracy: 0.0865
case acc: 0.10005542
case acc: 0.077434495
case acc: 0.08311002
case acc: 0.119461365
case acc: 0.072496906
case acc: 0.06659994
top acc: 0.0858 ::: bot acc: 0.1148
top acc: 0.0638 ::: bot acc: 0.0893
top acc: 0.0619 ::: bot acc: 0.1039
top acc: 0.1036 ::: bot acc: 0.1354
top acc: 0.0581 ::: bot acc: 0.0857
top acc: 0.0497 ::: bot acc: 0.0834
current epoch: 10
train loss is 0.046571
average val loss: 0.080162, accuracy: 0.0802
average test loss: 0.080497, accuracy: 0.0805
case acc: 0.09035672
case acc: 0.06917789
case acc: 0.0778895
case acc: 0.11479081
case acc: 0.065195985
case acc: 0.065553315
top acc: 0.0762 ::: bot acc: 0.1049
top acc: 0.0556 ::: bot acc: 0.0810
top acc: 0.0568 ::: bot acc: 0.0986
top acc: 0.0990 ::: bot acc: 0.1307
top acc: 0.0509 ::: bot acc: 0.0783
top acc: 0.0488 ::: bot acc: 0.0822
current epoch: 11
train loss is 0.040208
average val loss: 0.070176, accuracy: 0.0702
average test loss: 0.070470, accuracy: 0.0705
case acc: 0.077615574
case acc: 0.05804558
case acc: 0.06870319
case acc: 0.10530926
case acc: 0.05454393
case acc: 0.058510616
top acc: 0.0635 ::: bot acc: 0.0922
top acc: 0.0445 ::: bot acc: 0.0700
top acc: 0.0478 ::: bot acc: 0.0893
top acc: 0.0895 ::: bot acc: 0.1213
top acc: 0.0403 ::: bot acc: 0.0677
top acc: 0.0418 ::: bot acc: 0.0750
current epoch: 12
train loss is 0.034779
average val loss: 0.060093, accuracy: 0.0601
average test loss: 0.060360, accuracy: 0.0603
case acc: 0.06632144
case acc: 0.0485887
case acc: 0.05947166
case acc: 0.09288402
case acc: 0.045294788
case acc: 0.049395278
top acc: 0.0522 ::: bot acc: 0.0808
top acc: 0.0351 ::: bot acc: 0.0606
top acc: 0.0387 ::: bot acc: 0.0800
top acc: 0.0772 ::: bot acc: 0.1088
top acc: 0.0312 ::: bot acc: 0.0584
top acc: 0.0328 ::: bot acc: 0.0659
current epoch: 13
train loss is 0.031366
average val loss: 0.054695, accuracy: 0.0547
average test loss: 0.054933, accuracy: 0.0549
case acc: 0.060276743
case acc: 0.044476915
case acc: 0.055110294
case acc: 0.08310494
case acc: 0.04137834
case acc: 0.04494996
top acc: 0.0462 ::: bot acc: 0.0748
top acc: 0.0310 ::: bot acc: 0.0565
top acc: 0.0343 ::: bot acc: 0.0757
top acc: 0.0674 ::: bot acc: 0.0991
top acc: 0.0273 ::: bot acc: 0.0545
top acc: 0.0283 ::: bot acc: 0.0614
current epoch: 14
train loss is 0.028917
average val loss: 0.046045, accuracy: 0.0460
average test loss: 0.046335, accuracy: 0.0462
case acc: 0.051300734
case acc: 0.03742817
case acc: 0.04748497
case acc: 0.069431685
case acc: 0.034448236
case acc: 0.037332736
top acc: 0.0371 ::: bot acc: 0.0659
top acc: 0.0240 ::: bot acc: 0.0495
top acc: 0.0267 ::: bot acc: 0.0681
top acc: 0.0536 ::: bot acc: 0.0854
top acc: 0.0204 ::: bot acc: 0.0476
top acc: 0.0209 ::: bot acc: 0.0537
current epoch: 15
train loss is 0.026466
average val loss: 0.039647, accuracy: 0.0396
average test loss: 0.040033, accuracy: 0.0399
case acc: 0.04506304
case acc: 0.032912772
case acc: 0.04194073
case acc: 0.057996728
case acc: 0.030015264
case acc: 0.03144505
top acc: 0.0309 ::: bot acc: 0.0597
top acc: 0.0195 ::: bot acc: 0.0449
top acc: 0.0211 ::: bot acc: 0.0625
top acc: 0.0425 ::: bot acc: 0.0738
top acc: 0.0160 ::: bot acc: 0.0431
top acc: 0.0154 ::: bot acc: 0.0476
current epoch: 16
train loss is 0.024686
average val loss: 0.037160, accuracy: 0.0371
average test loss: 0.037545, accuracy: 0.0374
case acc: 0.04281458
case acc: 0.032162584
case acc: 0.04008291
case acc: 0.050652932
case acc: 0.029380957
case acc: 0.029431285
top acc: 0.0287 ::: bot acc: 0.0575
top acc: 0.0188 ::: bot acc: 0.0441
top acc: 0.0194 ::: bot acc: 0.0606
top acc: 0.0354 ::: bot acc: 0.0664
top acc: 0.0153 ::: bot acc: 0.0425
top acc: 0.0137 ::: bot acc: 0.0455
current epoch: 17
train loss is 0.022919
average val loss: 0.030443, accuracy: 0.0304
average test loss: 0.030995, accuracy: 0.0309
case acc: 0.03622694
case acc: 0.02701451
case acc: 0.034225464
case acc: 0.03993493
case acc: 0.024310017
case acc: 0.023582397
top acc: 0.0221 ::: bot acc: 0.0508
top acc: 0.0140 ::: bot acc: 0.0388
top acc: 0.0145 ::: bot acc: 0.0544
top acc: 0.0255 ::: bot acc: 0.0552
top acc: 0.0105 ::: bot acc: 0.0373
top acc: 0.0089 ::: bot acc: 0.0391
current epoch: 18
train loss is 0.021726
average val loss: 0.028272, accuracy: 0.0282
average test loss: 0.028862, accuracy: 0.0288
case acc: 0.03415537
case acc: 0.026088508
case acc: 0.032560136
case acc: 0.034186307
case acc: 0.023503024
case acc: 0.022097914
top acc: 0.0202 ::: bot acc: 0.0487
top acc: 0.0132 ::: bot acc: 0.0378
top acc: 0.0131 ::: bot acc: 0.0526
top acc: 0.0203 ::: bot acc: 0.0492
top acc: 0.0098 ::: bot acc: 0.0365
top acc: 0.0078 ::: bot acc: 0.0374
current epoch: 19
train loss is 0.020586
average val loss: 0.022587, accuracy: 0.0226
average test loss: 0.023492, accuracy: 0.0234
case acc: 0.028336337
case acc: 0.021508792
case acc: 0.027726358
case acc: 0.025703508
case acc: 0.018983848
case acc: 0.018397173
top acc: 0.0151 ::: bot acc: 0.0425
top acc: 0.0099 ::: bot acc: 0.0326
top acc: 0.0095 ::: bot acc: 0.0472
top acc: 0.0130 ::: bot acc: 0.0402
top acc: 0.0063 ::: bot acc: 0.0314
top acc: 0.0063 ::: bot acc: 0.0326
current epoch: 20
train loss is 0.019502
average val loss: 0.019269, accuracy: 0.0192
average test loss: 0.020499, accuracy: 0.0204
case acc: 0.02467478
case acc: 0.018861402
case acc: 0.0250576
case acc: 0.020543326
case acc: 0.016511276
case acc: 0.016780114
top acc: 0.0121 ::: bot acc: 0.0386
top acc: 0.0083 ::: bot acc: 0.0294
top acc: 0.0078 ::: bot acc: 0.0441
top acc: 0.0093 ::: bot acc: 0.0343
top acc: 0.0050 ::: bot acc: 0.0284
top acc: 0.0063 ::: bot acc: 0.0302
current epoch: 21
train loss is 0.018656
average val loss: 0.015730, accuracy: 0.0157
average test loss: 0.017448, accuracy: 0.0174
case acc: 0.02077281
case acc: 0.015801197
case acc: 0.022190003
case acc: 0.016530236
case acc: 0.0139053725
case acc: 0.0149186505
top acc: 0.0092 ::: bot acc: 0.0342
top acc: 0.0070 ::: bot acc: 0.0255
top acc: 0.0069 ::: bot acc: 0.0403
top acc: 0.0076 ::: bot acc: 0.0291
top acc: 0.0050 ::: bot acc: 0.0246
top acc: 0.0073 ::: bot acc: 0.0269
current epoch: 22
train loss is 0.017949
average val loss: 0.015281, accuracy: 0.0152
average test loss: 0.017060, accuracy: 0.0170
case acc: 0.019831251
case acc: 0.015187838
case acc: 0.021956734
case acc: 0.016124135
case acc: 0.0135187255
case acc: 0.015122837
top acc: 0.0086 ::: bot acc: 0.0331
top acc: 0.0068 ::: bot acc: 0.0247
top acc: 0.0070 ::: bot acc: 0.0400
top acc: 0.0076 ::: bot acc: 0.0286
top acc: 0.0053 ::: bot acc: 0.0239
top acc: 0.0072 ::: bot acc: 0.0273
current epoch: 23
train loss is 0.017786
average val loss: 0.012360, accuracy: 0.0123
average test loss: 0.014630, accuracy: 0.0145
case acc: 0.016348341
case acc: 0.012397949
case acc: 0.019506391
case acc: 0.013785328
case acc: 0.0115828095
case acc: 0.013630939
top acc: 0.0071 ::: bot acc: 0.0286
top acc: 0.0069 ::: bot acc: 0.0205
top acc: 0.0078 ::: bot acc: 0.0359
top acc: 0.0080 ::: bot acc: 0.0249
top acc: 0.0077 ::: bot acc: 0.0198
top acc: 0.0097 ::: bot acc: 0.0238
current epoch: 24
train loss is 0.017391
average val loss: 0.014220, accuracy: 0.0142
average test loss: 0.016157, accuracy: 0.0161
case acc: 0.018735712
case acc: 0.014424113
case acc: 0.020543573
case acc: 0.016030213
case acc: 0.012971921
case acc: 0.014004263
top acc: 0.0080 ::: bot acc: 0.0317
top acc: 0.0067 ::: bot acc: 0.0237
top acc: 0.0073 ::: bot acc: 0.0378
top acc: 0.0076 ::: bot acc: 0.0285
top acc: 0.0058 ::: bot acc: 0.0228
top acc: 0.0088 ::: bot acc: 0.0248
current epoch: 25
train loss is 0.017339
average val loss: 0.018930, accuracy: 0.0189
average test loss: 0.020144, accuracy: 0.0201
case acc: 0.024162635
case acc: 0.019544907
case acc: 0.023740523
case acc: 0.020644464
case acc: 0.017169243
case acc: 0.015579557
top acc: 0.0114 ::: bot acc: 0.0381
top acc: 0.0089 ::: bot acc: 0.0303
top acc: 0.0075 ::: bot acc: 0.0425
top acc: 0.0093 ::: bot acc: 0.0346
top acc: 0.0054 ::: bot acc: 0.0293
top acc: 0.0067 ::: bot acc: 0.0282
current epoch: 26
train loss is 0.018184
average val loss: 0.028272, accuracy: 0.0283
average test loss: 0.028780, accuracy: 0.0288
case acc: 0.034417946
case acc: 0.02989682
case acc: 0.03146264
case acc: 0.02802443
case acc: 0.0276684
case acc: 0.021102471
top acc: 0.0201 ::: bot acc: 0.0491
top acc: 0.0167 ::: bot acc: 0.0419
top acc: 0.0122 ::: bot acc: 0.0517
top acc: 0.0148 ::: bot acc: 0.0428
top acc: 0.0137 ::: bot acc: 0.0409
top acc: 0.0073 ::: bot acc: 0.0362
current epoch: 27
train loss is 0.020579
average val loss: 0.031858, accuracy: 0.0319
average test loss: 0.032238, accuracy: 0.0323
case acc: 0.038045254
case acc: 0.034609027
case acc: 0.035209388
case acc: 0.027619362
case acc: 0.032678697
case acc: 0.025351696
top acc: 0.0237 ::: bot acc: 0.0528
top acc: 0.0213 ::: bot acc: 0.0466
top acc: 0.0153 ::: bot acc: 0.0558
top acc: 0.0145 ::: bot acc: 0.0424
top acc: 0.0187 ::: bot acc: 0.0459
top acc: 0.0103 ::: bot acc: 0.0410
current epoch: 28
train loss is 0.024444
average val loss: 0.011488, accuracy: 0.0117
average test loss: 0.013494, accuracy: 0.0135
case acc: 0.011398503
case acc: 0.010602635
case acc: 0.015157411
case acc: 0.018843375
case acc: 0.011862011
case acc: 0.013285101
top acc: 0.0192 ::: bot acc: 0.0098
top acc: 0.0207 ::: bot acc: 0.0051
top acc: 0.0226 ::: bot acc: 0.0191
top acc: 0.0320 ::: bot acc: 0.0083
top acc: 0.0226 ::: bot acc: 0.0052
top acc: 0.0237 ::: bot acc: 0.0098
current epoch: 29
train loss is 0.021699
average val loss: 0.025869, accuracy: 0.0260
average test loss: 0.026223, accuracy: 0.0263
case acc: 0.027008554
case acc: 0.029492741
case acc: 0.021059887
case acc: 0.030722177
case acc: 0.030292062
case acc: 0.019508531
top acc: 0.0408 ::: bot acc: 0.0134
top acc: 0.0428 ::: bot acc: 0.0175
top acc: 0.0387 ::: bot acc: 0.0064
top acc: 0.0461 ::: bot acc: 0.0155
top acc: 0.0443 ::: bot acc: 0.0171
top acc: 0.0351 ::: bot acc: 0.0054
current epoch: 30
train loss is 0.025737
average val loss: 0.009944, accuracy: 0.0099
average test loss: 0.012584, accuracy: 0.0124
case acc: 0.011654104
case acc: 0.0095818555
case acc: 0.017447228
case acc: 0.012269309
case acc: 0.009931124
case acc: 0.013632508
top acc: 0.0088 ::: bot acc: 0.0207
top acc: 0.0114 ::: bot acc: 0.0139
top acc: 0.0103 ::: bot acc: 0.0317
top acc: 0.0108 ::: bot acc: 0.0212
top acc: 0.0134 ::: bot acc: 0.0139
top acc: 0.0097 ::: bot acc: 0.0238
current epoch: 31
train loss is 0.018419
average val loss: 0.020979, accuracy: 0.0210
average test loss: 0.021961, accuracy: 0.0220
case acc: 0.026066365
case acc: 0.02199887
case acc: 0.024659183
case acc: 0.023230886
case acc: 0.019630942
case acc: 0.01630195
top acc: 0.0129 ::: bot acc: 0.0401
top acc: 0.0104 ::: bot acc: 0.0332
top acc: 0.0078 ::: bot acc: 0.0438
top acc: 0.0110 ::: bot acc: 0.0376
top acc: 0.0067 ::: bot acc: 0.0323
top acc: 0.0065 ::: bot acc: 0.0294
current epoch: 32
train loss is 0.020041
average val loss: 0.033936, accuracy: 0.0339
average test loss: 0.034261, accuracy: 0.0343
case acc: 0.040959187
case acc: 0.037502393
case acc: 0.035588313
case acc: 0.03265161
case acc: 0.035294395
case acc: 0.023915099
top acc: 0.0267 ::: bot acc: 0.0556
top acc: 0.0242 ::: bot acc: 0.0495
top acc: 0.0155 ::: bot acc: 0.0563
top acc: 0.0190 ::: bot acc: 0.0477
top acc: 0.0213 ::: bot acc: 0.0485
top acc: 0.0092 ::: bot acc: 0.0394
current epoch: 33
train loss is 0.025877
average val loss: 0.010248, accuracy: 0.0104
average test loss: 0.012504, accuracy: 0.0124
case acc: 0.010436913
case acc: 0.0093996655
case acc: 0.015186433
case acc: 0.014282228
case acc: 0.010634561
case acc: 0.014487292
top acc: 0.0155 ::: bot acc: 0.0135
top acc: 0.0171 ::: bot acc: 0.0082
top acc: 0.0226 ::: bot acc: 0.0192
top acc: 0.0252 ::: bot acc: 0.0083
top acc: 0.0196 ::: bot acc: 0.0077
top acc: 0.0270 ::: bot acc: 0.0067
current epoch: 34
train loss is 0.016418
average val loss: 0.009696, accuracy: 0.0099
average test loss: 0.012078, accuracy: 0.0121
case acc: 0.010840327
case acc: 0.009973537
case acc: 0.015016659
case acc: 0.01272539
case acc: 0.011320053
case acc: 0.012616662
top acc: 0.0175 ::: bot acc: 0.0115
top acc: 0.0194 ::: bot acc: 0.0059
top acc: 0.0201 ::: bot acc: 0.0218
top acc: 0.0219 ::: bot acc: 0.0101
top acc: 0.0215 ::: bot acc: 0.0059
top acc: 0.0206 ::: bot acc: 0.0129
current epoch: 35
train loss is 0.016607
average val loss: 0.012124, accuracy: 0.0122
average test loss: 0.013947, accuracy: 0.0142
case acc: 0.013289148
case acc: 0.014231648
case acc: 0.015625706
case acc: 0.013055625
case acc: 0.015637083
case acc: 0.013620135
top acc: 0.0236 ::: bot acc: 0.0067
top acc: 0.0262 ::: bot acc: 0.0050
top acc: 0.0250 ::: bot acc: 0.0169
top acc: 0.0228 ::: bot acc: 0.0094
top acc: 0.0284 ::: bot acc: 0.0051
top acc: 0.0247 ::: bot acc: 0.0088
current epoch: 36
train loss is 0.018916
average val loss: 0.010150, accuracy: 0.0103
average test loss: 0.012755, accuracy: 0.0129
case acc: 0.012291649
case acc: 0.009804734
case acc: 0.016768277
case acc: 0.015932927
case acc: 0.009983613
case acc: 0.012430242
top acc: 0.0081 ::: bot acc: 0.0220
top acc: 0.0105 ::: bot acc: 0.0148
top acc: 0.0120 ::: bot acc: 0.0299
top acc: 0.0076 ::: bot acc: 0.0283
top acc: 0.0132 ::: bot acc: 0.0141
top acc: 0.0150 ::: bot acc: 0.0185
current epoch: 37
train loss is 0.019507
average val loss: 0.036990, accuracy: 0.0370
average test loss: 0.037219, accuracy: 0.0372
case acc: 0.04245801
case acc: 0.03792474
case acc: 0.037826534
case acc: 0.04372693
case acc: 0.035360485
case acc: 0.02603551
top acc: 0.0282 ::: bot acc: 0.0571
top acc: 0.0246 ::: bot acc: 0.0499
top acc: 0.0174 ::: bot acc: 0.0587
top acc: 0.0289 ::: bot acc: 0.0593
top acc: 0.0213 ::: bot acc: 0.0486
top acc: 0.0108 ::: bot acc: 0.0418
current epoch: 38
train loss is 0.024085
average val loss: 0.018826, accuracy: 0.0188
average test loss: 0.020064, accuracy: 0.0202
case acc: 0.024284055
case acc: 0.021250604
case acc: 0.02192306
case acc: 0.02201951
case acc: 0.018509489
case acc: 0.013317127
top acc: 0.0115 ::: bot acc: 0.0382
top acc: 0.0099 ::: bot acc: 0.0322
top acc: 0.0069 ::: bot acc: 0.0401
top acc: 0.0102 ::: bot acc: 0.0361
top acc: 0.0060 ::: bot acc: 0.0310
top acc: 0.0106 ::: bot acc: 0.0229
current epoch: 39
train loss is 0.019650
average val loss: 0.008800, accuracy: 0.0089
average test loss: 0.011519, accuracy: 0.0115
case acc: 0.010305729
case acc: 0.009237316
case acc: 0.015554197
case acc: 0.011444598
case acc: 0.009951109
case acc: 0.012333108
top acc: 0.0121 ::: bot acc: 0.0169
top acc: 0.0135 ::: bot acc: 0.0117
top acc: 0.0159 ::: bot acc: 0.0259
top acc: 0.0152 ::: bot acc: 0.0168
top acc: 0.0160 ::: bot acc: 0.0113
top acc: 0.0183 ::: bot acc: 0.0152
current epoch: 40
train loss is 0.015881
average val loss: 0.015707, accuracy: 0.0159
average test loss: 0.016924, accuracy: 0.0173
case acc: 0.017353285
case acc: 0.01853499
case acc: 0.016845368
case acc: 0.016418906
case acc: 0.01983957
case acc: 0.01480289
top acc: 0.0299 ::: bot acc: 0.0063
top acc: 0.0314 ::: bot acc: 0.0075
top acc: 0.0293 ::: bot acc: 0.0126
top acc: 0.0287 ::: bot acc: 0.0077
top acc: 0.0335 ::: bot acc: 0.0075
top acc: 0.0277 ::: bot acc: 0.0063
current epoch: 41
train loss is 0.020179
average val loss: 0.009388, accuracy: 0.0095
average test loss: 0.012069, accuracy: 0.0120
case acc: 0.010380656
case acc: 0.009201346
case acc: 0.01633859
case acc: 0.013582763
case acc: 0.009998994
case acc: 0.012613874
top acc: 0.0117 ::: bot acc: 0.0173
top acc: 0.0141 ::: bot acc: 0.0112
top acc: 0.0133 ::: bot acc: 0.0287
top acc: 0.0082 ::: bot acc: 0.0245
top acc: 0.0165 ::: bot acc: 0.0108
top acc: 0.0136 ::: bot acc: 0.0200
current epoch: 42
train loss is 0.019513
average val loss: 0.028784, accuracy: 0.0288
average test loss: 0.029238, accuracy: 0.0292
case acc: 0.032395348
case acc: 0.028856764
case acc: 0.031191718
case acc: 0.03494386
case acc: 0.02641377
case acc: 0.021482615
top acc: 0.0184 ::: bot acc: 0.0469
top acc: 0.0158 ::: bot acc: 0.0407
top acc: 0.0118 ::: bot acc: 0.0516
top acc: 0.0210 ::: bot acc: 0.0501
top acc: 0.0124 ::: bot acc: 0.0396
top acc: 0.0075 ::: bot acc: 0.0367
current epoch: 43
train loss is 0.020700
average val loss: 0.021447, accuracy: 0.0214
average test loss: 0.022388, accuracy: 0.0225
case acc: 0.026135854
case acc: 0.023776473
case acc: 0.024593921
case acc: 0.023818575
case acc: 0.02113389
case acc: 0.015243316
top acc: 0.0130 ::: bot acc: 0.0402
top acc: 0.0116 ::: bot acc: 0.0352
top acc: 0.0077 ::: bot acc: 0.0438
top acc: 0.0114 ::: bot acc: 0.0382
top acc: 0.0078 ::: bot acc: 0.0340
top acc: 0.0071 ::: bot acc: 0.0276
current epoch: 44
train loss is 0.020135
average val loss: 0.009216, accuracy: 0.0094
average test loss: 0.011736, accuracy: 0.0117
case acc: 0.010514844
case acc: 0.00929824
case acc: 0.015048985
case acc: 0.012074914
case acc: 0.010473018
case acc: 0.012950144
top acc: 0.0160 ::: bot acc: 0.0130
top acc: 0.0165 ::: bot acc: 0.0087
top acc: 0.0197 ::: bot acc: 0.0222
top acc: 0.0198 ::: bot acc: 0.0122
top acc: 0.0191 ::: bot acc: 0.0082
top acc: 0.0223 ::: bot acc: 0.0112
current epoch: 45
train loss is 0.015705
average val loss: 0.014381, accuracy: 0.0146
average test loss: 0.015790, accuracy: 0.0162
case acc: 0.016141336
case acc: 0.01640501
case acc: 0.016420929
case acc: 0.015570518
case acc: 0.017883794
case acc: 0.014494612
top acc: 0.0282 ::: bot acc: 0.0060
top acc: 0.0289 ::: bot acc: 0.0061
top acc: 0.0279 ::: bot acc: 0.0141
top acc: 0.0274 ::: bot acc: 0.0078
top acc: 0.0312 ::: bot acc: 0.0063
top acc: 0.0270 ::: bot acc: 0.0068
current epoch: 46
train loss is 0.018392
average val loss: 0.009192, accuracy: 0.0093
average test loss: 0.011759, accuracy: 0.0118
case acc: 0.010729939
case acc: 0.009727086
case acc: 0.015166665
case acc: 0.011810111
case acc: 0.0111818025
case acc: 0.012406868
top acc: 0.0170 ::: bot acc: 0.0120
top acc: 0.0186 ::: bot acc: 0.0066
top acc: 0.0183 ::: bot acc: 0.0237
top acc: 0.0127 ::: bot acc: 0.0193
top acc: 0.0212 ::: bot acc: 0.0062
top acc: 0.0190 ::: bot acc: 0.0146
current epoch: 47
train loss is 0.018609
average val loss: 0.024009, accuracy: 0.0240
average test loss: 0.024727, accuracy: 0.0248
case acc: 0.027137604
case acc: 0.024194382
case acc: 0.02705132
case acc: 0.03088336
case acc: 0.021478022
case acc: 0.017818503
top acc: 0.0138 ::: bot acc: 0.0413
top acc: 0.0119 ::: bot acc: 0.0356
top acc: 0.0090 ::: bot acc: 0.0468
top acc: 0.0174 ::: bot acc: 0.0458
top acc: 0.0081 ::: bot acc: 0.0344
top acc: 0.0064 ::: bot acc: 0.0318
current epoch: 48
train loss is 0.019590
average val loss: 0.026054, accuracy: 0.0260
average test loss: 0.026680, accuracy: 0.0267
case acc: 0.030703155
case acc: 0.028637096
case acc: 0.0284321
case acc: 0.02927571
case acc: 0.02591891
case acc: 0.017401328
top acc: 0.0169 ::: bot acc: 0.0451
top acc: 0.0156 ::: bot acc: 0.0405
top acc: 0.0099 ::: bot acc: 0.0484
top acc: 0.0160 ::: bot acc: 0.0441
top acc: 0.0120 ::: bot acc: 0.0391
top acc: 0.0064 ::: bot acc: 0.0311
current epoch: 49
train loss is 0.021767
average val loss: 0.009117, accuracy: 0.0092
average test loss: 0.011680, accuracy: 0.0117
case acc: 0.0103574125
case acc: 0.009173783
case acc: 0.0150427865
case acc: 0.011661212
case acc: 0.010202552
case acc: 0.013480781
top acc: 0.0149 ::: bot acc: 0.0141
top acc: 0.0150 ::: bot acc: 0.0102
top acc: 0.0196 ::: bot acc: 0.0223
top acc: 0.0177 ::: bot acc: 0.0143
top acc: 0.0180 ::: bot acc: 0.0094
top acc: 0.0242 ::: bot acc: 0.0093
current epoch: 50
train loss is 0.014518
average val loss: 0.009781, accuracy: 0.0099
average test loss: 0.012144, accuracy: 0.0122
case acc: 0.011564036
case acc: 0.010217966
case acc: 0.015038818
case acc: 0.011785963
case acc: 0.01182828
case acc: 0.012910774
top acc: 0.0197 ::: bot acc: 0.0093
top acc: 0.0200 ::: bot acc: 0.0054
top acc: 0.0208 ::: bot acc: 0.0212
top acc: 0.0185 ::: bot acc: 0.0135
top acc: 0.0226 ::: bot acc: 0.0052
top acc: 0.0221 ::: bot acc: 0.0115
LME_Co_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6798 6798 6798
1.7082474 -0.6288155 0.08104724 -0.08406281
Validation: 756 756 756
Testing: 774 774 774
pre-processing time: 0.0004329681396484375
the split date is 2010-07-01
net initializing with time: 0.1172475814819336
preparing training and testing date with time: 4.76837158203125e-07
current epoch: 1
train loss is 0.307150
average val loss: 0.151424, accuracy: 0.1514
average test loss: 0.152134, accuracy: 0.1521
case acc: 0.20839512
case acc: 0.35583934
case acc: 0.06403349
case acc: 0.14095795
case acc: 0.10074423
case acc: 0.042852707
top acc: 0.1933 ::: bot acc: 0.2234
top acc: 0.3420 ::: bot acc: 0.3695
top acc: 0.0408 ::: bot acc: 0.0867
top acc: 0.1231 ::: bot acc: 0.1577
top acc: 0.0806 ::: bot acc: 0.1176
top acc: 0.0269 ::: bot acc: 0.0593
current epoch: 2
train loss is 0.193897
average val loss: 0.095495, accuracy: 0.0952
average test loss: 0.095696, accuracy: 0.0955
case acc: 0.014238409
case acc: 0.1487032
case acc: 0.12901177
case acc: 0.051477373
case acc: 0.086194135
case acc: 0.1433477
top acc: 0.0101 ::: bot acc: 0.0234
top acc: 0.1349 ::: bot acc: 0.1622
top acc: 0.1522 ::: bot acc: 0.1064
top acc: 0.0694 ::: bot acc: 0.0350
top acc: 0.1066 ::: bot acc: 0.0690
top acc: 0.1603 ::: bot acc: 0.1266
current epoch: 3
train loss is 0.091268
average val loss: 0.133647, accuracy: 0.1336
average test loss: 0.134349, accuracy: 0.1344
case acc: 0.18479289
case acc: 0.3126727
case acc: 0.050043114
case acc: 0.124916844
case acc: 0.09475467
case acc: 0.039257944
top acc: 0.1693 ::: bot acc: 0.1996
top acc: 0.2989 ::: bot acc: 0.3260
top acc: 0.0276 ::: bot acc: 0.0723
top acc: 0.1070 ::: bot acc: 0.1413
top acc: 0.0747 ::: bot acc: 0.1119
top acc: 0.0233 ::: bot acc: 0.0556
current epoch: 4
train loss is 0.121290
average val loss: 0.095759, accuracy: 0.0965
average test loss: 0.096797, accuracy: 0.0972
case acc: 0.1401829
case acc: 0.26204237
case acc: 0.020353906
case acc: 0.08662075
case acc: 0.060677677
case acc: 0.013519283
top acc: 0.1246 ::: bot acc: 0.1551
top acc: 0.2482 ::: bot acc: 0.2753
top acc: 0.0117 ::: bot acc: 0.0357
top acc: 0.0686 ::: bot acc: 0.1030
top acc: 0.0414 ::: bot acc: 0.0775
top acc: 0.0119 ::: bot acc: 0.0225
current epoch: 5
train loss is 0.107982
average val loss: 0.085020, accuracy: 0.0860
average test loss: 0.085970, accuracy: 0.0866
case acc: 0.12191923
case acc: 0.23821121
case acc: 0.017475571
case acc: 0.07547994
case acc: 0.053997558
case acc: 0.01265651
top acc: 0.1061 ::: bot acc: 0.1369
top acc: 0.2245 ::: bot acc: 0.2514
top acc: 0.0202 ::: bot acc: 0.0261
top acc: 0.0575 ::: bot acc: 0.0917
top acc: 0.0347 ::: bot acc: 0.0708
top acc: 0.0169 ::: bot acc: 0.0172
current epoch: 6
train loss is 0.097644
average val loss: 0.083670, accuracy: 0.0845
average test loss: 0.084684, accuracy: 0.0852
case acc: 0.116209015
case acc: 0.22676685
case acc: 0.017977962
case acc: 0.07657385
case acc: 0.059451807
case acc: 0.014247453
top acc: 0.1003 ::: bot acc: 0.1313
top acc: 0.2130 ::: bot acc: 0.2400
top acc: 0.0175 ::: bot acc: 0.0290
top acc: 0.0585 ::: bot acc: 0.0926
top acc: 0.0398 ::: bot acc: 0.0765
top acc: 0.0109 ::: bot acc: 0.0243
current epoch: 7
train loss is 0.090895
average val loss: 0.084439, accuracy: 0.0851
average test loss: 0.085455, accuracy: 0.0859
case acc: 0.11253848
case acc: 0.217854
case acc: 0.019564329
case acc: 0.07962852
case acc: 0.0663353
case acc: 0.01936307
top acc: 0.0965 ::: bot acc: 0.1277
top acc: 0.2042 ::: bot acc: 0.2310
top acc: 0.0134 ::: bot acc: 0.0340
top acc: 0.0616 ::: bot acc: 0.0955
top acc: 0.0464 ::: bot acc: 0.0836
top acc: 0.0086 ::: bot acc: 0.0331
current epoch: 8
train loss is 0.085558
average val loss: 0.077586, accuracy: 0.0783
average test loss: 0.078574, accuracy: 0.0791
case acc: 0.09982967
case acc: 0.20025538
case acc: 0.018156467
case acc: 0.073485605
case acc: 0.06375657
case acc: 0.018858593
top acc: 0.0837 ::: bot acc: 0.1150
top acc: 0.1866 ::: bot acc: 0.2134
top acc: 0.0169 ::: bot acc: 0.0298
top acc: 0.0554 ::: bot acc: 0.0894
top acc: 0.0439 ::: bot acc: 0.0810
top acc: 0.0086 ::: bot acc: 0.0324
current epoch: 9
train loss is 0.079476
average val loss: 0.078917, accuracy: 0.0794
average test loss: 0.079860, accuracy: 0.0803
case acc: 0.096491545
case acc: 0.19305639
case acc: 0.01991248
case acc: 0.0769804
case acc: 0.069875024
case acc: 0.025256855
top acc: 0.0804 ::: bot acc: 0.1115
top acc: 0.1795 ::: bot acc: 0.2060
top acc: 0.0123 ::: bot acc: 0.0350
top acc: 0.0588 ::: bot acc: 0.0929
top acc: 0.0500 ::: bot acc: 0.0873
top acc: 0.0115 ::: bot acc: 0.0404
current epoch: 10
train loss is 0.079267
average val loss: 0.089388, accuracy: 0.0895
average test loss: 0.090159, accuracy: 0.0904
case acc: 0.1020728
case acc: 0.19643864
case acc: 0.029599896
case acc: 0.08984454
case acc: 0.084313594
case acc: 0.040401228
top acc: 0.0860 ::: bot acc: 0.1171
top acc: 0.1829 ::: bot acc: 0.2093
top acc: 0.0127 ::: bot acc: 0.0494
top acc: 0.0717 ::: bot acc: 0.1058
top acc: 0.0641 ::: bot acc: 0.1019
top acc: 0.0240 ::: bot acc: 0.0568
current epoch: 11
train loss is 0.075688
average val loss: 0.075056, accuracy: 0.0755
average test loss: 0.075927, accuracy: 0.0763
case acc: 0.081521444
case acc: 0.17428231
case acc: 0.021048557
case acc: 0.07670227
case acc: 0.07293873
case acc: 0.03117161
top acc: 0.0654 ::: bot acc: 0.0966
top acc: 0.1607 ::: bot acc: 0.1873
top acc: 0.0106 ::: bot acc: 0.0376
top acc: 0.0586 ::: bot acc: 0.0927
top acc: 0.0531 ::: bot acc: 0.0904
top acc: 0.0159 ::: bot acc: 0.0470
current epoch: 12
train loss is 0.071366
average val loss: 0.076518, accuracy: 0.0768
average test loss: 0.077335, accuracy: 0.0776
case acc: 0.07756604
case acc: 0.16904828
case acc: 0.024017463
case acc: 0.08016474
case acc: 0.07766695
case acc: 0.037358202
top acc: 0.0615 ::: bot acc: 0.0927
top acc: 0.1554 ::: bot acc: 0.1820
top acc: 0.0100 ::: bot acc: 0.0424
top acc: 0.0620 ::: bot acc: 0.0961
top acc: 0.0577 ::: bot acc: 0.0952
top acc: 0.0213 ::: bot acc: 0.0536
current epoch: 13
train loss is 0.067992
average val loss: 0.066676, accuracy: 0.0672
average test loss: 0.067524, accuracy: 0.0679
case acc: 0.061620835
case acc: 0.15208107
case acc: 0.019851185
case acc: 0.071578346
case acc: 0.070452504
case acc: 0.032024242
top acc: 0.0455 ::: bot acc: 0.0769
top acc: 0.1385 ::: bot acc: 0.1651
top acc: 0.0123 ::: bot acc: 0.0351
top acc: 0.0535 ::: bot acc: 0.0875
top acc: 0.0508 ::: bot acc: 0.0879
top acc: 0.0167 ::: bot acc: 0.0479
current epoch: 14
train loss is 0.062804
average val loss: 0.059963, accuracy: 0.0605
average test loss: 0.060810, accuracy: 0.0613
case acc: 0.049069792
case acc: 0.13852213
case acc: 0.018209003
case acc: 0.066084445
case acc: 0.06615498
case acc: 0.029552381
top acc: 0.0329 ::: bot acc: 0.0644
top acc: 0.1249 ::: bot acc: 0.1515
top acc: 0.0159 ::: bot acc: 0.0308
top acc: 0.0480 ::: bot acc: 0.0820
top acc: 0.0467 ::: bot acc: 0.0836
top acc: 0.0146 ::: bot acc: 0.0452
current epoch: 15
train loss is 0.058969
average val loss: 0.056683, accuracy: 0.0573
average test loss: 0.057532, accuracy: 0.0580
case acc: 0.04073622
case acc: 0.12893379
case acc: 0.018005447
case acc: 0.064325124
case acc: 0.06542475
case acc: 0.030451143
top acc: 0.0247 ::: bot acc: 0.0560
top acc: 0.1153 ::: bot acc: 0.1419
top acc: 0.0165 ::: bot acc: 0.0302
top acc: 0.0463 ::: bot acc: 0.0802
top acc: 0.0460 ::: bot acc: 0.0829
top acc: 0.0153 ::: bot acc: 0.0461
current epoch: 16
train loss is 0.054581
average val loss: 0.046368, accuracy: 0.0469
average test loss: 0.047281, accuracy: 0.0478
case acc: 0.025488498
case acc: 0.110557
case acc: 0.017282674
case acc: 0.05372956
case acc: 0.05603105
case acc: 0.023540096
top acc: 0.0128 ::: bot acc: 0.0391
top acc: 0.0970 ::: bot acc: 0.1235
top acc: 0.0258 ::: bot acc: 0.0208
top acc: 0.0357 ::: bot acc: 0.0696
top acc: 0.0369 ::: bot acc: 0.0734
top acc: 0.0102 ::: bot acc: 0.0383
current epoch: 17
train loss is 0.048587
average val loss: 0.040462, accuracy: 0.0410
average test loss: 0.041397, accuracy: 0.0417
case acc: 0.017001089
case acc: 0.09643421
case acc: 0.018133093
case acc: 0.047262065
case acc: 0.050777316
case acc: 0.020668197
top acc: 0.0097 ::: bot acc: 0.0278
top acc: 0.0829 ::: bot acc: 0.1093
top acc: 0.0307 ::: bot acc: 0.0158
top acc: 0.0292 ::: bot acc: 0.0631
top acc: 0.0319 ::: bot acc: 0.0680
top acc: 0.0087 ::: bot acc: 0.0347
current epoch: 18
train loss is 0.041771
average val loss: 0.031016, accuracy: 0.0313
average test loss: 0.031824, accuracy: 0.0316
case acc: 0.012581365
case acc: 0.07146847
case acc: 0.025667442
case acc: 0.031196257
case acc: 0.03559222
case acc: 0.013113192
top acc: 0.0229 ::: bot acc: 0.0092
top acc: 0.0580 ::: bot acc: 0.0843
top acc: 0.0452 ::: bot acc: 0.0099
top acc: 0.0150 ::: bot acc: 0.0461
top acc: 0.0176 ::: bot acc: 0.0524
top acc: 0.0127 ::: bot acc: 0.0212
current epoch: 19
train loss is 0.036597
average val loss: 0.025814, accuracy: 0.0259
average test loss: 0.026566, accuracy: 0.0265
case acc: 0.020733736
case acc: 0.046550713
case acc: 0.035236478
case acc: 0.018948333
case acc: 0.024264429
case acc: 0.013172819
top acc: 0.0356 ::: bot acc: 0.0080
top acc: 0.0330 ::: bot acc: 0.0594
top acc: 0.0568 ::: bot acc: 0.0155
top acc: 0.0101 ::: bot acc: 0.0302
top acc: 0.0098 ::: bot acc: 0.0394
top acc: 0.0233 ::: bot acc: 0.0106
current epoch: 20
train loss is 0.036153
average val loss: 0.023157, accuracy: 0.0230
average test loss: 0.023889, accuracy: 0.0236
case acc: 0.029183479
case acc: 0.020382866
case acc: 0.045318995
case acc: 0.01220794
case acc: 0.017504402
case acc: 0.01706418
top acc: 0.0449 ::: bot acc: 0.0146
top acc: 0.0086 ::: bot acc: 0.0323
top acc: 0.0676 ::: bot acc: 0.0242
top acc: 0.0196 ::: bot acc: 0.0144
top acc: 0.0121 ::: bot acc: 0.0281
top acc: 0.0318 ::: bot acc: 0.0053
current epoch: 21
train loss is 0.034901
average val loss: 0.021972, accuracy: 0.0214
average test loss: 0.022643, accuracy: 0.0222
case acc: 0.028825415
case acc: 0.009870738
case acc: 0.047839757
case acc: 0.013738871
case acc: 0.016808577
case acc: 0.016247783
top acc: 0.0445 ::: bot acc: 0.0144
top acc: 0.0140 ::: bot acc: 0.0124
top acc: 0.0701 ::: bot acc: 0.0265
top acc: 0.0266 ::: bot acc: 0.0080
top acc: 0.0129 ::: bot acc: 0.0268
top acc: 0.0305 ::: bot acc: 0.0054
current epoch: 22
train loss is 0.031798
average val loss: 0.026587, accuracy: 0.0263
average test loss: 0.026923, accuracy: 0.0269
case acc: 0.03142926
case acc: 0.024011659
case acc: 0.053768422
case acc: 0.020030443
case acc: 0.015236073
case acc: 0.016995545
top acc: 0.0473 ::: bot acc: 0.0166
top acc: 0.0375 ::: bot acc: 0.0113
top acc: 0.0763 ::: bot acc: 0.0320
top acc: 0.0365 ::: bot acc: 0.0072
top acc: 0.0158 ::: bot acc: 0.0230
top acc: 0.0317 ::: bot acc: 0.0051
current epoch: 23
train loss is 0.028007
average val loss: 0.039294, accuracy: 0.0390
average test loss: 0.039326, accuracy: 0.0394
case acc: 0.040573128
case acc: 0.0542453
case acc: 0.06693006
case acc: 0.036007844
case acc: 0.01461447
case acc: 0.023930606
top acc: 0.0566 ::: bot acc: 0.0254
top acc: 0.0677 ::: bot acc: 0.0415
top acc: 0.0897 ::: bot acc: 0.0445
top acc: 0.0537 ::: bot acc: 0.0207
top acc: 0.0269 ::: bot acc: 0.0120
top acc: 0.0405 ::: bot acc: 0.0083
current epoch: 24
train loss is 0.031573
average val loss: 0.066668, accuracy: 0.0666
average test loss: 0.066436, accuracy: 0.0664
case acc: 0.06174503
case acc: 0.095859826
case acc: 0.094677225
case acc: 0.06664572
case acc: 0.03230271
case acc: 0.04694302
top acc: 0.0779 ::: bot acc: 0.0465
top acc: 0.1093 ::: bot acc: 0.0832
top acc: 0.1177 ::: bot acc: 0.0716
top acc: 0.0847 ::: bot acc: 0.0508
top acc: 0.0521 ::: bot acc: 0.0148
top acc: 0.0640 ::: bot acc: 0.0304
current epoch: 25
train loss is 0.051211
average val loss: 0.091228, accuracy: 0.0912
average test loss: 0.090962, accuracy: 0.0909
case acc: 0.07754661
case acc: 0.12743954
case acc: 0.12034861
case acc: 0.09432237
case acc: 0.055836063
case acc: 0.07008688
top acc: 0.0937 ::: bot acc: 0.0621
top acc: 0.1409 ::: bot acc: 0.1147
top acc: 0.1435 ::: bot acc: 0.0971
top acc: 0.1123 ::: bot acc: 0.0785
top acc: 0.0760 ::: bot acc: 0.0375
top acc: 0.0872 ::: bot acc: 0.0536
current epoch: 26
train loss is 0.077214
average val loss: 0.031911, accuracy: 0.0315
average test loss: 0.032408, accuracy: 0.0325
case acc: 0.012214319
case acc: 0.060429085
case acc: 0.05771857
case acc: 0.03491666
case acc: 0.014718002
case acc: 0.014979443
top acc: 0.0218 ::: bot acc: 0.0101
top acc: 0.0739 ::: bot acc: 0.0477
top acc: 0.0803 ::: bot acc: 0.0357
top acc: 0.0525 ::: bot acc: 0.0198
top acc: 0.0166 ::: bot acc: 0.0219
top acc: 0.0283 ::: bot acc: 0.0061
current epoch: 27
train loss is 0.065850
average val loss: 0.022397, accuracy: 0.0220
average test loss: 0.023225, accuracy: 0.0230
case acc: 0.033824664
case acc: 0.01453428
case acc: 0.025328921
case acc: 0.012160838
case acc: 0.03318286
case acc: 0.018723015
top acc: 0.0185 ::: bot acc: 0.0487
top acc: 0.0266 ::: bot acc: 0.0045
top acc: 0.0446 ::: bot acc: 0.0096
top acc: 0.0192 ::: bot acc: 0.0147
top acc: 0.0159 ::: bot acc: 0.0501
top acc: 0.0080 ::: bot acc: 0.0320
current epoch: 28
train loss is 0.052573
average val loss: 0.017919, accuracy: 0.0174
average test loss: 0.019023, accuracy: 0.0186
case acc: 0.024848001
case acc: 0.009674228
case acc: 0.028727822
case acc: 0.012317275
case acc: 0.023488732
case acc: 0.012554403
top acc: 0.0122 ::: bot acc: 0.0384
top acc: 0.0150 ::: bot acc: 0.0111
top acc: 0.0490 ::: bot acc: 0.0110
top acc: 0.0227 ::: bot acc: 0.0112
top acc: 0.0094 ::: bot acc: 0.0389
top acc: 0.0144 ::: bot acc: 0.0191
current epoch: 29
train loss is 0.040599
average val loss: 0.017719, accuracy: 0.0170
average test loss: 0.018685, accuracy: 0.0182
case acc: 0.013043016
case acc: 0.01038767
case acc: 0.03750748
case acc: 0.016342824
case acc: 0.01470227
case acc: 0.017470235
top acc: 0.0104 ::: bot acc: 0.0216
top acc: 0.0092 ::: bot acc: 0.0168
top acc: 0.0589 ::: bot acc: 0.0175
top acc: 0.0316 ::: bot acc: 0.0059
top acc: 0.0162 ::: bot acc: 0.0222
top acc: 0.0326 ::: bot acc: 0.0050
current epoch: 30
train loss is 0.030810
average val loss: 0.019753, accuracy: 0.0192
average test loss: 0.020574, accuracy: 0.0202
case acc: 0.011689388
case acc: 0.016796218
case acc: 0.037831046
case acc: 0.017123045
case acc: 0.013850484
case acc: 0.023786703
top acc: 0.0134 ::: bot acc: 0.0181
top acc: 0.0066 ::: bot acc: 0.0278
top acc: 0.0593 ::: bot acc: 0.0177
top acc: 0.0327 ::: bot acc: 0.0060
top acc: 0.0229 ::: bot acc: 0.0154
top acc: 0.0404 ::: bot acc: 0.0083
current epoch: 31
train loss is 0.026390
average val loss: 0.019018, accuracy: 0.0187
average test loss: 0.019996, accuracy: 0.0202
case acc: 0.018504977
case acc: 0.03311646
case acc: 0.025508467
case acc: 0.0121253235
case acc: 0.015532928
case acc: 0.016334798
top acc: 0.0096 ::: bot acc: 0.0302
top acc: 0.0197 ::: bot acc: 0.0457
top acc: 0.0449 ::: bot acc: 0.0096
top acc: 0.0204 ::: bot acc: 0.0135
top acc: 0.0140 ::: bot acc: 0.0247
top acc: 0.0309 ::: bot acc: 0.0050
current epoch: 32
train loss is 0.031679
average val loss: 0.025598, accuracy: 0.0262
average test loss: 0.026690, accuracy: 0.0273
case acc: 0.031195851
case acc: 0.05668668
case acc: 0.016871031
case acc: 0.021001713
case acc: 0.025362086
case acc: 0.012606517
top acc: 0.0164 ::: bot acc: 0.0458
top acc: 0.0432 ::: bot acc: 0.0693
top acc: 0.0243 ::: bot acc: 0.0219
top acc: 0.0103 ::: bot acc: 0.0332
top acc: 0.0102 ::: bot acc: 0.0414
top acc: 0.0137 ::: bot acc: 0.0197
current epoch: 33
train loss is 0.041482
average val loss: 0.053647, accuracy: 0.0537
average test loss: 0.054072, accuracy: 0.0543
case acc: 0.05615854
case acc: 0.09348518
case acc: 0.034257274
case acc: 0.051311634
case acc: 0.054960083
case acc: 0.03541454
top acc: 0.0401 ::: bot acc: 0.0715
top acc: 0.0800 ::: bot acc: 0.1062
top acc: 0.0149 ::: bot acc: 0.0556
top acc: 0.0334 ::: bot acc: 0.0672
top acc: 0.0366 ::: bot acc: 0.0725
top acc: 0.0198 ::: bot acc: 0.0511
current epoch: 34
train loss is 0.040003
average val loss: 0.034103, accuracy: 0.0345
average test loss: 0.035006, accuracy: 0.0352
case acc: 0.029108167
case acc: 0.070962764
case acc: 0.020519251
case acc: 0.0334097
case acc: 0.037198436
case acc: 0.020234717
top acc: 0.0148 ::: bot acc: 0.0435
top acc: 0.0575 ::: bot acc: 0.0836
top acc: 0.0103 ::: bot acc: 0.0373
top acc: 0.0167 ::: bot acc: 0.0487
top acc: 0.0195 ::: bot acc: 0.0544
top acc: 0.0084 ::: bot acc: 0.0340
current epoch: 35
train loss is 0.034800
average val loss: 0.031136, accuracy: 0.0315
average test loss: 0.032132, accuracy: 0.0324
case acc: 0.02095627
case acc: 0.063605584
case acc: 0.020102374
case acc: 0.03198565
case acc: 0.036870323
case acc: 0.021016616
top acc: 0.0106 ::: bot acc: 0.0334
top acc: 0.0501 ::: bot acc: 0.0762
top acc: 0.0108 ::: bot acc: 0.0364
top acc: 0.0156 ::: bot acc: 0.0471
top acc: 0.0192 ::: bot acc: 0.0541
top acc: 0.0088 ::: bot acc: 0.0351
current epoch: 36
train loss is 0.030269
average val loss: 0.023129, accuracy: 0.0235
average test loss: 0.024312, accuracy: 0.0246
case acc: 0.011469638
case acc: 0.048535354
case acc: 0.01726122
case acc: 0.024284223
case acc: 0.0293672
case acc: 0.016401451
top acc: 0.0144 ::: bot acc: 0.0171
top acc: 0.0350 ::: bot acc: 0.0612
top acc: 0.0182 ::: bot acc: 0.0281
top acc: 0.0114 ::: bot acc: 0.0377
top acc: 0.0129 ::: bot acc: 0.0461
top acc: 0.0083 ::: bot acc: 0.0283
current epoch: 37
train loss is 0.023167
average val loss: 0.016446, accuracy: 0.0167
average test loss: 0.017554, accuracy: 0.0178
case acc: 0.018170046
case acc: 0.025958497
case acc: 0.018658567
case acc: 0.013605704
case acc: 0.018335402
case acc: 0.012140501
top acc: 0.0323 ::: bot acc: 0.0067
top acc: 0.0132 ::: bot acc: 0.0382
top acc: 0.0326 ::: bot acc: 0.0137
top acc: 0.0130 ::: bot acc: 0.0209
top acc: 0.0102 ::: bot acc: 0.0309
top acc: 0.0184 ::: bot acc: 0.0149
current epoch: 38
train loss is 0.019763
average val loss: 0.014527, accuracy: 0.0145
average test loss: 0.015598, accuracy: 0.0155
case acc: 0.019164396
case acc: 0.012619235
case acc: 0.02064034
case acc: 0.012165267
case acc: 0.015741011
case acc: 0.012660747
top acc: 0.0336 ::: bot acc: 0.0072
top acc: 0.0058 ::: bot acc: 0.0220
top acc: 0.0373 ::: bot acc: 0.0104
top acc: 0.0215 ::: bot acc: 0.0124
top acc: 0.0135 ::: bot acc: 0.0253
top acc: 0.0219 ::: bot acc: 0.0114
current epoch: 39
train loss is 0.018438
average val loss: 0.014621, accuracy: 0.0143
average test loss: 0.015537, accuracy: 0.0154
case acc: 0.017529724
case acc: 0.010770757
case acc: 0.022158405
case acc: 0.014350518
case acc: 0.014813085
case acc: 0.012755497
top acc: 0.0314 ::: bot acc: 0.0065
top acc: 0.0203 ::: bot acc: 0.0061
top acc: 0.0401 ::: bot acc: 0.0094
top acc: 0.0280 ::: bot acc: 0.0069
top acc: 0.0158 ::: bot acc: 0.0227
top acc: 0.0223 ::: bot acc: 0.0110
current epoch: 40
train loss is 0.015948
average val loss: 0.018886, accuracy: 0.0188
average test loss: 0.019460, accuracy: 0.0196
case acc: 0.018608112
case acc: 0.024230845
case acc: 0.026307734
case acc: 0.020522695
case acc: 0.013816322
case acc: 0.013964583
top acc: 0.0328 ::: bot acc: 0.0069
top acc: 0.0377 ::: bot acc: 0.0116
top acc: 0.0461 ::: bot acc: 0.0097
top acc: 0.0370 ::: bot acc: 0.0075
top acc: 0.0213 ::: bot acc: 0.0172
top acc: 0.0260 ::: bot acc: 0.0075
current epoch: 41
train loss is 0.017347
average val loss: 0.024387, accuracy: 0.0241
average test loss: 0.024745, accuracy: 0.0249
case acc: 0.020026244
case acc: 0.037951402
case acc: 0.032019984
case acc: 0.028125081
case acc: 0.01478746
case acc: 0.016381582
top acc: 0.0346 ::: bot acc: 0.0076
top acc: 0.0515 ::: bot acc: 0.0252
top acc: 0.0530 ::: bot acc: 0.0130
top acc: 0.0453 ::: bot acc: 0.0135
top acc: 0.0272 ::: bot acc: 0.0113
top acc: 0.0309 ::: bot acc: 0.0049
current epoch: 42
train loss is 0.020639
average val loss: 0.036052, accuracy: 0.0359
average test loss: 0.036135, accuracy: 0.0361
case acc: 0.027552016
case acc: 0.05647956
case acc: 0.044524968
case acc: 0.04180806
case acc: 0.021089306
case acc: 0.025340237
top acc: 0.0432 ::: bot acc: 0.0130
top acc: 0.0700 ::: bot acc: 0.0438
top acc: 0.0666 ::: bot acc: 0.0235
top acc: 0.0595 ::: bot acc: 0.0262
top acc: 0.0389 ::: bot acc: 0.0069
top acc: 0.0421 ::: bot acc: 0.0095
current epoch: 43
train loss is 0.028696
average val loss: 0.058757, accuracy: 0.0587
average test loss: 0.058658, accuracy: 0.0586
case acc: 0.0442923
case acc: 0.08338961
case acc: 0.06793935
case acc: 0.06640644
case acc: 0.04175127
case acc: 0.047739215
top acc: 0.0604 ::: bot acc: 0.0288
top acc: 0.0969 ::: bot acc: 0.0707
top acc: 0.0907 ::: bot acc: 0.0453
top acc: 0.0843 ::: bot acc: 0.0504
top acc: 0.0617 ::: bot acc: 0.0232
top acc: 0.0647 ::: bot acc: 0.0314
current epoch: 44
train loss is 0.039095
average val loss: 0.042440, accuracy: 0.0423
average test loss: 0.042494, accuracy: 0.0424
case acc: 0.021169214
case acc: 0.06420748
case acc: 0.05321198
case acc: 0.05219495
case acc: 0.028917145
case acc: 0.034943912
top acc: 0.0360 ::: bot acc: 0.0082
top acc: 0.0777 ::: bot acc: 0.0515
top acc: 0.0756 ::: bot acc: 0.0315
top acc: 0.0701 ::: bot acc: 0.0363
top acc: 0.0482 ::: bot acc: 0.0117
top acc: 0.0519 ::: bot acc: 0.0186
current epoch: 45
train loss is 0.038682
average val loss: 0.020723, accuracy: 0.0204
average test loss: 0.021353, accuracy: 0.0217
case acc: 0.018906003
case acc: 0.027157137
case acc: 0.027203921
case acc: 0.026461922
case acc: 0.0143438205
case acc: 0.015931495
top acc: 0.0098 ::: bot acc: 0.0308
top acc: 0.0406 ::: bot acc: 0.0145
top acc: 0.0473 ::: bot acc: 0.0100
top acc: 0.0436 ::: bot acc: 0.0121
top acc: 0.0254 ::: bot acc: 0.0132
top acc: 0.0302 ::: bot acc: 0.0051
current epoch: 46
train loss is 0.042658
average val loss: 0.023613, accuracy: 0.0238
average test loss: 0.024801, accuracy: 0.0250
case acc: 0.048169635
case acc: 0.023784364
case acc: 0.019041963
case acc: 0.016000142
case acc: 0.025602134
case acc: 0.017442094
top acc: 0.0320 ::: bot acc: 0.0636
top acc: 0.0114 ::: bot acc: 0.0359
top acc: 0.0126 ::: bot acc: 0.0340
top acc: 0.0098 ::: bot acc: 0.0261
top acc: 0.0104 ::: bot acc: 0.0418
top acc: 0.0079 ::: bot acc: 0.0300
current epoch: 47
train loss is 0.030698
average val loss: 0.020292, accuracy: 0.0207
average test loss: 0.021538, accuracy: 0.0221
case acc: 0.03350526
case acc: 0.034744114
case acc: 0.017577104
case acc: 0.015121757
case acc: 0.018972859
case acc: 0.012480105
top acc: 0.0183 ::: bot acc: 0.0484
top acc: 0.0212 ::: bot acc: 0.0474
top acc: 0.0170 ::: bot acc: 0.0294
top acc: 0.0103 ::: bot acc: 0.0244
top acc: 0.0096 ::: bot acc: 0.0322
top acc: 0.0142 ::: bot acc: 0.0192
current epoch: 48
train loss is 0.031287
average val loss: 0.040898, accuracy: 0.0410
average test loss: 0.041515, accuracy: 0.0416
case acc: 0.04708094
case acc: 0.071209356
case acc: 0.03325894
case acc: 0.036455605
case acc: 0.036480475
case acc: 0.025360692
top acc: 0.0309 ::: bot acc: 0.0625
top acc: 0.0577 ::: bot acc: 0.0839
top acc: 0.0141 ::: bot acc: 0.0546
top acc: 0.0193 ::: bot acc: 0.0520
top acc: 0.0189 ::: bot acc: 0.0539
top acc: 0.0117 ::: bot acc: 0.0400
current epoch: 49
train loss is 0.034848
average val loss: 0.034773, accuracy: 0.0349
average test loss: 0.035559, accuracy: 0.0357
case acc: 0.03249107
case acc: 0.06524526
case acc: 0.029489217
case acc: 0.032595087
case acc: 0.032286707
case acc: 0.021933842
top acc: 0.0175 ::: bot acc: 0.0474
top acc: 0.0517 ::: bot acc: 0.0779
top acc: 0.0118 ::: bot acc: 0.0501
top acc: 0.0161 ::: bot acc: 0.0478
top acc: 0.0153 ::: bot acc: 0.0494
top acc: 0.0092 ::: bot acc: 0.0361
current epoch: 50
train loss is 0.028530
average val loss: 0.024410, accuracy: 0.0246
average test loss: 0.025589, accuracy: 0.0258
case acc: 0.01667305
case acc: 0.04889534
case acc: 0.02210798
case acc: 0.024448184
case acc: 0.025489852
case acc: 0.017054025
top acc: 0.0093 ::: bot acc: 0.0278
top acc: 0.0354 ::: bot acc: 0.0616
top acc: 0.0092 ::: bot acc: 0.0403
top acc: 0.0114 ::: bot acc: 0.0380
top acc: 0.0103 ::: bot acc: 0.0417
top acc: 0.0079 ::: bot acc: 0.0294
LME_Co_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6810 6810 6810
1.7082474 -0.6288155 0.08104724 -0.08406281
Validation: 762 762 762
Testing: 750 750 750
pre-processing time: 0.0002338886260986328
the split date is 2011-01-01
net initializing with time: 0.10719895362854004
preparing training and testing date with time: 2.384185791015625e-07
current epoch: 1
train loss is 0.321928
average val loss: 0.046546, accuracy: 0.0471
average test loss: 0.045626, accuracy: 0.0466
case acc: 0.11328221
case acc: 0.089633666
case acc: 0.01699474
case acc: 0.016197141
case acc: 0.018703345
case acc: 0.025005646
top acc: 0.0994 ::: bot acc: 0.1277
top acc: 0.0781 ::: bot acc: 0.1029
top acc: 0.0277 ::: bot acc: 0.0158
top acc: 0.0278 ::: bot acc: 0.0086
top acc: 0.0325 ::: bot acc: 0.0080
top acc: 0.0094 ::: bot acc: 0.0406
current epoch: 2
train loss is 0.109958
average val loss: 0.039966, accuracy: 0.0401
average test loss: 0.039495, accuracy: 0.0404
case acc: 0.08228095
case acc: 0.059486754
case acc: 0.025877975
case acc: 0.028689278
case acc: 0.03180799
case acc: 0.014480712
top acc: 0.0681 ::: bot acc: 0.0971
top acc: 0.0480 ::: bot acc: 0.0726
top acc: 0.0432 ::: bot acc: 0.0119
top acc: 0.0431 ::: bot acc: 0.0151
top acc: 0.0496 ::: bot acc: 0.0128
top acc: 0.0104 ::: bot acc: 0.0244
current epoch: 3
train loss is 0.092100
average val loss: 0.075592, accuracy: 0.0757
average test loss: 0.073293, accuracy: 0.0734
case acc: 0.13516322
case acc: 0.11639499
case acc: 0.043645255
case acc: 0.041337352
case acc: 0.035097625
case acc: 0.06853585
top acc: 0.1210 ::: bot acc: 0.1500
top acc: 0.1049 ::: bot acc: 0.1294
top acc: 0.0236 ::: bot acc: 0.0645
top acc: 0.0260 ::: bot acc: 0.0572
top acc: 0.0181 ::: bot acc: 0.0541
top acc: 0.0513 ::: bot acc: 0.0851
current epoch: 4
train loss is 0.099098
average val loss: 0.097659, accuracy: 0.0977
average test loss: 0.095384, accuracy: 0.0954
case acc: 0.1479412
case acc: 0.13667849
case acc: 0.06743012
case acc: 0.074030414
case acc: 0.0639078
case acc: 0.082316905
top acc: 0.1337 ::: bot acc: 0.1628
top acc: 0.1252 ::: bot acc: 0.1497
top acc: 0.0466 ::: bot acc: 0.0887
top acc: 0.0588 ::: bot acc: 0.0896
top acc: 0.0457 ::: bot acc: 0.0836
top acc: 0.0650 ::: bot acc: 0.0989
current epoch: 5
train loss is 0.085228
average val loss: 0.073973, accuracy: 0.0741
average test loss: 0.071570, accuracy: 0.0716
case acc: 0.11355548
case acc: 0.107902944
case acc: 0.04683878
case acc: 0.061081123
case acc: 0.048551477
case acc: 0.05167364
top acc: 0.0993 ::: bot acc: 0.1284
top acc: 0.0963 ::: bot acc: 0.1210
top acc: 0.0266 ::: bot acc: 0.0678
top acc: 0.0460 ::: bot acc: 0.0764
top acc: 0.0302 ::: bot acc: 0.0682
top acc: 0.0343 ::: bot acc: 0.0683
current epoch: 6
train loss is 0.067954
average val loss: 0.068853, accuracy: 0.0690
average test loss: 0.066357, accuracy: 0.0664
case acc: 0.09753192
case acc: 0.09577838
case acc: 0.0457901
case acc: 0.06545948
case acc: 0.050175086
case acc: 0.043575138
top acc: 0.0831 ::: bot acc: 0.1124
top acc: 0.0841 ::: bot acc: 0.1089
top acc: 0.0256 ::: bot acc: 0.0667
top acc: 0.0506 ::: bot acc: 0.0806
top acc: 0.0317 ::: bot acc: 0.0699
top acc: 0.0261 ::: bot acc: 0.0604
current epoch: 7
train loss is 0.060591
average val loss: 0.071523, accuracy: 0.0716
average test loss: 0.068955, accuracy: 0.0690
case acc: 0.08966093
case acc: 0.09213073
case acc: 0.052274887
case acc: 0.0773156
case acc: 0.058638316
case acc: 0.043771904
top acc: 0.0751 ::: bot acc: 0.1045
top acc: 0.0804 ::: bot acc: 0.1053
top acc: 0.0317 ::: bot acc: 0.0734
top acc: 0.0626 ::: bot acc: 0.0921
top acc: 0.0400 ::: bot acc: 0.0784
top acc: 0.0262 ::: bot acc: 0.0607
current epoch: 8
train loss is 0.054391
average val loss: 0.071602, accuracy: 0.0717
average test loss: 0.068966, accuracy: 0.0690
case acc: 0.07921214
case acc: 0.08572741
case acc: 0.056479625
case acc: 0.0863129
case acc: 0.06406494
case acc: 0.041972
top acc: 0.0647 ::: bot acc: 0.0940
top acc: 0.0740 ::: bot acc: 0.0989
top acc: 0.0358 ::: bot acc: 0.0778
top acc: 0.0717 ::: bot acc: 0.1008
top acc: 0.0453 ::: bot acc: 0.0839
top acc: 0.0244 ::: bot acc: 0.0590
current epoch: 9
train loss is 0.047159
average val loss: 0.068179, accuracy: 0.0682
average test loss: 0.065481, accuracy: 0.0655
case acc: 0.06541339
case acc: 0.07507146
case acc: 0.057587933
case acc: 0.09101769
case acc: 0.06542155
case acc: 0.038274877
top acc: 0.0509 ::: bot acc: 0.0801
top acc: 0.0633 ::: bot acc: 0.0883
top acc: 0.0369 ::: bot acc: 0.0789
top acc: 0.0766 ::: bot acc: 0.1053
top acc: 0.0465 ::: bot acc: 0.0853
top acc: 0.0207 ::: bot acc: 0.0553
current epoch: 10
train loss is 0.041809
average val loss: 0.064065, accuracy: 0.0641
average test loss: 0.061339, accuracy: 0.0613
case acc: 0.05116226
case acc: 0.06194262
case acc: 0.05891262
case acc: 0.09340852
case acc: 0.06509503
case acc: 0.037332024
top acc: 0.0367 ::: bot acc: 0.0657
top acc: 0.0501 ::: bot acc: 0.0752
top acc: 0.0381 ::: bot acc: 0.0803
top acc: 0.0791 ::: bot acc: 0.1075
top acc: 0.0461 ::: bot acc: 0.0850
top acc: 0.0198 ::: bot acc: 0.0544
current epoch: 11
train loss is 0.039718
average val loss: 0.059820, accuracy: 0.0598
average test loss: 0.057063, accuracy: 0.0570
case acc: 0.037344337
case acc: 0.047339033
case acc: 0.06010904
case acc: 0.09418362
case acc: 0.06485638
case acc: 0.038088933
top acc: 0.0229 ::: bot acc: 0.0519
top acc: 0.0355 ::: bot acc: 0.0604
top acc: 0.0393 ::: bot acc: 0.0816
top acc: 0.0799 ::: bot acc: 0.1083
top acc: 0.0459 ::: bot acc: 0.0849
top acc: 0.0206 ::: bot acc: 0.0552
current epoch: 12
train loss is 0.045235
average val loss: 0.037880, accuracy: 0.0374
average test loss: 0.035188, accuracy: 0.0344
case acc: 0.011092551
case acc: 0.013149602
case acc: 0.041500956
case acc: 0.073766746
case acc: 0.045450658
case acc: 0.021654485
top acc: 0.0100 ::: bot acc: 0.0190
top acc: 0.0042 ::: bot acc: 0.0248
top acc: 0.0218 ::: bot acc: 0.0624
top acc: 0.0595 ::: bot acc: 0.0879
top acc: 0.0265 ::: bot acc: 0.0654
top acc: 0.0071 ::: bot acc: 0.0374
current epoch: 13
train loss is 0.062891
average val loss: 0.054627, accuracy: 0.0546
average test loss: 0.056912, accuracy: 0.0569
case acc: 0.09074985
case acc: 0.09044712
case acc: 0.044419114
case acc: 0.017273031
case acc: 0.0393543
case acc: 0.058871556
top acc: 0.1051 ::: bot acc: 0.0762
top acc: 0.1023 ::: bot acc: 0.0774
top acc: 0.0644 ::: bot acc: 0.0247
top acc: 0.0293 ::: bot acc: 0.0077
top acc: 0.0584 ::: bot acc: 0.0193
top acc: 0.0764 ::: bot acc: 0.0417
current epoch: 14
train loss is 0.078445
average val loss: 0.080821, accuracy: 0.0808
average test loss: 0.083323, accuracy: 0.0833
case acc: 0.11379592
case acc: 0.12519658
case acc: 0.06899471
case acc: 0.050114308
case acc: 0.06832112
case acc: 0.07353829
top acc: 0.1282 ::: bot acc: 0.0992
top acc: 0.1371 ::: bot acc: 0.1122
top acc: 0.0896 ::: bot acc: 0.0479
top acc: 0.0645 ::: bot acc: 0.0359
top acc: 0.0874 ::: bot acc: 0.0482
top acc: 0.0910 ::: bot acc: 0.0563
current epoch: 15
train loss is 0.061733
average val loss: 0.054408, accuracy: 0.0545
average test loss: 0.056821, accuracy: 0.0569
case acc: 0.077524856
case acc: 0.09569582
case acc: 0.04455733
case acc: 0.03489967
case acc: 0.050268006
case acc: 0.038220707
top acc: 0.0919 ::: bot acc: 0.0630
top acc: 0.1076 ::: bot acc: 0.0828
top acc: 0.0646 ::: bot acc: 0.0248
top acc: 0.0490 ::: bot acc: 0.0211
top acc: 0.0695 ::: bot acc: 0.0301
top acc: 0.0557 ::: bot acc: 0.0210
current epoch: 16
train loss is 0.053597
average val loss: 0.063714, accuracy: 0.0637
average test loss: 0.066143, accuracy: 0.0662
case acc: 0.07607467
case acc: 0.09808033
case acc: 0.05728819
case acc: 0.054295484
case acc: 0.06719395
case acc: 0.04399404
top acc: 0.0905 ::: bot acc: 0.0615
top acc: 0.1100 ::: bot acc: 0.0852
top acc: 0.0777 ::: bot acc: 0.0366
top acc: 0.0686 ::: bot acc: 0.0402
top acc: 0.0864 ::: bot acc: 0.0470
top acc: 0.0614 ::: bot acc: 0.0267
current epoch: 17
train loss is 0.046450
average val loss: 0.055451, accuracy: 0.0554
average test loss: 0.057842, accuracy: 0.0578
case acc: 0.056248687
case acc: 0.08145587
case acc: 0.0537675
case acc: 0.055929177
case acc: 0.065434985
case acc: 0.034182355
top acc: 0.0706 ::: bot acc: 0.0417
top acc: 0.0934 ::: bot acc: 0.0687
top acc: 0.0741 ::: bot acc: 0.0331
top acc: 0.0702 ::: bot acc: 0.0419
top acc: 0.0847 ::: bot acc: 0.0452
top acc: 0.0515 ::: bot acc: 0.0170
current epoch: 18
train loss is 0.037712
average val loss: 0.047877, accuracy: 0.0478
average test loss: 0.050202, accuracy: 0.0502
case acc: 0.037014283
case acc: 0.06452433
case acc: 0.05192753
case acc: 0.05707628
case acc: 0.06217027
case acc: 0.028312244
top acc: 0.0514 ::: bot acc: 0.0225
top acc: 0.0765 ::: bot acc: 0.0518
top acc: 0.0722 ::: bot acc: 0.0314
top acc: 0.0713 ::: bot acc: 0.0430
top acc: 0.0814 ::: bot acc: 0.0419
top acc: 0.0454 ::: bot acc: 0.0116
current epoch: 19
train loss is 0.030139
average val loss: 0.041269, accuracy: 0.0411
average test loss: 0.043483, accuracy: 0.0434
case acc: 0.02022663
case acc: 0.048245866
case acc: 0.051063895
case acc: 0.057533767
case acc: 0.057895374
case acc: 0.02529375
top acc: 0.0336 ::: bot acc: 0.0077
top acc: 0.0602 ::: bot acc: 0.0355
top acc: 0.0714 ::: bot acc: 0.0306
top acc: 0.0717 ::: bot acc: 0.0436
top acc: 0.0772 ::: bot acc: 0.0376
top acc: 0.0422 ::: bot acc: 0.0091
current epoch: 20
train loss is 0.026982
average val loss: 0.042374, accuracy: 0.0421
average test loss: 0.044489, accuracy: 0.0443
case acc: 0.014357471
case acc: 0.039896216
case acc: 0.056556325
case acc: 0.063719936
case acc: 0.061687518
case acc: 0.029625531
top acc: 0.0257 ::: bot acc: 0.0062
top acc: 0.0519 ::: bot acc: 0.0271
top acc: 0.0770 ::: bot acc: 0.0358
top acc: 0.0779 ::: bot acc: 0.0497
top acc: 0.0810 ::: bot acc: 0.0413
top acc: 0.0468 ::: bot acc: 0.0128
current epoch: 21
train loss is 0.037057
average val loss: 0.030620, accuracy: 0.0302
average test loss: 0.031788, accuracy: 0.0316
case acc: 0.016134609
case acc: 0.014039673
case acc: 0.042898405
case acc: 0.04999524
case acc: 0.04863596
case acc: 0.0180876
top acc: 0.0060 ::: bot acc: 0.0285
top acc: 0.0240 ::: bot acc: 0.0054
top acc: 0.0627 ::: bot acc: 0.0233
top acc: 0.0642 ::: bot acc: 0.0360
top acc: 0.0679 ::: bot acc: 0.0283
top acc: 0.0331 ::: bot acc: 0.0058
current epoch: 22
train loss is 0.058315
average val loss: 0.069037, accuracy: 0.0691
average test loss: 0.066461, accuracy: 0.0665
case acc: 0.110156596
case acc: 0.09233588
case acc: 0.04657761
case acc: 0.04293185
case acc: 0.041010723
case acc: 0.066016875
top acc: 0.0958 ::: bot acc: 0.1246
top acc: 0.0804 ::: bot acc: 0.1051
top acc: 0.0264 ::: bot acc: 0.0679
top acc: 0.0287 ::: bot acc: 0.0570
top acc: 0.0222 ::: bot acc: 0.0612
top acc: 0.0486 ::: bot acc: 0.0832
current epoch: 23
train loss is 0.068788
average val loss: 0.058789, accuracy: 0.0589
average test loss: 0.056150, accuracy: 0.0563
case acc: 0.09248421
case acc: 0.08435816
case acc: 0.03762552
case acc: 0.041856114
case acc: 0.03460519
case acc: 0.046643883
top acc: 0.0781 ::: bot acc: 0.1070
top acc: 0.0724 ::: bot acc: 0.0971
top acc: 0.0183 ::: bot acc: 0.0585
top acc: 0.0276 ::: bot acc: 0.0560
top acc: 0.0165 ::: bot acc: 0.0544
top acc: 0.0293 ::: bot acc: 0.0638
current epoch: 24
train loss is 0.046284
average val loss: 0.041251, accuracy: 0.0414
average test loss: 0.038444, accuracy: 0.0387
case acc: 0.063984506
case acc: 0.060416758
case acc: 0.024677848
case acc: 0.03360016
case acc: 0.025177313
case acc: 0.024564687
top acc: 0.0495 ::: bot acc: 0.0785
top acc: 0.0485 ::: bot acc: 0.0732
top acc: 0.0098 ::: bot acc: 0.0434
top acc: 0.0196 ::: bot acc: 0.0477
top acc: 0.0093 ::: bot acc: 0.0439
top acc: 0.0087 ::: bot acc: 0.0410
current epoch: 25
train loss is 0.041910
average val loss: 0.059214, accuracy: 0.0593
average test loss: 0.056578, accuracy: 0.0566
case acc: 0.07287373
case acc: 0.07464387
case acc: 0.043289073
case acc: 0.061954852
case acc: 0.05028543
case acc: 0.03646622
top acc: 0.0584 ::: bot acc: 0.0874
top acc: 0.0627 ::: bot acc: 0.0874
top acc: 0.0233 ::: bot acc: 0.0645
top acc: 0.0477 ::: bot acc: 0.0762
top acc: 0.0310 ::: bot acc: 0.0707
top acc: 0.0191 ::: bot acc: 0.0536
current epoch: 26
train loss is 0.038830
average val loss: 0.056599, accuracy: 0.0567
average test loss: 0.053941, accuracy: 0.0539
case acc: 0.05950933
case acc: 0.0654677
case acc: 0.04414426
case acc: 0.06909358
case acc: 0.055158395
case acc: 0.030166788
top acc: 0.0450 ::: bot acc: 0.0741
top acc: 0.0535 ::: bot acc: 0.0782
top acc: 0.0241 ::: bot acc: 0.0654
top acc: 0.0548 ::: bot acc: 0.0833
top acc: 0.0359 ::: bot acc: 0.0755
top acc: 0.0131 ::: bot acc: 0.0471
current epoch: 27
train loss is 0.035177
average val loss: 0.048390, accuracy: 0.0484
average test loss: 0.045660, accuracy: 0.0456
case acc: 0.040357217
case acc: 0.04701382
case acc: 0.041150007
case acc: 0.06811323
case acc: 0.05235374
case acc: 0.024754148
top acc: 0.0259 ::: bot acc: 0.0549
top acc: 0.0350 ::: bot acc: 0.0598
top acc: 0.0214 ::: bot acc: 0.0622
top acc: 0.0538 ::: bot acc: 0.0823
top acc: 0.0330 ::: bot acc: 0.0727
top acc: 0.0089 ::: bot acc: 0.0411
current epoch: 28
train loss is 0.041084
average val loss: 0.019687, accuracy: 0.0195
average test loss: 0.018455, accuracy: 0.0180
case acc: 0.01275199
case acc: 0.009861316
case acc: 0.016511735
case acc: 0.03437493
case acc: 0.020920401
case acc: 0.013687715
top acc: 0.0227 ::: bot acc: 0.0073
top acc: 0.0162 ::: bot acc: 0.0085
top acc: 0.0130 ::: bot acc: 0.0296
top acc: 0.0203 ::: bot acc: 0.0484
top acc: 0.0075 ::: bot acc: 0.0384
top acc: 0.0243 ::: bot acc: 0.0102
current epoch: 29
train loss is 0.043276
average val loss: 0.044856, accuracy: 0.0449
average test loss: 0.047147, accuracy: 0.0471
case acc: 0.06703597
case acc: 0.07142324
case acc: 0.041642804
case acc: 0.021495886
case acc: 0.032643177
case acc: 0.048609044
top acc: 0.0815 ::: bot acc: 0.0525
top acc: 0.0834 ::: bot acc: 0.0587
top acc: 0.0613 ::: bot acc: 0.0224
top acc: 0.0345 ::: bot acc: 0.0099
top acc: 0.0519 ::: bot acc: 0.0123
top acc: 0.0660 ::: bot acc: 0.0315
current epoch: 30
train loss is 0.054670
average val loss: 0.056682, accuracy: 0.0567
average test loss: 0.059097, accuracy: 0.0591
case acc: 0.07438692
case acc: 0.0894153
case acc: 0.052376628
case acc: 0.040793307
case acc: 0.04734611
case acc: 0.05039195
top acc: 0.0888 ::: bot acc: 0.0598
top acc: 0.1014 ::: bot acc: 0.0767
top acc: 0.0726 ::: bot acc: 0.0320
top acc: 0.0550 ::: bot acc: 0.0268
top acc: 0.0667 ::: bot acc: 0.0270
top acc: 0.0677 ::: bot acc: 0.0333
current epoch: 31
train loss is 0.041536
average val loss: 0.042541, accuracy: 0.0425
average test loss: 0.044870, accuracy: 0.0449
case acc: 0.050570667
case acc: 0.071221285
case acc: 0.040457394
case acc: 0.036519025
case acc: 0.041000966
case acc: 0.029770713
top acc: 0.0650 ::: bot acc: 0.0360
top acc: 0.0832 ::: bot acc: 0.0585
top acc: 0.0601 ::: bot acc: 0.0213
top acc: 0.0506 ::: bot acc: 0.0227
top acc: 0.0603 ::: bot acc: 0.0206
top acc: 0.0470 ::: bot acc: 0.0130
current epoch: 32
train loss is 0.034991
average val loss: 0.046835, accuracy: 0.0468
average test loss: 0.049199, accuracy: 0.0492
case acc: 0.044429407
case acc: 0.06819932
case acc: 0.04811484
case acc: 0.04996592
case acc: 0.05258075
case acc: 0.031884942
top acc: 0.0589 ::: bot acc: 0.0299
top acc: 0.0802 ::: bot acc: 0.0555
top acc: 0.0682 ::: bot acc: 0.0279
top acc: 0.0642 ::: bot acc: 0.0359
top acc: 0.0719 ::: bot acc: 0.0322
top acc: 0.0491 ::: bot acc: 0.0150
current epoch: 33
train loss is 0.029747
average val loss: 0.043190, accuracy: 0.0431
average test loss: 0.045488, accuracy: 0.0454
case acc: 0.02979313
case acc: 0.0559386
case acc: 0.048914794
case acc: 0.054936655
case acc: 0.05492772
case acc: 0.028081162
top acc: 0.0442 ::: bot acc: 0.0153
top acc: 0.0679 ::: bot acc: 0.0432
top acc: 0.0691 ::: bot acc: 0.0287
top acc: 0.0692 ::: bot acc: 0.0409
top acc: 0.0743 ::: bot acc: 0.0345
top acc: 0.0451 ::: bot acc: 0.0115
current epoch: 34
train loss is 0.026658
average val loss: 0.040419, accuracy: 0.0403
average test loss: 0.042622, accuracy: 0.0425
case acc: 0.018019738
case acc: 0.042934332
case acc: 0.05072791
case acc: 0.0587463
case acc: 0.05669379
case acc: 0.027887886
top acc: 0.0308 ::: bot acc: 0.0067
top acc: 0.0549 ::: bot acc: 0.0302
top acc: 0.0709 ::: bot acc: 0.0304
top acc: 0.0730 ::: bot acc: 0.0447
top acc: 0.0761 ::: bot acc: 0.0363
top acc: 0.0449 ::: bot acc: 0.0114
current epoch: 35
train loss is 0.035696
average val loss: 0.020829, accuracy: 0.0207
average test loss: 0.020574, accuracy: 0.0210
case acc: 0.029814702
case acc: 0.009852709
case acc: 0.02177999
case acc: 0.02631729
case acc: 0.024951989
case acc: 0.013218891
top acc: 0.0156 ::: bot acc: 0.0442
top acc: 0.0064 ::: bot acc: 0.0185
top acc: 0.0375 ::: bot acc: 0.0107
top acc: 0.0399 ::: bot acc: 0.0136
top acc: 0.0434 ::: bot acc: 0.0066
top acc: 0.0123 ::: bot acc: 0.0222
current epoch: 36
train loss is 0.053120
average val loss: 0.067458, accuracy: 0.0675
average test loss: 0.064902, accuracy: 0.0649
case acc: 0.1003027
case acc: 0.08658318
case acc: 0.04858015
case acc: 0.046586625
case acc: 0.04628829
case acc: 0.06119286
top acc: 0.0860 ::: bot acc: 0.1148
top acc: 0.0745 ::: bot acc: 0.0994
top acc: 0.0282 ::: bot acc: 0.0699
top acc: 0.0324 ::: bot acc: 0.0605
top acc: 0.0270 ::: bot acc: 0.0666
top acc: 0.0439 ::: bot acc: 0.0783
current epoch: 37
train loss is 0.047530
average val loss: 0.040788, accuracy: 0.0410
average test loss: 0.037991, accuracy: 0.0383
case acc: 0.0645892
case acc: 0.058626343
case acc: 0.024295028
case acc: 0.029623957
case acc: 0.027860986
case acc: 0.024564682
top acc: 0.0502 ::: bot acc: 0.0791
top acc: 0.0466 ::: bot acc: 0.0715
top acc: 0.0094 ::: bot acc: 0.0429
top acc: 0.0162 ::: bot acc: 0.0433
top acc: 0.0108 ::: bot acc: 0.0471
top acc: 0.0088 ::: bot acc: 0.0409
current epoch: 38
train loss is 0.035504
average val loss: 0.038705, accuracy: 0.0388
average test loss: 0.035925, accuracy: 0.0361
case acc: 0.0522048
case acc: 0.0498183
case acc: 0.025371574
case acc: 0.036411297
case acc: 0.032772318
case acc: 0.020279162
top acc: 0.0378 ::: bot acc: 0.0667
top acc: 0.0378 ::: bot acc: 0.0626
top acc: 0.0099 ::: bot acc: 0.0443
top acc: 0.0223 ::: bot acc: 0.0505
top acc: 0.0148 ::: bot acc: 0.0525
top acc: 0.0064 ::: bot acc: 0.0357
current epoch: 39
train loss is 0.029945
average val loss: 0.038164, accuracy: 0.0382
average test loss: 0.035408, accuracy: 0.0355
case acc: 0.041118313
case acc: 0.04165874
case acc: 0.0287657
case acc: 0.044443905
case acc: 0.03751846
case acc: 0.01965067
top acc: 0.0268 ::: bot acc: 0.0556
top acc: 0.0296 ::: bot acc: 0.0544
top acc: 0.0117 ::: bot acc: 0.0485
top acc: 0.0302 ::: bot acc: 0.0585
top acc: 0.0189 ::: bot acc: 0.0575
top acc: 0.0062 ::: bot acc: 0.0348
current epoch: 40
train loss is 0.025262
average val loss: 0.032592, accuracy: 0.0325
average test loss: 0.029760, accuracy: 0.0297
case acc: 0.024941105
case acc: 0.026468826
case acc: 0.028619355
case acc: 0.04536608
case acc: 0.03531359
case acc: 0.017553264
top acc: 0.0114 ::: bot acc: 0.0390
top acc: 0.0144 ::: bot acc: 0.0392
top acc: 0.0116 ::: bot acc: 0.0483
top acc: 0.0311 ::: bot acc: 0.0594
top acc: 0.0170 ::: bot acc: 0.0552
top acc: 0.0061 ::: bot acc: 0.0318
current epoch: 41
train loss is 0.022544
average val loss: 0.027356, accuracy: 0.0270
average test loss: 0.024645, accuracy: 0.0241
case acc: 0.012738425
case acc: 0.011943567
case acc: 0.027579105
case acc: 0.04359708
case acc: 0.032142226
case acc: 0.016817726
top acc: 0.0067 ::: bot acc: 0.0231
top acc: 0.0043 ::: bot acc: 0.0226
top acc: 0.0111 ::: bot acc: 0.0471
top acc: 0.0293 ::: bot acc: 0.0576
top acc: 0.0142 ::: bot acc: 0.0518
top acc: 0.0062 ::: bot acc: 0.0308
current epoch: 42
train loss is 0.027607
average val loss: 0.020258, accuracy: 0.0208
average test loss: 0.019972, accuracy: 0.0202
case acc: 0.027918415
case acc: 0.030076241
case acc: 0.0150888655
case acc: 0.018821817
case acc: 0.014967812
case acc: 0.014367119
top acc: 0.0422 ::: bot acc: 0.0135
top acc: 0.0421 ::: bot acc: 0.0174
top acc: 0.0206 ::: bot acc: 0.0220
top acc: 0.0076 ::: bot acc: 0.0313
top acc: 0.0134 ::: bot acc: 0.0264
top acc: 0.0263 ::: bot acc: 0.0083
current epoch: 43
train loss is 0.039171
average val loss: 0.054472, accuracy: 0.0545
average test loss: 0.056843, accuracy: 0.0569
case acc: 0.07882701
case acc: 0.09053032
case acc: 0.04636932
case acc: 0.035642784
case acc: 0.043080322
case acc: 0.04685207
top acc: 0.0931 ::: bot acc: 0.0644
top acc: 0.1025 ::: bot acc: 0.0778
top acc: 0.0664 ::: bot acc: 0.0264
top acc: 0.0498 ::: bot acc: 0.0220
top acc: 0.0625 ::: bot acc: 0.0227
top acc: 0.0642 ::: bot acc: 0.0296
current epoch: 44
train loss is 0.053359
average val loss: 0.049013, accuracy: 0.0491
average test loss: 0.051369, accuracy: 0.0514
case acc: 0.06518396
case acc: 0.083373986
case acc: 0.042963978
case acc: 0.038953252
case acc: 0.042173717
case acc: 0.035822496
top acc: 0.0795 ::: bot acc: 0.0508
top acc: 0.0954 ::: bot acc: 0.0706
top acc: 0.0628 ::: bot acc: 0.0234
top acc: 0.0531 ::: bot acc: 0.0252
top acc: 0.0616 ::: bot acc: 0.0218
top acc: 0.0531 ::: bot acc: 0.0186
current epoch: 45
train loss is 0.042416
average val loss: 0.031038, accuracy: 0.0311
average test loss: 0.033141, accuracy: 0.0332
case acc: 0.03687747
case acc: 0.055542786
case acc: 0.029334217
case acc: 0.027659386
case acc: 0.029613866
case acc: 0.020459782
top acc: 0.0512 ::: bot acc: 0.0225
top acc: 0.0676 ::: bot acc: 0.0428
top acc: 0.0478 ::: bot acc: 0.0125
top acc: 0.0414 ::: bot acc: 0.0148
top acc: 0.0489 ::: bot acc: 0.0095
top acc: 0.0364 ::: bot acc: 0.0061
current epoch: 46
train loss is 0.027379
average val loss: 0.027856, accuracy: 0.0279
average test loss: 0.029933, accuracy: 0.0299
case acc: 0.024198927
case acc: 0.040773086
case acc: 0.030993352
case acc: 0.0299882
case acc: 0.031105356
case acc: 0.022631593
top acc: 0.0382 ::: bot acc: 0.0104
top acc: 0.0528 ::: bot acc: 0.0280
top acc: 0.0497 ::: bot acc: 0.0137
top acc: 0.0439 ::: bot acc: 0.0168
top acc: 0.0505 ::: bot acc: 0.0108
top acc: 0.0391 ::: bot acc: 0.0072
current epoch: 47
train loss is 0.019618
average val loss: 0.022572, accuracy: 0.0224
average test loss: 0.024312, accuracy: 0.0242
case acc: 0.012534622
case acc: 0.026222302
case acc: 0.028910894
case acc: 0.030023202
case acc: 0.02913473
case acc: 0.018553436
top acc: 0.0224 ::: bot acc: 0.0072
top acc: 0.0382 ::: bot acc: 0.0137
top acc: 0.0473 ::: bot acc: 0.0123
top acc: 0.0439 ::: bot acc: 0.0169
top acc: 0.0484 ::: bot acc: 0.0091
top acc: 0.0337 ::: bot acc: 0.0057
current epoch: 48
train loss is 0.014998
average val loss: 0.022824, accuracy: 0.0225
average test loss: 0.024405, accuracy: 0.0242
case acc: 0.010467374
case acc: 0.021037774
case acc: 0.03031996
case acc: 0.03364403
case acc: 0.031876698
case acc: 0.017964633
top acc: 0.0167 ::: bot acc: 0.0119
top acc: 0.0327 ::: bot acc: 0.0091
top acc: 0.0490 ::: bot acc: 0.0132
top acc: 0.0477 ::: bot acc: 0.0202
top acc: 0.0513 ::: bot acc: 0.0115
top acc: 0.0329 ::: bot acc: 0.0056
current epoch: 49
train loss is 0.019984
average val loss: 0.023908, accuracy: 0.0235
average test loss: 0.025354, accuracy: 0.0251
case acc: 0.010265377
case acc: 0.015180705
case acc: 0.032703318
case acc: 0.036048885
case acc: 0.035718754
case acc: 0.02044419
top acc: 0.0133 ::: bot acc: 0.0154
top acc: 0.0257 ::: bot acc: 0.0056
top acc: 0.0516 ::: bot acc: 0.0150
top acc: 0.0501 ::: bot acc: 0.0225
top acc: 0.0551 ::: bot acc: 0.0153
top acc: 0.0364 ::: bot acc: 0.0061
current epoch: 50
train loss is 0.029142
average val loss: 0.021201, accuracy: 0.0216
average test loss: 0.019634, accuracy: 0.0205
case acc: 0.037943218
case acc: 0.029707277
case acc: 0.015087078
case acc: 0.010300323
case acc: 0.015743935
case acc: 0.014099252
top acc: 0.0237 ::: bot acc: 0.0523
top acc: 0.0177 ::: bot acc: 0.0425
top acc: 0.0211 ::: bot acc: 0.0215
top acc: 0.0175 ::: bot acc: 0.0105
top acc: 0.0259 ::: bot acc: 0.0139
top acc: 0.0094 ::: bot acc: 0.0252
LME_Co_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6804 6804 6804
1.7082474 -0.6288155 0.10460696 -0.09017589
Validation: 756 756 756
Testing: 768 768 768
pre-processing time: 0.0003323554992675781
the split date is 2011-07-01
net initializing with time: 0.0029573440551757812
preparing training and testing date with time: 2.384185791015625e-07
current epoch: 1
train loss is 0.280169
average val loss: 0.245311, accuracy: 0.2454
average test loss: 0.244686, accuracy: 0.2447
case acc: 0.43484163
case acc: 0.37054956
case acc: 0.03689368
case acc: 0.18748842
case acc: 0.38414043
case acc: 0.05431226
top acc: 0.4444 ::: bot acc: 0.4204
top acc: 0.3819 ::: bot acc: 0.3604
top acc: 0.0568 ::: bot acc: 0.0180
top acc: 0.1986 ::: bot acc: 0.1753
top acc: 0.4004 ::: bot acc: 0.3660
top acc: 0.0704 ::: bot acc: 0.0379
current epoch: 2
train loss is 0.261024
average val loss: 0.148960, accuracy: 0.1488
average test loss: 0.148899, accuracy: 0.1487
case acc: 0.22941035
case acc: 0.17110853
case acc: 0.15127714
case acc: 0.012291281
case acc: 0.18285613
case acc: 0.1451579
top acc: 0.2397 ::: bot acc: 0.2155
top acc: 0.1822 ::: bot acc: 0.1609
top acc: 0.1308 ::: bot acc: 0.1714
top acc: 0.0084 ::: bot acc: 0.0207
top acc: 0.1992 ::: bot acc: 0.1649
top acc: 0.1288 ::: bot acc: 0.1619
current epoch: 3
train loss is 0.151909
average val loss: 0.160279, accuracy: 0.1605
average test loss: 0.160384, accuracy: 0.1607
case acc: 0.29240412
case acc: 0.24064715
case acc: 0.057616286
case acc: 0.07221535
case acc: 0.25137323
case acc: 0.050210662
top acc: 0.3030 ::: bot acc: 0.2787
top acc: 0.2517 ::: bot acc: 0.2304
top acc: 0.0374 ::: bot acc: 0.0776
top acc: 0.0830 ::: bot acc: 0.0606
top acc: 0.2677 ::: bot acc: 0.2334
top acc: 0.0352 ::: bot acc: 0.0664
current epoch: 4
train loss is 0.158108
average val loss: 0.135773, accuracy: 0.1360
average test loss: 0.135868, accuracy: 0.1361
case acc: 0.23730773
case acc: 0.19246924
case acc: 0.07997709
case acc: 0.03604964
case acc: 0.20192578
case acc: 0.068723574
top acc: 0.2482 ::: bot acc: 0.2238
top acc: 0.2034 ::: bot acc: 0.1823
top acc: 0.0595 ::: bot acc: 0.1002
top acc: 0.0467 ::: bot acc: 0.0245
top acc: 0.2183 ::: bot acc: 0.1840
top acc: 0.0522 ::: bot acc: 0.0859
current epoch: 5
train loss is 0.136761
average val loss: 0.129956, accuracy: 0.1302
average test loss: 0.130070, accuracy: 0.1305
case acc: 0.23855138
case acc: 0.20109959
case acc: 0.044706807
case acc: 0.05780956
case acc: 0.20883603
case acc: 0.031917136
top acc: 0.2495 ::: bot acc: 0.2251
top acc: 0.2120 ::: bot acc: 0.1909
top acc: 0.0250 ::: bot acc: 0.0646
top acc: 0.0684 ::: bot acc: 0.0463
top acc: 0.2253 ::: bot acc: 0.1909
top acc: 0.0180 ::: bot acc: 0.0479
current epoch: 6
train loss is 0.125406
average val loss: 0.114383, accuracy: 0.1147
average test loss: 0.114483, accuracy: 0.1149
case acc: 0.20964614
case acc: 0.17943703
case acc: 0.04077632
case acc: 0.04845498
case acc: 0.18552074
case acc: 0.025782397
top acc: 0.2207 ::: bot acc: 0.1963
top acc: 0.1904 ::: bot acc: 0.1693
top acc: 0.0216 ::: bot acc: 0.0604
top acc: 0.0590 ::: bot acc: 0.0370
top acc: 0.2020 ::: bot acc: 0.1676
top acc: 0.0132 ::: bot acc: 0.0413
current epoch: 7
train loss is 0.113638
average val loss: 0.105118, accuracy: 0.1056
average test loss: 0.104767, accuracy: 0.1055
case acc: 0.19441158
case acc: 0.17154048
case acc: 0.025192015
case acc: 0.052656073
case acc: 0.17592978
case acc: 0.013259725
top acc: 0.2057 ::: bot acc: 0.1812
top acc: 0.1824 ::: bot acc: 0.1614
top acc: 0.0103 ::: bot acc: 0.0428
top acc: 0.0632 ::: bot acc: 0.0411
top acc: 0.1924 ::: bot acc: 0.1579
top acc: 0.0133 ::: bot acc: 0.0220
current epoch: 8
train loss is 0.101102
average val loss: 0.090940, accuracy: 0.0915
average test loss: 0.090436, accuracy: 0.0912
case acc: 0.16582802
case acc: 0.15023977
case acc: 0.022439728
case acc: 0.04286543
case acc: 0.15294552
case acc: 0.013102839
top acc: 0.1773 ::: bot acc: 0.1528
top acc: 0.1611 ::: bot acc: 0.1402
top acc: 0.0089 ::: bot acc: 0.0395
top acc: 0.0534 ::: bot acc: 0.0314
top acc: 0.1695 ::: bot acc: 0.1350
top acc: 0.0187 ::: bot acc: 0.0169
current epoch: 9
train loss is 0.089583
average val loss: 0.089510, accuracy: 0.0901
average test loss: 0.088563, accuracy: 0.0893
case acc: 0.15424979
case acc: 0.14613909
case acc: 0.014782732
case acc: 0.050061937
case acc: 0.14707483
case acc: 0.023757977
top acc: 0.1658 ::: bot acc: 0.1412
top acc: 0.1569 ::: bot acc: 0.1361
top acc: 0.0219 ::: bot acc: 0.0190
top acc: 0.0606 ::: bot acc: 0.0386
top acc: 0.1636 ::: bot acc: 0.1291
top acc: 0.0395 ::: bot acc: 0.0088
current epoch: 10
train loss is 0.079614
average val loss: 0.078852, accuracy: 0.0794
average test loss: 0.077881, accuracy: 0.0785
case acc: 0.12865531
case acc: 0.1281638
case acc: 0.015944147
case acc: 0.04298097
case acc: 0.12744811
case acc: 0.02804489
top acc: 0.1403 ::: bot acc: 0.1157
top acc: 0.1389 ::: bot acc: 0.1181
top acc: 0.0275 ::: bot acc: 0.0134
top acc: 0.0535 ::: bot acc: 0.0315
top acc: 0.1440 ::: bot acc: 0.1094
top acc: 0.0442 ::: bot acc: 0.0122
current epoch: 11
train loss is 0.068798
average val loss: 0.073035, accuracy: 0.0734
average test loss: 0.072105, accuracy: 0.0725
case acc: 0.1083061
case acc: 0.11556485
case acc: 0.021340368
case acc: 0.04081429
case acc: 0.113142475
case acc: 0.035762288
top acc: 0.1200 ::: bot acc: 0.0954
top acc: 0.1264 ::: bot acc: 0.1055
top acc: 0.0378 ::: bot acc: 0.0090
top acc: 0.0514 ::: bot acc: 0.0293
top acc: 0.1298 ::: bot acc: 0.0950
top acc: 0.0524 ::: bot acc: 0.0189
current epoch: 12
train loss is 0.060856
average val loss: 0.069929, accuracy: 0.0701
average test loss: 0.069014, accuracy: 0.0691
case acc: 0.09118438
case acc: 0.10639126
case acc: 0.031015163
case acc: 0.041290767
case acc: 0.1022735
case acc: 0.04265032
top acc: 0.1030 ::: bot acc: 0.0784
top acc: 0.1172 ::: bot acc: 0.0963
top acc: 0.0502 ::: bot acc: 0.0132
top acc: 0.0518 ::: bot acc: 0.0298
top acc: 0.1189 ::: bot acc: 0.0842
top acc: 0.0596 ::: bot acc: 0.0253
current epoch: 13
train loss is 0.053004
average val loss: 0.058287, accuracy: 0.0584
average test loss: 0.057368, accuracy: 0.0574
case acc: 0.06628772
case acc: 0.08955544
case acc: 0.0337924
case acc: 0.033243112
case acc: 0.0836993
case acc: 0.038012262
top acc: 0.0783 ::: bot acc: 0.0536
top acc: 0.1004 ::: bot acc: 0.0794
top acc: 0.0532 ::: bot acc: 0.0154
top acc: 0.0437 ::: bot acc: 0.0218
top acc: 0.1004 ::: bot acc: 0.0656
top acc: 0.0548 ::: bot acc: 0.0209
current epoch: 14
train loss is 0.044305
average val loss: 0.053330, accuracy: 0.0534
average test loss: 0.052415, accuracy: 0.0524
case acc: 0.050266467
case acc: 0.080832675
case acc: 0.042257033
case acc: 0.031932887
case acc: 0.072879046
case acc: 0.036184583
top acc: 0.0624 ::: bot acc: 0.0376
top acc: 0.0916 ::: bot acc: 0.0706
top acc: 0.0622 ::: bot acc: 0.0226
top acc: 0.0424 ::: bot acc: 0.0205
top acc: 0.0896 ::: bot acc: 0.0548
top acc: 0.0529 ::: bot acc: 0.0192
current epoch: 15
train loss is 0.037598
average val loss: 0.047735, accuracy: 0.0477
average test loss: 0.046851, accuracy: 0.0468
case acc: 0.036537148
case acc: 0.07255942
case acc: 0.04894817
case acc: 0.02960487
case acc: 0.06255388
case acc: 0.030525599
top acc: 0.0488 ::: bot acc: 0.0239
top acc: 0.0833 ::: bot acc: 0.0623
top acc: 0.0690 ::: bot acc: 0.0289
top acc: 0.0400 ::: bot acc: 0.0182
top acc: 0.0791 ::: bot acc: 0.0448
top acc: 0.0469 ::: bot acc: 0.0142
current epoch: 16
train loss is 0.032342
average val loss: 0.045598, accuracy: 0.0455
average test loss: 0.044768, accuracy: 0.0447
case acc: 0.029186163
case acc: 0.0684074
case acc: 0.0570872
case acc: 0.030242367
case acc: 0.056517504
case acc: 0.026784297
top acc: 0.0415 ::: bot acc: 0.0168
top acc: 0.0792 ::: bot acc: 0.0582
top acc: 0.0771 ::: bot acc: 0.0370
top acc: 0.0407 ::: bot acc: 0.0189
top acc: 0.0730 ::: bot acc: 0.0390
top acc: 0.0428 ::: bot acc: 0.0111
current epoch: 17
train loss is 0.030175
average val loss: 0.059605, accuracy: 0.0595
average test loss: 0.058810, accuracy: 0.0588
case acc: 0.039654844
case acc: 0.08071594
case acc: 0.07902737
case acc: 0.046958417
case acc: 0.06755919
case acc: 0.038941115
top acc: 0.0521 ::: bot acc: 0.0271
top acc: 0.0915 ::: bot acc: 0.0705
top acc: 0.0990 ::: bot acc: 0.0590
top acc: 0.0574 ::: bot acc: 0.0356
top acc: 0.0842 ::: bot acc: 0.0496
top acc: 0.0555 ::: bot acc: 0.0220
current epoch: 18
train loss is 0.033639
average val loss: 0.078708, accuracy: 0.0787
average test loss: 0.077950, accuracy: 0.0780
case acc: 0.053856477
case acc: 0.098178566
case acc: 0.10438058
case acc: 0.06935415
case acc: 0.085060865
case acc: 0.056912437
top acc: 0.0664 ::: bot acc: 0.0414
top acc: 0.1089 ::: bot acc: 0.0880
top acc: 0.1243 ::: bot acc: 0.0844
top acc: 0.0798 ::: bot acc: 0.0580
top acc: 0.1017 ::: bot acc: 0.0670
top acc: 0.0738 ::: bot acc: 0.0393
current epoch: 19
train loss is 0.042495
average val loss: 0.094553, accuracy: 0.0945
average test loss: 0.093857, accuracy: 0.0939
case acc: 0.062575676
case acc: 0.112780035
case acc: 0.12513904
case acc: 0.08954457
case acc: 0.10111125
case acc: 0.071951
top acc: 0.0751 ::: bot acc: 0.0501
top acc: 0.1234 ::: bot acc: 0.1026
top acc: 0.1451 ::: bot acc: 0.1051
top acc: 0.1000 ::: bot acc: 0.0783
top acc: 0.1178 ::: bot acc: 0.0830
top acc: 0.0890 ::: bot acc: 0.0539
current epoch: 20
train loss is 0.059514
average val loss: 0.059880, accuracy: 0.0597
average test loss: 0.059200, accuracy: 0.0591
case acc: 0.020192306
case acc: 0.07637532
case acc: 0.08918159
case acc: 0.05884283
case acc: 0.06903395
case acc: 0.04088159
top acc: 0.0324 ::: bot acc: 0.0086
top acc: 0.0870 ::: bot acc: 0.0663
top acc: 0.1091 ::: bot acc: 0.0691
top acc: 0.0692 ::: bot acc: 0.0476
top acc: 0.0856 ::: bot acc: 0.0511
top acc: 0.0574 ::: bot acc: 0.0240
current epoch: 21
train loss is 0.064805
average val loss: 0.021569, accuracy: 0.0221
average test loss: 0.020927, accuracy: 0.0209
case acc: 0.055206515
case acc: 0.007642456
case acc: 0.017067518
case acc: 0.01295284
case acc: 0.012716724
case acc: 0.019581378
top acc: 0.0425 ::: bot acc: 0.0676
top acc: 0.0128 ::: bot acc: 0.0079
top acc: 0.0305 ::: bot acc: 0.0103
top acc: 0.0053 ::: bot acc: 0.0228
top acc: 0.0177 ::: bot acc: 0.0171
top acc: 0.0084 ::: bot acc: 0.0347
current epoch: 22
train loss is 0.050733
average val loss: 0.020649, accuracy: 0.0213
average test loss: 0.019998, accuracy: 0.0205
case acc: 0.053233057
case acc: 0.009159426
case acc: 0.014809196
case acc: 0.02035098
case acc: 0.012564976
case acc: 0.012913938
top acc: 0.0405 ::: bot acc: 0.0656
top acc: 0.0052 ::: bot acc: 0.0161
top acc: 0.0150 ::: bot acc: 0.0250
top acc: 0.0109 ::: bot acc: 0.0311
top acc: 0.0146 ::: bot acc: 0.0201
top acc: 0.0127 ::: bot acc: 0.0224
current epoch: 23
train loss is 0.036802
average val loss: 0.020963, accuracy: 0.0213
average test loss: 0.020481, accuracy: 0.0209
case acc: 0.043281883
case acc: 0.010247479
case acc: 0.019327767
case acc: 0.023501944
case acc: 0.0125898225
case acc: 0.016185176
top acc: 0.0305 ::: bot acc: 0.0556
top acc: 0.0045 ::: bot acc: 0.0180
top acc: 0.0084 ::: bot acc: 0.0350
top acc: 0.0136 ::: bot acc: 0.0344
top acc: 0.0167 ::: bot acc: 0.0180
top acc: 0.0284 ::: bot acc: 0.0080
current epoch: 24
train loss is 0.028764
average val loss: 0.029736, accuracy: 0.0299
average test loss: 0.029803, accuracy: 0.0301
case acc: 0.0476856
case acc: 0.023212083
case acc: 0.039532647
case acc: 0.04066033
case acc: 0.016155165
case acc: 0.013556897
top acc: 0.0349 ::: bot acc: 0.0599
top acc: 0.0130 ::: bot acc: 0.0331
top acc: 0.0212 ::: bot acc: 0.0588
top acc: 0.0302 ::: bot acc: 0.0519
top acc: 0.0072 ::: bot acc: 0.0305
top acc: 0.0219 ::: bot acc: 0.0132
current epoch: 25
train loss is 0.032045
average val loss: 0.047726, accuracy: 0.0477
average test loss: 0.048215, accuracy: 0.0483
case acc: 0.05915417
case acc: 0.04402404
case acc: 0.06792341
case acc: 0.06597988
case acc: 0.03373327
case acc: 0.01911171
top acc: 0.0464 ::: bot acc: 0.0714
top acc: 0.0335 ::: bot acc: 0.0541
top acc: 0.0480 ::: bot acc: 0.0880
top acc: 0.0556 ::: bot acc: 0.0772
top acc: 0.0179 ::: bot acc: 0.0514
top acc: 0.0082 ::: bot acc: 0.0342
current epoch: 26
train loss is 0.055102
average val loss: 0.026116, accuracy: 0.0260
average test loss: 0.026007, accuracy: 0.0262
case acc: 0.023749195
case acc: 0.017104397
case acc: 0.043827843
case acc: 0.043761976
case acc: 0.01411034
case acc: 0.014374268
top acc: 0.0120 ::: bot acc: 0.0354
top acc: 0.0076 ::: bot acc: 0.0267
top acc: 0.0248 ::: bot acc: 0.0635
top acc: 0.0333 ::: bot acc: 0.0550
top acc: 0.0082 ::: bot acc: 0.0269
top acc: 0.0244 ::: bot acc: 0.0107
current epoch: 27
train loss is 0.063168
average val loss: 0.051519, accuracy: 0.0517
average test loss: 0.051029, accuracy: 0.0510
case acc: 0.057515867
case acc: 0.05934821
case acc: 0.034694076
case acc: 0.027564062
case acc: 0.061224997
case acc: 0.06544225
top acc: 0.0703 ::: bot acc: 0.0453
top acc: 0.0698 ::: bot acc: 0.0493
top acc: 0.0541 ::: bot acc: 0.0158
top acc: 0.0380 ::: bot acc: 0.0164
top acc: 0.0777 ::: bot acc: 0.0435
top acc: 0.0824 ::: bot acc: 0.0476
current epoch: 28
train loss is 0.043663
average val loss: 0.034218, accuracy: 0.0342
average test loss: 0.033637, accuracy: 0.0336
case acc: 0.037785925
case acc: 0.045398444
case acc: 0.028099326
case acc: 0.014909975
case acc: 0.04272253
case acc: 0.032391176
top acc: 0.0506 ::: bot acc: 0.0256
top acc: 0.0559 ::: bot acc: 0.0353
top acc: 0.0468 ::: bot acc: 0.0108
top acc: 0.0242 ::: bot acc: 0.0060
top acc: 0.0588 ::: bot acc: 0.0258
top acc: 0.0486 ::: bot acc: 0.0161
current epoch: 29
train loss is 0.030271
average val loss: 0.031054, accuracy: 0.0309
average test loss: 0.030358, accuracy: 0.0303
case acc: 0.030972004
case acc: 0.0449123
case acc: 0.03525047
case acc: 0.0157275
case acc: 0.03784314
case acc: 0.017201526
top acc: 0.0438 ::: bot acc: 0.0189
top acc: 0.0554 ::: bot acc: 0.0348
top acc: 0.0547 ::: bot acc: 0.0163
top acc: 0.0252 ::: bot acc: 0.0065
top acc: 0.0538 ::: bot acc: 0.0212
top acc: 0.0304 ::: bot acc: 0.0071
current epoch: 30
train loss is 0.024449
average val loss: 0.041932, accuracy: 0.0419
average test loss: 0.041366, accuracy: 0.0414
case acc: 0.03916859
case acc: 0.057940457
case acc: 0.057116553
case acc: 0.029846024
case acc: 0.04656659
case acc: 0.018022003
top acc: 0.0520 ::: bot acc: 0.0270
top acc: 0.0684 ::: bot acc: 0.0479
top acc: 0.0771 ::: bot acc: 0.0370
top acc: 0.0403 ::: bot acc: 0.0187
top acc: 0.0628 ::: bot acc: 0.0294
top acc: 0.0317 ::: bot acc: 0.0070
current epoch: 31
train loss is 0.025259
average val loss: 0.066436, accuracy: 0.0664
average test loss: 0.065969, accuracy: 0.0660
case acc: 0.05693204
case acc: 0.082077295
case acc: 0.09331697
case acc: 0.058628798
case acc: 0.06803842
case acc: 0.037069887
top acc: 0.0698 ::: bot acc: 0.0448
top acc: 0.0926 ::: bot acc: 0.0720
top acc: 0.1133 ::: bot acc: 0.0732
top acc: 0.0691 ::: bot acc: 0.0475
top acc: 0.0846 ::: bot acc: 0.0501
top acc: 0.0534 ::: bot acc: 0.0204
current epoch: 32
train loss is 0.045946
average val loss: 0.072194, accuracy: 0.0721
average test loss: 0.071726, accuracy: 0.0717
case acc: 0.052747715
case acc: 0.08589562
case acc: 0.10602528
case acc: 0.06879341
case acc: 0.07277537
case acc: 0.044239853
top acc: 0.0655 ::: bot acc: 0.0406
top acc: 0.0964 ::: bot acc: 0.0759
top acc: 0.1260 ::: bot acc: 0.0859
top acc: 0.0793 ::: bot acc: 0.0577
top acc: 0.0894 ::: bot acc: 0.0547
top acc: 0.0608 ::: bot acc: 0.0271
current epoch: 33
train loss is 0.060989
average val loss: 0.020105, accuracy: 0.0203
average test loss: 0.019331, accuracy: 0.0189
case acc: 0.023303736
case acc: 0.015657546
case acc: 0.03570557
case acc: 0.00852768
case acc: 0.014689004
case acc: 0.015427149
top acc: 0.0118 ::: bot acc: 0.0349
top acc: 0.0261 ::: bot acc: 0.0057
top acc: 0.0552 ::: bot acc: 0.0167
top acc: 0.0140 ::: bot acc: 0.0076
top acc: 0.0245 ::: bot acc: 0.0106
top acc: 0.0080 ::: bot acc: 0.0287
current epoch: 34
train loss is 0.047551
average val loss: 0.019820, accuracy: 0.0202
average test loss: 0.019382, accuracy: 0.0195
case acc: 0.03979688
case acc: 0.009989008
case acc: 0.015195681
case acc: 0.01960188
case acc: 0.014842646
case acc: 0.017341536
top acc: 0.0270 ::: bot acc: 0.0520
top acc: 0.0044 ::: bot acc: 0.0176
top acc: 0.0255 ::: bot acc: 0.0146
top acc: 0.0103 ::: bot acc: 0.0302
top acc: 0.0075 ::: bot acc: 0.0283
top acc: 0.0075 ::: bot acc: 0.0318
current epoch: 35
train loss is 0.031590
average val loss: 0.015536, accuracy: 0.0157
average test loss: 0.014547, accuracy: 0.0145
case acc: 0.021558927
case acc: 0.0074563385
case acc: 0.015455289
case acc: 0.012756621
case acc: 0.0130087305
case acc: 0.017055089
top acc: 0.0106 ::: bot acc: 0.0328
top acc: 0.0120 ::: bot acc: 0.0085
top acc: 0.0264 ::: bot acc: 0.0137
top acc: 0.0052 ::: bot acc: 0.0224
top acc: 0.0195 ::: bot acc: 0.0153
top acc: 0.0302 ::: bot acc: 0.0070
current epoch: 36
train loss is 0.023643
average val loss: 0.016643, accuracy: 0.0168
average test loss: 0.015989, accuracy: 0.0163
case acc: 0.02108666
case acc: 0.0091868285
case acc: 0.017365295
case acc: 0.021251895
case acc: 0.012543021
case acc: 0.01636884
top acc: 0.0103 ::: bot acc: 0.0323
top acc: 0.0050 ::: bot acc: 0.0161
top acc: 0.0098 ::: bot acc: 0.0314
top acc: 0.0117 ::: bot acc: 0.0319
top acc: 0.0150 ::: bot acc: 0.0198
top acc: 0.0289 ::: bot acc: 0.0076
current epoch: 37
train loss is 0.020436
average val loss: 0.023434, accuracy: 0.0235
average test loss: 0.023403, accuracy: 0.0236
case acc: 0.024666343
case acc: 0.017920092
case acc: 0.03367608
case acc: 0.035853233
case acc: 0.016275583
case acc: 0.012922082
top acc: 0.0129 ::: bot acc: 0.0363
top acc: 0.0083 ::: bot acc: 0.0275
top acc: 0.0161 ::: bot acc: 0.0526
top acc: 0.0254 ::: bot acc: 0.0470
top acc: 0.0072 ::: bot acc: 0.0306
top acc: 0.0124 ::: bot acc: 0.0225
current epoch: 38
train loss is 0.023359
average val loss: 0.030829, accuracy: 0.0308
average test loss: 0.031097, accuracy: 0.0311
case acc: 0.024765896
case acc: 0.026052037
case acc: 0.04712063
case acc: 0.048323162
case acc: 0.023246521
case acc: 0.017030356
top acc: 0.0129 ::: bot acc: 0.0364
top acc: 0.0158 ::: bot acc: 0.0359
top acc: 0.0278 ::: bot acc: 0.0669
top acc: 0.0379 ::: bot acc: 0.0595
top acc: 0.0095 ::: bot acc: 0.0399
top acc: 0.0075 ::: bot acc: 0.0314
current epoch: 39
train loss is 0.029260
average val loss: 0.036190, accuracy: 0.0360
average test loss: 0.036567, accuracy: 0.0366
case acc: 0.022019017
case acc: 0.031371944
case acc: 0.055927567
case acc: 0.058503117
case acc: 0.029937636
case acc: 0.021620063
top acc: 0.0109 ::: bot acc: 0.0333
top acc: 0.0210 ::: bot acc: 0.0413
top acc: 0.0362 ::: bot acc: 0.0759
top acc: 0.0480 ::: bot acc: 0.0697
top acc: 0.0146 ::: bot acc: 0.0473
top acc: 0.0097 ::: bot acc: 0.0371
current epoch: 40
train loss is 0.047780
average val loss: 0.027021, accuracy: 0.0270
average test loss: 0.026291, accuracy: 0.0264
case acc: 0.045241363
case acc: 0.028853562
case acc: 0.015460495
case acc: 0.007939791
case acc: 0.027400447
case acc: 0.03332135
top acc: 0.0581 ::: bot acc: 0.0331
top acc: 0.0394 ::: bot acc: 0.0189
top acc: 0.0265 ::: bot acc: 0.0135
top acc: 0.0078 ::: bot acc: 0.0139
top acc: 0.0426 ::: bot acc: 0.0123
top acc: 0.0495 ::: bot acc: 0.0171
current epoch: 41
train loss is 0.048156
average val loss: 0.044781, accuracy: 0.0448
average test loss: 0.044343, accuracy: 0.0443
case acc: 0.065548256
case acc: 0.053884298
case acc: 0.038168106
case acc: 0.022258898
case acc: 0.04665923
case acc: 0.039154794
top acc: 0.0784 ::: bot acc: 0.0534
top acc: 0.0644 ::: bot acc: 0.0439
top acc: 0.0577 ::: bot acc: 0.0188
top acc: 0.0325 ::: bot acc: 0.0115
top acc: 0.0629 ::: bot acc: 0.0295
top acc: 0.0556 ::: bot acc: 0.0224
current epoch: 42
train loss is 0.033889
average val loss: 0.044967, accuracy: 0.0450
average test loss: 0.044557, accuracy: 0.0446
case acc: 0.05830529
case acc: 0.05678888
case acc: 0.05063357
case acc: 0.028693214
case acc: 0.046428192
case acc: 0.026490472
top acc: 0.0711 ::: bot acc: 0.0462
top acc: 0.0673 ::: bot acc: 0.0468
top acc: 0.0706 ::: bot acc: 0.0305
top acc: 0.0392 ::: bot acc: 0.0175
top acc: 0.0627 ::: bot acc: 0.0292
top acc: 0.0422 ::: bot acc: 0.0112
current epoch: 43
train loss is 0.029263
average val loss: 0.061226, accuracy: 0.0612
average test loss: 0.060771, accuracy: 0.0608
case acc: 0.064418636
case acc: 0.07357207
case acc: 0.08005565
case acc: 0.051292837
case acc: 0.061028123
case acc: 0.03465636
top acc: 0.0772 ::: bot acc: 0.0523
top acc: 0.0841 ::: bot acc: 0.0636
top acc: 0.1000 ::: bot acc: 0.0600
top acc: 0.0618 ::: bot acc: 0.0401
top acc: 0.0775 ::: bot acc: 0.0433
top acc: 0.0508 ::: bot acc: 0.0183
current epoch: 44
train loss is 0.045285
average val loss: 0.054325, accuracy: 0.0542
average test loss: 0.053883, accuracy: 0.0540
case acc: 0.04691703
case acc: 0.065325975
case acc: 0.080065556
case acc: 0.049596462
case acc: 0.054132067
case acc: 0.027685104
top acc: 0.0597 ::: bot acc: 0.0347
top acc: 0.0759 ::: bot acc: 0.0553
top acc: 0.1000 ::: bot acc: 0.0600
top acc: 0.0601 ::: bot acc: 0.0384
top acc: 0.0705 ::: bot acc: 0.0366
top acc: 0.0434 ::: bot acc: 0.0122
current epoch: 45
train loss is 0.051895
average val loss: 0.017216, accuracy: 0.0173
average test loss: 0.016200, accuracy: 0.0158
case acc: 0.012691574
case acc: 0.0144397095
case acc: 0.030209845
case acc: 0.008699127
case acc: 0.014770282
case acc: 0.013902914
top acc: 0.0068 ::: bot acc: 0.0215
top acc: 0.0248 ::: bot acc: 0.0048
top acc: 0.0491 ::: bot acc: 0.0122
top acc: 0.0143 ::: bot acc: 0.0075
top acc: 0.0247 ::: bot acc: 0.0105
top acc: 0.0090 ::: bot acc: 0.0259
current epoch: 46
train loss is 0.032927
average val loss: 0.017105, accuracy: 0.0169
average test loss: 0.015982, accuracy: 0.0156
case acc: 0.010875098
case acc: 0.01426787
case acc: 0.0259444
case acc: 0.0093603255
case acc: 0.017295204
case acc: 0.016118951
top acc: 0.0074 ::: bot acc: 0.0185
top acc: 0.0246 ::: bot acc: 0.0047
top acc: 0.0440 ::: bot acc: 0.0098
top acc: 0.0159 ::: bot acc: 0.0063
top acc: 0.0294 ::: bot acc: 0.0085
top acc: 0.0283 ::: bot acc: 0.0078
current epoch: 47
train loss is 0.024795
average val loss: 0.015369, accuracy: 0.0153
average test loss: 0.014151, accuracy: 0.0139
case acc: 0.012072658
case acc: 0.009425582
case acc: 0.01670339
case acc: 0.00785153
case acc: 0.016116653
case acc: 0.021002265
top acc: 0.0069 ::: bot acc: 0.0205
top acc: 0.0182 ::: bot acc: 0.0030
top acc: 0.0299 ::: bot acc: 0.0104
top acc: 0.0100 ::: bot acc: 0.0118
top acc: 0.0275 ::: bot acc: 0.0089
top acc: 0.0355 ::: bot acc: 0.0080
current epoch: 48
train loss is 0.017945
average val loss: 0.014152, accuracy: 0.0142
average test loss: 0.013112, accuracy: 0.0133
case acc: 0.0154451355
case acc: 0.0076100933
case acc: 0.01598441
case acc: 0.012271104
case acc: 0.013336111
case acc: 0.015420853
top acc: 0.0075 ::: bot acc: 0.0252
top acc: 0.0090 ::: bot acc: 0.0115
top acc: 0.0119 ::: bot acc: 0.0283
top acc: 0.0049 ::: bot acc: 0.0220
top acc: 0.0208 ::: bot acc: 0.0140
top acc: 0.0269 ::: bot acc: 0.0087
current epoch: 49
train loss is 0.016998
average val loss: 0.016767, accuracy: 0.0169
average test loss: 0.016210, accuracy: 0.0165
case acc: 0.016554622
case acc: 0.010804325
case acc: 0.025364716
case acc: 0.021042297
case acc: 0.012568377
case acc: 0.012420658
top acc: 0.0080 ::: bot acc: 0.0267
top acc: 0.0044 ::: bot acc: 0.0188
top acc: 0.0106 ::: bot acc: 0.0429
top acc: 0.0113 ::: bot acc: 0.0319
top acc: 0.0138 ::: bot acc: 0.0210
top acc: 0.0155 ::: bot acc: 0.0193
current epoch: 50
train loss is 0.017274
average val loss: 0.021446, accuracy: 0.0215
average test loss: 0.021297, accuracy: 0.0214
case acc: 0.017112333
case acc: 0.017140478
case acc: 0.034801885
case acc: 0.030935237
case acc: 0.015407791
case acc: 0.013073938
top acc: 0.0083 ::: bot acc: 0.0274
top acc: 0.0076 ::: bot acc: 0.0266
top acc: 0.0171 ::: bot acc: 0.0538
top acc: 0.0204 ::: bot acc: 0.0422
top acc: 0.0073 ::: bot acc: 0.0293
top acc: 0.0113 ::: bot acc: 0.0235

		{"drop_out": 0.6, "drop_out_mc": 0.1, "repeat_mc": 50, "hidden": 20, "embedding_size": 5, "batch": 512, "lag": 3}
{'generate_norm_params': 'v1', 'generate_tech_params': 'v3', 'generate_strat_params': None, 'generate_SD_params': 'v1', 'deal_with_abnormal_value': 'v2', 'labelling': 'v3', 'process_missing_value': 'v1', 'strategy_signal': None, 'normalize_without_1d_return': 'v1', 'technical_indication': 'v4', 'supply_and_demand': None, 'remove_unused_columns': 'v6', 'price_normalization': 'v3', 'scaling': None, 'construct': 'v4'}
LME_Co_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6798 6798 6798
1.8562728 -0.6288155 0.09756618 -0.123651974
Validation: 756 756 756
Testing: 774 774 774
pre-processing time: 0.0002288818359375
the split date is 2009-07-01
net initializing with time: 0.003583669662475586
preparing training and testing date with time: 0.0
current epoch: 1
train loss is 0.483695
average val loss: 0.426696, accuracy: 0.4267
average test loss: 0.425899, accuracy: 0.4259
case acc: 0.3632601
case acc: 0.5070758
case acc: 0.4013899
case acc: 0.2634799
case acc: 0.5800089
case acc: 0.44017828
top acc: 0.3720 ::: bot acc: 0.3549
top acc: 0.5190 ::: bot acc: 0.4951
top acc: 0.4162 ::: bot acc: 0.3857
top acc: 0.2744 ::: bot acc: 0.2523
top acc: 0.5921 ::: bot acc: 0.5685
top acc: 0.4508 ::: bot acc: 0.4290
current epoch: 2
train loss is 0.179137
average val loss: 0.080893, accuracy: 0.0806
average test loss: 0.081275, accuracy: 0.0817
case acc: 0.08079625
case acc: 0.058046076
case acc: 0.038134474
case acc: 0.17378625
case acc: 0.130099
case acc: 0.009373699
top acc: 0.0717 ::: bot acc: 0.0894
top acc: 0.0698 ::: bot acc: 0.0462
top acc: 0.0233 ::: bot acc: 0.0536
top acc: 0.1632 ::: bot acc: 0.1847
top acc: 0.1421 ::: bot acc: 0.1184
top acc: 0.0083 ::: bot acc: 0.0144
current epoch: 3
train loss is 0.127991
average val loss: 0.084725, accuracy: 0.0851
average test loss: 0.084673, accuracy: 0.0848
case acc: 0.021209814
case acc: 0.108990945
case acc: 0.023052592
case acc: 0.107314914
case acc: 0.18886112
case acc: 0.059538674
top acc: 0.0121 ::: bot acc: 0.0299
top acc: 0.1207 ::: bot acc: 0.0972
top acc: 0.0374 ::: bot acc: 0.0097
top acc: 0.0971 ::: bot acc: 0.1179
top acc: 0.2008 ::: bot acc: 0.1771
top acc: 0.0704 ::: bot acc: 0.0482
current epoch: 4
train loss is 0.115230
average val loss: 0.095543, accuracy: 0.0956
average test loss: 0.095065, accuracy: 0.0950
case acc: 0.012262509
case acc: 0.13949485
case acc: 0.054198064
case acc: 0.07356819
case acc: 0.20259954
case acc: 0.08761319
top acc: 0.0206 ::: bot acc: 0.0050
top acc: 0.1513 ::: bot acc: 0.1277
top acc: 0.0700 ::: bot acc: 0.0381
top acc: 0.0636 ::: bot acc: 0.0840
top acc: 0.2146 ::: bot acc: 0.1908
top acc: 0.0986 ::: bot acc: 0.0763
current epoch: 5
train loss is 0.094734
average val loss: 0.073103, accuracy: 0.0736
average test loss: 0.072930, accuracy: 0.0733
case acc: 0.02858554
case acc: 0.09447545
case acc: 0.018507823
case acc: 0.11043751
case acc: 0.1435728
case acc: 0.04393645
top acc: 0.0195 ::: bot acc: 0.0375
top acc: 0.1063 ::: bot acc: 0.0826
top acc: 0.0320 ::: bot acc: 0.0073
top acc: 0.1006 ::: bot acc: 0.1208
top acc: 0.1557 ::: bot acc: 0.1318
top acc: 0.0550 ::: bot acc: 0.0326
current epoch: 6
train loss is 0.090805
average val loss: 0.069203, accuracy: 0.0697
average test loss: 0.068993, accuracy: 0.0692
case acc: 0.025537502
case acc: 0.09050072
case acc: 0.021991663
case acc: 0.103968054
case acc: 0.12892967
case acc: 0.044298284
top acc: 0.0164 ::: bot acc: 0.0344
top acc: 0.1024 ::: bot acc: 0.0786
top acc: 0.0366 ::: bot acc: 0.0087
top acc: 0.0941 ::: bot acc: 0.1144
top acc: 0.1410 ::: bot acc: 0.1171
top acc: 0.0554 ::: bot acc: 0.0329
current epoch: 7
train loss is 0.086883
average val loss: 0.067116, accuracy: 0.0675
average test loss: 0.066865, accuracy: 0.0669
case acc: 0.017592123
case acc: 0.09311255
case acc: 0.03044725
case acc: 0.093484774
case acc: 0.11817701
case acc: 0.048564505
top acc: 0.0087 ::: bot acc: 0.0264
top acc: 0.1050 ::: bot acc: 0.0813
top acc: 0.0461 ::: bot acc: 0.0152
top acc: 0.0836 ::: bot acc: 0.1039
top acc: 0.1302 ::: bot acc: 0.1064
top acc: 0.0597 ::: bot acc: 0.0372
current epoch: 8
train loss is 0.080046
average val loss: 0.061280, accuracy: 0.0617
average test loss: 0.061001, accuracy: 0.0611
case acc: 0.02072857
case acc: 0.08457719
case acc: 0.02911865
case acc: 0.09440319
case acc: 0.0962049
case acc: 0.04141437
top acc: 0.0116 ::: bot acc: 0.0297
top acc: 0.0965 ::: bot acc: 0.0727
top acc: 0.0448 ::: bot acc: 0.0140
top acc: 0.0846 ::: bot acc: 0.1048
top acc: 0.1082 ::: bot acc: 0.0844
top acc: 0.0525 ::: bot acc: 0.0300
current epoch: 9
train loss is 0.071560
average val loss: 0.055059, accuracy: 0.0555
average test loss: 0.054754, accuracy: 0.0549
case acc: 0.025388952
case acc: 0.07370845
case acc: 0.026273891
case acc: 0.09653907
case acc: 0.073942035
case acc: 0.03346207
top acc: 0.0162 ::: bot acc: 0.0344
top acc: 0.0857 ::: bot acc: 0.0619
top acc: 0.0418 ::: bot acc: 0.0115
top acc: 0.0868 ::: bot acc: 0.1070
top acc: 0.0860 ::: bot acc: 0.0621
top acc: 0.0447 ::: bot acc: 0.0219
current epoch: 10
train loss is 0.067591
average val loss: 0.049901, accuracy: 0.0503
average test loss: 0.049578, accuracy: 0.0497
case acc: 0.026921287
case acc: 0.065244764
case acc: 0.025790613
case acc: 0.09534391
case acc: 0.0558321
case acc: 0.029200299
top acc: 0.0178 ::: bot acc: 0.0360
top acc: 0.0772 ::: bot acc: 0.0534
top acc: 0.0414 ::: bot acc: 0.0111
top acc: 0.0857 ::: bot acc: 0.1057
top acc: 0.0679 ::: bot acc: 0.0440
top acc: 0.0404 ::: bot acc: 0.0177
current epoch: 11
train loss is 0.063514
average val loss: 0.047211, accuracy: 0.0476
average test loss: 0.046869, accuracy: 0.0469
case acc: 0.021561187
case acc: 0.064766265
case acc: 0.031418283
case acc: 0.0876184
case acc: 0.04478373
case acc: 0.031418942
top acc: 0.0124 ::: bot acc: 0.0306
top acc: 0.0768 ::: bot acc: 0.0529
top acc: 0.0474 ::: bot acc: 0.0159
top acc: 0.0780 ::: bot acc: 0.0980
top acc: 0.0568 ::: bot acc: 0.0329
top acc: 0.0426 ::: bot acc: 0.0199
current epoch: 12
train loss is 0.059850
average val loss: 0.046210, accuracy: 0.0464
average test loss: 0.045823, accuracy: 0.0457
case acc: 0.01303568
case acc: 0.069105975
case acc: 0.040819135
case acc: 0.07621268
case acc: 0.03819292
case acc: 0.037131906
top acc: 0.0050 ::: bot acc: 0.0215
top acc: 0.0811 ::: bot acc: 0.0572
top acc: 0.0571 ::: bot acc: 0.0247
top acc: 0.0666 ::: bot acc: 0.0865
top acc: 0.0503 ::: bot acc: 0.0263
top acc: 0.0483 ::: bot acc: 0.0256
current epoch: 13
train loss is 0.055354
average val loss: 0.045717, accuracy: 0.0458
average test loss: 0.045235, accuracy: 0.0450
case acc: 0.0076691792
case acc: 0.07171871
case acc: 0.049492624
case acc: 0.06474087
case acc: 0.033994336
case acc: 0.042522445
top acc: 0.0048 ::: bot acc: 0.0136
top acc: 0.0838 ::: bot acc: 0.0598
top acc: 0.0659 ::: bot acc: 0.0331
top acc: 0.0552 ::: bot acc: 0.0750
top acc: 0.0460 ::: bot acc: 0.0223
top acc: 0.0537 ::: bot acc: 0.0310
current epoch: 14
train loss is 0.053362
average val loss: 0.046847, accuracy: 0.0468
average test loss: 0.046180, accuracy: 0.0460
case acc: 0.007459905
case acc: 0.07361378
case acc: 0.059040047
case acc: 0.051059496
case acc: 0.035131764
case acc: 0.04949126
top acc: 0.0128 ::: bot acc: 0.0060
top acc: 0.0857 ::: bot acc: 0.0617
top acc: 0.0755 ::: bot acc: 0.0427
top acc: 0.0415 ::: bot acc: 0.0613
top acc: 0.0472 ::: bot acc: 0.0234
top acc: 0.0607 ::: bot acc: 0.0380
current epoch: 15
train loss is 0.051488
average val loss: 0.047356, accuracy: 0.0474
average test loss: 0.046600, accuracy: 0.0464
case acc: 0.009903169
case acc: 0.07160697
case acc: 0.065578744
case acc: 0.03890464
case acc: 0.038333446
case acc: 0.05427339
top acc: 0.0176 ::: bot acc: 0.0038
top acc: 0.0837 ::: bot acc: 0.0597
top acc: 0.0821 ::: bot acc: 0.0492
top acc: 0.0294 ::: bot acc: 0.0492
top acc: 0.0504 ::: bot acc: 0.0265
top acc: 0.0655 ::: bot acc: 0.0428
current epoch: 16
train loss is 0.049351
average val loss: 0.047529, accuracy: 0.0475
average test loss: 0.046731, accuracy: 0.0466
case acc: 0.011844119
case acc: 0.06700035
case acc: 0.070207626
case acc: 0.027186941
case acc: 0.045405347
case acc: 0.058069065
top acc: 0.0203 ::: bot acc: 0.0043
top acc: 0.0791 ::: bot acc: 0.0550
top acc: 0.0868 ::: bot acc: 0.0538
top acc: 0.0182 ::: bot acc: 0.0372
top acc: 0.0575 ::: bot acc: 0.0336
top acc: 0.0693 ::: bot acc: 0.0466
current epoch: 17
train loss is 0.044253
average val loss: 0.038740, accuracy: 0.0388
average test loss: 0.038174, accuracy: 0.0380
case acc: 0.0070858197
case acc: 0.04599661
case acc: 0.05863647
case acc: 0.030267581
case acc: 0.039463494
case acc: 0.046280794
top acc: 0.0066 ::: bot acc: 0.0118
top acc: 0.0581 ::: bot acc: 0.0340
top acc: 0.0752 ::: bot acc: 0.0422
top acc: 0.0211 ::: bot acc: 0.0404
top acc: 0.0516 ::: bot acc: 0.0276
top acc: 0.0575 ::: bot acc: 0.0348
current epoch: 18
train loss is 0.040719
average val loss: 0.031501, accuracy: 0.0317
average test loss: 0.031100, accuracy: 0.0310
case acc: 0.017931905
case acc: 0.022976935
case acc: 0.0445001
case acc: 0.03522818
case acc: 0.032504585
case acc: 0.03299976
top acc: 0.0088 ::: bot acc: 0.0270
top acc: 0.0349 ::: bot acc: 0.0113
top acc: 0.0611 ::: bot acc: 0.0282
top acc: 0.0257 ::: bot acc: 0.0456
top acc: 0.0445 ::: bot acc: 0.0208
top acc: 0.0442 ::: bot acc: 0.0215
current epoch: 19
train loss is 0.037372
average val loss: 0.025884, accuracy: 0.0262
average test loss: 0.025841, accuracy: 0.0259
case acc: 0.033925507
case acc: 0.008899788
case acc: 0.02852129
case acc: 0.04277959
case acc: 0.02249728
case acc: 0.018619798
top acc: 0.0247 ::: bot acc: 0.0431
top acc: 0.0115 ::: bot acc: 0.0125
top acc: 0.0446 ::: bot acc: 0.0133
top acc: 0.0332 ::: bot acc: 0.0531
top acc: 0.0340 ::: bot acc: 0.0116
top acc: 0.0294 ::: bot acc: 0.0080
current epoch: 20
train loss is 0.036543
average val loss: 0.025553, accuracy: 0.0260
average test loss: 0.026017, accuracy: 0.0262
case acc: 0.048218444
case acc: 0.021710144
case acc: 0.01587098
case acc: 0.05170034
case acc: 0.010291741
case acc: 0.009133472
top acc: 0.0389 ::: bot acc: 0.0574
top acc: 0.0104 ::: bot acc: 0.0333
top acc: 0.0287 ::: bot acc: 0.0071
top acc: 0.0421 ::: bot acc: 0.0621
top acc: 0.0182 ::: bot acc: 0.0066
top acc: 0.0154 ::: bot acc: 0.0075
current epoch: 21
train loss is 0.037704
average val loss: 0.028369, accuracy: 0.0291
average test loss: 0.029293, accuracy: 0.0296
case acc: 0.054900702
case acc: 0.032351673
case acc: 0.012120112
case acc: 0.05715696
case acc: 0.012012809
case acc: 0.0088678
top acc: 0.0456 ::: bot acc: 0.0641
top acc: 0.0204 ::: bot acc: 0.0443
top acc: 0.0193 ::: bot acc: 0.0138
top acc: 0.0476 ::: bot acc: 0.0676
top acc: 0.0052 ::: bot acc: 0.0213
top acc: 0.0076 ::: bot acc: 0.0152
current epoch: 22
train loss is 0.037773
average val loss: 0.029877, accuracy: 0.0306
average test loss: 0.030887, accuracy: 0.0311
case acc: 0.053882007
case acc: 0.033040114
case acc: 0.012065904
case acc: 0.058301907
case acc: 0.020404974
case acc: 0.009189839
top acc: 0.0445 ::: bot acc: 0.0631
top acc: 0.0211 ::: bot acc: 0.0450
top acc: 0.0168 ::: bot acc: 0.0164
top acc: 0.0487 ::: bot acc: 0.0687
top acc: 0.0092 ::: bot acc: 0.0319
top acc: 0.0065 ::: bot acc: 0.0163
current epoch: 23
train loss is 0.036641
average val loss: 0.029471, accuracy: 0.0302
average test loss: 0.030448, accuracy: 0.0307
case acc: 0.049991325
case acc: 0.029615078
case acc: 0.01205706
case acc: 0.057290353
case acc: 0.026488237
case acc: 0.008764091
top acc: 0.0406 ::: bot acc: 0.0593
top acc: 0.0178 ::: bot acc: 0.0415
top acc: 0.0169 ::: bot acc: 0.0162
top acc: 0.0478 ::: bot acc: 0.0676
top acc: 0.0146 ::: bot acc: 0.0383
top acc: 0.0079 ::: bot acc: 0.0148
current epoch: 24
train loss is 0.035807
average val loss: 0.028091, accuracy: 0.0288
average test loss: 0.029037, accuracy: 0.0293
case acc: 0.045304276
case acc: 0.023123242
case acc: 0.012038197
case acc: 0.055327274
case acc: 0.031278033
case acc: 0.008493673
top acc: 0.0358 ::: bot acc: 0.0546
top acc: 0.0117 ::: bot acc: 0.0348
top acc: 0.0178 ::: bot acc: 0.0154
top acc: 0.0458 ::: bot acc: 0.0657
top acc: 0.0192 ::: bot acc: 0.0432
top acc: 0.0094 ::: bot acc: 0.0133
current epoch: 25
train loss is 0.035430
average val loss: 0.024443, accuracy: 0.0252
average test loss: 0.025209, accuracy: 0.0253
case acc: 0.036546014
case acc: 0.01028075
case acc: 0.01283705
case acc: 0.050243836
case acc: 0.033657953
case acc: 0.00845915
top acc: 0.0271 ::: bot acc: 0.0459
top acc: 0.0052 ::: bot acc: 0.0188
top acc: 0.0224 ::: bot acc: 0.0109
top acc: 0.0407 ::: bot acc: 0.0606
top acc: 0.0216 ::: bot acc: 0.0456
top acc: 0.0127 ::: bot acc: 0.0100
current epoch: 26
train loss is 0.035568
average val loss: 0.023451, accuracy: 0.0236
average test loss: 0.023475, accuracy: 0.0231
case acc: 0.011958442
case acc: 0.028998138
case acc: 0.027637405
case acc: 0.028657347
case acc: 0.0210547
case acc: 0.020323815
top acc: 0.0043 ::: bot acc: 0.0204
top acc: 0.0409 ::: bot acc: 0.0171
top acc: 0.0439 ::: bot acc: 0.0124
top acc: 0.0196 ::: bot acc: 0.0387
top acc: 0.0097 ::: bot acc: 0.0327
top acc: 0.0313 ::: bot acc: 0.0094
current epoch: 27
train loss is 0.036496
average val loss: 0.048058, accuracy: 0.0480
average test loss: 0.046944, accuracy: 0.0469
case acc: 0.034602113
case acc: 0.08228344
case acc: 0.07071135
case acc: 0.017504558
case acc: 0.016358199
case acc: 0.06000747
top acc: 0.0441 ::: bot acc: 0.0252
top acc: 0.0942 ::: bot acc: 0.0703
top acc: 0.0876 ::: bot acc: 0.0542
top acc: 0.0262 ::: bot acc: 0.0088
top acc: 0.0272 ::: bot acc: 0.0069
top acc: 0.0713 ::: bot acc: 0.0485
current epoch: 28
train loss is 0.046207
average val loss: 0.100130, accuracy: 0.1001
average test loss: 0.098912, accuracy: 0.0989
case acc: 0.085026056
case acc: 0.13565361
case acc: 0.12305606
case acc: 0.07364717
case acc: 0.067295074
case acc: 0.10879647
top acc: 0.0946 ::: bot acc: 0.0756
top acc: 0.1476 ::: bot acc: 0.1237
top acc: 0.1399 ::: bot acc: 0.1066
top acc: 0.0831 ::: bot acc: 0.0633
top acc: 0.0794 ::: bot acc: 0.0553
top acc: 0.1201 ::: bot acc: 0.0973
current epoch: 29
train loss is 0.065249
average val loss: 0.059405, accuracy: 0.0594
average test loss: 0.058160, accuracy: 0.0581
case acc: 0.036598288
case acc: 0.077607505
case acc: 0.0812916
case acc: 0.043455236
case acc: 0.04286154
case acc: 0.06706272
top acc: 0.0462 ::: bot acc: 0.0271
top acc: 0.0896 ::: bot acc: 0.0656
top acc: 0.0981 ::: bot acc: 0.0648
top acc: 0.0530 ::: bot acc: 0.0330
top acc: 0.0549 ::: bot acc: 0.0308
top acc: 0.0784 ::: bot acc: 0.0556
current epoch: 30
train loss is 0.039271
average val loss: 0.045576, accuracy: 0.0455
average test loss: 0.044428, accuracy: 0.0442
case acc: 0.01238577
case acc: 0.03767722
case acc: 0.06309879
case acc: 0.042372312
case acc: 0.05645158
case acc: 0.05334157
top acc: 0.0213 ::: bot acc: 0.0044
top acc: 0.0497 ::: bot acc: 0.0257
top acc: 0.0799 ::: bot acc: 0.0466
top acc: 0.0519 ::: bot acc: 0.0320
top acc: 0.0686 ::: bot acc: 0.0444
top acc: 0.0647 ::: bot acc: 0.0419
current epoch: 31
train loss is 0.024291
average val loss: 0.028404, accuracy: 0.0286
average test loss: 0.028058, accuracy: 0.0278
case acc: 0.026849285
case acc: 0.015055726
case acc: 0.029254047
case acc: 0.023294445
case acc: 0.048836015
case acc: 0.02375766
top acc: 0.0173 ::: bot acc: 0.0363
top acc: 0.0056 ::: bot acc: 0.0258
top acc: 0.0456 ::: bot acc: 0.0138
top acc: 0.0325 ::: bot acc: 0.0135
top acc: 0.0609 ::: bot acc: 0.0368
top acc: 0.0350 ::: bot acc: 0.0126
current epoch: 32
train loss is 0.042386
average val loss: 0.057863, accuracy: 0.0578
average test loss: 0.059071, accuracy: 0.0591
case acc: 0.101858646
case acc: 0.100670524
case acc: 0.046109688
case acc: 0.045764953
case acc: 0.014149329
case acc: 0.046149105
top acc: 0.0923 ::: bot acc: 0.1113
top acc: 0.0887 ::: bot acc: 0.1126
top acc: 0.0295 ::: bot acc: 0.0625
top acc: 0.0363 ::: bot acc: 0.0561
top acc: 0.0053 ::: bot acc: 0.0246
top acc: 0.0348 ::: bot acc: 0.0576
current epoch: 33
train loss is 0.083648
average val loss: 0.055299, accuracy: 0.0553
average test loss: 0.056519, accuracy: 0.0565
case acc: 0.09460885
case acc: 0.08973762
case acc: 0.04425239
case acc: 0.05009516
case acc: 0.018315578
case acc: 0.04220482
top acc: 0.0850 ::: bot acc: 0.1040
top acc: 0.0778 ::: bot acc: 0.1017
top acc: 0.0277 ::: bot acc: 0.0606
top acc: 0.0406 ::: bot acc: 0.0604
top acc: 0.0077 ::: bot acc: 0.0296
top acc: 0.0309 ::: bot acc: 0.0536
current epoch: 34
train loss is 0.057151
average val loss: 0.027887, accuracy: 0.0283
average test loss: 0.029114, accuracy: 0.0294
case acc: 0.056326594
case acc: 0.03571942
case acc: 0.016130181
case acc: 0.034220587
case acc: 0.0171453
case acc: 0.016814938
top acc: 0.0467 ::: bot acc: 0.0658
top acc: 0.0238 ::: bot acc: 0.0477
top acc: 0.0069 ::: bot acc: 0.0288
top acc: 0.0249 ::: bot acc: 0.0446
top acc: 0.0070 ::: bot acc: 0.0282
top acc: 0.0069 ::: bot acc: 0.0276
current epoch: 35
train loss is 0.031300
average val loss: 0.016318, accuracy: 0.0169
average test loss: 0.016881, accuracy: 0.0170
case acc: 0.02886049
case acc: 0.009745607
case acc: 0.01424386
case acc: 0.024257919
case acc: 0.016677747
case acc: 0.00848904
top acc: 0.0192 ::: bot acc: 0.0383
top acc: 0.0171 ::: bot acc: 0.0068
top acc: 0.0258 ::: bot acc: 0.0082
top acc: 0.0155 ::: bot acc: 0.0343
top acc: 0.0067 ::: bot acc: 0.0277
top acc: 0.0131 ::: bot acc: 0.0098
current epoch: 36
train loss is 0.029720
average val loss: 0.024435, accuracy: 0.0242
average test loss: 0.023622, accuracy: 0.0233
case acc: 0.007081501
case acc: 0.031880602
case acc: 0.03769343
case acc: 0.010631762
case acc: 0.01956326
case acc: 0.0326535
top acc: 0.0108 ::: bot acc: 0.0083
top acc: 0.0438 ::: bot acc: 0.0199
top acc: 0.0543 ::: bot acc: 0.0217
top acc: 0.0177 ::: bot acc: 0.0051
top acc: 0.0309 ::: bot acc: 0.0090
top acc: 0.0440 ::: bot acc: 0.0211
current epoch: 37
train loss is 0.023424
average val loss: 0.015066, accuracy: 0.0150
average test loss: 0.014906, accuracy: 0.0146
case acc: 0.01769678
case acc: 0.0104608955
case acc: 0.021469172
case acc: 0.007179898
case acc: 0.0136349145
case acc: 0.016901953
top acc: 0.0083 ::: bot acc: 0.0271
top acc: 0.0193 ::: bot acc: 0.0048
top acc: 0.0369 ::: bot acc: 0.0077
top acc: 0.0082 ::: bot acc: 0.0117
top acc: 0.0236 ::: bot acc: 0.0059
top acc: 0.0277 ::: bot acc: 0.0065
current epoch: 38
train loss is 0.021520
average val loss: 0.013585, accuracy: 0.0137
average test loss: 0.013660, accuracy: 0.0136
case acc: 0.023391098
case acc: 0.008875945
case acc: 0.017095359
case acc: 0.007242443
case acc: 0.012610769
case acc: 0.012290709
top acc: 0.0138 ::: bot acc: 0.0329
top acc: 0.0121 ::: bot acc: 0.0118
top acc: 0.0308 ::: bot acc: 0.0068
top acc: 0.0074 ::: bot acc: 0.0125
top acc: 0.0221 ::: bot acc: 0.0059
top acc: 0.0217 ::: bot acc: 0.0047
current epoch: 39
train loss is 0.023048
average val loss: 0.016312, accuracy: 0.0165
average test loss: 0.016164, accuracy: 0.0161
case acc: 0.021236544
case acc: 0.009189468
case acc: 0.018324329
case acc: 0.009630162
case acc: 0.022320101
case acc: 0.01560468
top acc: 0.0116 ::: bot acc: 0.0307
top acc: 0.0089 ::: bot acc: 0.0151
top acc: 0.0328 ::: bot acc: 0.0067
top acc: 0.0160 ::: bot acc: 0.0054
top acc: 0.0339 ::: bot acc: 0.0112
top acc: 0.0262 ::: bot acc: 0.0056
current epoch: 40
train loss is 0.024782
average val loss: 0.020692, accuracy: 0.0210
average test loss: 0.020526, accuracy: 0.0205
case acc: 0.024712423
case acc: 0.01700397
case acc: 0.016310766
case acc: 0.013102792
case acc: 0.034826066
case acc: 0.017127024
top acc: 0.0151 ::: bot acc: 0.0342
top acc: 0.0069 ::: bot acc: 0.0280
top acc: 0.0297 ::: bot acc: 0.0069
top acc: 0.0209 ::: bot acc: 0.0060
top acc: 0.0469 ::: bot acc: 0.0229
top acc: 0.0280 ::: bot acc: 0.0067
current epoch: 41
train loss is 0.037139
average val loss: 0.050517, accuracy: 0.0504
average test loss: 0.051723, accuracy: 0.0518
case acc: 0.084409125
case acc: 0.08934484
case acc: 0.046428148
case acc: 0.042444184
case acc: 0.012030357
case acc: 0.036081154
top acc: 0.0748 ::: bot acc: 0.0939
top acc: 0.0774 ::: bot acc: 0.1013
top acc: 0.0297 ::: bot acc: 0.0629
top acc: 0.0330 ::: bot acc: 0.0528
top acc: 0.0051 ::: bot acc: 0.0215
top acc: 0.0247 ::: bot acc: 0.0475
current epoch: 42
train loss is 0.072812
average val loss: 0.058252, accuracy: 0.0582
average test loss: 0.059480, accuracy: 0.0595
case acc: 0.088448696
case acc: 0.09185998
case acc: 0.054446775
case acc: 0.05656376
case acc: 0.023551779
case acc: 0.04183966
top acc: 0.0788 ::: bot acc: 0.0980
top acc: 0.0799 ::: bot acc: 0.1038
top acc: 0.0375 ::: bot acc: 0.0710
top acc: 0.0471 ::: bot acc: 0.0669
top acc: 0.0119 ::: bot acc: 0.0354
top acc: 0.0305 ::: bot acc: 0.0533
current epoch: 43
train loss is 0.058562
average val loss: 0.028874, accuracy: 0.0290
average test loss: 0.030106, accuracy: 0.0302
case acc: 0.048582364
case acc: 0.037117016
case acc: 0.021863965
case acc: 0.03824467
case acc: 0.020596065
case acc: 0.0146508785
top acc: 0.0390 ::: bot acc: 0.0581
top acc: 0.0252 ::: bot acc: 0.0490
top acc: 0.0083 ::: bot acc: 0.0368
top acc: 0.0287 ::: bot acc: 0.0486
top acc: 0.0094 ::: bot acc: 0.0323
top acc: 0.0053 ::: bot acc: 0.0251
current epoch: 44
train loss is 0.032116
average val loss: 0.024215, accuracy: 0.0247
average test loss: 0.025348, accuracy: 0.0257
case acc: 0.032789044
case acc: 0.0092411395
case acc: 0.014918433
case acc: 0.042926323
case acc: 0.041752238
case acc: 0.012680251
top acc: 0.0231 ::: bot acc: 0.0423
top acc: 0.0085 ::: bot acc: 0.0154
top acc: 0.0078 ::: bot acc: 0.0266
top acc: 0.0334 ::: bot acc: 0.0533
top acc: 0.0297 ::: bot acc: 0.0538
top acc: 0.0045 ::: bot acc: 0.0226
current epoch: 45
train loss is 0.029720
average val loss: 0.036300, accuracy: 0.0362
average test loss: 0.035410, accuracy: 0.0352
case acc: 0.02903155
case acc: 0.068304844
case acc: 0.048699435
case acc: 0.012736637
case acc: 0.008782422
case acc: 0.04357772
top acc: 0.0387 ::: bot acc: 0.0196
top acc: 0.0802 ::: bot acc: 0.0564
top acc: 0.0655 ::: bot acc: 0.0322
top acc: 0.0205 ::: bot acc: 0.0058
top acc: 0.0141 ::: bot acc: 0.0100
top acc: 0.0549 ::: bot acc: 0.0321
current epoch: 46
train loss is 0.045078
average val loss: 0.079084, accuracy: 0.0791
average test loss: 0.077846, accuracy: 0.0778
case acc: 0.06982299
case acc: 0.11053817
case acc: 0.09149234
case acc: 0.059549574
case acc: 0.05128458
case acc: 0.08438973
top acc: 0.0794 ::: bot acc: 0.0603
top acc: 0.1225 ::: bot acc: 0.0986
top acc: 0.1083 ::: bot acc: 0.0750
top acc: 0.0691 ::: bot acc: 0.0491
top acc: 0.0633 ::: bot acc: 0.0393
top acc: 0.0958 ::: bot acc: 0.0729
current epoch: 47
train loss is 0.053658
average val loss: 0.032372, accuracy: 0.0323
average test loss: 0.031206, accuracy: 0.0310
case acc: 0.013936964
case acc: 0.04173435
case acc: 0.041324362
case acc: 0.024376215
case acc: 0.028170643
case acc: 0.036720518
top acc: 0.0230 ::: bot acc: 0.0055
top acc: 0.0537 ::: bot acc: 0.0298
top acc: 0.0581 ::: bot acc: 0.0250
top acc: 0.0337 ::: bot acc: 0.0144
top acc: 0.0400 ::: bot acc: 0.0164
top acc: 0.0481 ::: bot acc: 0.0252
current epoch: 48
train loss is 0.024969
average val loss: 0.020792, accuracy: 0.0210
average test loss: 0.020373, accuracy: 0.0202
case acc: 0.014117786
case acc: 0.008851406
case acc: 0.021160768
case acc: 0.01976139
case acc: 0.036699157
case acc: 0.020860543
top acc: 0.0054 ::: bot acc: 0.0232
top acc: 0.0113 ::: bot acc: 0.0126
top acc: 0.0366 ::: bot acc: 0.0076
top acc: 0.0288 ::: bot acc: 0.0104
top acc: 0.0487 ::: bot acc: 0.0246
top acc: 0.0320 ::: bot acc: 0.0099
current epoch: 49
train loss is 0.025063
average val loss: 0.025838, accuracy: 0.0258
average test loss: 0.026676, accuracy: 0.0269
case acc: 0.051577576
case acc: 0.049131904
case acc: 0.01874577
case acc: 0.009908229
case acc: 0.019582756
case acc: 0.012627996
top acc: 0.0419 ::: bot acc: 0.0611
top acc: 0.0372 ::: bot acc: 0.0611
top acc: 0.0069 ::: bot acc: 0.0328
top acc: 0.0043 ::: bot acc: 0.0183
top acc: 0.0309 ::: bot acc: 0.0090
top acc: 0.0045 ::: bot acc: 0.0225
current epoch: 50
train loss is 0.053607
average val loss: 0.073760, accuracy: 0.0737
average test loss: 0.074992, accuracy: 0.0750
case acc: 0.10495375
case acc: 0.110980526
case acc: 0.07062292
case acc: 0.06460205
case acc: 0.037149873
case acc: 0.06160867
top acc: 0.0953 ::: bot acc: 0.1145
top acc: 0.0990 ::: bot acc: 0.1229
top acc: 0.0537 ::: bot acc: 0.0872
top acc: 0.0551 ::: bot acc: 0.0750
top acc: 0.0251 ::: bot acc: 0.0492
top acc: 0.0502 ::: bot acc: 0.0731
LME_Co_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6810 6810 6810
1.8562728 -0.6288155 0.08104724 -0.1112376
Validation: 762 762 762
Testing: 744 744 744
pre-processing time: 0.0004429817199707031
the split date is 2010-01-01
net initializing with time: 0.38379573822021484
preparing training and testing date with time: 2.384185791015625e-07
current epoch: 1
train loss is 0.186677
average val loss: 0.047312, accuracy: 0.0470
average test loss: 0.047085, accuracy: 0.0470
case acc: 0.015460459
case acc: 0.026191762
case acc: 0.053183176
case acc: 0.014659184
case acc: 0.045605764
case acc: 0.12679973
top acc: 0.0122 ::: bot acc: 0.0244
top acc: 0.0401 ::: bot acc: 0.0150
top acc: 0.0758 ::: bot acc: 0.0321
top acc: 0.0247 ::: bot acc: 0.0119
top acc: 0.0609 ::: bot acc: 0.0315
top acc: 0.1453 ::: bot acc: 0.1083
current epoch: 2
train loss is 0.073040
average val loss: 0.069266, accuracy: 0.0691
average test loss: 0.069948, accuracy: 0.0702
case acc: 0.11416012
case acc: 0.07930239
case acc: 0.054648906
case acc: 0.09511296
case acc: 0.061692677
case acc: 0.016515534
top acc: 0.0995 ::: bot acc: 0.1294
top acc: 0.0655 ::: bot acc: 0.0908
top acc: 0.0326 ::: bot acc: 0.0755
top acc: 0.0786 ::: bot acc: 0.1112
top acc: 0.0466 ::: bot acc: 0.0754
top acc: 0.0298 ::: bot acc: 0.0078
current epoch: 3
train loss is 0.066096
average val loss: 0.135524, accuracy: 0.1355
average test loss: 0.136278, accuracy: 0.1363
case acc: 0.1803905
case acc: 0.14695054
case acc: 0.12725574
case acc: 0.16380292
case acc: 0.13127872
case acc: 0.067982264
top acc: 0.1660 ::: bot acc: 0.1954
top acc: 0.1332 ::: bot acc: 0.1587
top acc: 0.1056 ::: bot acc: 0.1480
top acc: 0.1478 ::: bot acc: 0.1797
top acc: 0.1164 ::: bot acc: 0.1448
top acc: 0.0506 ::: bot acc: 0.0853
current epoch: 4
train loss is 0.082180
average val loss: 0.144739, accuracy: 0.1447
average test loss: 0.145373, accuracy: 0.1454
case acc: 0.18415299
case acc: 0.1525907
case acc: 0.13784096
case acc: 0.1743503
case acc: 0.13867983
case acc: 0.08462502
top acc: 0.1699 ::: bot acc: 0.1990
top acc: 0.1389 ::: bot acc: 0.1645
top acc: 0.1165 ::: bot acc: 0.1585
top acc: 0.1585 ::: bot acc: 0.1902
top acc: 0.1240 ::: bot acc: 0.1520
top acc: 0.0675 ::: bot acc: 0.1016
current epoch: 5
train loss is 0.090982
average val loss: 0.120296, accuracy: 0.1203
average test loss: 0.120869, accuracy: 0.1209
case acc: 0.15452436
case acc: 0.1247914
case acc: 0.114167504
case acc: 0.15259276
case acc: 0.11248938
case acc: 0.06664503
top acc: 0.1403 ::: bot acc: 0.1693
top acc: 0.1111 ::: bot acc: 0.1367
top acc: 0.0929 ::: bot acc: 0.1348
top acc: 0.1368 ::: bot acc: 0.1684
top acc: 0.0980 ::: bot acc: 0.1258
top acc: 0.0496 ::: bot acc: 0.0835
current epoch: 6
train loss is 0.099460
average val loss: 0.048580, accuracy: 0.0485
average test loss: 0.049441, accuracy: 0.0497
case acc: 0.07619375
case acc: 0.04844385
case acc: 0.04159837
case acc: 0.080773555
case acc: 0.03820009
case acc: 0.0128269885
top acc: 0.0619 ::: bot acc: 0.0910
top acc: 0.0348 ::: bot acc: 0.0603
top acc: 0.0202 ::: bot acc: 0.0623
top acc: 0.0648 ::: bot acc: 0.0967
top acc: 0.0237 ::: bot acc: 0.0516
top acc: 0.0152 ::: bot acc: 0.0188
current epoch: 7
train loss is 0.061838
average val loss: 0.070955, accuracy: 0.0709
average test loss: 0.071503, accuracy: 0.0715
case acc: 0.094453335
case acc: 0.06849355
case acc: 0.06610661
case acc: 0.103910685
case acc: 0.06039092
case acc: 0.035643127
top acc: 0.0801 ::: bot acc: 0.1093
top acc: 0.0548 ::: bot acc: 0.0803
top acc: 0.0447 ::: bot acc: 0.0869
top acc: 0.0878 ::: bot acc: 0.1198
top acc: 0.0460 ::: bot acc: 0.0737
top acc: 0.0190 ::: bot acc: 0.0524
current epoch: 8
train loss is 0.059631
average val loss: 0.077883, accuracy: 0.0779
average test loss: 0.078366, accuracy: 0.0784
case acc: 0.09634885
case acc: 0.07221636
case acc: 0.07400643
case acc: 0.110444464
case acc: 0.06586619
case acc: 0.05125758
top acc: 0.0820 ::: bot acc: 0.1111
top acc: 0.0586 ::: bot acc: 0.0840
top acc: 0.0526 ::: bot acc: 0.0949
top acc: 0.0944 ::: bot acc: 0.1264
top acc: 0.0515 ::: bot acc: 0.0791
top acc: 0.0342 ::: bot acc: 0.0682
current epoch: 9
train loss is 0.051906
average val loss: 0.086120, accuracy: 0.0861
average test loss: 0.086527, accuracy: 0.0865
case acc: 0.10005542
case acc: 0.077434495
case acc: 0.08311002
case acc: 0.119461365
case acc: 0.072496906
case acc: 0.06659994
top acc: 0.0858 ::: bot acc: 0.1148
top acc: 0.0638 ::: bot acc: 0.0893
top acc: 0.0619 ::: bot acc: 0.1039
top acc: 0.1036 ::: bot acc: 0.1354
top acc: 0.0581 ::: bot acc: 0.0857
top acc: 0.0497 ::: bot acc: 0.0834
current epoch: 10
train loss is 0.046571
average val loss: 0.080162, accuracy: 0.0802
average test loss: 0.080497, accuracy: 0.0805
case acc: 0.09035672
case acc: 0.06917789
case acc: 0.0778895
case acc: 0.11479081
case acc: 0.065195985
case acc: 0.065553315
top acc: 0.0762 ::: bot acc: 0.1049
top acc: 0.0556 ::: bot acc: 0.0810
top acc: 0.0568 ::: bot acc: 0.0986
top acc: 0.0990 ::: bot acc: 0.1307
top acc: 0.0509 ::: bot acc: 0.0783
top acc: 0.0488 ::: bot acc: 0.0822
current epoch: 11
train loss is 0.040208
average val loss: 0.070176, accuracy: 0.0702
average test loss: 0.070470, accuracy: 0.0705
case acc: 0.077615574
case acc: 0.05804558
case acc: 0.06870319
case acc: 0.10530926
case acc: 0.05454393
case acc: 0.058510616
top acc: 0.0635 ::: bot acc: 0.0922
top acc: 0.0445 ::: bot acc: 0.0700
top acc: 0.0478 ::: bot acc: 0.0893
top acc: 0.0895 ::: bot acc: 0.1213
top acc: 0.0403 ::: bot acc: 0.0677
top acc: 0.0418 ::: bot acc: 0.0750
current epoch: 12
train loss is 0.034779
average val loss: 0.060093, accuracy: 0.0601
average test loss: 0.060360, accuracy: 0.0603
case acc: 0.06632144
case acc: 0.0485887
case acc: 0.05947166
case acc: 0.09288402
case acc: 0.045294788
case acc: 0.049395278
top acc: 0.0522 ::: bot acc: 0.0808
top acc: 0.0351 ::: bot acc: 0.0606
top acc: 0.0387 ::: bot acc: 0.0800
top acc: 0.0772 ::: bot acc: 0.1088
top acc: 0.0312 ::: bot acc: 0.0584
top acc: 0.0328 ::: bot acc: 0.0659
current epoch: 13
train loss is 0.031366
average val loss: 0.054695, accuracy: 0.0547
average test loss: 0.054933, accuracy: 0.0549
case acc: 0.060276743
case acc: 0.044476915
case acc: 0.055110294
case acc: 0.08310494
case acc: 0.04137834
case acc: 0.04494996
top acc: 0.0462 ::: bot acc: 0.0748
top acc: 0.0310 ::: bot acc: 0.0565
top acc: 0.0343 ::: bot acc: 0.0757
top acc: 0.0674 ::: bot acc: 0.0991
top acc: 0.0273 ::: bot acc: 0.0545
top acc: 0.0283 ::: bot acc: 0.0614
current epoch: 14
train loss is 0.028917
average val loss: 0.046045, accuracy: 0.0460
average test loss: 0.046335, accuracy: 0.0462
case acc: 0.051300734
case acc: 0.03742817
case acc: 0.04748497
case acc: 0.069431685
case acc: 0.034448236
case acc: 0.037332736
top acc: 0.0371 ::: bot acc: 0.0659
top acc: 0.0240 ::: bot acc: 0.0495
top acc: 0.0267 ::: bot acc: 0.0681
top acc: 0.0536 ::: bot acc: 0.0854
top acc: 0.0204 ::: bot acc: 0.0476
top acc: 0.0209 ::: bot acc: 0.0537
current epoch: 15
train loss is 0.026466
average val loss: 0.039647, accuracy: 0.0396
average test loss: 0.040033, accuracy: 0.0399
case acc: 0.04506304
case acc: 0.032912772
case acc: 0.04194073
case acc: 0.057996728
case acc: 0.030015264
case acc: 0.03144505
top acc: 0.0309 ::: bot acc: 0.0597
top acc: 0.0195 ::: bot acc: 0.0449
top acc: 0.0211 ::: bot acc: 0.0625
top acc: 0.0425 ::: bot acc: 0.0738
top acc: 0.0160 ::: bot acc: 0.0431
top acc: 0.0154 ::: bot acc: 0.0476
current epoch: 16
train loss is 0.024686
average val loss: 0.037160, accuracy: 0.0371
average test loss: 0.037545, accuracy: 0.0374
case acc: 0.04281458
case acc: 0.032162584
case acc: 0.04008291
case acc: 0.050652932
case acc: 0.029380957
case acc: 0.029431285
top acc: 0.0287 ::: bot acc: 0.0575
top acc: 0.0188 ::: bot acc: 0.0441
top acc: 0.0194 ::: bot acc: 0.0606
top acc: 0.0354 ::: bot acc: 0.0664
top acc: 0.0153 ::: bot acc: 0.0425
top acc: 0.0137 ::: bot acc: 0.0455
current epoch: 17
train loss is 0.022919
average val loss: 0.030443, accuracy: 0.0304
average test loss: 0.030995, accuracy: 0.0309
case acc: 0.03622694
case acc: 0.02701451
case acc: 0.034225464
case acc: 0.03993493
case acc: 0.024310017
case acc: 0.023582397
top acc: 0.0221 ::: bot acc: 0.0508
top acc: 0.0140 ::: bot acc: 0.0388
top acc: 0.0145 ::: bot acc: 0.0544
top acc: 0.0255 ::: bot acc: 0.0552
top acc: 0.0105 ::: bot acc: 0.0373
top acc: 0.0089 ::: bot acc: 0.0391
current epoch: 18
train loss is 0.021726
average val loss: 0.028272, accuracy: 0.0282
average test loss: 0.028862, accuracy: 0.0288
case acc: 0.03415537
case acc: 0.026088508
case acc: 0.032560136
case acc: 0.034186307
case acc: 0.023503024
case acc: 0.022097914
top acc: 0.0202 ::: bot acc: 0.0487
top acc: 0.0132 ::: bot acc: 0.0378
top acc: 0.0131 ::: bot acc: 0.0526
top acc: 0.0203 ::: bot acc: 0.0492
top acc: 0.0098 ::: bot acc: 0.0365
top acc: 0.0078 ::: bot acc: 0.0374
current epoch: 19
train loss is 0.020586
average val loss: 0.022587, accuracy: 0.0226
average test loss: 0.023492, accuracy: 0.0234
case acc: 0.028336337
case acc: 0.021508792
case acc: 0.027726358
case acc: 0.025703508
case acc: 0.018983848
case acc: 0.018397173
top acc: 0.0151 ::: bot acc: 0.0425
top acc: 0.0099 ::: bot acc: 0.0326
top acc: 0.0095 ::: bot acc: 0.0472
top acc: 0.0130 ::: bot acc: 0.0402
top acc: 0.0063 ::: bot acc: 0.0314
top acc: 0.0063 ::: bot acc: 0.0326
current epoch: 20
train loss is 0.019502
average val loss: 0.019269, accuracy: 0.0192
average test loss: 0.020499, accuracy: 0.0204
case acc: 0.02467478
case acc: 0.018861402
case acc: 0.0250576
case acc: 0.020543326
case acc: 0.016511276
case acc: 0.016780114
top acc: 0.0121 ::: bot acc: 0.0386
top acc: 0.0083 ::: bot acc: 0.0294
top acc: 0.0078 ::: bot acc: 0.0441
top acc: 0.0093 ::: bot acc: 0.0343
top acc: 0.0050 ::: bot acc: 0.0284
top acc: 0.0063 ::: bot acc: 0.0302
current epoch: 21
train loss is 0.018656
average val loss: 0.015730, accuracy: 0.0157
average test loss: 0.017448, accuracy: 0.0174
case acc: 0.02077281
case acc: 0.015801197
case acc: 0.022190003
case acc: 0.016530236
case acc: 0.0139053725
case acc: 0.0149186505
top acc: 0.0092 ::: bot acc: 0.0342
top acc: 0.0070 ::: bot acc: 0.0255
top acc: 0.0069 ::: bot acc: 0.0403
top acc: 0.0076 ::: bot acc: 0.0291
top acc: 0.0050 ::: bot acc: 0.0246
top acc: 0.0073 ::: bot acc: 0.0269
current epoch: 22
train loss is 0.017949
average val loss: 0.015281, accuracy: 0.0152
average test loss: 0.017060, accuracy: 0.0170
case acc: 0.019831251
case acc: 0.015187838
case acc: 0.021956734
case acc: 0.016124135
case acc: 0.0135187255
case acc: 0.015122837
top acc: 0.0086 ::: bot acc: 0.0331
top acc: 0.0068 ::: bot acc: 0.0247
top acc: 0.0070 ::: bot acc: 0.0400
top acc: 0.0076 ::: bot acc: 0.0286
top acc: 0.0053 ::: bot acc: 0.0239
top acc: 0.0072 ::: bot acc: 0.0273
current epoch: 23
train loss is 0.017786
average val loss: 0.012360, accuracy: 0.0123
average test loss: 0.014630, accuracy: 0.0145
case acc: 0.016348341
case acc: 0.012397949
case acc: 0.019506391
case acc: 0.013785328
case acc: 0.0115828095
case acc: 0.013630939
top acc: 0.0071 ::: bot acc: 0.0286
top acc: 0.0069 ::: bot acc: 0.0205
top acc: 0.0078 ::: bot acc: 0.0359
top acc: 0.0080 ::: bot acc: 0.0249
top acc: 0.0077 ::: bot acc: 0.0198
top acc: 0.0097 ::: bot acc: 0.0238
current epoch: 24
train loss is 0.017391
average val loss: 0.014220, accuracy: 0.0142
average test loss: 0.016157, accuracy: 0.0161
case acc: 0.018735712
case acc: 0.014424113
case acc: 0.020543573
case acc: 0.016030213
case acc: 0.012971921
case acc: 0.014004263
top acc: 0.0080 ::: bot acc: 0.0317
top acc: 0.0067 ::: bot acc: 0.0237
top acc: 0.0073 ::: bot acc: 0.0378
top acc: 0.0076 ::: bot acc: 0.0285
top acc: 0.0058 ::: bot acc: 0.0228
top acc: 0.0088 ::: bot acc: 0.0248
current epoch: 25
train loss is 0.017339
average val loss: 0.018930, accuracy: 0.0189
average test loss: 0.020144, accuracy: 0.0201
case acc: 0.024162635
case acc: 0.019544907
case acc: 0.023740523
case acc: 0.020644464
case acc: 0.017169243
case acc: 0.015579557
top acc: 0.0114 ::: bot acc: 0.0381
top acc: 0.0089 ::: bot acc: 0.0303
top acc: 0.0075 ::: bot acc: 0.0425
top acc: 0.0093 ::: bot acc: 0.0346
top acc: 0.0054 ::: bot acc: 0.0293
top acc: 0.0067 ::: bot acc: 0.0282
current epoch: 26
train loss is 0.018184
average val loss: 0.028272, accuracy: 0.0283
average test loss: 0.028780, accuracy: 0.0288
case acc: 0.034417946
case acc: 0.02989682
case acc: 0.03146264
case acc: 0.02802443
case acc: 0.0276684
case acc: 0.021102471
top acc: 0.0201 ::: bot acc: 0.0491
top acc: 0.0167 ::: bot acc: 0.0419
top acc: 0.0122 ::: bot acc: 0.0517
top acc: 0.0148 ::: bot acc: 0.0428
top acc: 0.0137 ::: bot acc: 0.0409
top acc: 0.0073 ::: bot acc: 0.0362
current epoch: 27
train loss is 0.020579
average val loss: 0.031858, accuracy: 0.0319
average test loss: 0.032238, accuracy: 0.0323
case acc: 0.038045254
case acc: 0.034609027
case acc: 0.035209388
case acc: 0.027619362
case acc: 0.032678697
case acc: 0.025351696
top acc: 0.0237 ::: bot acc: 0.0528
top acc: 0.0213 ::: bot acc: 0.0466
top acc: 0.0153 ::: bot acc: 0.0558
top acc: 0.0145 ::: bot acc: 0.0424
top acc: 0.0187 ::: bot acc: 0.0459
top acc: 0.0103 ::: bot acc: 0.0410
current epoch: 28
train loss is 0.024444
average val loss: 0.011488, accuracy: 0.0117
average test loss: 0.013494, accuracy: 0.0135
case acc: 0.011398503
case acc: 0.010602635
case acc: 0.015157411
case acc: 0.018843375
case acc: 0.011862011
case acc: 0.013285101
top acc: 0.0192 ::: bot acc: 0.0098
top acc: 0.0207 ::: bot acc: 0.0051
top acc: 0.0226 ::: bot acc: 0.0191
top acc: 0.0320 ::: bot acc: 0.0083
top acc: 0.0226 ::: bot acc: 0.0052
top acc: 0.0237 ::: bot acc: 0.0098
current epoch: 29
train loss is 0.021699
average val loss: 0.025869, accuracy: 0.0260
average test loss: 0.026223, accuracy: 0.0263
case acc: 0.027008554
case acc: 0.029492741
case acc: 0.021059887
case acc: 0.030722177
case acc: 0.030292062
case acc: 0.019508531
top acc: 0.0408 ::: bot acc: 0.0134
top acc: 0.0428 ::: bot acc: 0.0175
top acc: 0.0387 ::: bot acc: 0.0064
top acc: 0.0461 ::: bot acc: 0.0155
top acc: 0.0443 ::: bot acc: 0.0171
top acc: 0.0351 ::: bot acc: 0.0054
current epoch: 30
train loss is 0.025737
average val loss: 0.009944, accuracy: 0.0099
average test loss: 0.012584, accuracy: 0.0124
case acc: 0.011654104
case acc: 0.0095818555
case acc: 0.017447228
case acc: 0.012269309
case acc: 0.009931124
case acc: 0.013632508
top acc: 0.0088 ::: bot acc: 0.0207
top acc: 0.0114 ::: bot acc: 0.0139
top acc: 0.0103 ::: bot acc: 0.0317
top acc: 0.0108 ::: bot acc: 0.0212
top acc: 0.0134 ::: bot acc: 0.0139
top acc: 0.0097 ::: bot acc: 0.0238
current epoch: 31
train loss is 0.018419
average val loss: 0.020979, accuracy: 0.0210
average test loss: 0.021961, accuracy: 0.0220
case acc: 0.026066365
case acc: 0.02199887
case acc: 0.024659183
case acc: 0.023230886
case acc: 0.019630942
case acc: 0.01630195
top acc: 0.0129 ::: bot acc: 0.0401
top acc: 0.0104 ::: bot acc: 0.0332
top acc: 0.0078 ::: bot acc: 0.0438
top acc: 0.0110 ::: bot acc: 0.0376
top acc: 0.0067 ::: bot acc: 0.0323
top acc: 0.0065 ::: bot acc: 0.0294
current epoch: 32
train loss is 0.020041
average val loss: 0.033936, accuracy: 0.0339
average test loss: 0.034261, accuracy: 0.0343
case acc: 0.040959187
case acc: 0.037502393
case acc: 0.035588313
case acc: 0.03265161
case acc: 0.035294395
case acc: 0.023915099
top acc: 0.0267 ::: bot acc: 0.0556
top acc: 0.0242 ::: bot acc: 0.0495
top acc: 0.0155 ::: bot acc: 0.0563
top acc: 0.0190 ::: bot acc: 0.0477
top acc: 0.0213 ::: bot acc: 0.0485
top acc: 0.0092 ::: bot acc: 0.0394
current epoch: 33
train loss is 0.025877
average val loss: 0.010248, accuracy: 0.0104
average test loss: 0.012504, accuracy: 0.0124
case acc: 0.010436913
case acc: 0.0093996655
case acc: 0.015186433
case acc: 0.014282228
case acc: 0.010634561
case acc: 0.014487292
top acc: 0.0155 ::: bot acc: 0.0135
top acc: 0.0171 ::: bot acc: 0.0082
top acc: 0.0226 ::: bot acc: 0.0192
top acc: 0.0252 ::: bot acc: 0.0083
top acc: 0.0196 ::: bot acc: 0.0077
top acc: 0.0270 ::: bot acc: 0.0067
current epoch: 34
train loss is 0.016418
average val loss: 0.009696, accuracy: 0.0099
average test loss: 0.012078, accuracy: 0.0121
case acc: 0.010840327
case acc: 0.009973537
case acc: 0.015016659
case acc: 0.01272539
case acc: 0.011320053
case acc: 0.012616662
top acc: 0.0175 ::: bot acc: 0.0115
top acc: 0.0194 ::: bot acc: 0.0059
top acc: 0.0201 ::: bot acc: 0.0218
top acc: 0.0219 ::: bot acc: 0.0101
top acc: 0.0215 ::: bot acc: 0.0059
top acc: 0.0206 ::: bot acc: 0.0129
current epoch: 35
train loss is 0.016607
average val loss: 0.012124, accuracy: 0.0122
average test loss: 0.013947, accuracy: 0.0142
case acc: 0.013289148
case acc: 0.014231648
case acc: 0.015625706
case acc: 0.013055625
case acc: 0.015637083
case acc: 0.013620135
top acc: 0.0236 ::: bot acc: 0.0067
top acc: 0.0262 ::: bot acc: 0.0050
top acc: 0.0250 ::: bot acc: 0.0169
top acc: 0.0228 ::: bot acc: 0.0094
top acc: 0.0284 ::: bot acc: 0.0051
top acc: 0.0247 ::: bot acc: 0.0088
current epoch: 36
train loss is 0.018916
average val loss: 0.010150, accuracy: 0.0103
average test loss: 0.012755, accuracy: 0.0129
case acc: 0.012291649
case acc: 0.009804734
case acc: 0.016768277
case acc: 0.015932927
case acc: 0.009983613
case acc: 0.012430242
top acc: 0.0081 ::: bot acc: 0.0220
top acc: 0.0105 ::: bot acc: 0.0148
top acc: 0.0120 ::: bot acc: 0.0299
top acc: 0.0076 ::: bot acc: 0.0283
top acc: 0.0132 ::: bot acc: 0.0141
top acc: 0.0150 ::: bot acc: 0.0185
current epoch: 37
train loss is 0.019507
average val loss: 0.036990, accuracy: 0.0370
average test loss: 0.037219, accuracy: 0.0372
case acc: 0.04245801
case acc: 0.03792474
case acc: 0.037826534
case acc: 0.04372693
case acc: 0.035360485
case acc: 0.02603551
top acc: 0.0282 ::: bot acc: 0.0571
top acc: 0.0246 ::: bot acc: 0.0499
top acc: 0.0174 ::: bot acc: 0.0587
top acc: 0.0289 ::: bot acc: 0.0593
top acc: 0.0213 ::: bot acc: 0.0486
top acc: 0.0108 ::: bot acc: 0.0418
current epoch: 38
train loss is 0.024085
average val loss: 0.018826, accuracy: 0.0188
average test loss: 0.020064, accuracy: 0.0202
case acc: 0.024284055
case acc: 0.021250604
case acc: 0.02192306
case acc: 0.02201951
case acc: 0.018509489
case acc: 0.013317127
top acc: 0.0115 ::: bot acc: 0.0382
top acc: 0.0099 ::: bot acc: 0.0322
top acc: 0.0069 ::: bot acc: 0.0401
top acc: 0.0102 ::: bot acc: 0.0361
top acc: 0.0060 ::: bot acc: 0.0310
top acc: 0.0106 ::: bot acc: 0.0229
current epoch: 39
train loss is 0.019650
average val loss: 0.008800, accuracy: 0.0089
average test loss: 0.011519, accuracy: 0.0115
case acc: 0.010305729
case acc: 0.009237316
case acc: 0.015554197
case acc: 0.011444598
case acc: 0.009951109
case acc: 0.012333108
top acc: 0.0121 ::: bot acc: 0.0169
top acc: 0.0135 ::: bot acc: 0.0117
top acc: 0.0159 ::: bot acc: 0.0259
top acc: 0.0152 ::: bot acc: 0.0168
top acc: 0.0160 ::: bot acc: 0.0113
top acc: 0.0183 ::: bot acc: 0.0152
current epoch: 40
train loss is 0.015881
average val loss: 0.015707, accuracy: 0.0159
average test loss: 0.016924, accuracy: 0.0173
case acc: 0.017353285
case acc: 0.01853499
case acc: 0.016845368
case acc: 0.016418906
case acc: 0.01983957
case acc: 0.01480289
top acc: 0.0299 ::: bot acc: 0.0063
top acc: 0.0314 ::: bot acc: 0.0075
top acc: 0.0293 ::: bot acc: 0.0126
top acc: 0.0287 ::: bot acc: 0.0077
top acc: 0.0335 ::: bot acc: 0.0075
top acc: 0.0277 ::: bot acc: 0.0063
current epoch: 41
train loss is 0.020179
average val loss: 0.009388, accuracy: 0.0095
average test loss: 0.012069, accuracy: 0.0120
case acc: 0.010380656
case acc: 0.009201346
case acc: 0.01633859
case acc: 0.013582763
case acc: 0.009998994
case acc: 0.012613874
top acc: 0.0117 ::: bot acc: 0.0173
top acc: 0.0141 ::: bot acc: 0.0112
top acc: 0.0133 ::: bot acc: 0.0287
top acc: 0.0082 ::: bot acc: 0.0245
top acc: 0.0165 ::: bot acc: 0.0108
top acc: 0.0136 ::: bot acc: 0.0200
current epoch: 42
train loss is 0.019513
average val loss: 0.028784, accuracy: 0.0288
average test loss: 0.029238, accuracy: 0.0292
case acc: 0.032395348
case acc: 0.028856764
case acc: 0.031191718
case acc: 0.03494386
case acc: 0.02641377
case acc: 0.021482615
top acc: 0.0184 ::: bot acc: 0.0469
top acc: 0.0158 ::: bot acc: 0.0407
top acc: 0.0118 ::: bot acc: 0.0516
top acc: 0.0210 ::: bot acc: 0.0501
top acc: 0.0124 ::: bot acc: 0.0396
top acc: 0.0075 ::: bot acc: 0.0367
current epoch: 43
train loss is 0.020700
average val loss: 0.021447, accuracy: 0.0214
average test loss: 0.022388, accuracy: 0.0225
case acc: 0.026135854
case acc: 0.023776473
case acc: 0.024593921
case acc: 0.023818575
case acc: 0.02113389
case acc: 0.015243316
top acc: 0.0130 ::: bot acc: 0.0402
top acc: 0.0116 ::: bot acc: 0.0352
top acc: 0.0077 ::: bot acc: 0.0438
top acc: 0.0114 ::: bot acc: 0.0382
top acc: 0.0078 ::: bot acc: 0.0340
top acc: 0.0071 ::: bot acc: 0.0276
current epoch: 44
train loss is 0.020135
average val loss: 0.009216, accuracy: 0.0094
average test loss: 0.011736, accuracy: 0.0117
case acc: 0.010514844
case acc: 0.00929824
case acc: 0.015048985
case acc: 0.012074914
case acc: 0.010473018
case acc: 0.012950144
top acc: 0.0160 ::: bot acc: 0.0130
top acc: 0.0165 ::: bot acc: 0.0087
top acc: 0.0197 ::: bot acc: 0.0222
top acc: 0.0198 ::: bot acc: 0.0122
top acc: 0.0191 ::: bot acc: 0.0082
top acc: 0.0223 ::: bot acc: 0.0112
current epoch: 45
train loss is 0.015705
average val loss: 0.014381, accuracy: 0.0146
average test loss: 0.015790, accuracy: 0.0162
case acc: 0.016141336
case acc: 0.01640501
case acc: 0.016420929
case acc: 0.015570518
case acc: 0.017883794
case acc: 0.014494612
top acc: 0.0282 ::: bot acc: 0.0060
top acc: 0.0289 ::: bot acc: 0.0061
top acc: 0.0279 ::: bot acc: 0.0141
top acc: 0.0274 ::: bot acc: 0.0078
top acc: 0.0312 ::: bot acc: 0.0063
top acc: 0.0270 ::: bot acc: 0.0068
current epoch: 46
train loss is 0.018392
average val loss: 0.009192, accuracy: 0.0093
average test loss: 0.011759, accuracy: 0.0118
case acc: 0.010729939
case acc: 0.009727086
case acc: 0.015166665
case acc: 0.011810111
case acc: 0.0111818025
case acc: 0.012406868
top acc: 0.0170 ::: bot acc: 0.0120
top acc: 0.0186 ::: bot acc: 0.0066
top acc: 0.0183 ::: bot acc: 0.0237
top acc: 0.0127 ::: bot acc: 0.0193
top acc: 0.0212 ::: bot acc: 0.0062
top acc: 0.0190 ::: bot acc: 0.0146
current epoch: 47
train loss is 0.018609
average val loss: 0.024009, accuracy: 0.0240
average test loss: 0.024727, accuracy: 0.0248
case acc: 0.027137604
case acc: 0.024194382
case acc: 0.02705132
case acc: 0.03088336
case acc: 0.021478022
case acc: 0.017818503
top acc: 0.0138 ::: bot acc: 0.0413
top acc: 0.0119 ::: bot acc: 0.0356
top acc: 0.0090 ::: bot acc: 0.0468
top acc: 0.0174 ::: bot acc: 0.0458
top acc: 0.0081 ::: bot acc: 0.0344
top acc: 0.0064 ::: bot acc: 0.0318
current epoch: 48
train loss is 0.019590
average val loss: 0.026054, accuracy: 0.0260
average test loss: 0.026680, accuracy: 0.0267
case acc: 0.030703155
case acc: 0.028637096
case acc: 0.0284321
case acc: 0.02927571
case acc: 0.02591891
case acc: 0.017401328
top acc: 0.0169 ::: bot acc: 0.0451
top acc: 0.0156 ::: bot acc: 0.0405
top acc: 0.0099 ::: bot acc: 0.0484
top acc: 0.0160 ::: bot acc: 0.0441
top acc: 0.0120 ::: bot acc: 0.0391
top acc: 0.0064 ::: bot acc: 0.0311
current epoch: 49
train loss is 0.021767
average val loss: 0.009117, accuracy: 0.0092
average test loss: 0.011680, accuracy: 0.0117
case acc: 0.0103574125
case acc: 0.009173783
case acc: 0.0150427865
case acc: 0.011661212
case acc: 0.010202552
case acc: 0.013480781
top acc: 0.0149 ::: bot acc: 0.0141
top acc: 0.0150 ::: bot acc: 0.0102
top acc: 0.0196 ::: bot acc: 0.0223
top acc: 0.0177 ::: bot acc: 0.0143
top acc: 0.0180 ::: bot acc: 0.0094
top acc: 0.0242 ::: bot acc: 0.0093
current epoch: 50
train loss is 0.014518
average val loss: 0.009781, accuracy: 0.0099
average test loss: 0.012144, accuracy: 0.0122
case acc: 0.011564036
case acc: 0.010217966
case acc: 0.015038818
case acc: 0.011785963
case acc: 0.01182828
case acc: 0.012910774
top acc: 0.0197 ::: bot acc: 0.0093
top acc: 0.0200 ::: bot acc: 0.0054
top acc: 0.0208 ::: bot acc: 0.0212
top acc: 0.0185 ::: bot acc: 0.0135
top acc: 0.0226 ::: bot acc: 0.0052
top acc: 0.0221 ::: bot acc: 0.0115
LME_Co_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6798 6798 6798
1.7082474 -0.6288155 0.08104724 -0.08406281
Validation: 756 756 756
Testing: 774 774 774
pre-processing time: 0.00021314620971679688
the split date is 2010-07-01
net initializing with time: 0.0023627281188964844
preparing training and testing date with time: 2.384185791015625e-07
current epoch: 1
train loss is 0.307150
average val loss: 0.151424, accuracy: 0.1514
average test loss: 0.152134, accuracy: 0.1521
case acc: 0.20839512
case acc: 0.35583934
case acc: 0.06403349
case acc: 0.14095795
case acc: 0.10074423
case acc: 0.042852707
top acc: 0.1933 ::: bot acc: 0.2234
top acc: 0.3420 ::: bot acc: 0.3695
top acc: 0.0408 ::: bot acc: 0.0867
top acc: 0.1231 ::: bot acc: 0.1577
top acc: 0.0806 ::: bot acc: 0.1176
top acc: 0.0269 ::: bot acc: 0.0593
current epoch: 2
train loss is 0.193897
average val loss: 0.095495, accuracy: 0.0952
average test loss: 0.095696, accuracy: 0.0955
case acc: 0.014238409
case acc: 0.1487032
case acc: 0.12901177
case acc: 0.051477373
case acc: 0.086194135
case acc: 0.1433477
top acc: 0.0101 ::: bot acc: 0.0234
top acc: 0.1349 ::: bot acc: 0.1622
top acc: 0.1522 ::: bot acc: 0.1064
top acc: 0.0694 ::: bot acc: 0.0350
top acc: 0.1066 ::: bot acc: 0.0690
top acc: 0.1603 ::: bot acc: 0.1266
current epoch: 3
train loss is 0.091268
average val loss: 0.133647, accuracy: 0.1336
average test loss: 0.134349, accuracy: 0.1344
case acc: 0.18479289
case acc: 0.3126727
case acc: 0.050043114
case acc: 0.124916844
case acc: 0.09475467
case acc: 0.039257944
top acc: 0.1693 ::: bot acc: 0.1996
top acc: 0.2989 ::: bot acc: 0.3260
top acc: 0.0276 ::: bot acc: 0.0723
top acc: 0.1070 ::: bot acc: 0.1413
top acc: 0.0747 ::: bot acc: 0.1119
top acc: 0.0233 ::: bot acc: 0.0556
current epoch: 4
train loss is 0.121290
average val loss: 0.095759, accuracy: 0.0965
average test loss: 0.096797, accuracy: 0.0972
case acc: 0.1401829
case acc: 0.26204237
case acc: 0.020353906
case acc: 0.08662075
case acc: 0.060677677
case acc: 0.013519283
top acc: 0.1246 ::: bot acc: 0.1551
top acc: 0.2482 ::: bot acc: 0.2753
top acc: 0.0117 ::: bot acc: 0.0357
top acc: 0.0686 ::: bot acc: 0.1030
top acc: 0.0414 ::: bot acc: 0.0775
top acc: 0.0119 ::: bot acc: 0.0225
current epoch: 5
train loss is 0.107982
average val loss: 0.085020, accuracy: 0.0860
average test loss: 0.085970, accuracy: 0.0866
case acc: 0.12191923
case acc: 0.23821121
case acc: 0.017475571
case acc: 0.07547994
case acc: 0.053997558
case acc: 0.01265651
top acc: 0.1061 ::: bot acc: 0.1369
top acc: 0.2245 ::: bot acc: 0.2514
top acc: 0.0202 ::: bot acc: 0.0261
top acc: 0.0575 ::: bot acc: 0.0917
top acc: 0.0347 ::: bot acc: 0.0708
top acc: 0.0169 ::: bot acc: 0.0172
current epoch: 6
train loss is 0.097644
average val loss: 0.083670, accuracy: 0.0845
average test loss: 0.084684, accuracy: 0.0852
case acc: 0.116209015
case acc: 0.22676685
case acc: 0.017977962
case acc: 0.07657385
case acc: 0.059451807
case acc: 0.014247453
top acc: 0.1003 ::: bot acc: 0.1313
top acc: 0.2130 ::: bot acc: 0.2400
top acc: 0.0175 ::: bot acc: 0.0290
top acc: 0.0585 ::: bot acc: 0.0926
top acc: 0.0398 ::: bot acc: 0.0765
top acc: 0.0109 ::: bot acc: 0.0243
current epoch: 7
train loss is 0.090895
average val loss: 0.084439, accuracy: 0.0851
average test loss: 0.085455, accuracy: 0.0859
case acc: 0.11253848
case acc: 0.217854
case acc: 0.019564329
case acc: 0.07962852
case acc: 0.0663353
case acc: 0.01936307
top acc: 0.0965 ::: bot acc: 0.1277
top acc: 0.2042 ::: bot acc: 0.2310
top acc: 0.0134 ::: bot acc: 0.0340
top acc: 0.0616 ::: bot acc: 0.0955
top acc: 0.0464 ::: bot acc: 0.0836
top acc: 0.0086 ::: bot acc: 0.0331
current epoch: 8
train loss is 0.085558
average val loss: 0.077586, accuracy: 0.0783
average test loss: 0.078574, accuracy: 0.0791
case acc: 0.09982967
case acc: 0.20025538
case acc: 0.018156467
case acc: 0.073485605
case acc: 0.06375657
case acc: 0.018858593
top acc: 0.0837 ::: bot acc: 0.1150
top acc: 0.1866 ::: bot acc: 0.2134
top acc: 0.0169 ::: bot acc: 0.0298
top acc: 0.0554 ::: bot acc: 0.0894
top acc: 0.0439 ::: bot acc: 0.0810
top acc: 0.0086 ::: bot acc: 0.0324
current epoch: 9
train loss is 0.079476
average val loss: 0.078917, accuracy: 0.0794
average test loss: 0.079860, accuracy: 0.0803
case acc: 0.096491545
case acc: 0.19305639
case acc: 0.01991248
case acc: 0.0769804
case acc: 0.069875024
case acc: 0.025256855
top acc: 0.0804 ::: bot acc: 0.1115
top acc: 0.1795 ::: bot acc: 0.2060
top acc: 0.0123 ::: bot acc: 0.0350
top acc: 0.0588 ::: bot acc: 0.0929
top acc: 0.0500 ::: bot acc: 0.0873
top acc: 0.0115 ::: bot acc: 0.0404
current epoch: 10
train loss is 0.079267
average val loss: 0.089388, accuracy: 0.0895
average test loss: 0.090159, accuracy: 0.0904
case acc: 0.1020728
case acc: 0.19643864
case acc: 0.029599896
case acc: 0.08984454
case acc: 0.084313594
case acc: 0.040401228
top acc: 0.0860 ::: bot acc: 0.1171
top acc: 0.1829 ::: bot acc: 0.2093
top acc: 0.0127 ::: bot acc: 0.0494
top acc: 0.0717 ::: bot acc: 0.1058
top acc: 0.0641 ::: bot acc: 0.1019
top acc: 0.0240 ::: bot acc: 0.0568
current epoch: 11
train loss is 0.075688
average val loss: 0.075056, accuracy: 0.0755
average test loss: 0.075927, accuracy: 0.0763
case acc: 0.081521444
case acc: 0.17428231
case acc: 0.021048557
case acc: 0.07670227
case acc: 0.07293873
case acc: 0.03117161
top acc: 0.0654 ::: bot acc: 0.0966
top acc: 0.1607 ::: bot acc: 0.1873
top acc: 0.0106 ::: bot acc: 0.0376
top acc: 0.0586 ::: bot acc: 0.0927
top acc: 0.0531 ::: bot acc: 0.0904
top acc: 0.0159 ::: bot acc: 0.0470
current epoch: 12
train loss is 0.071366
average val loss: 0.076518, accuracy: 0.0768
average test loss: 0.077335, accuracy: 0.0776
case acc: 0.07756604
case acc: 0.16904828
case acc: 0.024017463
case acc: 0.08016474
case acc: 0.07766695
case acc: 0.037358202
top acc: 0.0615 ::: bot acc: 0.0927
top acc: 0.1554 ::: bot acc: 0.1820
top acc: 0.0100 ::: bot acc: 0.0424
top acc: 0.0620 ::: bot acc: 0.0961
top acc: 0.0577 ::: bot acc: 0.0952
top acc: 0.0213 ::: bot acc: 0.0536
current epoch: 13
train loss is 0.067992
average val loss: 0.066676, accuracy: 0.0672
average test loss: 0.067524, accuracy: 0.0679
case acc: 0.061620835
case acc: 0.15208107
case acc: 0.019851185
case acc: 0.071578346
case acc: 0.070452504
case acc: 0.032024242
top acc: 0.0455 ::: bot acc: 0.0769
top acc: 0.1385 ::: bot acc: 0.1651
top acc: 0.0123 ::: bot acc: 0.0351
top acc: 0.0535 ::: bot acc: 0.0875
top acc: 0.0508 ::: bot acc: 0.0879
top acc: 0.0167 ::: bot acc: 0.0479
current epoch: 14
train loss is 0.062804
average val loss: 0.059963, accuracy: 0.0605
average test loss: 0.060810, accuracy: 0.0613
case acc: 0.049069792
case acc: 0.13852213
case acc: 0.018209003
case acc: 0.066084445
case acc: 0.06615498
case acc: 0.029552381
top acc: 0.0329 ::: bot acc: 0.0644
top acc: 0.1249 ::: bot acc: 0.1515
top acc: 0.0159 ::: bot acc: 0.0308
top acc: 0.0480 ::: bot acc: 0.0820
top acc: 0.0467 ::: bot acc: 0.0836
top acc: 0.0146 ::: bot acc: 0.0452
current epoch: 15
train loss is 0.058969
average val loss: 0.056683, accuracy: 0.0573
average test loss: 0.057532, accuracy: 0.0580
case acc: 0.04073622
case acc: 0.12893379
case acc: 0.018005447
case acc: 0.064325124
case acc: 0.06542475
case acc: 0.030451143
top acc: 0.0247 ::: bot acc: 0.0560
top acc: 0.1153 ::: bot acc: 0.1419
top acc: 0.0165 ::: bot acc: 0.0302
top acc: 0.0463 ::: bot acc: 0.0802
top acc: 0.0460 ::: bot acc: 0.0829
top acc: 0.0153 ::: bot acc: 0.0461
current epoch: 16
train loss is 0.054581
average val loss: 0.046368, accuracy: 0.0469
average test loss: 0.047281, accuracy: 0.0478
case acc: 0.025488498
case acc: 0.110557
case acc: 0.017282674
case acc: 0.05372956
case acc: 0.05603105
case acc: 0.023540096
top acc: 0.0128 ::: bot acc: 0.0391
top acc: 0.0970 ::: bot acc: 0.1235
top acc: 0.0258 ::: bot acc: 0.0208
top acc: 0.0357 ::: bot acc: 0.0696
top acc: 0.0369 ::: bot acc: 0.0734
top acc: 0.0102 ::: bot acc: 0.0383
current epoch: 17
train loss is 0.048587
average val loss: 0.040462, accuracy: 0.0410
average test loss: 0.041397, accuracy: 0.0417
case acc: 0.017001089
case acc: 0.09643421
case acc: 0.018133093
case acc: 0.047262065
case acc: 0.050777316
case acc: 0.020668197
top acc: 0.0097 ::: bot acc: 0.0278
top acc: 0.0829 ::: bot acc: 0.1093
top acc: 0.0307 ::: bot acc: 0.0158
top acc: 0.0292 ::: bot acc: 0.0631
top acc: 0.0319 ::: bot acc: 0.0680
top acc: 0.0087 ::: bot acc: 0.0347
current epoch: 18
train loss is 0.041771
average val loss: 0.031016, accuracy: 0.0313
average test loss: 0.031824, accuracy: 0.0316
case acc: 0.012581365
case acc: 0.07146847
case acc: 0.025667442
case acc: 0.031196257
case acc: 0.03559222
case acc: 0.013113192
top acc: 0.0229 ::: bot acc: 0.0092
top acc: 0.0580 ::: bot acc: 0.0843
top acc: 0.0452 ::: bot acc: 0.0099
top acc: 0.0150 ::: bot acc: 0.0461
top acc: 0.0176 ::: bot acc: 0.0524
top acc: 0.0127 ::: bot acc: 0.0212
current epoch: 19
train loss is 0.036597
average val loss: 0.025814, accuracy: 0.0259
average test loss: 0.026566, accuracy: 0.0265
case acc: 0.020733736
case acc: 0.046550713
case acc: 0.035236478
case acc: 0.018948333
case acc: 0.024264429
case acc: 0.013172819
top acc: 0.0356 ::: bot acc: 0.0080
top acc: 0.0330 ::: bot acc: 0.0594
top acc: 0.0568 ::: bot acc: 0.0155
top acc: 0.0101 ::: bot acc: 0.0302
top acc: 0.0098 ::: bot acc: 0.0394
top acc: 0.0233 ::: bot acc: 0.0106
current epoch: 20
train loss is 0.036153
average val loss: 0.023157, accuracy: 0.0230
average test loss: 0.023889, accuracy: 0.0236
case acc: 0.029183479
case acc: 0.020382866
case acc: 0.045318995
case acc: 0.01220794
case acc: 0.017504402
case acc: 0.01706418
top acc: 0.0449 ::: bot acc: 0.0146
top acc: 0.0086 ::: bot acc: 0.0323
top acc: 0.0676 ::: bot acc: 0.0242
top acc: 0.0196 ::: bot acc: 0.0144
top acc: 0.0121 ::: bot acc: 0.0281
top acc: 0.0318 ::: bot acc: 0.0053
current epoch: 21
train loss is 0.034901
average val loss: 0.021972, accuracy: 0.0214
average test loss: 0.022643, accuracy: 0.0222
case acc: 0.028825415
case acc: 0.009870738
case acc: 0.047839757
case acc: 0.013738871
case acc: 0.016808577
case acc: 0.016247783
top acc: 0.0445 ::: bot acc: 0.0144
top acc: 0.0140 ::: bot acc: 0.0124
top acc: 0.0701 ::: bot acc: 0.0265
top acc: 0.0266 ::: bot acc: 0.0080
top acc: 0.0129 ::: bot acc: 0.0268
top acc: 0.0305 ::: bot acc: 0.0054
current epoch: 22
train loss is 0.031798
average val loss: 0.026587, accuracy: 0.0263
average test loss: 0.026923, accuracy: 0.0269
case acc: 0.03142926
case acc: 0.024011659
case acc: 0.053768422
case acc: 0.020030443
case acc: 0.015236073
case acc: 0.016995545
top acc: 0.0473 ::: bot acc: 0.0166
top acc: 0.0375 ::: bot acc: 0.0113
top acc: 0.0763 ::: bot acc: 0.0320
top acc: 0.0365 ::: bot acc: 0.0072
top acc: 0.0158 ::: bot acc: 0.0230
top acc: 0.0317 ::: bot acc: 0.0051
current epoch: 23
train loss is 0.028007
average val loss: 0.039294, accuracy: 0.0390
average test loss: 0.039326, accuracy: 0.0394
case acc: 0.040573128
case acc: 0.0542453
case acc: 0.06693006
case acc: 0.036007844
case acc: 0.01461447
case acc: 0.023930606
top acc: 0.0566 ::: bot acc: 0.0254
top acc: 0.0677 ::: bot acc: 0.0415
top acc: 0.0897 ::: bot acc: 0.0445
top acc: 0.0537 ::: bot acc: 0.0207
top acc: 0.0269 ::: bot acc: 0.0120
top acc: 0.0405 ::: bot acc: 0.0083
current epoch: 24
train loss is 0.031573
average val loss: 0.066668, accuracy: 0.0666
average test loss: 0.066436, accuracy: 0.0664
case acc: 0.06174503
case acc: 0.095859826
case acc: 0.094677225
case acc: 0.06664572
case acc: 0.03230271
case acc: 0.04694302
top acc: 0.0779 ::: bot acc: 0.0465
top acc: 0.1093 ::: bot acc: 0.0832
top acc: 0.1177 ::: bot acc: 0.0716
top acc: 0.0847 ::: bot acc: 0.0508
top acc: 0.0521 ::: bot acc: 0.0148
top acc: 0.0640 ::: bot acc: 0.0304
current epoch: 25
train loss is 0.051211
average val loss: 0.091228, accuracy: 0.0912
average test loss: 0.090962, accuracy: 0.0909
case acc: 0.07754661
case acc: 0.12743954
case acc: 0.12034861
case acc: 0.09432237
case acc: 0.055836063
case acc: 0.07008688
top acc: 0.0937 ::: bot acc: 0.0621
top acc: 0.1409 ::: bot acc: 0.1147
top acc: 0.1435 ::: bot acc: 0.0971
top acc: 0.1123 ::: bot acc: 0.0785
top acc: 0.0760 ::: bot acc: 0.0375
top acc: 0.0872 ::: bot acc: 0.0536
current epoch: 26
train loss is 0.077214
average val loss: 0.031911, accuracy: 0.0315
average test loss: 0.032408, accuracy: 0.0325
case acc: 0.012214319
case acc: 0.060429085
case acc: 0.05771857
case acc: 0.03491666
case acc: 0.014718002
case acc: 0.014979443
top acc: 0.0218 ::: bot acc: 0.0101
top acc: 0.0739 ::: bot acc: 0.0477
top acc: 0.0803 ::: bot acc: 0.0357
top acc: 0.0525 ::: bot acc: 0.0198
top acc: 0.0166 ::: bot acc: 0.0219
top acc: 0.0283 ::: bot acc: 0.0061
current epoch: 27
train loss is 0.065850
average val loss: 0.022397, accuracy: 0.0220
average test loss: 0.023225, accuracy: 0.0230
case acc: 0.033824664
case acc: 0.01453428
case acc: 0.025328921
case acc: 0.012160838
case acc: 0.03318286
case acc: 0.018723015
top acc: 0.0185 ::: bot acc: 0.0487
top acc: 0.0266 ::: bot acc: 0.0045
top acc: 0.0446 ::: bot acc: 0.0096
top acc: 0.0192 ::: bot acc: 0.0147
top acc: 0.0159 ::: bot acc: 0.0501
top acc: 0.0080 ::: bot acc: 0.0320
current epoch: 28
train loss is 0.052573
average val loss: 0.017919, accuracy: 0.0174
average test loss: 0.019023, accuracy: 0.0186
case acc: 0.024848001
case acc: 0.009674228
case acc: 0.028727822
case acc: 0.012317275
case acc: 0.023488732
case acc: 0.012554403
top acc: 0.0122 ::: bot acc: 0.0384
top acc: 0.0150 ::: bot acc: 0.0111
top acc: 0.0490 ::: bot acc: 0.0110
top acc: 0.0227 ::: bot acc: 0.0112
top acc: 0.0094 ::: bot acc: 0.0389
top acc: 0.0144 ::: bot acc: 0.0191
current epoch: 29
train loss is 0.040599
average val loss: 0.017719, accuracy: 0.0170
average test loss: 0.018685, accuracy: 0.0182
case acc: 0.013043016
case acc: 0.01038767
case acc: 0.03750748
case acc: 0.016342824
case acc: 0.01470227
case acc: 0.017470235
top acc: 0.0104 ::: bot acc: 0.0216
top acc: 0.0092 ::: bot acc: 0.0168
top acc: 0.0589 ::: bot acc: 0.0175
top acc: 0.0316 ::: bot acc: 0.0059
top acc: 0.0162 ::: bot acc: 0.0222
top acc: 0.0326 ::: bot acc: 0.0050
current epoch: 30
train loss is 0.030810
average val loss: 0.019753, accuracy: 0.0192
average test loss: 0.020574, accuracy: 0.0202
case acc: 0.011689388
case acc: 0.016796218
case acc: 0.037831046
case acc: 0.017123045
case acc: 0.013850484
case acc: 0.023786703
top acc: 0.0134 ::: bot acc: 0.0181
top acc: 0.0066 ::: bot acc: 0.0278
top acc: 0.0593 ::: bot acc: 0.0177
top acc: 0.0327 ::: bot acc: 0.0060
top acc: 0.0229 ::: bot acc: 0.0154
top acc: 0.0404 ::: bot acc: 0.0083
current epoch: 31
train loss is 0.026390
average val loss: 0.019018, accuracy: 0.0187
average test loss: 0.019996, accuracy: 0.0202
case acc: 0.018504977
case acc: 0.03311646
case acc: 0.025508467
case acc: 0.0121253235
case acc: 0.015532928
case acc: 0.016334798
top acc: 0.0096 ::: bot acc: 0.0302
top acc: 0.0197 ::: bot acc: 0.0457
top acc: 0.0449 ::: bot acc: 0.0096
top acc: 0.0204 ::: bot acc: 0.0135
top acc: 0.0140 ::: bot acc: 0.0247
top acc: 0.0309 ::: bot acc: 0.0050
current epoch: 32
train loss is 0.031679
average val loss: 0.025598, accuracy: 0.0262
average test loss: 0.026690, accuracy: 0.0273
case acc: 0.031195851
case acc: 0.05668668
case acc: 0.016871031
case acc: 0.021001713
case acc: 0.025362086
case acc: 0.012606517
top acc: 0.0164 ::: bot acc: 0.0458
top acc: 0.0432 ::: bot acc: 0.0693
top acc: 0.0243 ::: bot acc: 0.0219
top acc: 0.0103 ::: bot acc: 0.0332
top acc: 0.0102 ::: bot acc: 0.0414
top acc: 0.0137 ::: bot acc: 0.0197
current epoch: 33
train loss is 0.041482
average val loss: 0.053647, accuracy: 0.0537
average test loss: 0.054072, accuracy: 0.0543
case acc: 0.05615854
case acc: 0.09348518
case acc: 0.034257274
case acc: 0.051311634
case acc: 0.054960083
case acc: 0.03541454
top acc: 0.0401 ::: bot acc: 0.0715
top acc: 0.0800 ::: bot acc: 0.1062
top acc: 0.0149 ::: bot acc: 0.0556
top acc: 0.0334 ::: bot acc: 0.0672
top acc: 0.0366 ::: bot acc: 0.0725
top acc: 0.0198 ::: bot acc: 0.0511
current epoch: 34
train loss is 0.040003
average val loss: 0.034103, accuracy: 0.0345
average test loss: 0.035006, accuracy: 0.0352
case acc: 0.029108167
case acc: 0.070962764
case acc: 0.020519251
case acc: 0.0334097
case acc: 0.037198436
case acc: 0.020234717
top acc: 0.0148 ::: bot acc: 0.0435
top acc: 0.0575 ::: bot acc: 0.0836
top acc: 0.0103 ::: bot acc: 0.0373
top acc: 0.0167 ::: bot acc: 0.0487
top acc: 0.0195 ::: bot acc: 0.0544
top acc: 0.0084 ::: bot acc: 0.0340
current epoch: 35
train loss is 0.034800
average val loss: 0.031136, accuracy: 0.0315
average test loss: 0.032132, accuracy: 0.0324
case acc: 0.02095627
case acc: 0.063605584
case acc: 0.020102374
case acc: 0.03198565
case acc: 0.036870323
case acc: 0.021016616
top acc: 0.0106 ::: bot acc: 0.0334
top acc: 0.0501 ::: bot acc: 0.0762
top acc: 0.0108 ::: bot acc: 0.0364
top acc: 0.0156 ::: bot acc: 0.0471
top acc: 0.0192 ::: bot acc: 0.0541
top acc: 0.0088 ::: bot acc: 0.0351
current epoch: 36
train loss is 0.030269
average val loss: 0.023129, accuracy: 0.0235
average test loss: 0.024312, accuracy: 0.0246
case acc: 0.011469638
case acc: 0.048535354
case acc: 0.01726122
case acc: 0.024284223
case acc: 0.0293672
case acc: 0.016401451
top acc: 0.0144 ::: bot acc: 0.0171
top acc: 0.0350 ::: bot acc: 0.0612
top acc: 0.0182 ::: bot acc: 0.0281
top acc: 0.0114 ::: bot acc: 0.0377
top acc: 0.0129 ::: bot acc: 0.0461
top acc: 0.0083 ::: bot acc: 0.0283
current epoch: 37
train loss is 0.023167
average val loss: 0.016446, accuracy: 0.0167
average test loss: 0.017554, accuracy: 0.0178
case acc: 0.018170046
case acc: 0.025958497
case acc: 0.018658567
case acc: 0.013605704
case acc: 0.018335402
case acc: 0.012140501
top acc: 0.0323 ::: bot acc: 0.0067
top acc: 0.0132 ::: bot acc: 0.0382
top acc: 0.0326 ::: bot acc: 0.0137
top acc: 0.0130 ::: bot acc: 0.0209
top acc: 0.0102 ::: bot acc: 0.0309
top acc: 0.0184 ::: bot acc: 0.0149
current epoch: 38
train loss is 0.019763
average val loss: 0.014527, accuracy: 0.0145
average test loss: 0.015598, accuracy: 0.0155
case acc: 0.019164396
case acc: 0.012619235
case acc: 0.02064034
case acc: 0.012165267
case acc: 0.015741011
case acc: 0.012660747
top acc: 0.0336 ::: bot acc: 0.0072
top acc: 0.0058 ::: bot acc: 0.0220
top acc: 0.0373 ::: bot acc: 0.0104
top acc: 0.0215 ::: bot acc: 0.0124
top acc: 0.0135 ::: bot acc: 0.0253
top acc: 0.0219 ::: bot acc: 0.0114
current epoch: 39
train loss is 0.018438
average val loss: 0.014621, accuracy: 0.0143
average test loss: 0.015537, accuracy: 0.0154
case acc: 0.017529724
case acc: 0.010770757
case acc: 0.022158405
case acc: 0.014350518
case acc: 0.014813085
case acc: 0.012755497
top acc: 0.0314 ::: bot acc: 0.0065
top acc: 0.0203 ::: bot acc: 0.0061
top acc: 0.0401 ::: bot acc: 0.0094
top acc: 0.0280 ::: bot acc: 0.0069
top acc: 0.0158 ::: bot acc: 0.0227
top acc: 0.0223 ::: bot acc: 0.0110
current epoch: 40
train loss is 0.015948
average val loss: 0.018886, accuracy: 0.0188
average test loss: 0.019460, accuracy: 0.0196
case acc: 0.018608112
case acc: 0.024230845
case acc: 0.026307734
case acc: 0.020522695
case acc: 0.013816322
case acc: 0.013964583
top acc: 0.0328 ::: bot acc: 0.0069
top acc: 0.0377 ::: bot acc: 0.0116
top acc: 0.0461 ::: bot acc: 0.0097
top acc: 0.0370 ::: bot acc: 0.0075
top acc: 0.0213 ::: bot acc: 0.0172
top acc: 0.0260 ::: bot acc: 0.0075
current epoch: 41
train loss is 0.017347
average val loss: 0.024387, accuracy: 0.0241
average test loss: 0.024745, accuracy: 0.0249
case acc: 0.020026244
case acc: 0.037951402
case acc: 0.032019984
case acc: 0.028125081
case acc: 0.01478746
case acc: 0.016381582
top acc: 0.0346 ::: bot acc: 0.0076
top acc: 0.0515 ::: bot acc: 0.0252
top acc: 0.0530 ::: bot acc: 0.0130
top acc: 0.0453 ::: bot acc: 0.0135
top acc: 0.0272 ::: bot acc: 0.0113
top acc: 0.0309 ::: bot acc: 0.0049
current epoch: 42
train loss is 0.020639
average val loss: 0.036052, accuracy: 0.0359
average test loss: 0.036135, accuracy: 0.0361
case acc: 0.027552016
case acc: 0.05647956
case acc: 0.044524968
case acc: 0.04180806
case acc: 0.021089306
case acc: 0.025340237
top acc: 0.0432 ::: bot acc: 0.0130
top acc: 0.0700 ::: bot acc: 0.0438
top acc: 0.0666 ::: bot acc: 0.0235
top acc: 0.0595 ::: bot acc: 0.0262
top acc: 0.0389 ::: bot acc: 0.0069
top acc: 0.0421 ::: bot acc: 0.0095
current epoch: 43
train loss is 0.028696
average val loss: 0.058757, accuracy: 0.0587
average test loss: 0.058658, accuracy: 0.0586
case acc: 0.0442923
case acc: 0.08338961
case acc: 0.06793935
case acc: 0.06640644
case acc: 0.04175127
case acc: 0.047739215
top acc: 0.0604 ::: bot acc: 0.0288
top acc: 0.0969 ::: bot acc: 0.0707
top acc: 0.0907 ::: bot acc: 0.0453
top acc: 0.0843 ::: bot acc: 0.0504
top acc: 0.0617 ::: bot acc: 0.0232
top acc: 0.0647 ::: bot acc: 0.0314
current epoch: 44
train loss is 0.039095
average val loss: 0.042440, accuracy: 0.0423
average test loss: 0.042494, accuracy: 0.0424
case acc: 0.021169214
case acc: 0.06420748
case acc: 0.05321198
case acc: 0.05219495
case acc: 0.028917145
case acc: 0.034943912
top acc: 0.0360 ::: bot acc: 0.0082
top acc: 0.0777 ::: bot acc: 0.0515
top acc: 0.0756 ::: bot acc: 0.0315
top acc: 0.0701 ::: bot acc: 0.0363
top acc: 0.0482 ::: bot acc: 0.0117
top acc: 0.0519 ::: bot acc: 0.0186
current epoch: 45
train loss is 0.038682
average val loss: 0.020723, accuracy: 0.0204
average test loss: 0.021353, accuracy: 0.0217
case acc: 0.018906003
case acc: 0.027157137
case acc: 0.027203921
case acc: 0.026461922
case acc: 0.0143438205
case acc: 0.015931495
top acc: 0.0098 ::: bot acc: 0.0308
top acc: 0.0406 ::: bot acc: 0.0145
top acc: 0.0473 ::: bot acc: 0.0100
top acc: 0.0436 ::: bot acc: 0.0121
top acc: 0.0254 ::: bot acc: 0.0132
top acc: 0.0302 ::: bot acc: 0.0051
current epoch: 46
train loss is 0.042658
average val loss: 0.023613, accuracy: 0.0238
average test loss: 0.024801, accuracy: 0.0250
case acc: 0.048169635
case acc: 0.023784364
case acc: 0.019041963
case acc: 0.016000142
case acc: 0.025602134
case acc: 0.017442094
top acc: 0.0320 ::: bot acc: 0.0636
top acc: 0.0114 ::: bot acc: 0.0359
top acc: 0.0126 ::: bot acc: 0.0340
top acc: 0.0098 ::: bot acc: 0.0261
top acc: 0.0104 ::: bot acc: 0.0418
top acc: 0.0079 ::: bot acc: 0.0300
current epoch: 47
train loss is 0.030698
average val loss: 0.020292, accuracy: 0.0207
average test loss: 0.021538, accuracy: 0.0221
case acc: 0.03350526
case acc: 0.034744114
case acc: 0.017577104
case acc: 0.015121757
case acc: 0.018972859
case acc: 0.012480105
top acc: 0.0183 ::: bot acc: 0.0484
top acc: 0.0212 ::: bot acc: 0.0474
top acc: 0.0170 ::: bot acc: 0.0294
top acc: 0.0103 ::: bot acc: 0.0244
top acc: 0.0096 ::: bot acc: 0.0322
top acc: 0.0142 ::: bot acc: 0.0192
current epoch: 48
train loss is 0.031287
average val loss: 0.040898, accuracy: 0.0410
average test loss: 0.041515, accuracy: 0.0416
case acc: 0.04708094
case acc: 0.071209356
case acc: 0.03325894
case acc: 0.036455605
case acc: 0.036480475
case acc: 0.025360692
top acc: 0.0309 ::: bot acc: 0.0625
top acc: 0.0577 ::: bot acc: 0.0839
top acc: 0.0141 ::: bot acc: 0.0546
top acc: 0.0193 ::: bot acc: 0.0520
top acc: 0.0189 ::: bot acc: 0.0539
top acc: 0.0117 ::: bot acc: 0.0400
current epoch: 49
train loss is 0.034848
average val loss: 0.034773, accuracy: 0.0349
average test loss: 0.035559, accuracy: 0.0357
case acc: 0.03249107
case acc: 0.06524526
case acc: 0.029489217
case acc: 0.032595087
case acc: 0.032286707
case acc: 0.021933842
top acc: 0.0175 ::: bot acc: 0.0474
top acc: 0.0517 ::: bot acc: 0.0779
top acc: 0.0118 ::: bot acc: 0.0501
top acc: 0.0161 ::: bot acc: 0.0478
top acc: 0.0153 ::: bot acc: 0.0494
top acc: 0.0092 ::: bot acc: 0.0361
current epoch: 50
train loss is 0.028530
average val loss: 0.024410, accuracy: 0.0246
average test loss: 0.025589, accuracy: 0.0258
case acc: 0.01667305
case acc: 0.04889534
case acc: 0.02210798
case acc: 0.024448184
case acc: 0.025489852
case acc: 0.017054025
top acc: 0.0093 ::: bot acc: 0.0278
top acc: 0.0354 ::: bot acc: 0.0616
top acc: 0.0092 ::: bot acc: 0.0403
top acc: 0.0114 ::: bot acc: 0.0380
top acc: 0.0103 ::: bot acc: 0.0417
top acc: 0.0079 ::: bot acc: 0.0294
LME_Co_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6810 6810 6810
1.7082474 -0.6288155 0.08104724 -0.08406281
Validation: 762 762 762
Testing: 750 750 750
pre-processing time: 0.0004134178161621094
the split date is 2011-01-01
net initializing with time: 0.002963542938232422
preparing training and testing date with time: 2.384185791015625e-07
current epoch: 1
train loss is 0.321928
average val loss: 0.046546, accuracy: 0.0471
average test loss: 0.045626, accuracy: 0.0466
case acc: 0.11328221
case acc: 0.089633666
case acc: 0.01699474
case acc: 0.016197141
case acc: 0.018703345
case acc: 0.025005646
top acc: 0.0994 ::: bot acc: 0.1277
top acc: 0.0781 ::: bot acc: 0.1029
top acc: 0.0277 ::: bot acc: 0.0158
top acc: 0.0278 ::: bot acc: 0.0086
top acc: 0.0325 ::: bot acc: 0.0080
top acc: 0.0094 ::: bot acc: 0.0406
current epoch: 2
train loss is 0.109958
average val loss: 0.039966, accuracy: 0.0401
average test loss: 0.039495, accuracy: 0.0404
case acc: 0.08228095
case acc: 0.059486754
case acc: 0.025877975
case acc: 0.028689278
case acc: 0.03180799
case acc: 0.014480712
top acc: 0.0681 ::: bot acc: 0.0971
top acc: 0.0480 ::: bot acc: 0.0726
top acc: 0.0432 ::: bot acc: 0.0119
top acc: 0.0431 ::: bot acc: 0.0151
top acc: 0.0496 ::: bot acc: 0.0128
top acc: 0.0104 ::: bot acc: 0.0244
current epoch: 3
train loss is 0.092100
average val loss: 0.075592, accuracy: 0.0757
average test loss: 0.073293, accuracy: 0.0734
case acc: 0.13516322
case acc: 0.11639499
case acc: 0.043645255
case acc: 0.041337352
case acc: 0.035097625
case acc: 0.06853585
top acc: 0.1210 ::: bot acc: 0.1500
top acc: 0.1049 ::: bot acc: 0.1294
top acc: 0.0236 ::: bot acc: 0.0645
top acc: 0.0260 ::: bot acc: 0.0572
top acc: 0.0181 ::: bot acc: 0.0541
top acc: 0.0513 ::: bot acc: 0.0851
current epoch: 4
train loss is 0.099098
average val loss: 0.097659, accuracy: 0.0977
average test loss: 0.095384, accuracy: 0.0954
case acc: 0.1479412
case acc: 0.13667849
case acc: 0.06743012
case acc: 0.074030414
case acc: 0.0639078
case acc: 0.082316905
top acc: 0.1337 ::: bot acc: 0.1628
top acc: 0.1252 ::: bot acc: 0.1497
top acc: 0.0466 ::: bot acc: 0.0887
top acc: 0.0588 ::: bot acc: 0.0896
top acc: 0.0457 ::: bot acc: 0.0836
top acc: 0.0650 ::: bot acc: 0.0989
current epoch: 5
train loss is 0.085228
average val loss: 0.073973, accuracy: 0.0741
average test loss: 0.071570, accuracy: 0.0716
case acc: 0.11355548
case acc: 0.107902944
case acc: 0.04683878
case acc: 0.061081123
case acc: 0.048551477
case acc: 0.05167364
top acc: 0.0993 ::: bot acc: 0.1284
top acc: 0.0963 ::: bot acc: 0.1210
top acc: 0.0266 ::: bot acc: 0.0678
top acc: 0.0460 ::: bot acc: 0.0764
top acc: 0.0302 ::: bot acc: 0.0682
top acc: 0.0343 ::: bot acc: 0.0683
current epoch: 6
train loss is 0.067954
average val loss: 0.068853, accuracy: 0.0690
average test loss: 0.066357, accuracy: 0.0664
case acc: 0.09753192
case acc: 0.09577838
case acc: 0.0457901
case acc: 0.06545948
case acc: 0.050175086
case acc: 0.043575138
top acc: 0.0831 ::: bot acc: 0.1124
top acc: 0.0841 ::: bot acc: 0.1089
top acc: 0.0256 ::: bot acc: 0.0667
top acc: 0.0506 ::: bot acc: 0.0806
top acc: 0.0317 ::: bot acc: 0.0699
top acc: 0.0261 ::: bot acc: 0.0604
current epoch: 7
train loss is 0.060591
average val loss: 0.071523, accuracy: 0.0716
average test loss: 0.068955, accuracy: 0.0690
case acc: 0.08966093
case acc: 0.09213073
case acc: 0.052274887
case acc: 0.0773156
case acc: 0.058638316
case acc: 0.043771904
top acc: 0.0751 ::: bot acc: 0.1045
top acc: 0.0804 ::: bot acc: 0.1053
top acc: 0.0317 ::: bot acc: 0.0734
top acc: 0.0626 ::: bot acc: 0.0921
top acc: 0.0400 ::: bot acc: 0.0784
top acc: 0.0262 ::: bot acc: 0.0607
current epoch: 8
train loss is 0.054391
average val loss: 0.071602, accuracy: 0.0717
average test loss: 0.068966, accuracy: 0.0690
case acc: 0.07921214
case acc: 0.08572741
case acc: 0.056479625
case acc: 0.0863129
case acc: 0.06406494
case acc: 0.041972
top acc: 0.0647 ::: bot acc: 0.0940
top acc: 0.0740 ::: bot acc: 0.0989
top acc: 0.0358 ::: bot acc: 0.0778
top acc: 0.0717 ::: bot acc: 0.1008
top acc: 0.0453 ::: bot acc: 0.0839
top acc: 0.0244 ::: bot acc: 0.0590
current epoch: 9
train loss is 0.047159
average val loss: 0.068179, accuracy: 0.0682
average test loss: 0.065481, accuracy: 0.0655
case acc: 0.06541339
case acc: 0.07507146
case acc: 0.057587933
case acc: 0.09101769
case acc: 0.06542155
case acc: 0.038274877
top acc: 0.0509 ::: bot acc: 0.0801
top acc: 0.0633 ::: bot acc: 0.0883
top acc: 0.0369 ::: bot acc: 0.0789
top acc: 0.0766 ::: bot acc: 0.1053
top acc: 0.0465 ::: bot acc: 0.0853
top acc: 0.0207 ::: bot acc: 0.0553
current epoch: 10
train loss is 0.041809
average val loss: 0.064065, accuracy: 0.0641
average test loss: 0.061339, accuracy: 0.0613
case acc: 0.05116226
case acc: 0.06194262
case acc: 0.05891262
case acc: 0.09340852
case acc: 0.06509503
case acc: 0.037332024
top acc: 0.0367 ::: bot acc: 0.0657
top acc: 0.0501 ::: bot acc: 0.0752
top acc: 0.0381 ::: bot acc: 0.0803
top acc: 0.0791 ::: bot acc: 0.1075
top acc: 0.0461 ::: bot acc: 0.0850
top acc: 0.0198 ::: bot acc: 0.0544
current epoch: 11
train loss is 0.039718
average val loss: 0.059820, accuracy: 0.0598
average test loss: 0.057063, accuracy: 0.0570
case acc: 0.037344337
case acc: 0.047339033
case acc: 0.06010904
case acc: 0.09418362
case acc: 0.06485638
case acc: 0.038088933
top acc: 0.0229 ::: bot acc: 0.0519
top acc: 0.0355 ::: bot acc: 0.0604
top acc: 0.0393 ::: bot acc: 0.0816
top acc: 0.0799 ::: bot acc: 0.1083
top acc: 0.0459 ::: bot acc: 0.0849
top acc: 0.0206 ::: bot acc: 0.0552
current epoch: 12
train loss is 0.045235
average val loss: 0.037880, accuracy: 0.0374
average test loss: 0.035188, accuracy: 0.0344
case acc: 0.011092551
case acc: 0.013149602
case acc: 0.041500956
case acc: 0.073766746
case acc: 0.045450658
case acc: 0.021654485
top acc: 0.0100 ::: bot acc: 0.0190
top acc: 0.0042 ::: bot acc: 0.0248
top acc: 0.0218 ::: bot acc: 0.0624
top acc: 0.0595 ::: bot acc: 0.0879
top acc: 0.0265 ::: bot acc: 0.0654
top acc: 0.0071 ::: bot acc: 0.0374
current epoch: 13
train loss is 0.062891
average val loss: 0.054627, accuracy: 0.0546
average test loss: 0.056912, accuracy: 0.0569
case acc: 0.09074985
case acc: 0.09044712
case acc: 0.044419114
case acc: 0.017273031
case acc: 0.0393543
case acc: 0.058871556
top acc: 0.1051 ::: bot acc: 0.0762
top acc: 0.1023 ::: bot acc: 0.0774
top acc: 0.0644 ::: bot acc: 0.0247
top acc: 0.0293 ::: bot acc: 0.0077
top acc: 0.0584 ::: bot acc: 0.0193
top acc: 0.0764 ::: bot acc: 0.0417
current epoch: 14
train loss is 0.078445
average val loss: 0.080821, accuracy: 0.0808
average test loss: 0.083323, accuracy: 0.0833
case acc: 0.11379592
case acc: 0.12519658
case acc: 0.06899471
case acc: 0.050114308
case acc: 0.06832112
case acc: 0.07353829
top acc: 0.1282 ::: bot acc: 0.0992
top acc: 0.1371 ::: bot acc: 0.1122
top acc: 0.0896 ::: bot acc: 0.0479
top acc: 0.0645 ::: bot acc: 0.0359
top acc: 0.0874 ::: bot acc: 0.0482
top acc: 0.0910 ::: bot acc: 0.0563
current epoch: 15
train loss is 0.061733
average val loss: 0.054408, accuracy: 0.0545
average test loss: 0.056821, accuracy: 0.0569
case acc: 0.077524856
case acc: 0.09569582
case acc: 0.04455733
case acc: 0.03489967
case acc: 0.050268006
case acc: 0.038220707
top acc: 0.0919 ::: bot acc: 0.0630
top acc: 0.1076 ::: bot acc: 0.0828
top acc: 0.0646 ::: bot acc: 0.0248
top acc: 0.0490 ::: bot acc: 0.0211
top acc: 0.0695 ::: bot acc: 0.0301
top acc: 0.0557 ::: bot acc: 0.0210
current epoch: 16
train loss is 0.053597
average val loss: 0.063714, accuracy: 0.0637
average test loss: 0.066143, accuracy: 0.0662
case acc: 0.07607467
case acc: 0.09808033
case acc: 0.05728819
case acc: 0.054295484
case acc: 0.06719395
case acc: 0.04399404
top acc: 0.0905 ::: bot acc: 0.0615
top acc: 0.1100 ::: bot acc: 0.0852
top acc: 0.0777 ::: bot acc: 0.0366
top acc: 0.0686 ::: bot acc: 0.0402
top acc: 0.0864 ::: bot acc: 0.0470
top acc: 0.0614 ::: bot acc: 0.0267
current epoch: 17
train loss is 0.046450
average val loss: 0.055451, accuracy: 0.0554
average test loss: 0.057842, accuracy: 0.0578
case acc: 0.056248687
case acc: 0.08145587
case acc: 0.0537675
case acc: 0.055929177
case acc: 0.065434985
case acc: 0.034182355
top acc: 0.0706 ::: bot acc: 0.0417
top acc: 0.0934 ::: bot acc: 0.0687
top acc: 0.0741 ::: bot acc: 0.0331
top acc: 0.0702 ::: bot acc: 0.0419
top acc: 0.0847 ::: bot acc: 0.0452
top acc: 0.0515 ::: bot acc: 0.0170
current epoch: 18
train loss is 0.037712
average val loss: 0.047877, accuracy: 0.0478
average test loss: 0.050202, accuracy: 0.0502
case acc: 0.037014283
case acc: 0.06452433
case acc: 0.05192753
case acc: 0.05707628
case acc: 0.06217027
case acc: 0.028312244
top acc: 0.0514 ::: bot acc: 0.0225
top acc: 0.0765 ::: bot acc: 0.0518
top acc: 0.0722 ::: bot acc: 0.0314
top acc: 0.0713 ::: bot acc: 0.0430
top acc: 0.0814 ::: bot acc: 0.0419
top acc: 0.0454 ::: bot acc: 0.0116
current epoch: 19
train loss is 0.030139
average val loss: 0.041269, accuracy: 0.0411
average test loss: 0.043483, accuracy: 0.0434
case acc: 0.02022663
case acc: 0.048245866
case acc: 0.051063895
case acc: 0.057533767
case acc: 0.057895374
case acc: 0.02529375
top acc: 0.0336 ::: bot acc: 0.0077
top acc: 0.0602 ::: bot acc: 0.0355
top acc: 0.0714 ::: bot acc: 0.0306
top acc: 0.0717 ::: bot acc: 0.0436
top acc: 0.0772 ::: bot acc: 0.0376
top acc: 0.0422 ::: bot acc: 0.0091
current epoch: 20
train loss is 0.026982
average val loss: 0.042374, accuracy: 0.0421
average test loss: 0.044489, accuracy: 0.0443
case acc: 0.014357471
case acc: 0.039896216
case acc: 0.056556325
case acc: 0.063719936
case acc: 0.061687518
case acc: 0.029625531
top acc: 0.0257 ::: bot acc: 0.0062
top acc: 0.0519 ::: bot acc: 0.0271
top acc: 0.0770 ::: bot acc: 0.0358
top acc: 0.0779 ::: bot acc: 0.0497
top acc: 0.0810 ::: bot acc: 0.0413
top acc: 0.0468 ::: bot acc: 0.0128
current epoch: 21
train loss is 0.037057
average val loss: 0.030620, accuracy: 0.0302
average test loss: 0.031788, accuracy: 0.0316
case acc: 0.016134609
case acc: 0.014039673
case acc: 0.042898405
case acc: 0.04999524
case acc: 0.04863596
case acc: 0.0180876
top acc: 0.0060 ::: bot acc: 0.0285
top acc: 0.0240 ::: bot acc: 0.0054
top acc: 0.0627 ::: bot acc: 0.0233
top acc: 0.0642 ::: bot acc: 0.0360
top acc: 0.0679 ::: bot acc: 0.0283
top acc: 0.0331 ::: bot acc: 0.0058
current epoch: 22
train loss is 0.058315
average val loss: 0.069037, accuracy: 0.0691
average test loss: 0.066461, accuracy: 0.0665
case acc: 0.110156596
case acc: 0.09233588
case acc: 0.04657761
case acc: 0.04293185
case acc: 0.041010723
case acc: 0.066016875
top acc: 0.0958 ::: bot acc: 0.1246
top acc: 0.0804 ::: bot acc: 0.1051
top acc: 0.0264 ::: bot acc: 0.0679
top acc: 0.0287 ::: bot acc: 0.0570
top acc: 0.0222 ::: bot acc: 0.0612
top acc: 0.0486 ::: bot acc: 0.0832
current epoch: 23
train loss is 0.068788
average val loss: 0.058789, accuracy: 0.0589
average test loss: 0.056150, accuracy: 0.0563
case acc: 0.09248421
case acc: 0.08435816
case acc: 0.03762552
case acc: 0.041856114
case acc: 0.03460519
case acc: 0.046643883
top acc: 0.0781 ::: bot acc: 0.1070
top acc: 0.0724 ::: bot acc: 0.0971
top acc: 0.0183 ::: bot acc: 0.0585
top acc: 0.0276 ::: bot acc: 0.0560
top acc: 0.0165 ::: bot acc: 0.0544
top acc: 0.0293 ::: bot acc: 0.0638
current epoch: 24
train loss is 0.046284
average val loss: 0.041251, accuracy: 0.0414
average test loss: 0.038444, accuracy: 0.0387
case acc: 0.063984506
case acc: 0.060416758
case acc: 0.024677848
case acc: 0.03360016
case acc: 0.025177313
case acc: 0.024564687
top acc: 0.0495 ::: bot acc: 0.0785
top acc: 0.0485 ::: bot acc: 0.0732
top acc: 0.0098 ::: bot acc: 0.0434
top acc: 0.0196 ::: bot acc: 0.0477
top acc: 0.0093 ::: bot acc: 0.0439
top acc: 0.0087 ::: bot acc: 0.0410
current epoch: 25
train loss is 0.041910
average val loss: 0.059214, accuracy: 0.0593
average test loss: 0.056578, accuracy: 0.0566
case acc: 0.07287373
case acc: 0.07464387
case acc: 0.043289073
case acc: 0.061954852
case acc: 0.05028543
case acc: 0.03646622
top acc: 0.0584 ::: bot acc: 0.0874
top acc: 0.0627 ::: bot acc: 0.0874
top acc: 0.0233 ::: bot acc: 0.0645
top acc: 0.0477 ::: bot acc: 0.0762
top acc: 0.0310 ::: bot acc: 0.0707
top acc: 0.0191 ::: bot acc: 0.0536
current epoch: 26
train loss is 0.038830
average val loss: 0.056599, accuracy: 0.0567
average test loss: 0.053941, accuracy: 0.0539
case acc: 0.05950933
case acc: 0.0654677
case acc: 0.04414426
case acc: 0.06909358
case acc: 0.055158395
case acc: 0.030166788
top acc: 0.0450 ::: bot acc: 0.0741
top acc: 0.0535 ::: bot acc: 0.0782
top acc: 0.0241 ::: bot acc: 0.0654
top acc: 0.0548 ::: bot acc: 0.0833
top acc: 0.0359 ::: bot acc: 0.0755
top acc: 0.0131 ::: bot acc: 0.0471
current epoch: 27
train loss is 0.035177
average val loss: 0.048390, accuracy: 0.0484
average test loss: 0.045660, accuracy: 0.0456
case acc: 0.040357217
case acc: 0.04701382
case acc: 0.041150007
case acc: 0.06811323
case acc: 0.05235374
case acc: 0.024754148
top acc: 0.0259 ::: bot acc: 0.0549
top acc: 0.0350 ::: bot acc: 0.0598
top acc: 0.0214 ::: bot acc: 0.0622
top acc: 0.0538 ::: bot acc: 0.0823
top acc: 0.0330 ::: bot acc: 0.0727
top acc: 0.0089 ::: bot acc: 0.0411
current epoch: 28
train loss is 0.041084
average val loss: 0.019687, accuracy: 0.0195
average test loss: 0.018455, accuracy: 0.0180
case acc: 0.01275199
case acc: 0.009861316
case acc: 0.016511735
case acc: 0.03437493
case acc: 0.020920401
case acc: 0.013687715
top acc: 0.0227 ::: bot acc: 0.0073
top acc: 0.0162 ::: bot acc: 0.0085
top acc: 0.0130 ::: bot acc: 0.0296
top acc: 0.0203 ::: bot acc: 0.0484
top acc: 0.0075 ::: bot acc: 0.0384
top acc: 0.0243 ::: bot acc: 0.0102
current epoch: 29
train loss is 0.043276
average val loss: 0.044856, accuracy: 0.0449
average test loss: 0.047147, accuracy: 0.0471
case acc: 0.06703597
case acc: 0.07142324
case acc: 0.041642804
case acc: 0.021495886
case acc: 0.032643177
case acc: 0.048609044
top acc: 0.0815 ::: bot acc: 0.0525
top acc: 0.0834 ::: bot acc: 0.0587
top acc: 0.0613 ::: bot acc: 0.0224
top acc: 0.0345 ::: bot acc: 0.0099
top acc: 0.0519 ::: bot acc: 0.0123
top acc: 0.0660 ::: bot acc: 0.0315
current epoch: 30
train loss is 0.054670
average val loss: 0.056682, accuracy: 0.0567
average test loss: 0.059097, accuracy: 0.0591
case acc: 0.07438692
case acc: 0.0894153
case acc: 0.052376628
case acc: 0.040793307
case acc: 0.04734611
case acc: 0.05039195
top acc: 0.0888 ::: bot acc: 0.0598
top acc: 0.1014 ::: bot acc: 0.0767
top acc: 0.0726 ::: bot acc: 0.0320
top acc: 0.0550 ::: bot acc: 0.0268
top acc: 0.0667 ::: bot acc: 0.0270
top acc: 0.0677 ::: bot acc: 0.0333
current epoch: 31
train loss is 0.041536
average val loss: 0.042541, accuracy: 0.0425
average test loss: 0.044870, accuracy: 0.0449
case acc: 0.050570667
case acc: 0.071221285
case acc: 0.040457394
case acc: 0.036519025
case acc: 0.041000966
case acc: 0.029770713
top acc: 0.0650 ::: bot acc: 0.0360
top acc: 0.0832 ::: bot acc: 0.0585
top acc: 0.0601 ::: bot acc: 0.0213
top acc: 0.0506 ::: bot acc: 0.0227
top acc: 0.0603 ::: bot acc: 0.0206
top acc: 0.0470 ::: bot acc: 0.0130
current epoch: 32
train loss is 0.034991
average val loss: 0.046835, accuracy: 0.0468
average test loss: 0.049199, accuracy: 0.0492
case acc: 0.044429407
case acc: 0.06819932
case acc: 0.04811484
case acc: 0.04996592
case acc: 0.05258075
case acc: 0.031884942
top acc: 0.0589 ::: bot acc: 0.0299
top acc: 0.0802 ::: bot acc: 0.0555
top acc: 0.0682 ::: bot acc: 0.0279
top acc: 0.0642 ::: bot acc: 0.0359
top acc: 0.0719 ::: bot acc: 0.0322
top acc: 0.0491 ::: bot acc: 0.0150
current epoch: 33
train loss is 0.029747
average val loss: 0.043190, accuracy: 0.0431
average test loss: 0.045488, accuracy: 0.0454
case acc: 0.02979313
case acc: 0.0559386
case acc: 0.048914794
case acc: 0.054936655
case acc: 0.05492772
case acc: 0.028081162
top acc: 0.0442 ::: bot acc: 0.0153
top acc: 0.0679 ::: bot acc: 0.0432
top acc: 0.0691 ::: bot acc: 0.0287
top acc: 0.0692 ::: bot acc: 0.0409
top acc: 0.0743 ::: bot acc: 0.0345
top acc: 0.0451 ::: bot acc: 0.0115
current epoch: 34
train loss is 0.026658
average val loss: 0.040419, accuracy: 0.0403
average test loss: 0.042622, accuracy: 0.0425
case acc: 0.018019738
case acc: 0.042934332
case acc: 0.05072791
case acc: 0.0587463
case acc: 0.05669379
case acc: 0.027887886
top acc: 0.0308 ::: bot acc: 0.0067
top acc: 0.0549 ::: bot acc: 0.0302
top acc: 0.0709 ::: bot acc: 0.0304
top acc: 0.0730 ::: bot acc: 0.0447
top acc: 0.0761 ::: bot acc: 0.0363
top acc: 0.0449 ::: bot acc: 0.0114
current epoch: 35
train loss is 0.035696
average val loss: 0.020829, accuracy: 0.0207
average test loss: 0.020574, accuracy: 0.0210
case acc: 0.029814702
case acc: 0.009852709
case acc: 0.02177999
case acc: 0.02631729
case acc: 0.024951989
case acc: 0.013218891
top acc: 0.0156 ::: bot acc: 0.0442
top acc: 0.0064 ::: bot acc: 0.0185
top acc: 0.0375 ::: bot acc: 0.0107
top acc: 0.0399 ::: bot acc: 0.0136
top acc: 0.0434 ::: bot acc: 0.0066
top acc: 0.0123 ::: bot acc: 0.0222
current epoch: 36
train loss is 0.053120
average val loss: 0.067458, accuracy: 0.0675
average test loss: 0.064902, accuracy: 0.0649
case acc: 0.1003027
case acc: 0.08658318
case acc: 0.04858015
case acc: 0.046586625
case acc: 0.04628829
case acc: 0.06119286
top acc: 0.0860 ::: bot acc: 0.1148
top acc: 0.0745 ::: bot acc: 0.0994
top acc: 0.0282 ::: bot acc: 0.0699
top acc: 0.0324 ::: bot acc: 0.0605
top acc: 0.0270 ::: bot acc: 0.0666
top acc: 0.0439 ::: bot acc: 0.0783
current epoch: 37
train loss is 0.047530
average val loss: 0.040788, accuracy: 0.0410
average test loss: 0.037991, accuracy: 0.0383
case acc: 0.0645892
case acc: 0.058626343
case acc: 0.024295028
case acc: 0.029623957
case acc: 0.027860986
case acc: 0.024564682
top acc: 0.0502 ::: bot acc: 0.0791
top acc: 0.0466 ::: bot acc: 0.0715
top acc: 0.0094 ::: bot acc: 0.0429
top acc: 0.0162 ::: bot acc: 0.0433
top acc: 0.0108 ::: bot acc: 0.0471
top acc: 0.0088 ::: bot acc: 0.0409
current epoch: 38
train loss is 0.035504
average val loss: 0.038705, accuracy: 0.0388
average test loss: 0.035925, accuracy: 0.0361
case acc: 0.0522048
case acc: 0.0498183
case acc: 0.025371574
case acc: 0.036411297
case acc: 0.032772318
case acc: 0.020279162
top acc: 0.0378 ::: bot acc: 0.0667
top acc: 0.0378 ::: bot acc: 0.0626
top acc: 0.0099 ::: bot acc: 0.0443
top acc: 0.0223 ::: bot acc: 0.0505
top acc: 0.0148 ::: bot acc: 0.0525
top acc: 0.0064 ::: bot acc: 0.0357
current epoch: 39
train loss is 0.029945
average val loss: 0.038164, accuracy: 0.0382
average test loss: 0.035408, accuracy: 0.0355
case acc: 0.041118313
case acc: 0.04165874
case acc: 0.0287657
case acc: 0.044443905
case acc: 0.03751846
case acc: 0.01965067
top acc: 0.0268 ::: bot acc: 0.0556
top acc: 0.0296 ::: bot acc: 0.0544
top acc: 0.0117 ::: bot acc: 0.0485
top acc: 0.0302 ::: bot acc: 0.0585
top acc: 0.0189 ::: bot acc: 0.0575
top acc: 0.0062 ::: bot acc: 0.0348
current epoch: 40
train loss is 0.025262
average val loss: 0.032592, accuracy: 0.0325
average test loss: 0.029760, accuracy: 0.0297
case acc: 0.024941105
case acc: 0.026468826
case acc: 0.028619355
case acc: 0.04536608
case acc: 0.03531359
case acc: 0.017553264
top acc: 0.0114 ::: bot acc: 0.0390
top acc: 0.0144 ::: bot acc: 0.0392
top acc: 0.0116 ::: bot acc: 0.0483
top acc: 0.0311 ::: bot acc: 0.0594
top acc: 0.0170 ::: bot acc: 0.0552
top acc: 0.0061 ::: bot acc: 0.0318
current epoch: 41
train loss is 0.022544
average val loss: 0.027356, accuracy: 0.0270
average test loss: 0.024645, accuracy: 0.0241
case acc: 0.012738425
case acc: 0.011943567
case acc: 0.027579105
case acc: 0.04359708
case acc: 0.032142226
case acc: 0.016817726
top acc: 0.0067 ::: bot acc: 0.0231
top acc: 0.0043 ::: bot acc: 0.0226
top acc: 0.0111 ::: bot acc: 0.0471
top acc: 0.0293 ::: bot acc: 0.0576
top acc: 0.0142 ::: bot acc: 0.0518
top acc: 0.0062 ::: bot acc: 0.0308
current epoch: 42
train loss is 0.027607
average val loss: 0.020258, accuracy: 0.0208
average test loss: 0.019972, accuracy: 0.0202
case acc: 0.027918415
case acc: 0.030076241
case acc: 0.0150888655
case acc: 0.018821817
case acc: 0.014967812
case acc: 0.014367119
top acc: 0.0422 ::: bot acc: 0.0135
top acc: 0.0421 ::: bot acc: 0.0174
top acc: 0.0206 ::: bot acc: 0.0220
top acc: 0.0076 ::: bot acc: 0.0313
top acc: 0.0134 ::: bot acc: 0.0264
top acc: 0.0263 ::: bot acc: 0.0083
current epoch: 43
train loss is 0.039171
average val loss: 0.054472, accuracy: 0.0545
average test loss: 0.056843, accuracy: 0.0569
case acc: 0.07882701
case acc: 0.09053032
case acc: 0.04636932
case acc: 0.035642784
case acc: 0.043080322
case acc: 0.04685207
top acc: 0.0931 ::: bot acc: 0.0644
top acc: 0.1025 ::: bot acc: 0.0778
top acc: 0.0664 ::: bot acc: 0.0264
top acc: 0.0498 ::: bot acc: 0.0220
top acc: 0.0625 ::: bot acc: 0.0227
top acc: 0.0642 ::: bot acc: 0.0296
current epoch: 44
train loss is 0.053359
average val loss: 0.049013, accuracy: 0.0491
average test loss: 0.051369, accuracy: 0.0514
case acc: 0.06518396
case acc: 0.083373986
case acc: 0.042963978
case acc: 0.038953252
case acc: 0.042173717
case acc: 0.035822496
top acc: 0.0795 ::: bot acc: 0.0508
top acc: 0.0954 ::: bot acc: 0.0706
top acc: 0.0628 ::: bot acc: 0.0234
top acc: 0.0531 ::: bot acc: 0.0252
top acc: 0.0616 ::: bot acc: 0.0218
top acc: 0.0531 ::: bot acc: 0.0186
current epoch: 45
train loss is 0.042416
average val loss: 0.031038, accuracy: 0.0311
average test loss: 0.033141, accuracy: 0.0332
case acc: 0.03687747
case acc: 0.055542786
case acc: 0.029334217
case acc: 0.027659386
case acc: 0.029613866
case acc: 0.020459782
top acc: 0.0512 ::: bot acc: 0.0225
top acc: 0.0676 ::: bot acc: 0.0428
top acc: 0.0478 ::: bot acc: 0.0125
top acc: 0.0414 ::: bot acc: 0.0148
top acc: 0.0489 ::: bot acc: 0.0095
top acc: 0.0364 ::: bot acc: 0.0061
current epoch: 46
train loss is 0.027379
average val loss: 0.027856, accuracy: 0.0279
average test loss: 0.029933, accuracy: 0.0299
case acc: 0.024198927
case acc: 0.040773086
case acc: 0.030993352
case acc: 0.0299882
case acc: 0.031105356
case acc: 0.022631593
top acc: 0.0382 ::: bot acc: 0.0104
top acc: 0.0528 ::: bot acc: 0.0280
top acc: 0.0497 ::: bot acc: 0.0137
top acc: 0.0439 ::: bot acc: 0.0168
top acc: 0.0505 ::: bot acc: 0.0108
top acc: 0.0391 ::: bot acc: 0.0072
current epoch: 47
train loss is 0.019618
average val loss: 0.022572, accuracy: 0.0224
average test loss: 0.024312, accuracy: 0.0242
case acc: 0.012534622
case acc: 0.026222302
case acc: 0.028910894
case acc: 0.030023202
case acc: 0.02913473
case acc: 0.018553436
top acc: 0.0224 ::: bot acc: 0.0072
top acc: 0.0382 ::: bot acc: 0.0137
top acc: 0.0473 ::: bot acc: 0.0123
top acc: 0.0439 ::: bot acc: 0.0169
top acc: 0.0484 ::: bot acc: 0.0091
top acc: 0.0337 ::: bot acc: 0.0057
current epoch: 48
train loss is 0.014998
average val loss: 0.022824, accuracy: 0.0225
average test loss: 0.024405, accuracy: 0.0242
case acc: 0.010467374
case acc: 0.021037774
case acc: 0.03031996
case acc: 0.03364403
case acc: 0.031876698
case acc: 0.017964633
top acc: 0.0167 ::: bot acc: 0.0119
top acc: 0.0327 ::: bot acc: 0.0091
top acc: 0.0490 ::: bot acc: 0.0132
top acc: 0.0477 ::: bot acc: 0.0202
top acc: 0.0513 ::: bot acc: 0.0115
top acc: 0.0329 ::: bot acc: 0.0056
current epoch: 49
train loss is 0.019984
average val loss: 0.023908, accuracy: 0.0235
average test loss: 0.025354, accuracy: 0.0251
case acc: 0.010265377
case acc: 0.015180705
case acc: 0.032703318
case acc: 0.036048885
case acc: 0.035718754
case acc: 0.02044419
top acc: 0.0133 ::: bot acc: 0.0154
top acc: 0.0257 ::: bot acc: 0.0056
top acc: 0.0516 ::: bot acc: 0.0150
top acc: 0.0501 ::: bot acc: 0.0225
top acc: 0.0551 ::: bot acc: 0.0153
top acc: 0.0364 ::: bot acc: 0.0061
current epoch: 50
train loss is 0.029142
average val loss: 0.021201, accuracy: 0.0216
average test loss: 0.019634, accuracy: 0.0205
case acc: 0.037943218
case acc: 0.029707277
case acc: 0.015087078
case acc: 0.010300323
case acc: 0.015743935
case acc: 0.014099252
top acc: 0.0237 ::: bot acc: 0.0523
top acc: 0.0177 ::: bot acc: 0.0425
top acc: 0.0211 ::: bot acc: 0.0215
top acc: 0.0175 ::: bot acc: 0.0105
top acc: 0.0259 ::: bot acc: 0.0139
top acc: 0.0094 ::: bot acc: 0.0252
LME_Co_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6804 6804 6804
1.7082474 -0.6288155 0.10460696 -0.09017589
Validation: 756 756 756
Testing: 768 768 768
pre-processing time: 0.000396728515625
the split date is 2011-07-01
net initializing with time: 0.0029189586639404297
preparing training and testing date with time: 0.0
current epoch: 1
train loss is 0.280169
average val loss: 0.245311, accuracy: 0.2454
average test loss: 0.244686, accuracy: 0.2447
case acc: 0.43484163
case acc: 0.37054956
case acc: 0.03689368
case acc: 0.18748842
case acc: 0.38414043
case acc: 0.05431226
top acc: 0.4444 ::: bot acc: 0.4204
top acc: 0.3819 ::: bot acc: 0.3604
top acc: 0.0568 ::: bot acc: 0.0180
top acc: 0.1986 ::: bot acc: 0.1753
top acc: 0.4004 ::: bot acc: 0.3660
top acc: 0.0704 ::: bot acc: 0.0379
current epoch: 2
train loss is 0.261024
average val loss: 0.148960, accuracy: 0.1488
average test loss: 0.148899, accuracy: 0.1487
case acc: 0.22941035
case acc: 0.17110853
case acc: 0.15127714
case acc: 0.012291281
case acc: 0.18285613
case acc: 0.1451579
top acc: 0.2397 ::: bot acc: 0.2155
top acc: 0.1822 ::: bot acc: 0.1609
top acc: 0.1308 ::: bot acc: 0.1714
top acc: 0.0084 ::: bot acc: 0.0207
top acc: 0.1992 ::: bot acc: 0.1649
top acc: 0.1288 ::: bot acc: 0.1619
current epoch: 3
train loss is 0.151909
average val loss: 0.160279, accuracy: 0.1605
average test loss: 0.160384, accuracy: 0.1607
case acc: 0.29240412
case acc: 0.24064715
case acc: 0.057616286
case acc: 0.07221535
case acc: 0.25137323
case acc: 0.050210662
top acc: 0.3030 ::: bot acc: 0.2787
top acc: 0.2517 ::: bot acc: 0.2304
top acc: 0.0374 ::: bot acc: 0.0776
top acc: 0.0830 ::: bot acc: 0.0606
top acc: 0.2677 ::: bot acc: 0.2334
top acc: 0.0352 ::: bot acc: 0.0664
current epoch: 4
train loss is 0.158108
average val loss: 0.135773, accuracy: 0.1360
average test loss: 0.135868, accuracy: 0.1361
case acc: 0.23730773
case acc: 0.19246924
case acc: 0.07997709
case acc: 0.03604964
case acc: 0.20192578
case acc: 0.068723574
top acc: 0.2482 ::: bot acc: 0.2238
top acc: 0.2034 ::: bot acc: 0.1823
top acc: 0.0595 ::: bot acc: 0.1002
top acc: 0.0467 ::: bot acc: 0.0245
top acc: 0.2183 ::: bot acc: 0.1840
top acc: 0.0522 ::: bot acc: 0.0859
current epoch: 5
train loss is 0.136761
average val loss: 0.129956, accuracy: 0.1302
average test loss: 0.130070, accuracy: 0.1305
case acc: 0.23855138
case acc: 0.20109959
case acc: 0.044706807
case acc: 0.05780956
case acc: 0.20883603
case acc: 0.031917136
top acc: 0.2495 ::: bot acc: 0.2251
top acc: 0.2120 ::: bot acc: 0.1909
top acc: 0.0250 ::: bot acc: 0.0646
top acc: 0.0684 ::: bot acc: 0.0463
top acc: 0.2253 ::: bot acc: 0.1909
top acc: 0.0180 ::: bot acc: 0.0479
current epoch: 6
train loss is 0.125406
average val loss: 0.114383, accuracy: 0.1147
average test loss: 0.114483, accuracy: 0.1149
case acc: 0.20964614
case acc: 0.17943703
case acc: 0.04077632
case acc: 0.04845498
case acc: 0.18552074
case acc: 0.025782397
top acc: 0.2207 ::: bot acc: 0.1963
top acc: 0.1904 ::: bot acc: 0.1693
top acc: 0.0216 ::: bot acc: 0.0604
top acc: 0.0590 ::: bot acc: 0.0370
top acc: 0.2020 ::: bot acc: 0.1676
top acc: 0.0132 ::: bot acc: 0.0413
current epoch: 7
train loss is 0.113638
average val loss: 0.105118, accuracy: 0.1056
average test loss: 0.104767, accuracy: 0.1055
case acc: 0.19441158
case acc: 0.17154048
case acc: 0.025192015
case acc: 0.052656073
case acc: 0.17592978
case acc: 0.013259725
top acc: 0.2057 ::: bot acc: 0.1812
top acc: 0.1824 ::: bot acc: 0.1614
top acc: 0.0103 ::: bot acc: 0.0428
top acc: 0.0632 ::: bot acc: 0.0411
top acc: 0.1924 ::: bot acc: 0.1579
top acc: 0.0133 ::: bot acc: 0.0220
current epoch: 8
train loss is 0.101102
average val loss: 0.090940, accuracy: 0.0915
average test loss: 0.090436, accuracy: 0.0912
case acc: 0.16582802
case acc: 0.15023977
case acc: 0.022439728
case acc: 0.04286543
case acc: 0.15294552
case acc: 0.013102839
top acc: 0.1773 ::: bot acc: 0.1528
top acc: 0.1611 ::: bot acc: 0.1402
top acc: 0.0089 ::: bot acc: 0.0395
top acc: 0.0534 ::: bot acc: 0.0314
top acc: 0.1695 ::: bot acc: 0.1350
top acc: 0.0187 ::: bot acc: 0.0169
current epoch: 9
train loss is 0.089583
average val loss: 0.089510, accuracy: 0.0901
average test loss: 0.088563, accuracy: 0.0893
case acc: 0.15424979
case acc: 0.14613909
case acc: 0.014782732
case acc: 0.050061937
case acc: 0.14707483
case acc: 0.023757977
top acc: 0.1658 ::: bot acc: 0.1412
top acc: 0.1569 ::: bot acc: 0.1361
top acc: 0.0219 ::: bot acc: 0.0190
top acc: 0.0606 ::: bot acc: 0.0386
top acc: 0.1636 ::: bot acc: 0.1291
top acc: 0.0395 ::: bot acc: 0.0088
current epoch: 10
train loss is 0.079614
average val loss: 0.078852, accuracy: 0.0794
average test loss: 0.077881, accuracy: 0.0785
case acc: 0.12865531
case acc: 0.1281638
case acc: 0.015944147
case acc: 0.04298097
case acc: 0.12744811
case acc: 0.02804489
top acc: 0.1403 ::: bot acc: 0.1157
top acc: 0.1389 ::: bot acc: 0.1181
top acc: 0.0275 ::: bot acc: 0.0134
top acc: 0.0535 ::: bot acc: 0.0315
top acc: 0.1440 ::: bot acc: 0.1094
top acc: 0.0442 ::: bot acc: 0.0122
current epoch: 11
train loss is 0.068798
average val loss: 0.073035, accuracy: 0.0734
average test loss: 0.072105, accuracy: 0.0725
case acc: 0.1083061
case acc: 0.11556485
case acc: 0.021340368
case acc: 0.04081429
case acc: 0.113142475
case acc: 0.035762288
top acc: 0.1200 ::: bot acc: 0.0954
top acc: 0.1264 ::: bot acc: 0.1055
top acc: 0.0378 ::: bot acc: 0.0090
top acc: 0.0514 ::: bot acc: 0.0293
top acc: 0.1298 ::: bot acc: 0.0950
top acc: 0.0524 ::: bot acc: 0.0189
current epoch: 12
train loss is 0.060856
average val loss: 0.069929, accuracy: 0.0701
average test loss: 0.069014, accuracy: 0.0691
case acc: 0.09118438
case acc: 0.10639126
case acc: 0.031015163
case acc: 0.041290767
case acc: 0.1022735
case acc: 0.04265032
top acc: 0.1030 ::: bot acc: 0.0784
top acc: 0.1172 ::: bot acc: 0.0963
top acc: 0.0502 ::: bot acc: 0.0132
top acc: 0.0518 ::: bot acc: 0.0298
top acc: 0.1189 ::: bot acc: 0.0842
top acc: 0.0596 ::: bot acc: 0.0253
current epoch: 13
train loss is 0.053004
average val loss: 0.058287, accuracy: 0.0584
average test loss: 0.057368, accuracy: 0.0574
case acc: 0.06628772
case acc: 0.08955544
case acc: 0.0337924
case acc: 0.033243112
case acc: 0.0836993
case acc: 0.038012262
top acc: 0.0783 ::: bot acc: 0.0536
top acc: 0.1004 ::: bot acc: 0.0794
top acc: 0.0532 ::: bot acc: 0.0154
top acc: 0.0437 ::: bot acc: 0.0218
top acc: 0.1004 ::: bot acc: 0.0656
top acc: 0.0548 ::: bot acc: 0.0209
current epoch: 14
train loss is 0.044305
average val loss: 0.053330, accuracy: 0.0534
average test loss: 0.052415, accuracy: 0.0524
case acc: 0.050266467
case acc: 0.080832675
case acc: 0.042257033
case acc: 0.031932887
case acc: 0.072879046
case acc: 0.036184583
top acc: 0.0624 ::: bot acc: 0.0376
top acc: 0.0916 ::: bot acc: 0.0706
top acc: 0.0622 ::: bot acc: 0.0226
top acc: 0.0424 ::: bot acc: 0.0205
top acc: 0.0896 ::: bot acc: 0.0548
top acc: 0.0529 ::: bot acc: 0.0192
current epoch: 15
train loss is 0.037598
average val loss: 0.047735, accuracy: 0.0477
average test loss: 0.046851, accuracy: 0.0468
case acc: 0.036537148
case acc: 0.07255942
case acc: 0.04894817
case acc: 0.02960487
case acc: 0.06255388
case acc: 0.030525599
top acc: 0.0488 ::: bot acc: 0.0239
top acc: 0.0833 ::: bot acc: 0.0623
top acc: 0.0690 ::: bot acc: 0.0289
top acc: 0.0400 ::: bot acc: 0.0182
top acc: 0.0791 ::: bot acc: 0.0448
top acc: 0.0469 ::: bot acc: 0.0142
current epoch: 16
train loss is 0.032342
average val loss: 0.045598, accuracy: 0.0455
average test loss: 0.044768, accuracy: 0.0447
case acc: 0.029186163
case acc: 0.0684074
case acc: 0.0570872
case acc: 0.030242367
case acc: 0.056517504
case acc: 0.026784297
top acc: 0.0415 ::: bot acc: 0.0168
top acc: 0.0792 ::: bot acc: 0.0582
top acc: 0.0771 ::: bot acc: 0.0370
top acc: 0.0407 ::: bot acc: 0.0189
top acc: 0.0730 ::: bot acc: 0.0390
top acc: 0.0428 ::: bot acc: 0.0111
current epoch: 17
train loss is 0.030175
average val loss: 0.059605, accuracy: 0.0595
average test loss: 0.058810, accuracy: 0.0588
case acc: 0.039654844
case acc: 0.08071594
case acc: 0.07902737
case acc: 0.046958417
case acc: 0.06755919
case acc: 0.038941115
top acc: 0.0521 ::: bot acc: 0.0271
top acc: 0.0915 ::: bot acc: 0.0705
top acc: 0.0990 ::: bot acc: 0.0590
top acc: 0.0574 ::: bot acc: 0.0356
top acc: 0.0842 ::: bot acc: 0.0496
top acc: 0.0555 ::: bot acc: 0.0220
current epoch: 18
train loss is 0.033639
average val loss: 0.078708, accuracy: 0.0787
average test loss: 0.077950, accuracy: 0.0780
case acc: 0.053856477
case acc: 0.098178566
case acc: 0.10438058
case acc: 0.06935415
case acc: 0.085060865
case acc: 0.056912437
top acc: 0.0664 ::: bot acc: 0.0414
top acc: 0.1089 ::: bot acc: 0.0880
top acc: 0.1243 ::: bot acc: 0.0844
top acc: 0.0798 ::: bot acc: 0.0580
top acc: 0.1017 ::: bot acc: 0.0670
top acc: 0.0738 ::: bot acc: 0.0393
current epoch: 19
train loss is 0.042495
average val loss: 0.094553, accuracy: 0.0945
average test loss: 0.093857, accuracy: 0.0939
case acc: 0.062575676
case acc: 0.112780035
case acc: 0.12513904
case acc: 0.08954457
case acc: 0.10111125
case acc: 0.071951
top acc: 0.0751 ::: bot acc: 0.0501
top acc: 0.1234 ::: bot acc: 0.1026
top acc: 0.1451 ::: bot acc: 0.1051
top acc: 0.1000 ::: bot acc: 0.0783
top acc: 0.1178 ::: bot acc: 0.0830
top acc: 0.0890 ::: bot acc: 0.0539
current epoch: 20
train loss is 0.059514
average val loss: 0.059880, accuracy: 0.0597
average test loss: 0.059200, accuracy: 0.0591
case acc: 0.020192306
case acc: 0.07637532
case acc: 0.08918159
case acc: 0.05884283
case acc: 0.06903395
case acc: 0.04088159
top acc: 0.0324 ::: bot acc: 0.0086
top acc: 0.0870 ::: bot acc: 0.0663
top acc: 0.1091 ::: bot acc: 0.0691
top acc: 0.0692 ::: bot acc: 0.0476
top acc: 0.0856 ::: bot acc: 0.0511
top acc: 0.0574 ::: bot acc: 0.0240
current epoch: 21
train loss is 0.064805
average val loss: 0.021569, accuracy: 0.0221
average test loss: 0.020927, accuracy: 0.0209
case acc: 0.055206515
case acc: 0.007642456
case acc: 0.017067518
case acc: 0.01295284
case acc: 0.012716724
case acc: 0.019581378
top acc: 0.0425 ::: bot acc: 0.0676
top acc: 0.0128 ::: bot acc: 0.0079
top acc: 0.0305 ::: bot acc: 0.0103
top acc: 0.0053 ::: bot acc: 0.0228
top acc: 0.0177 ::: bot acc: 0.0171
top acc: 0.0084 ::: bot acc: 0.0347
current epoch: 22
train loss is 0.050733
average val loss: 0.020649, accuracy: 0.0213
average test loss: 0.019998, accuracy: 0.0205
case acc: 0.053233057
case acc: 0.009159426
case acc: 0.014809196
case acc: 0.02035098
case acc: 0.012564976
case acc: 0.012913938
top acc: 0.0405 ::: bot acc: 0.0656
top acc: 0.0052 ::: bot acc: 0.0161
top acc: 0.0150 ::: bot acc: 0.0250
top acc: 0.0109 ::: bot acc: 0.0311
top acc: 0.0146 ::: bot acc: 0.0201
top acc: 0.0127 ::: bot acc: 0.0224
current epoch: 23
train loss is 0.036802
average val loss: 0.020963, accuracy: 0.0213
average test loss: 0.020481, accuracy: 0.0209
case acc: 0.043281883
case acc: 0.010247479
case acc: 0.019327767
case acc: 0.023501944
case acc: 0.0125898225
case acc: 0.016185176
top acc: 0.0305 ::: bot acc: 0.0556
top acc: 0.0045 ::: bot acc: 0.0180
top acc: 0.0084 ::: bot acc: 0.0350
top acc: 0.0136 ::: bot acc: 0.0344
top acc: 0.0167 ::: bot acc: 0.0180
top acc: 0.0284 ::: bot acc: 0.0080
current epoch: 24
train loss is 0.028764
average val loss: 0.029736, accuracy: 0.0299
average test loss: 0.029803, accuracy: 0.0301
case acc: 0.0476856
case acc: 0.023212083
case acc: 0.039532647
case acc: 0.04066033
case acc: 0.016155165
case acc: 0.013556897
top acc: 0.0349 ::: bot acc: 0.0599
top acc: 0.0130 ::: bot acc: 0.0331
top acc: 0.0212 ::: bot acc: 0.0588
top acc: 0.0302 ::: bot acc: 0.0519
top acc: 0.0072 ::: bot acc: 0.0305
top acc: 0.0219 ::: bot acc: 0.0132
current epoch: 25
train loss is 0.032045
average val loss: 0.047726, accuracy: 0.0477
average test loss: 0.048215, accuracy: 0.0483
case acc: 0.05915417
case acc: 0.04402404
case acc: 0.06792341
case acc: 0.06597988
case acc: 0.03373327
case acc: 0.01911171
top acc: 0.0464 ::: bot acc: 0.0714
top acc: 0.0335 ::: bot acc: 0.0541
top acc: 0.0480 ::: bot acc: 0.0880
top acc: 0.0556 ::: bot acc: 0.0772
top acc: 0.0179 ::: bot acc: 0.0514
top acc: 0.0082 ::: bot acc: 0.0342
current epoch: 26
train loss is 0.055102
average val loss: 0.026116, accuracy: 0.0260
average test loss: 0.026007, accuracy: 0.0262
case acc: 0.023749195
case acc: 0.017104397
case acc: 0.043827843
case acc: 0.043761976
case acc: 0.01411034
case acc: 0.014374268
top acc: 0.0120 ::: bot acc: 0.0354
top acc: 0.0076 ::: bot acc: 0.0267
top acc: 0.0248 ::: bot acc: 0.0635
top acc: 0.0333 ::: bot acc: 0.0550
top acc: 0.0082 ::: bot acc: 0.0269
top acc: 0.0244 ::: bot acc: 0.0107
current epoch: 27
train loss is 0.063168
average val loss: 0.051519, accuracy: 0.0517
average test loss: 0.051029, accuracy: 0.0510
case acc: 0.057515867
case acc: 0.05934821
case acc: 0.034694076
case acc: 0.027564062
case acc: 0.061224997
case acc: 0.06544225
top acc: 0.0703 ::: bot acc: 0.0453
top acc: 0.0698 ::: bot acc: 0.0493
top acc: 0.0541 ::: bot acc: 0.0158
top acc: 0.0380 ::: bot acc: 0.0164
top acc: 0.0777 ::: bot acc: 0.0435
top acc: 0.0824 ::: bot acc: 0.0476
current epoch: 28
train loss is 0.043663
average val loss: 0.034218, accuracy: 0.0342
average test loss: 0.033637, accuracy: 0.0336
case acc: 0.037785925
case acc: 0.045398444
case acc: 0.028099326
case acc: 0.014909975
case acc: 0.04272253
case acc: 0.032391176
top acc: 0.0506 ::: bot acc: 0.0256
top acc: 0.0559 ::: bot acc: 0.0353
top acc: 0.0468 ::: bot acc: 0.0108
top acc: 0.0242 ::: bot acc: 0.0060
top acc: 0.0588 ::: bot acc: 0.0258
top acc: 0.0486 ::: bot acc: 0.0161
current epoch: 29
train loss is 0.030271
average val loss: 0.031054, accuracy: 0.0309
average test loss: 0.030358, accuracy: 0.0303
case acc: 0.030972004
case acc: 0.0449123
case acc: 0.03525047
case acc: 0.0157275
case acc: 0.03784314
case acc: 0.017201526
top acc: 0.0438 ::: bot acc: 0.0189
top acc: 0.0554 ::: bot acc: 0.0348
top acc: 0.0547 ::: bot acc: 0.0163
top acc: 0.0252 ::: bot acc: 0.0065
top acc: 0.0538 ::: bot acc: 0.0212
top acc: 0.0304 ::: bot acc: 0.0071
current epoch: 30
train loss is 0.024449
average val loss: 0.041932, accuracy: 0.0419
average test loss: 0.041366, accuracy: 0.0414
case acc: 0.03916859
case acc: 0.057940457
case acc: 0.057116553
case acc: 0.029846024
case acc: 0.04656659
case acc: 0.018022003
top acc: 0.0520 ::: bot acc: 0.0270
top acc: 0.0684 ::: bot acc: 0.0479
top acc: 0.0771 ::: bot acc: 0.0370
top acc: 0.0403 ::: bot acc: 0.0187
top acc: 0.0628 ::: bot acc: 0.0294
top acc: 0.0317 ::: bot acc: 0.0070
current epoch: 31
train loss is 0.025259
average val loss: 0.066436, accuracy: 0.0664
average test loss: 0.065969, accuracy: 0.0660
case acc: 0.05693204
case acc: 0.082077295
case acc: 0.09331697
case acc: 0.058628798
case acc: 0.06803842
case acc: 0.037069887
top acc: 0.0698 ::: bot acc: 0.0448
top acc: 0.0926 ::: bot acc: 0.0720
top acc: 0.1133 ::: bot acc: 0.0732
top acc: 0.0691 ::: bot acc: 0.0475
top acc: 0.0846 ::: bot acc: 0.0501
top acc: 0.0534 ::: bot acc: 0.0204
current epoch: 32
train loss is 0.045946
average val loss: 0.072194, accuracy: 0.0721
average test loss: 0.071726, accuracy: 0.0717
case acc: 0.052747715
case acc: 0.08589562
case acc: 0.10602528
case acc: 0.06879341
case acc: 0.07277537
case acc: 0.044239853
top acc: 0.0655 ::: bot acc: 0.0406
top acc: 0.0964 ::: bot acc: 0.0759
top acc: 0.1260 ::: bot acc: 0.0859
top acc: 0.0793 ::: bot acc: 0.0577
top acc: 0.0894 ::: bot acc: 0.0547
top acc: 0.0608 ::: bot acc: 0.0271
current epoch: 33
train loss is 0.060989
average val loss: 0.020105, accuracy: 0.0203
average test loss: 0.019331, accuracy: 0.0189
case acc: 0.023303736
case acc: 0.015657546
case acc: 0.03570557
case acc: 0.00852768
case acc: 0.014689004
case acc: 0.015427149
top acc: 0.0118 ::: bot acc: 0.0349
top acc: 0.0261 ::: bot acc: 0.0057
top acc: 0.0552 ::: bot acc: 0.0167
top acc: 0.0140 ::: bot acc: 0.0076
top acc: 0.0245 ::: bot acc: 0.0106
top acc: 0.0080 ::: bot acc: 0.0287
current epoch: 34
train loss is 0.047551
average val loss: 0.019820, accuracy: 0.0202
average test loss: 0.019382, accuracy: 0.0195
case acc: 0.03979688
case acc: 0.009989008
case acc: 0.015195681
case acc: 0.01960188
case acc: 0.014842646
case acc: 0.017341536
top acc: 0.0270 ::: bot acc: 0.0520
top acc: 0.0044 ::: bot acc: 0.0176
top acc: 0.0255 ::: bot acc: 0.0146
top acc: 0.0103 ::: bot acc: 0.0302
top acc: 0.0075 ::: bot acc: 0.0283
top acc: 0.0075 ::: bot acc: 0.0318
current epoch: 35
train loss is 0.031590
average val loss: 0.015536, accuracy: 0.0157
average test loss: 0.014547, accuracy: 0.0145
case acc: 0.021558927
case acc: 0.0074563385
case acc: 0.015455289
case acc: 0.012756621
case acc: 0.0130087305
case acc: 0.017055089
top acc: 0.0106 ::: bot acc: 0.0328
top acc: 0.0120 ::: bot acc: 0.0085
top acc: 0.0264 ::: bot acc: 0.0137
top acc: 0.0052 ::: bot acc: 0.0224
top acc: 0.0195 ::: bot acc: 0.0153
top acc: 0.0302 ::: bot acc: 0.0070
current epoch: 36
train loss is 0.023643
average val loss: 0.016643, accuracy: 0.0168
average test loss: 0.015989, accuracy: 0.0163
case acc: 0.02108666
case acc: 0.0091868285
case acc: 0.017365295
case acc: 0.021251895
case acc: 0.012543021
case acc: 0.01636884
top acc: 0.0103 ::: bot acc: 0.0323
top acc: 0.0050 ::: bot acc: 0.0161
top acc: 0.0098 ::: bot acc: 0.0314
top acc: 0.0117 ::: bot acc: 0.0319
top acc: 0.0150 ::: bot acc: 0.0198
top acc: 0.0289 ::: bot acc: 0.0076
current epoch: 37
train loss is 0.020436
average val loss: 0.023434, accuracy: 0.0235
average test loss: 0.023403, accuracy: 0.0236
case acc: 0.024666343
case acc: 0.017920092
case acc: 0.03367608
case acc: 0.035853233
case acc: 0.016275583
case acc: 0.012922082
top acc: 0.0129 ::: bot acc: 0.0363
top acc: 0.0083 ::: bot acc: 0.0275
top acc: 0.0161 ::: bot acc: 0.0526
top acc: 0.0254 ::: bot acc: 0.0470
top acc: 0.0072 ::: bot acc: 0.0306
top acc: 0.0124 ::: bot acc: 0.0225
current epoch: 38
train loss is 0.023359
average val loss: 0.030829, accuracy: 0.0308
average test loss: 0.031097, accuracy: 0.0311
case acc: 0.024765896
case acc: 0.026052037
case acc: 0.04712063
case acc: 0.048323162
case acc: 0.023246521
case acc: 0.017030356
top acc: 0.0129 ::: bot acc: 0.0364
top acc: 0.0158 ::: bot acc: 0.0359
top acc: 0.0278 ::: bot acc: 0.0669
top acc: 0.0379 ::: bot acc: 0.0595
top acc: 0.0095 ::: bot acc: 0.0399
top acc: 0.0075 ::: bot acc: 0.0314
current epoch: 39
train loss is 0.029260
average val loss: 0.036190, accuracy: 0.0360
average test loss: 0.036567, accuracy: 0.0366
case acc: 0.022019017
case acc: 0.031371944
case acc: 0.055927567
case acc: 0.058503117
case acc: 0.029937636
case acc: 0.021620063
top acc: 0.0109 ::: bot acc: 0.0333
top acc: 0.0210 ::: bot acc: 0.0413
top acc: 0.0362 ::: bot acc: 0.0759
top acc: 0.0480 ::: bot acc: 0.0697
top acc: 0.0146 ::: bot acc: 0.0473
top acc: 0.0097 ::: bot acc: 0.0371
current epoch: 40
train loss is 0.047780
average val loss: 0.027021, accuracy: 0.0270
average test loss: 0.026291, accuracy: 0.0264
case acc: 0.045241363
case acc: 0.028853562
case acc: 0.015460495
case acc: 0.007939791
case acc: 0.027400447
case acc: 0.03332135
top acc: 0.0581 ::: bot acc: 0.0331
top acc: 0.0394 ::: bot acc: 0.0189
top acc: 0.0265 ::: bot acc: 0.0135
top acc: 0.0078 ::: bot acc: 0.0139
top acc: 0.0426 ::: bot acc: 0.0123
top acc: 0.0495 ::: bot acc: 0.0171
current epoch: 41
train loss is 0.048156
average val loss: 0.044781, accuracy: 0.0448
average test loss: 0.044343, accuracy: 0.0443
case acc: 0.065548256
case acc: 0.053884298
case acc: 0.038168106
case acc: 0.022258898
case acc: 0.04665923
case acc: 0.039154794
top acc: 0.0784 ::: bot acc: 0.0534
top acc: 0.0644 ::: bot acc: 0.0439
top acc: 0.0577 ::: bot acc: 0.0188
top acc: 0.0325 ::: bot acc: 0.0115
top acc: 0.0629 ::: bot acc: 0.0295
top acc: 0.0556 ::: bot acc: 0.0224
current epoch: 42
train loss is 0.033889
average val loss: 0.044967, accuracy: 0.0450
average test loss: 0.044557, accuracy: 0.0446
case acc: 0.05830529
case acc: 0.05678888
case acc: 0.05063357
case acc: 0.028693214
case acc: 0.046428192
case acc: 0.026490472
top acc: 0.0711 ::: bot acc: 0.0462
top acc: 0.0673 ::: bot acc: 0.0468
top acc: 0.0706 ::: bot acc: 0.0305
top acc: 0.0392 ::: bot acc: 0.0175
top acc: 0.0627 ::: bot acc: 0.0292
top acc: 0.0422 ::: bot acc: 0.0112
current epoch: 43
train loss is 0.029263
average val loss: 0.061226, accuracy: 0.0612
average test loss: 0.060771, accuracy: 0.0608
case acc: 0.064418636
case acc: 0.07357207
case acc: 0.08005565
case acc: 0.051292837
case acc: 0.061028123
case acc: 0.03465636
top acc: 0.0772 ::: bot acc: 0.0523
top acc: 0.0841 ::: bot acc: 0.0636
top acc: 0.1000 ::: bot acc: 0.0600
top acc: 0.0618 ::: bot acc: 0.0401
top acc: 0.0775 ::: bot acc: 0.0433
top acc: 0.0508 ::: bot acc: 0.0183
current epoch: 44
train loss is 0.045285
average val loss: 0.054325, accuracy: 0.0542
average test loss: 0.053883, accuracy: 0.0540
case acc: 0.04691703
case acc: 0.065325975
case acc: 0.080065556
case acc: 0.049596462
case acc: 0.054132067
case acc: 0.027685104
top acc: 0.0597 ::: bot acc: 0.0347
top acc: 0.0759 ::: bot acc: 0.0553
top acc: 0.1000 ::: bot acc: 0.0600
top acc: 0.0601 ::: bot acc: 0.0384
top acc: 0.0705 ::: bot acc: 0.0366
top acc: 0.0434 ::: bot acc: 0.0122
current epoch: 45
train loss is 0.051895
average val loss: 0.017216, accuracy: 0.0173
average test loss: 0.016200, accuracy: 0.0158
case acc: 0.012691574
case acc: 0.0144397095
case acc: 0.030209845
case acc: 0.008699127
case acc: 0.014770282
case acc: 0.013902914
top acc: 0.0068 ::: bot acc: 0.0215
top acc: 0.0248 ::: bot acc: 0.0048
top acc: 0.0491 ::: bot acc: 0.0122
top acc: 0.0143 ::: bot acc: 0.0075
top acc: 0.0247 ::: bot acc: 0.0105
top acc: 0.0090 ::: bot acc: 0.0259
current epoch: 46
train loss is 0.032927
average val loss: 0.017105, accuracy: 0.0169
average test loss: 0.015982, accuracy: 0.0156
case acc: 0.010875098
case acc: 0.01426787
case acc: 0.0259444
case acc: 0.0093603255
case acc: 0.017295204
case acc: 0.016118951
top acc: 0.0074 ::: bot acc: 0.0185
top acc: 0.0246 ::: bot acc: 0.0047
top acc: 0.0440 ::: bot acc: 0.0098
top acc: 0.0159 ::: bot acc: 0.0063
top acc: 0.0294 ::: bot acc: 0.0085
top acc: 0.0283 ::: bot acc: 0.0078
current epoch: 47
train loss is 0.024795
average val loss: 0.015369, accuracy: 0.0153
average test loss: 0.014151, accuracy: 0.0139
case acc: 0.012072658
case acc: 0.009425582
case acc: 0.01670339
case acc: 0.00785153
case acc: 0.016116653
case acc: 0.021002265
top acc: 0.0069 ::: bot acc: 0.0205
top acc: 0.0182 ::: bot acc: 0.0030
top acc: 0.0299 ::: bot acc: 0.0104
top acc: 0.0100 ::: bot acc: 0.0118
top acc: 0.0275 ::: bot acc: 0.0089
top acc: 0.0355 ::: bot acc: 0.0080
current epoch: 48
train loss is 0.017945
average val loss: 0.014152, accuracy: 0.0142
average test loss: 0.013112, accuracy: 0.0133
case acc: 0.0154451355
case acc: 0.0076100933
case acc: 0.01598441
case acc: 0.012271104
case acc: 0.013336111
case acc: 0.015420853
top acc: 0.0075 ::: bot acc: 0.0252
top acc: 0.0090 ::: bot acc: 0.0115
top acc: 0.0119 ::: bot acc: 0.0283
top acc: 0.0049 ::: bot acc: 0.0220
top acc: 0.0208 ::: bot acc: 0.0140
top acc: 0.0269 ::: bot acc: 0.0087
current epoch: 49
train loss is 0.016998
average val loss: 0.016767, accuracy: 0.0169
average test loss: 0.016210, accuracy: 0.0165
case acc: 0.016554622
case acc: 0.010804325
case acc: 0.025364716
case acc: 0.021042297
case acc: 0.012568377
case acc: 0.012420658
top acc: 0.0080 ::: bot acc: 0.0267
top acc: 0.0044 ::: bot acc: 0.0188
top acc: 0.0106 ::: bot acc: 0.0429
top acc: 0.0113 ::: bot acc: 0.0319
top acc: 0.0138 ::: bot acc: 0.0210
top acc: 0.0155 ::: bot acc: 0.0193
current epoch: 50
train loss is 0.017274
average val loss: 0.021446, accuracy: 0.0215
average test loss: 0.021297, accuracy: 0.0214
case acc: 0.017112333
case acc: 0.017140478
case acc: 0.034801885
case acc: 0.030935237
case acc: 0.015407791
case acc: 0.013073938
top acc: 0.0083 ::: bot acc: 0.0274
top acc: 0.0076 ::: bot acc: 0.0266
top acc: 0.0171 ::: bot acc: 0.0538
top acc: 0.0204 ::: bot acc: 0.0422
top acc: 0.0073 ::: bot acc: 0.0293
top acc: 0.0113 ::: bot acc: 0.0235

		{"drop_out": 0.6, "drop_out_mc": 0.15, "repeat_mc": 50, "hidden": 20, "embedding_size": 5, "batch": 512, "lag": 3}
{'generate_norm_params': 'v1', 'generate_tech_params': 'v3', 'generate_strat_params': None, 'generate_SD_params': 'v1', 'deal_with_abnormal_value': 'v2', 'labelling': 'v3', 'process_missing_value': 'v1', 'strategy_signal': None, 'normalize_without_1d_return': 'v1', 'technical_indication': 'v4', 'supply_and_demand': None, 'remove_unused_columns': 'v6', 'price_normalization': 'v3', 'scaling': None, 'construct': 'v4'}
LME_Co_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6798 6798 6798
1.8562728 -0.6288155 0.09756618 -0.123651974
Validation: 756 756 756
Testing: 774 774 774
pre-processing time: 0.00033783912658691406
the split date is 2009-07-01
net initializing with time: 0.0389404296875
preparing training and testing date with time: 2.384185791015625e-07
current epoch: 1
train loss is 0.483695
average val loss: 0.426696, accuracy: 0.4267
average test loss: 0.425899, accuracy: 0.4259
case acc: 0.3632601
case acc: 0.5070758
case acc: 0.4013899
case acc: 0.2634799
case acc: 0.5800089
case acc: 0.44017828
top acc: 0.3720 ::: bot acc: 0.3549
top acc: 0.5190 ::: bot acc: 0.4951
top acc: 0.4162 ::: bot acc: 0.3857
top acc: 0.2744 ::: bot acc: 0.2523
top acc: 0.5921 ::: bot acc: 0.5685
top acc: 0.4508 ::: bot acc: 0.4290
current epoch: 2
train loss is 0.179137
average val loss: 0.080893, accuracy: 0.0806
average test loss: 0.081275, accuracy: 0.0817
case acc: 0.08079625
case acc: 0.058046076
case acc: 0.038134474
case acc: 0.17378625
case acc: 0.130099
case acc: 0.009373699
top acc: 0.0717 ::: bot acc: 0.0894
top acc: 0.0698 ::: bot acc: 0.0462
top acc: 0.0233 ::: bot acc: 0.0536
top acc: 0.1632 ::: bot acc: 0.1847
top acc: 0.1421 ::: bot acc: 0.1184
top acc: 0.0083 ::: bot acc: 0.0144
current epoch: 3
train loss is 0.127991
average val loss: 0.084725, accuracy: 0.0851
average test loss: 0.084673, accuracy: 0.0848
case acc: 0.021209814
case acc: 0.108990945
case acc: 0.023052592
case acc: 0.107314914
case acc: 0.18886112
case acc: 0.059538674
top acc: 0.0121 ::: bot acc: 0.0299
top acc: 0.1207 ::: bot acc: 0.0972
top acc: 0.0374 ::: bot acc: 0.0097
top acc: 0.0971 ::: bot acc: 0.1179
top acc: 0.2008 ::: bot acc: 0.1771
top acc: 0.0704 ::: bot acc: 0.0482
current epoch: 4
train loss is 0.115230
average val loss: 0.095543, accuracy: 0.0956
average test loss: 0.095065, accuracy: 0.0950
case acc: 0.012262509
case acc: 0.13949485
case acc: 0.054198064
case acc: 0.07356819
case acc: 0.20259954
case acc: 0.08761319
top acc: 0.0206 ::: bot acc: 0.0050
top acc: 0.1513 ::: bot acc: 0.1277
top acc: 0.0700 ::: bot acc: 0.0381
top acc: 0.0636 ::: bot acc: 0.0840
top acc: 0.2146 ::: bot acc: 0.1908
top acc: 0.0986 ::: bot acc: 0.0763
current epoch: 5
train loss is 0.094734
average val loss: 0.073103, accuracy: 0.0736
average test loss: 0.072930, accuracy: 0.0733
case acc: 0.02858554
case acc: 0.09447545
case acc: 0.018507823
case acc: 0.11043751
case acc: 0.1435728
case acc: 0.04393645
top acc: 0.0195 ::: bot acc: 0.0375
top acc: 0.1063 ::: bot acc: 0.0826
top acc: 0.0320 ::: bot acc: 0.0073
top acc: 0.1006 ::: bot acc: 0.1208
top acc: 0.1557 ::: bot acc: 0.1318
top acc: 0.0550 ::: bot acc: 0.0326
current epoch: 6
train loss is 0.090805
average val loss: 0.069203, accuracy: 0.0697
average test loss: 0.068993, accuracy: 0.0692
case acc: 0.025537502
case acc: 0.09050072
case acc: 0.021991663
case acc: 0.103968054
case acc: 0.12892967
case acc: 0.044298284
top acc: 0.0164 ::: bot acc: 0.0344
top acc: 0.1024 ::: bot acc: 0.0786
top acc: 0.0366 ::: bot acc: 0.0087
top acc: 0.0941 ::: bot acc: 0.1144
top acc: 0.1410 ::: bot acc: 0.1171
top acc: 0.0554 ::: bot acc: 0.0329
current epoch: 7
train loss is 0.086883
average val loss: 0.067116, accuracy: 0.0675
average test loss: 0.066865, accuracy: 0.0669
case acc: 0.017592123
case acc: 0.09311255
case acc: 0.03044725
case acc: 0.093484774
case acc: 0.11817701
case acc: 0.048564505
top acc: 0.0087 ::: bot acc: 0.0264
top acc: 0.1050 ::: bot acc: 0.0813
top acc: 0.0461 ::: bot acc: 0.0152
top acc: 0.0836 ::: bot acc: 0.1039
top acc: 0.1302 ::: bot acc: 0.1064
top acc: 0.0597 ::: bot acc: 0.0372
current epoch: 8
train loss is 0.080046
average val loss: 0.061280, accuracy: 0.0617
average test loss: 0.061001, accuracy: 0.0611
case acc: 0.02072857
case acc: 0.08457719
case acc: 0.02911865
case acc: 0.09440319
case acc: 0.0962049
case acc: 0.04141437
top acc: 0.0116 ::: bot acc: 0.0297
top acc: 0.0965 ::: bot acc: 0.0727
top acc: 0.0448 ::: bot acc: 0.0140
top acc: 0.0846 ::: bot acc: 0.1048
top acc: 0.1082 ::: bot acc: 0.0844
top acc: 0.0525 ::: bot acc: 0.0300
current epoch: 9
train loss is 0.071560
average val loss: 0.055059, accuracy: 0.0555
average test loss: 0.054754, accuracy: 0.0549
case acc: 0.025388952
case acc: 0.07370845
case acc: 0.026273891
case acc: 0.09653907
case acc: 0.073942035
case acc: 0.03346207
top acc: 0.0162 ::: bot acc: 0.0344
top acc: 0.0857 ::: bot acc: 0.0619
top acc: 0.0418 ::: bot acc: 0.0115
top acc: 0.0868 ::: bot acc: 0.1070
top acc: 0.0860 ::: bot acc: 0.0621
top acc: 0.0447 ::: bot acc: 0.0219
current epoch: 10
train loss is 0.067591
average val loss: 0.049901, accuracy: 0.0503
average test loss: 0.049578, accuracy: 0.0497
case acc: 0.026921287
case acc: 0.065244764
case acc: 0.025790613
case acc: 0.09534391
case acc: 0.0558321
case acc: 0.029200299
top acc: 0.0178 ::: bot acc: 0.0360
top acc: 0.0772 ::: bot acc: 0.0534
top acc: 0.0414 ::: bot acc: 0.0111
top acc: 0.0857 ::: bot acc: 0.1057
top acc: 0.0679 ::: bot acc: 0.0440
top acc: 0.0404 ::: bot acc: 0.0177
current epoch: 11
train loss is 0.063514
average val loss: 0.047211, accuracy: 0.0476
average test loss: 0.046869, accuracy: 0.0469
case acc: 0.021561187
case acc: 0.064766265
case acc: 0.031418283
case acc: 0.0876184
case acc: 0.04478373
case acc: 0.031418942
top acc: 0.0124 ::: bot acc: 0.0306
top acc: 0.0768 ::: bot acc: 0.0529
top acc: 0.0474 ::: bot acc: 0.0159
top acc: 0.0780 ::: bot acc: 0.0980
top acc: 0.0568 ::: bot acc: 0.0329
top acc: 0.0426 ::: bot acc: 0.0199
current epoch: 12
train loss is 0.059850
average val loss: 0.046210, accuracy: 0.0464
average test loss: 0.045823, accuracy: 0.0457
case acc: 0.01303568
case acc: 0.069105975
case acc: 0.040819135
case acc: 0.07621268
case acc: 0.03819292
case acc: 0.037131906
top acc: 0.0050 ::: bot acc: 0.0215
top acc: 0.0811 ::: bot acc: 0.0572
top acc: 0.0571 ::: bot acc: 0.0247
top acc: 0.0666 ::: bot acc: 0.0865
top acc: 0.0503 ::: bot acc: 0.0263
top acc: 0.0483 ::: bot acc: 0.0256
current epoch: 13
train loss is 0.055354
average val loss: 0.045717, accuracy: 0.0458
average test loss: 0.045235, accuracy: 0.0450
case acc: 0.0076691792
case acc: 0.07171871
case acc: 0.049492624
case acc: 0.06474087
case acc: 0.033994336
case acc: 0.042522445
top acc: 0.0048 ::: bot acc: 0.0136
top acc: 0.0838 ::: bot acc: 0.0598
top acc: 0.0659 ::: bot acc: 0.0331
top acc: 0.0552 ::: bot acc: 0.0750
top acc: 0.0460 ::: bot acc: 0.0223
top acc: 0.0537 ::: bot acc: 0.0310
current epoch: 14
train loss is 0.053362
average val loss: 0.046847, accuracy: 0.0468
average test loss: 0.046180, accuracy: 0.0460
case acc: 0.007459905
case acc: 0.07361378
case acc: 0.059040047
case acc: 0.051059496
case acc: 0.035131764
case acc: 0.04949126
top acc: 0.0128 ::: bot acc: 0.0060
top acc: 0.0857 ::: bot acc: 0.0617
top acc: 0.0755 ::: bot acc: 0.0427
top acc: 0.0415 ::: bot acc: 0.0613
top acc: 0.0472 ::: bot acc: 0.0234
top acc: 0.0607 ::: bot acc: 0.0380
current epoch: 15
train loss is 0.051488
average val loss: 0.047356, accuracy: 0.0474
average test loss: 0.046600, accuracy: 0.0464
case acc: 0.009903169
case acc: 0.07160697
case acc: 0.065578744
case acc: 0.03890464
case acc: 0.038333446
case acc: 0.05427339
top acc: 0.0176 ::: bot acc: 0.0038
top acc: 0.0837 ::: bot acc: 0.0597
top acc: 0.0821 ::: bot acc: 0.0492
top acc: 0.0294 ::: bot acc: 0.0492
top acc: 0.0504 ::: bot acc: 0.0265
top acc: 0.0655 ::: bot acc: 0.0428
current epoch: 16
train loss is 0.049351
average val loss: 0.047529, accuracy: 0.0475
average test loss: 0.046731, accuracy: 0.0466
case acc: 0.011844119
case acc: 0.06700035
case acc: 0.070207626
case acc: 0.027186941
case acc: 0.045405347
case acc: 0.058069065
top acc: 0.0203 ::: bot acc: 0.0043
top acc: 0.0791 ::: bot acc: 0.0550
top acc: 0.0868 ::: bot acc: 0.0538
top acc: 0.0182 ::: bot acc: 0.0372
top acc: 0.0575 ::: bot acc: 0.0336
top acc: 0.0693 ::: bot acc: 0.0466
current epoch: 17
train loss is 0.044253
average val loss: 0.038740, accuracy: 0.0388
average test loss: 0.038174, accuracy: 0.0380
case acc: 0.0070858197
case acc: 0.04599661
case acc: 0.05863647
case acc: 0.030267581
case acc: 0.039463494
case acc: 0.046280794
top acc: 0.0066 ::: bot acc: 0.0118
top acc: 0.0581 ::: bot acc: 0.0340
top acc: 0.0752 ::: bot acc: 0.0422
top acc: 0.0211 ::: bot acc: 0.0404
top acc: 0.0516 ::: bot acc: 0.0276
top acc: 0.0575 ::: bot acc: 0.0348
current epoch: 18
train loss is 0.040719
average val loss: 0.031501, accuracy: 0.0317
average test loss: 0.031100, accuracy: 0.0310
case acc: 0.017931905
case acc: 0.022976935
case acc: 0.0445001
case acc: 0.03522818
case acc: 0.032504585
case acc: 0.03299976
top acc: 0.0088 ::: bot acc: 0.0270
top acc: 0.0349 ::: bot acc: 0.0113
top acc: 0.0611 ::: bot acc: 0.0282
top acc: 0.0257 ::: bot acc: 0.0456
top acc: 0.0445 ::: bot acc: 0.0208
top acc: 0.0442 ::: bot acc: 0.0215
current epoch: 19
train loss is 0.037372
average val loss: 0.025884, accuracy: 0.0262
average test loss: 0.025841, accuracy: 0.0259
case acc: 0.033925507
case acc: 0.008899788
case acc: 0.02852129
case acc: 0.04277959
case acc: 0.02249728
case acc: 0.018619798
top acc: 0.0247 ::: bot acc: 0.0431
top acc: 0.0115 ::: bot acc: 0.0125
top acc: 0.0446 ::: bot acc: 0.0133
top acc: 0.0332 ::: bot acc: 0.0531
top acc: 0.0340 ::: bot acc: 0.0116
top acc: 0.0294 ::: bot acc: 0.0080
current epoch: 20
train loss is 0.036543
average val loss: 0.025553, accuracy: 0.0260
average test loss: 0.026017, accuracy: 0.0262
case acc: 0.048218444
case acc: 0.021710144
case acc: 0.01587098
case acc: 0.05170034
case acc: 0.010291741
case acc: 0.009133472
top acc: 0.0389 ::: bot acc: 0.0574
top acc: 0.0104 ::: bot acc: 0.0333
top acc: 0.0287 ::: bot acc: 0.0071
top acc: 0.0421 ::: bot acc: 0.0621
top acc: 0.0182 ::: bot acc: 0.0066
top acc: 0.0154 ::: bot acc: 0.0075
current epoch: 21
train loss is 0.037704
average val loss: 0.028369, accuracy: 0.0291
average test loss: 0.029293, accuracy: 0.0296
case acc: 0.054900702
case acc: 0.032351673
case acc: 0.012120112
case acc: 0.05715696
case acc: 0.012012809
case acc: 0.0088678
top acc: 0.0456 ::: bot acc: 0.0641
top acc: 0.0204 ::: bot acc: 0.0443
top acc: 0.0193 ::: bot acc: 0.0138
top acc: 0.0476 ::: bot acc: 0.0676
top acc: 0.0052 ::: bot acc: 0.0213
top acc: 0.0076 ::: bot acc: 0.0152
current epoch: 22
train loss is 0.037773
average val loss: 0.029877, accuracy: 0.0306
average test loss: 0.030887, accuracy: 0.0311
case acc: 0.053882007
case acc: 0.033040114
case acc: 0.012065904
case acc: 0.058301907
case acc: 0.020404974
case acc: 0.009189839
top acc: 0.0445 ::: bot acc: 0.0631
top acc: 0.0211 ::: bot acc: 0.0450
top acc: 0.0168 ::: bot acc: 0.0164
top acc: 0.0487 ::: bot acc: 0.0687
top acc: 0.0092 ::: bot acc: 0.0319
top acc: 0.0065 ::: bot acc: 0.0163
current epoch: 23
train loss is 0.036641
average val loss: 0.029471, accuracy: 0.0302
average test loss: 0.030448, accuracy: 0.0307
case acc: 0.049991325
case acc: 0.029615078
case acc: 0.01205706
case acc: 0.057290353
case acc: 0.026488237
case acc: 0.008764091
top acc: 0.0406 ::: bot acc: 0.0593
top acc: 0.0178 ::: bot acc: 0.0415
top acc: 0.0169 ::: bot acc: 0.0162
top acc: 0.0478 ::: bot acc: 0.0676
top acc: 0.0146 ::: bot acc: 0.0383
top acc: 0.0079 ::: bot acc: 0.0148
current epoch: 24
train loss is 0.035807
average val loss: 0.028091, accuracy: 0.0288
average test loss: 0.029037, accuracy: 0.0293
case acc: 0.045304276
case acc: 0.023123242
case acc: 0.012038197
case acc: 0.055327274
case acc: 0.031278033
case acc: 0.008493673
top acc: 0.0358 ::: bot acc: 0.0546
top acc: 0.0117 ::: bot acc: 0.0348
top acc: 0.0178 ::: bot acc: 0.0154
top acc: 0.0458 ::: bot acc: 0.0657
top acc: 0.0192 ::: bot acc: 0.0432
top acc: 0.0094 ::: bot acc: 0.0133
current epoch: 25
train loss is 0.035430
average val loss: 0.024443, accuracy: 0.0252
average test loss: 0.025209, accuracy: 0.0253
case acc: 0.036546014
case acc: 0.01028075
case acc: 0.01283705
case acc: 0.050243836
case acc: 0.033657953
case acc: 0.00845915
top acc: 0.0271 ::: bot acc: 0.0459
top acc: 0.0052 ::: bot acc: 0.0188
top acc: 0.0224 ::: bot acc: 0.0109
top acc: 0.0407 ::: bot acc: 0.0606
top acc: 0.0216 ::: bot acc: 0.0456
top acc: 0.0127 ::: bot acc: 0.0100
current epoch: 26
train loss is 0.035568
average val loss: 0.023451, accuracy: 0.0236
average test loss: 0.023475, accuracy: 0.0231
case acc: 0.011958442
case acc: 0.028998138
case acc: 0.027637405
case acc: 0.028657347
case acc: 0.0210547
case acc: 0.020323815
top acc: 0.0043 ::: bot acc: 0.0204
top acc: 0.0409 ::: bot acc: 0.0171
top acc: 0.0439 ::: bot acc: 0.0124
top acc: 0.0196 ::: bot acc: 0.0387
top acc: 0.0097 ::: bot acc: 0.0327
top acc: 0.0313 ::: bot acc: 0.0094
current epoch: 27
train loss is 0.036496
average val loss: 0.048058, accuracy: 0.0480
average test loss: 0.046944, accuracy: 0.0469
case acc: 0.034602113
case acc: 0.08228344
case acc: 0.07071135
case acc: 0.017504558
case acc: 0.016358199
case acc: 0.06000747
top acc: 0.0441 ::: bot acc: 0.0252
top acc: 0.0942 ::: bot acc: 0.0703
top acc: 0.0876 ::: bot acc: 0.0542
top acc: 0.0262 ::: bot acc: 0.0088
top acc: 0.0272 ::: bot acc: 0.0069
top acc: 0.0713 ::: bot acc: 0.0485
current epoch: 28
train loss is 0.046207
average val loss: 0.100130, accuracy: 0.1001
average test loss: 0.098912, accuracy: 0.0989
case acc: 0.085026056
case acc: 0.13565361
case acc: 0.12305606
case acc: 0.07364717
case acc: 0.067295074
case acc: 0.10879647
top acc: 0.0946 ::: bot acc: 0.0756
top acc: 0.1476 ::: bot acc: 0.1237
top acc: 0.1399 ::: bot acc: 0.1066
top acc: 0.0831 ::: bot acc: 0.0633
top acc: 0.0794 ::: bot acc: 0.0553
top acc: 0.1201 ::: bot acc: 0.0973
current epoch: 29
train loss is 0.065249
average val loss: 0.059405, accuracy: 0.0594
average test loss: 0.058160, accuracy: 0.0581
case acc: 0.036598288
case acc: 0.077607505
case acc: 0.0812916
case acc: 0.043455236
case acc: 0.04286154
case acc: 0.06706272
top acc: 0.0462 ::: bot acc: 0.0271
top acc: 0.0896 ::: bot acc: 0.0656
top acc: 0.0981 ::: bot acc: 0.0648
top acc: 0.0530 ::: bot acc: 0.0330
top acc: 0.0549 ::: bot acc: 0.0308
top acc: 0.0784 ::: bot acc: 0.0556
current epoch: 30
train loss is 0.039271
average val loss: 0.045576, accuracy: 0.0455
average test loss: 0.044428, accuracy: 0.0442
case acc: 0.01238577
case acc: 0.03767722
case acc: 0.06309879
case acc: 0.042372312
case acc: 0.05645158
case acc: 0.05334157
top acc: 0.0213 ::: bot acc: 0.0044
top acc: 0.0497 ::: bot acc: 0.0257
top acc: 0.0799 ::: bot acc: 0.0466
top acc: 0.0519 ::: bot acc: 0.0320
top acc: 0.0686 ::: bot acc: 0.0444
top acc: 0.0647 ::: bot acc: 0.0419
current epoch: 31
train loss is 0.024291
average val loss: 0.028404, accuracy: 0.0286
average test loss: 0.028058, accuracy: 0.0278
case acc: 0.026849285
case acc: 0.015055726
case acc: 0.029254047
case acc: 0.023294445
case acc: 0.048836015
case acc: 0.02375766
top acc: 0.0173 ::: bot acc: 0.0363
top acc: 0.0056 ::: bot acc: 0.0258
top acc: 0.0456 ::: bot acc: 0.0138
top acc: 0.0325 ::: bot acc: 0.0135
top acc: 0.0609 ::: bot acc: 0.0368
top acc: 0.0350 ::: bot acc: 0.0126
current epoch: 32
train loss is 0.042386
average val loss: 0.057863, accuracy: 0.0578
average test loss: 0.059071, accuracy: 0.0591
case acc: 0.101858646
case acc: 0.100670524
case acc: 0.046109688
case acc: 0.045764953
case acc: 0.014149329
case acc: 0.046149105
top acc: 0.0923 ::: bot acc: 0.1113
top acc: 0.0887 ::: bot acc: 0.1126
top acc: 0.0295 ::: bot acc: 0.0625
top acc: 0.0363 ::: bot acc: 0.0561
top acc: 0.0053 ::: bot acc: 0.0246
top acc: 0.0348 ::: bot acc: 0.0576
current epoch: 33
train loss is 0.083648
average val loss: 0.055299, accuracy: 0.0553
average test loss: 0.056519, accuracy: 0.0565
case acc: 0.09460885
case acc: 0.08973762
case acc: 0.04425239
case acc: 0.05009516
case acc: 0.018315578
case acc: 0.04220482
top acc: 0.0850 ::: bot acc: 0.1040
top acc: 0.0778 ::: bot acc: 0.1017
top acc: 0.0277 ::: bot acc: 0.0606
top acc: 0.0406 ::: bot acc: 0.0604
top acc: 0.0077 ::: bot acc: 0.0296
top acc: 0.0309 ::: bot acc: 0.0536
current epoch: 34
train loss is 0.057151
average val loss: 0.027887, accuracy: 0.0283
average test loss: 0.029114, accuracy: 0.0294
case acc: 0.056326594
case acc: 0.03571942
case acc: 0.016130181
case acc: 0.034220587
case acc: 0.0171453
case acc: 0.016814938
top acc: 0.0467 ::: bot acc: 0.0658
top acc: 0.0238 ::: bot acc: 0.0477
top acc: 0.0069 ::: bot acc: 0.0288
top acc: 0.0249 ::: bot acc: 0.0446
top acc: 0.0070 ::: bot acc: 0.0282
top acc: 0.0069 ::: bot acc: 0.0276
current epoch: 35
train loss is 0.031300
average val loss: 0.016318, accuracy: 0.0169
average test loss: 0.016881, accuracy: 0.0170
case acc: 0.02886049
case acc: 0.009745607
case acc: 0.01424386
case acc: 0.024257919
case acc: 0.016677747
case acc: 0.00848904
top acc: 0.0192 ::: bot acc: 0.0383
top acc: 0.0171 ::: bot acc: 0.0068
top acc: 0.0258 ::: bot acc: 0.0082
top acc: 0.0155 ::: bot acc: 0.0343
top acc: 0.0067 ::: bot acc: 0.0277
top acc: 0.0131 ::: bot acc: 0.0098
current epoch: 36
train loss is 0.029720
average val loss: 0.024435, accuracy: 0.0242
average test loss: 0.023622, accuracy: 0.0233
case acc: 0.007081501
case acc: 0.031880602
case acc: 0.03769343
case acc: 0.010631762
case acc: 0.01956326
case acc: 0.0326535
top acc: 0.0108 ::: bot acc: 0.0083
top acc: 0.0438 ::: bot acc: 0.0199
top acc: 0.0543 ::: bot acc: 0.0217
top acc: 0.0177 ::: bot acc: 0.0051
top acc: 0.0309 ::: bot acc: 0.0090
top acc: 0.0440 ::: bot acc: 0.0211
current epoch: 37
train loss is 0.023424
average val loss: 0.015066, accuracy: 0.0150
average test loss: 0.014906, accuracy: 0.0146
case acc: 0.01769678
case acc: 0.0104608955
case acc: 0.021469172
case acc: 0.007179898
case acc: 0.0136349145
case acc: 0.016901953
top acc: 0.0083 ::: bot acc: 0.0271
top acc: 0.0193 ::: bot acc: 0.0048
top acc: 0.0369 ::: bot acc: 0.0077
top acc: 0.0082 ::: bot acc: 0.0117
top acc: 0.0236 ::: bot acc: 0.0059
top acc: 0.0277 ::: bot acc: 0.0065
current epoch: 38
train loss is 0.021520
average val loss: 0.013585, accuracy: 0.0137
average test loss: 0.013660, accuracy: 0.0136
case acc: 0.023391098
case acc: 0.008875945
case acc: 0.017095359
case acc: 0.007242443
case acc: 0.012610769
case acc: 0.012290709
top acc: 0.0138 ::: bot acc: 0.0329
top acc: 0.0121 ::: bot acc: 0.0118
top acc: 0.0308 ::: bot acc: 0.0068
top acc: 0.0074 ::: bot acc: 0.0125
top acc: 0.0221 ::: bot acc: 0.0059
top acc: 0.0217 ::: bot acc: 0.0047
current epoch: 39
train loss is 0.023048
average val loss: 0.016312, accuracy: 0.0165
average test loss: 0.016164, accuracy: 0.0161
case acc: 0.021236544
case acc: 0.009189468
case acc: 0.018324329
case acc: 0.009630162
case acc: 0.022320101
case acc: 0.01560468
top acc: 0.0116 ::: bot acc: 0.0307
top acc: 0.0089 ::: bot acc: 0.0151
top acc: 0.0328 ::: bot acc: 0.0067
top acc: 0.0160 ::: bot acc: 0.0054
top acc: 0.0339 ::: bot acc: 0.0112
top acc: 0.0262 ::: bot acc: 0.0056
current epoch: 40
train loss is 0.024782
average val loss: 0.020692, accuracy: 0.0210
average test loss: 0.020526, accuracy: 0.0205
case acc: 0.024712423
case acc: 0.01700397
case acc: 0.016310766
case acc: 0.013102792
case acc: 0.034826066
case acc: 0.017127024
top acc: 0.0151 ::: bot acc: 0.0342
top acc: 0.0069 ::: bot acc: 0.0280
top acc: 0.0297 ::: bot acc: 0.0069
top acc: 0.0209 ::: bot acc: 0.0060
top acc: 0.0469 ::: bot acc: 0.0229
top acc: 0.0280 ::: bot acc: 0.0067
current epoch: 41
train loss is 0.037139
average val loss: 0.050517, accuracy: 0.0504
average test loss: 0.051723, accuracy: 0.0518
case acc: 0.084409125
case acc: 0.08934484
case acc: 0.046428148
case acc: 0.042444184
case acc: 0.012030357
case acc: 0.036081154
top acc: 0.0748 ::: bot acc: 0.0939
top acc: 0.0774 ::: bot acc: 0.1013
top acc: 0.0297 ::: bot acc: 0.0629
top acc: 0.0330 ::: bot acc: 0.0528
top acc: 0.0051 ::: bot acc: 0.0215
top acc: 0.0247 ::: bot acc: 0.0475
current epoch: 42
train loss is 0.072812
average val loss: 0.058252, accuracy: 0.0582
average test loss: 0.059480, accuracy: 0.0595
case acc: 0.088448696
case acc: 0.09185998
case acc: 0.054446775
case acc: 0.05656376
case acc: 0.023551779
case acc: 0.04183966
top acc: 0.0788 ::: bot acc: 0.0980
top acc: 0.0799 ::: bot acc: 0.1038
top acc: 0.0375 ::: bot acc: 0.0710
top acc: 0.0471 ::: bot acc: 0.0669
top acc: 0.0119 ::: bot acc: 0.0354
top acc: 0.0305 ::: bot acc: 0.0533
current epoch: 43
train loss is 0.058562
average val loss: 0.028874, accuracy: 0.0290
average test loss: 0.030106, accuracy: 0.0302
case acc: 0.048582364
case acc: 0.037117016
case acc: 0.021863965
case acc: 0.03824467
case acc: 0.020596065
case acc: 0.0146508785
top acc: 0.0390 ::: bot acc: 0.0581
top acc: 0.0252 ::: bot acc: 0.0490
top acc: 0.0083 ::: bot acc: 0.0368
top acc: 0.0287 ::: bot acc: 0.0486
top acc: 0.0094 ::: bot acc: 0.0323
top acc: 0.0053 ::: bot acc: 0.0251
current epoch: 44
train loss is 0.032116
average val loss: 0.024215, accuracy: 0.0247
average test loss: 0.025348, accuracy: 0.0257
case acc: 0.032789044
case acc: 0.0092411395
case acc: 0.014918433
case acc: 0.042926323
case acc: 0.041752238
case acc: 0.012680251
top acc: 0.0231 ::: bot acc: 0.0423
top acc: 0.0085 ::: bot acc: 0.0154
top acc: 0.0078 ::: bot acc: 0.0266
top acc: 0.0334 ::: bot acc: 0.0533
top acc: 0.0297 ::: bot acc: 0.0538
top acc: 0.0045 ::: bot acc: 0.0226
current epoch: 45
train loss is 0.029720
average val loss: 0.036300, accuracy: 0.0362
average test loss: 0.035410, accuracy: 0.0352
case acc: 0.02903155
case acc: 0.068304844
case acc: 0.048699435
case acc: 0.012736637
case acc: 0.008782422
case acc: 0.04357772
top acc: 0.0387 ::: bot acc: 0.0196
top acc: 0.0802 ::: bot acc: 0.0564
top acc: 0.0655 ::: bot acc: 0.0322
top acc: 0.0205 ::: bot acc: 0.0058
top acc: 0.0141 ::: bot acc: 0.0100
top acc: 0.0549 ::: bot acc: 0.0321
current epoch: 46
train loss is 0.045078
average val loss: 0.079084, accuracy: 0.0791
average test loss: 0.077846, accuracy: 0.0778
case acc: 0.06982299
case acc: 0.11053817
case acc: 0.09149234
case acc: 0.059549574
case acc: 0.05128458
case acc: 0.08438973
top acc: 0.0794 ::: bot acc: 0.0603
top acc: 0.1225 ::: bot acc: 0.0986
top acc: 0.1083 ::: bot acc: 0.0750
top acc: 0.0691 ::: bot acc: 0.0491
top acc: 0.0633 ::: bot acc: 0.0393
top acc: 0.0958 ::: bot acc: 0.0729
current epoch: 47
train loss is 0.053658
average val loss: 0.032372, accuracy: 0.0323
average test loss: 0.031206, accuracy: 0.0310
case acc: 0.013936964
case acc: 0.04173435
case acc: 0.041324362
case acc: 0.024376215
case acc: 0.028170643
case acc: 0.036720518
top acc: 0.0230 ::: bot acc: 0.0055
top acc: 0.0537 ::: bot acc: 0.0298
top acc: 0.0581 ::: bot acc: 0.0250
top acc: 0.0337 ::: bot acc: 0.0144
top acc: 0.0400 ::: bot acc: 0.0164
top acc: 0.0481 ::: bot acc: 0.0252
current epoch: 48
train loss is 0.024969
average val loss: 0.020792, accuracy: 0.0210
average test loss: 0.020373, accuracy: 0.0202
case acc: 0.014117786
case acc: 0.008851406
case acc: 0.021160768
case acc: 0.01976139
case acc: 0.036699157
case acc: 0.020860543
top acc: 0.0054 ::: bot acc: 0.0232
top acc: 0.0113 ::: bot acc: 0.0126
top acc: 0.0366 ::: bot acc: 0.0076
top acc: 0.0288 ::: bot acc: 0.0104
top acc: 0.0487 ::: bot acc: 0.0246
top acc: 0.0320 ::: bot acc: 0.0099
current epoch: 49
train loss is 0.025063
average val loss: 0.025838, accuracy: 0.0258
average test loss: 0.026676, accuracy: 0.0269
case acc: 0.051577576
case acc: 0.049131904
case acc: 0.01874577
case acc: 0.009908229
case acc: 0.019582756
case acc: 0.012627996
top acc: 0.0419 ::: bot acc: 0.0611
top acc: 0.0372 ::: bot acc: 0.0611
top acc: 0.0069 ::: bot acc: 0.0328
top acc: 0.0043 ::: bot acc: 0.0183
top acc: 0.0309 ::: bot acc: 0.0090
top acc: 0.0045 ::: bot acc: 0.0225
current epoch: 50
train loss is 0.053607
average val loss: 0.073760, accuracy: 0.0737
average test loss: 0.074992, accuracy: 0.0750
case acc: 0.10495375
case acc: 0.110980526
case acc: 0.07062292
case acc: 0.06460205
case acc: 0.037149873
case acc: 0.06160867
top acc: 0.0953 ::: bot acc: 0.1145
top acc: 0.0990 ::: bot acc: 0.1229
top acc: 0.0537 ::: bot acc: 0.0872
top acc: 0.0551 ::: bot acc: 0.0750
top acc: 0.0251 ::: bot acc: 0.0492
top acc: 0.0502 ::: bot acc: 0.0731
LME_Co_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6810 6810 6810
1.8562728 -0.6288155 0.08104724 -0.1112376
Validation: 762 762 762
Testing: 744 744 744
pre-processing time: 0.00038695335388183594
the split date is 2010-01-01
net initializing with time: 0.002977132797241211
preparing training and testing date with time: 2.384185791015625e-07
current epoch: 1
train loss is 0.186677
average val loss: 0.047312, accuracy: 0.0470
average test loss: 0.047085, accuracy: 0.0470
case acc: 0.015460459
case acc: 0.026191762
case acc: 0.053183176
case acc: 0.014659184
case acc: 0.045605764
case acc: 0.12679973
top acc: 0.0122 ::: bot acc: 0.0244
top acc: 0.0401 ::: bot acc: 0.0150
top acc: 0.0758 ::: bot acc: 0.0321
top acc: 0.0247 ::: bot acc: 0.0119
top acc: 0.0609 ::: bot acc: 0.0315
top acc: 0.1453 ::: bot acc: 0.1083
current epoch: 2
train loss is 0.073040
average val loss: 0.069266, accuracy: 0.0691
average test loss: 0.069948, accuracy: 0.0702
case acc: 0.11416012
case acc: 0.07930239
case acc: 0.054648906
case acc: 0.09511296
case acc: 0.061692677
case acc: 0.016515534
top acc: 0.0995 ::: bot acc: 0.1294
top acc: 0.0655 ::: bot acc: 0.0908
top acc: 0.0326 ::: bot acc: 0.0755
top acc: 0.0786 ::: bot acc: 0.1112
top acc: 0.0466 ::: bot acc: 0.0754
top acc: 0.0298 ::: bot acc: 0.0078
current epoch: 3
train loss is 0.066096
average val loss: 0.135524, accuracy: 0.1355
average test loss: 0.136278, accuracy: 0.1363
case acc: 0.1803905
case acc: 0.14695054
case acc: 0.12725574
case acc: 0.16380292
case acc: 0.13127872
case acc: 0.067982264
top acc: 0.1660 ::: bot acc: 0.1954
top acc: 0.1332 ::: bot acc: 0.1587
top acc: 0.1056 ::: bot acc: 0.1480
top acc: 0.1478 ::: bot acc: 0.1797
top acc: 0.1164 ::: bot acc: 0.1448
top acc: 0.0506 ::: bot acc: 0.0853
current epoch: 4
train loss is 0.082180
average val loss: 0.144739, accuracy: 0.1447
average test loss: 0.145373, accuracy: 0.1454
case acc: 0.18415299
case acc: 0.1525907
case acc: 0.13784096
case acc: 0.1743503
case acc: 0.13867983
case acc: 0.08462502
top acc: 0.1699 ::: bot acc: 0.1990
top acc: 0.1389 ::: bot acc: 0.1645
top acc: 0.1165 ::: bot acc: 0.1585
top acc: 0.1585 ::: bot acc: 0.1902
top acc: 0.1240 ::: bot acc: 0.1520
top acc: 0.0675 ::: bot acc: 0.1016
current epoch: 5
train loss is 0.090982
average val loss: 0.120296, accuracy: 0.1203
average test loss: 0.120869, accuracy: 0.1209
case acc: 0.15452436
case acc: 0.1247914
case acc: 0.114167504
case acc: 0.15259276
case acc: 0.11248938
case acc: 0.06664503
top acc: 0.1403 ::: bot acc: 0.1693
top acc: 0.1111 ::: bot acc: 0.1367
top acc: 0.0929 ::: bot acc: 0.1348
top acc: 0.1368 ::: bot acc: 0.1684
top acc: 0.0980 ::: bot acc: 0.1258
top acc: 0.0496 ::: bot acc: 0.0835
current epoch: 6
train loss is 0.099460
average val loss: 0.048580, accuracy: 0.0485
average test loss: 0.049441, accuracy: 0.0497
case acc: 0.07619375
case acc: 0.04844385
case acc: 0.04159837
case acc: 0.080773555
case acc: 0.03820009
case acc: 0.0128269885
top acc: 0.0619 ::: bot acc: 0.0910
top acc: 0.0348 ::: bot acc: 0.0603
top acc: 0.0202 ::: bot acc: 0.0623
top acc: 0.0648 ::: bot acc: 0.0967
top acc: 0.0237 ::: bot acc: 0.0516
top acc: 0.0152 ::: bot acc: 0.0188
current epoch: 7
train loss is 0.061838
average val loss: 0.070955, accuracy: 0.0709
average test loss: 0.071503, accuracy: 0.0715
case acc: 0.094453335
case acc: 0.06849355
case acc: 0.06610661
case acc: 0.103910685
case acc: 0.06039092
case acc: 0.035643127
top acc: 0.0801 ::: bot acc: 0.1093
top acc: 0.0548 ::: bot acc: 0.0803
top acc: 0.0447 ::: bot acc: 0.0869
top acc: 0.0878 ::: bot acc: 0.1198
top acc: 0.0460 ::: bot acc: 0.0737
top acc: 0.0190 ::: bot acc: 0.0524
current epoch: 8
train loss is 0.059631
average val loss: 0.077883, accuracy: 0.0779
average test loss: 0.078366, accuracy: 0.0784
case acc: 0.09634885
case acc: 0.07221636
case acc: 0.07400643
case acc: 0.110444464
case acc: 0.06586619
case acc: 0.05125758
top acc: 0.0820 ::: bot acc: 0.1111
top acc: 0.0586 ::: bot acc: 0.0840
top acc: 0.0526 ::: bot acc: 0.0949
top acc: 0.0944 ::: bot acc: 0.1264
top acc: 0.0515 ::: bot acc: 0.0791
top acc: 0.0342 ::: bot acc: 0.0682
current epoch: 9
train loss is 0.051906
average val loss: 0.086120, accuracy: 0.0861
average test loss: 0.086527, accuracy: 0.0865
case acc: 0.10005542
case acc: 0.077434495
case acc: 0.08311002
case acc: 0.119461365
case acc: 0.072496906
case acc: 0.06659994
top acc: 0.0858 ::: bot acc: 0.1148
top acc: 0.0638 ::: bot acc: 0.0893
top acc: 0.0619 ::: bot acc: 0.1039
top acc: 0.1036 ::: bot acc: 0.1354
top acc: 0.0581 ::: bot acc: 0.0857
top acc: 0.0497 ::: bot acc: 0.0834
current epoch: 10
train loss is 0.046571
average val loss: 0.080162, accuracy: 0.0802
average test loss: 0.080497, accuracy: 0.0805
case acc: 0.09035672
case acc: 0.06917789
case acc: 0.0778895
case acc: 0.11479081
case acc: 0.065195985
case acc: 0.065553315
top acc: 0.0762 ::: bot acc: 0.1049
top acc: 0.0556 ::: bot acc: 0.0810
top acc: 0.0568 ::: bot acc: 0.0986
top acc: 0.0990 ::: bot acc: 0.1307
top acc: 0.0509 ::: bot acc: 0.0783
top acc: 0.0488 ::: bot acc: 0.0822
current epoch: 11
train loss is 0.040208
average val loss: 0.070176, accuracy: 0.0702
average test loss: 0.070470, accuracy: 0.0705
case acc: 0.077615574
case acc: 0.05804558
case acc: 0.06870319
case acc: 0.10530926
case acc: 0.05454393
case acc: 0.058510616
top acc: 0.0635 ::: bot acc: 0.0922
top acc: 0.0445 ::: bot acc: 0.0700
top acc: 0.0478 ::: bot acc: 0.0893
top acc: 0.0895 ::: bot acc: 0.1213
top acc: 0.0403 ::: bot acc: 0.0677
top acc: 0.0418 ::: bot acc: 0.0750
current epoch: 12
train loss is 0.034779
average val loss: 0.060093, accuracy: 0.0601
average test loss: 0.060360, accuracy: 0.0603
case acc: 0.06632144
case acc: 0.0485887
case acc: 0.05947166
case acc: 0.09288402
case acc: 0.045294788
case acc: 0.049395278
top acc: 0.0522 ::: bot acc: 0.0808
top acc: 0.0351 ::: bot acc: 0.0606
top acc: 0.0387 ::: bot acc: 0.0800
top acc: 0.0772 ::: bot acc: 0.1088
top acc: 0.0312 ::: bot acc: 0.0584
top acc: 0.0328 ::: bot acc: 0.0659
current epoch: 13
train loss is 0.031366
average val loss: 0.054695, accuracy: 0.0547
average test loss: 0.054933, accuracy: 0.0549
case acc: 0.060276743
case acc: 0.044476915
case acc: 0.055110294
case acc: 0.08310494
case acc: 0.04137834
case acc: 0.04494996
top acc: 0.0462 ::: bot acc: 0.0748
top acc: 0.0310 ::: bot acc: 0.0565
top acc: 0.0343 ::: bot acc: 0.0757
top acc: 0.0674 ::: bot acc: 0.0991
top acc: 0.0273 ::: bot acc: 0.0545
top acc: 0.0283 ::: bot acc: 0.0614
current epoch: 14
train loss is 0.028917
average val loss: 0.046045, accuracy: 0.0460
average test loss: 0.046335, accuracy: 0.0462
case acc: 0.051300734
case acc: 0.03742817
case acc: 0.04748497
case acc: 0.069431685
case acc: 0.034448236
case acc: 0.037332736
top acc: 0.0371 ::: bot acc: 0.0659
top acc: 0.0240 ::: bot acc: 0.0495
top acc: 0.0267 ::: bot acc: 0.0681
top acc: 0.0536 ::: bot acc: 0.0854
top acc: 0.0204 ::: bot acc: 0.0476
top acc: 0.0209 ::: bot acc: 0.0537
current epoch: 15
train loss is 0.026466
average val loss: 0.039647, accuracy: 0.0396
average test loss: 0.040033, accuracy: 0.0399
case acc: 0.04506304
case acc: 0.032912772
case acc: 0.04194073
case acc: 0.057996728
case acc: 0.030015264
case acc: 0.03144505
top acc: 0.0309 ::: bot acc: 0.0597
top acc: 0.0195 ::: bot acc: 0.0449
top acc: 0.0211 ::: bot acc: 0.0625
top acc: 0.0425 ::: bot acc: 0.0738
top acc: 0.0160 ::: bot acc: 0.0431
top acc: 0.0154 ::: bot acc: 0.0476
current epoch: 16
train loss is 0.024686
average val loss: 0.037160, accuracy: 0.0371
average test loss: 0.037545, accuracy: 0.0374
case acc: 0.04281458
case acc: 0.032162584
case acc: 0.04008291
case acc: 0.050652932
case acc: 0.029380957
case acc: 0.029431285
top acc: 0.0287 ::: bot acc: 0.0575
top acc: 0.0188 ::: bot acc: 0.0441
top acc: 0.0194 ::: bot acc: 0.0606
top acc: 0.0354 ::: bot acc: 0.0664
top acc: 0.0153 ::: bot acc: 0.0425
top acc: 0.0137 ::: bot acc: 0.0455
current epoch: 17
train loss is 0.022919
average val loss: 0.030443, accuracy: 0.0304
average test loss: 0.030995, accuracy: 0.0309
case acc: 0.03622694
case acc: 0.02701451
case acc: 0.034225464
case acc: 0.03993493
case acc: 0.024310017
case acc: 0.023582397
top acc: 0.0221 ::: bot acc: 0.0508
top acc: 0.0140 ::: bot acc: 0.0388
top acc: 0.0145 ::: bot acc: 0.0544
top acc: 0.0255 ::: bot acc: 0.0552
top acc: 0.0105 ::: bot acc: 0.0373
top acc: 0.0089 ::: bot acc: 0.0391
current epoch: 18
train loss is 0.021726
average val loss: 0.028272, accuracy: 0.0282
average test loss: 0.028862, accuracy: 0.0288
case acc: 0.03415537
case acc: 0.026088508
case acc: 0.032560136
case acc: 0.034186307
case acc: 0.023503024
case acc: 0.022097914
top acc: 0.0202 ::: bot acc: 0.0487
top acc: 0.0132 ::: bot acc: 0.0378
top acc: 0.0131 ::: bot acc: 0.0526
top acc: 0.0203 ::: bot acc: 0.0492
top acc: 0.0098 ::: bot acc: 0.0365
top acc: 0.0078 ::: bot acc: 0.0374
current epoch: 19
train loss is 0.020586
average val loss: 0.022587, accuracy: 0.0226
average test loss: 0.023492, accuracy: 0.0234
case acc: 0.028336337
case acc: 0.021508792
case acc: 0.027726358
case acc: 0.025703508
case acc: 0.018983848
case acc: 0.018397173
top acc: 0.0151 ::: bot acc: 0.0425
top acc: 0.0099 ::: bot acc: 0.0326
top acc: 0.0095 ::: bot acc: 0.0472
top acc: 0.0130 ::: bot acc: 0.0402
top acc: 0.0063 ::: bot acc: 0.0314
top acc: 0.0063 ::: bot acc: 0.0326
current epoch: 20
train loss is 0.019502
average val loss: 0.019269, accuracy: 0.0192
average test loss: 0.020499, accuracy: 0.0204
case acc: 0.02467478
case acc: 0.018861402
case acc: 0.0250576
case acc: 0.020543326
case acc: 0.016511276
case acc: 0.016780114
top acc: 0.0121 ::: bot acc: 0.0386
top acc: 0.0083 ::: bot acc: 0.0294
top acc: 0.0078 ::: bot acc: 0.0441
top acc: 0.0093 ::: bot acc: 0.0343
top acc: 0.0050 ::: bot acc: 0.0284
top acc: 0.0063 ::: bot acc: 0.0302
current epoch: 21
train loss is 0.018656
average val loss: 0.015730, accuracy: 0.0157
average test loss: 0.017448, accuracy: 0.0174
case acc: 0.02077281
case acc: 0.015801197
case acc: 0.022190003
case acc: 0.016530236
case acc: 0.0139053725
case acc: 0.0149186505
top acc: 0.0092 ::: bot acc: 0.0342
top acc: 0.0070 ::: bot acc: 0.0255
top acc: 0.0069 ::: bot acc: 0.0403
top acc: 0.0076 ::: bot acc: 0.0291
top acc: 0.0050 ::: bot acc: 0.0246
top acc: 0.0073 ::: bot acc: 0.0269
current epoch: 22
train loss is 0.017949
average val loss: 0.015281, accuracy: 0.0152
average test loss: 0.017060, accuracy: 0.0170
case acc: 0.019831251
case acc: 0.015187838
case acc: 0.021956734
case acc: 0.016124135
case acc: 0.0135187255
case acc: 0.015122837
top acc: 0.0086 ::: bot acc: 0.0331
top acc: 0.0068 ::: bot acc: 0.0247
top acc: 0.0070 ::: bot acc: 0.0400
top acc: 0.0076 ::: bot acc: 0.0286
top acc: 0.0053 ::: bot acc: 0.0239
top acc: 0.0072 ::: bot acc: 0.0273
current epoch: 23
train loss is 0.017786
average val loss: 0.012360, accuracy: 0.0123
average test loss: 0.014630, accuracy: 0.0145
case acc: 0.016348341
case acc: 0.012397949
case acc: 0.019506391
case acc: 0.013785328
case acc: 0.0115828095
case acc: 0.013630939
top acc: 0.0071 ::: bot acc: 0.0286
top acc: 0.0069 ::: bot acc: 0.0205
top acc: 0.0078 ::: bot acc: 0.0359
top acc: 0.0080 ::: bot acc: 0.0249
top acc: 0.0077 ::: bot acc: 0.0198
top acc: 0.0097 ::: bot acc: 0.0238
current epoch: 24
train loss is 0.017391
average val loss: 0.014220, accuracy: 0.0142
average test loss: 0.016157, accuracy: 0.0161
case acc: 0.018735712
case acc: 0.014424113
case acc: 0.020543573
case acc: 0.016030213
case acc: 0.012971921
case acc: 0.014004263
top acc: 0.0080 ::: bot acc: 0.0317
top acc: 0.0067 ::: bot acc: 0.0237
top acc: 0.0073 ::: bot acc: 0.0378
top acc: 0.0076 ::: bot acc: 0.0285
top acc: 0.0058 ::: bot acc: 0.0228
top acc: 0.0088 ::: bot acc: 0.0248
current epoch: 25
train loss is 0.017339
average val loss: 0.018930, accuracy: 0.0189
average test loss: 0.020144, accuracy: 0.0201
case acc: 0.024162635
case acc: 0.019544907
case acc: 0.023740523
case acc: 0.020644464
case acc: 0.017169243
case acc: 0.015579557
top acc: 0.0114 ::: bot acc: 0.0381
top acc: 0.0089 ::: bot acc: 0.0303
top acc: 0.0075 ::: bot acc: 0.0425
top acc: 0.0093 ::: bot acc: 0.0346
top acc: 0.0054 ::: bot acc: 0.0293
top acc: 0.0067 ::: bot acc: 0.0282
current epoch: 26
train loss is 0.018184
average val loss: 0.028272, accuracy: 0.0283
average test loss: 0.028780, accuracy: 0.0288
case acc: 0.034417946
case acc: 0.02989682
case acc: 0.03146264
case acc: 0.02802443
case acc: 0.0276684
case acc: 0.021102471
top acc: 0.0201 ::: bot acc: 0.0491
top acc: 0.0167 ::: bot acc: 0.0419
top acc: 0.0122 ::: bot acc: 0.0517
top acc: 0.0148 ::: bot acc: 0.0428
top acc: 0.0137 ::: bot acc: 0.0409
top acc: 0.0073 ::: bot acc: 0.0362
current epoch: 27
train loss is 0.020579
average val loss: 0.031858, accuracy: 0.0319
average test loss: 0.032238, accuracy: 0.0323
case acc: 0.038045254
case acc: 0.034609027
case acc: 0.035209388
case acc: 0.027619362
case acc: 0.032678697
case acc: 0.025351696
top acc: 0.0237 ::: bot acc: 0.0528
top acc: 0.0213 ::: bot acc: 0.0466
top acc: 0.0153 ::: bot acc: 0.0558
top acc: 0.0145 ::: bot acc: 0.0424
top acc: 0.0187 ::: bot acc: 0.0459
top acc: 0.0103 ::: bot acc: 0.0410
current epoch: 28
train loss is 0.024444
average val loss: 0.011488, accuracy: 0.0117
average test loss: 0.013494, accuracy: 0.0135
case acc: 0.011398503
case acc: 0.010602635
case acc: 0.015157411
case acc: 0.018843375
case acc: 0.011862011
case acc: 0.013285101
top acc: 0.0192 ::: bot acc: 0.0098
top acc: 0.0207 ::: bot acc: 0.0051
top acc: 0.0226 ::: bot acc: 0.0191
top acc: 0.0320 ::: bot acc: 0.0083
top acc: 0.0226 ::: bot acc: 0.0052
top acc: 0.0237 ::: bot acc: 0.0098
current epoch: 29
train loss is 0.021699
average val loss: 0.025869, accuracy: 0.0260
average test loss: 0.026223, accuracy: 0.0263
case acc: 0.027008554
case acc: 0.029492741
case acc: 0.021059887
case acc: 0.030722177
case acc: 0.030292062
case acc: 0.019508531
top acc: 0.0408 ::: bot acc: 0.0134
top acc: 0.0428 ::: bot acc: 0.0175
top acc: 0.0387 ::: bot acc: 0.0064
top acc: 0.0461 ::: bot acc: 0.0155
top acc: 0.0443 ::: bot acc: 0.0171
top acc: 0.0351 ::: bot acc: 0.0054
current epoch: 30
train loss is 0.025737
average val loss: 0.009944, accuracy: 0.0099
average test loss: 0.012584, accuracy: 0.0124
case acc: 0.011654104
case acc: 0.0095818555
case acc: 0.017447228
case acc: 0.012269309
case acc: 0.009931124
case acc: 0.013632508
top acc: 0.0088 ::: bot acc: 0.0207
top acc: 0.0114 ::: bot acc: 0.0139
top acc: 0.0103 ::: bot acc: 0.0317
top acc: 0.0108 ::: bot acc: 0.0212
top acc: 0.0134 ::: bot acc: 0.0139
top acc: 0.0097 ::: bot acc: 0.0238
current epoch: 31
train loss is 0.018419
average val loss: 0.020979, accuracy: 0.0210
average test loss: 0.021961, accuracy: 0.0220
case acc: 0.026066365
case acc: 0.02199887
case acc: 0.024659183
case acc: 0.023230886
case acc: 0.019630942
case acc: 0.01630195
top acc: 0.0129 ::: bot acc: 0.0401
top acc: 0.0104 ::: bot acc: 0.0332
top acc: 0.0078 ::: bot acc: 0.0438
top acc: 0.0110 ::: bot acc: 0.0376
top acc: 0.0067 ::: bot acc: 0.0323
top acc: 0.0065 ::: bot acc: 0.0294
current epoch: 32
train loss is 0.020041
average val loss: 0.033936, accuracy: 0.0339
average test loss: 0.034261, accuracy: 0.0343
case acc: 0.040959187
case acc: 0.037502393
case acc: 0.035588313
case acc: 0.03265161
case acc: 0.035294395
case acc: 0.023915099
top acc: 0.0267 ::: bot acc: 0.0556
top acc: 0.0242 ::: bot acc: 0.0495
top acc: 0.0155 ::: bot acc: 0.0563
top acc: 0.0190 ::: bot acc: 0.0477
top acc: 0.0213 ::: bot acc: 0.0485
top acc: 0.0092 ::: bot acc: 0.0394
current epoch: 33
train loss is 0.025877
average val loss: 0.010248, accuracy: 0.0104
average test loss: 0.012504, accuracy: 0.0124
case acc: 0.010436913
case acc: 0.0093996655
case acc: 0.015186433
case acc: 0.014282228
case acc: 0.010634561
case acc: 0.014487292
top acc: 0.0155 ::: bot acc: 0.0135
top acc: 0.0171 ::: bot acc: 0.0082
top acc: 0.0226 ::: bot acc: 0.0192
top acc: 0.0252 ::: bot acc: 0.0083
top acc: 0.0196 ::: bot acc: 0.0077
top acc: 0.0270 ::: bot acc: 0.0067
current epoch: 34
train loss is 0.016418
average val loss: 0.009696, accuracy: 0.0099
average test loss: 0.012078, accuracy: 0.0121
case acc: 0.010840327
case acc: 0.009973537
case acc: 0.015016659
case acc: 0.01272539
case acc: 0.011320053
case acc: 0.012616662
top acc: 0.0175 ::: bot acc: 0.0115
top acc: 0.0194 ::: bot acc: 0.0059
top acc: 0.0201 ::: bot acc: 0.0218
top acc: 0.0219 ::: bot acc: 0.0101
top acc: 0.0215 ::: bot acc: 0.0059
top acc: 0.0206 ::: bot acc: 0.0129
current epoch: 35
train loss is 0.016607
average val loss: 0.012124, accuracy: 0.0122
average test loss: 0.013947, accuracy: 0.0142
case acc: 0.013289148
case acc: 0.014231648
case acc: 0.015625706
case acc: 0.013055625
case acc: 0.015637083
case acc: 0.013620135
top acc: 0.0236 ::: bot acc: 0.0067
top acc: 0.0262 ::: bot acc: 0.0050
top acc: 0.0250 ::: bot acc: 0.0169
top acc: 0.0228 ::: bot acc: 0.0094
top acc: 0.0284 ::: bot acc: 0.0051
top acc: 0.0247 ::: bot acc: 0.0088
current epoch: 36
train loss is 0.018916
average val loss: 0.010150, accuracy: 0.0103
average test loss: 0.012755, accuracy: 0.0129
case acc: 0.012291649
case acc: 0.009804734
case acc: 0.016768277
case acc: 0.015932927
case acc: 0.009983613
case acc: 0.012430242
top acc: 0.0081 ::: bot acc: 0.0220
top acc: 0.0105 ::: bot acc: 0.0148
top acc: 0.0120 ::: bot acc: 0.0299
top acc: 0.0076 ::: bot acc: 0.0283
top acc: 0.0132 ::: bot acc: 0.0141
top acc: 0.0150 ::: bot acc: 0.0185
current epoch: 37
train loss is 0.019507
average val loss: 0.036990, accuracy: 0.0370
average test loss: 0.037219, accuracy: 0.0372
case acc: 0.04245801
case acc: 0.03792474
case acc: 0.037826534
case acc: 0.04372693
case acc: 0.035360485
case acc: 0.02603551
top acc: 0.0282 ::: bot acc: 0.0571
top acc: 0.0246 ::: bot acc: 0.0499
top acc: 0.0174 ::: bot acc: 0.0587
top acc: 0.0289 ::: bot acc: 0.0593
top acc: 0.0213 ::: bot acc: 0.0486
top acc: 0.0108 ::: bot acc: 0.0418
current epoch: 38
train loss is 0.024085
average val loss: 0.018826, accuracy: 0.0188
average test loss: 0.020064, accuracy: 0.0202
case acc: 0.024284055
case acc: 0.021250604
case acc: 0.02192306
case acc: 0.02201951
case acc: 0.018509489
case acc: 0.013317127
top acc: 0.0115 ::: bot acc: 0.0382
top acc: 0.0099 ::: bot acc: 0.0322
top acc: 0.0069 ::: bot acc: 0.0401
top acc: 0.0102 ::: bot acc: 0.0361
top acc: 0.0060 ::: bot acc: 0.0310
top acc: 0.0106 ::: bot acc: 0.0229
current epoch: 39
train loss is 0.019650
average val loss: 0.008800, accuracy: 0.0089
average test loss: 0.011519, accuracy: 0.0115
case acc: 0.010305729
case acc: 0.009237316
case acc: 0.015554197
case acc: 0.011444598
case acc: 0.009951109
case acc: 0.012333108
top acc: 0.0121 ::: bot acc: 0.0169
top acc: 0.0135 ::: bot acc: 0.0117
top acc: 0.0159 ::: bot acc: 0.0259
top acc: 0.0152 ::: bot acc: 0.0168
top acc: 0.0160 ::: bot acc: 0.0113
top acc: 0.0183 ::: bot acc: 0.0152
current epoch: 40
train loss is 0.015881
average val loss: 0.015707, accuracy: 0.0159
average test loss: 0.016924, accuracy: 0.0173
case acc: 0.017353285
case acc: 0.01853499
case acc: 0.016845368
case acc: 0.016418906
case acc: 0.01983957
case acc: 0.01480289
top acc: 0.0299 ::: bot acc: 0.0063
top acc: 0.0314 ::: bot acc: 0.0075
top acc: 0.0293 ::: bot acc: 0.0126
top acc: 0.0287 ::: bot acc: 0.0077
top acc: 0.0335 ::: bot acc: 0.0075
top acc: 0.0277 ::: bot acc: 0.0063
current epoch: 41
train loss is 0.020179
average val loss: 0.009388, accuracy: 0.0095
average test loss: 0.012069, accuracy: 0.0120
case acc: 0.010380656
case acc: 0.009201346
case acc: 0.01633859
case acc: 0.013582763
case acc: 0.009998994
case acc: 0.012613874
top acc: 0.0117 ::: bot acc: 0.0173
top acc: 0.0141 ::: bot acc: 0.0112
top acc: 0.0133 ::: bot acc: 0.0287
top acc: 0.0082 ::: bot acc: 0.0245
top acc: 0.0165 ::: bot acc: 0.0108
top acc: 0.0136 ::: bot acc: 0.0200
current epoch: 42
train loss is 0.019513
average val loss: 0.028784, accuracy: 0.0288
average test loss: 0.029238, accuracy: 0.0292
case acc: 0.032395348
case acc: 0.028856764
case acc: 0.031191718
case acc: 0.03494386
case acc: 0.02641377
case acc: 0.021482615
top acc: 0.0184 ::: bot acc: 0.0469
top acc: 0.0158 ::: bot acc: 0.0407
top acc: 0.0118 ::: bot acc: 0.0516
top acc: 0.0210 ::: bot acc: 0.0501
top acc: 0.0124 ::: bot acc: 0.0396
top acc: 0.0075 ::: bot acc: 0.0367
current epoch: 43
train loss is 0.020700
average val loss: 0.021447, accuracy: 0.0214
average test loss: 0.022388, accuracy: 0.0225
case acc: 0.026135854
case acc: 0.023776473
case acc: 0.024593921
case acc: 0.023818575
case acc: 0.02113389
case acc: 0.015243316
top acc: 0.0130 ::: bot acc: 0.0402
top acc: 0.0116 ::: bot acc: 0.0352
top acc: 0.0077 ::: bot acc: 0.0438
top acc: 0.0114 ::: bot acc: 0.0382
top acc: 0.0078 ::: bot acc: 0.0340
top acc: 0.0071 ::: bot acc: 0.0276
current epoch: 44
train loss is 0.020135
average val loss: 0.009216, accuracy: 0.0094
average test loss: 0.011736, accuracy: 0.0117
case acc: 0.010514844
case acc: 0.00929824
case acc: 0.015048985
case acc: 0.012074914
case acc: 0.010473018
case acc: 0.012950144
top acc: 0.0160 ::: bot acc: 0.0130
top acc: 0.0165 ::: bot acc: 0.0087
top acc: 0.0197 ::: bot acc: 0.0222
top acc: 0.0198 ::: bot acc: 0.0122
top acc: 0.0191 ::: bot acc: 0.0082
top acc: 0.0223 ::: bot acc: 0.0112
current epoch: 45
train loss is 0.015705
average val loss: 0.014381, accuracy: 0.0146
average test loss: 0.015790, accuracy: 0.0162
case acc: 0.016141336
case acc: 0.01640501
case acc: 0.016420929
case acc: 0.015570518
case acc: 0.017883794
case acc: 0.014494612
top acc: 0.0282 ::: bot acc: 0.0060
top acc: 0.0289 ::: bot acc: 0.0061
top acc: 0.0279 ::: bot acc: 0.0141
top acc: 0.0274 ::: bot acc: 0.0078
top acc: 0.0312 ::: bot acc: 0.0063
top acc: 0.0270 ::: bot acc: 0.0068
current epoch: 46
train loss is 0.018392
average val loss: 0.009192, accuracy: 0.0093
average test loss: 0.011759, accuracy: 0.0118
case acc: 0.010729939
case acc: 0.009727086
case acc: 0.015166665
case acc: 0.011810111
case acc: 0.0111818025
case acc: 0.012406868
top acc: 0.0170 ::: bot acc: 0.0120
top acc: 0.0186 ::: bot acc: 0.0066
top acc: 0.0183 ::: bot acc: 0.0237
top acc: 0.0127 ::: bot acc: 0.0193
top acc: 0.0212 ::: bot acc: 0.0062
top acc: 0.0190 ::: bot acc: 0.0146
current epoch: 47
train loss is 0.018609
average val loss: 0.024009, accuracy: 0.0240
average test loss: 0.024727, accuracy: 0.0248
case acc: 0.027137604
case acc: 0.024194382
case acc: 0.02705132
case acc: 0.03088336
case acc: 0.021478022
case acc: 0.017818503
top acc: 0.0138 ::: bot acc: 0.0413
top acc: 0.0119 ::: bot acc: 0.0356
top acc: 0.0090 ::: bot acc: 0.0468
top acc: 0.0174 ::: bot acc: 0.0458
top acc: 0.0081 ::: bot acc: 0.0344
top acc: 0.0064 ::: bot acc: 0.0318
current epoch: 48
train loss is 0.019590
average val loss: 0.026054, accuracy: 0.0260
average test loss: 0.026680, accuracy: 0.0267
case acc: 0.030703155
case acc: 0.028637096
case acc: 0.0284321
case acc: 0.02927571
case acc: 0.02591891
case acc: 0.017401328
top acc: 0.0169 ::: bot acc: 0.0451
top acc: 0.0156 ::: bot acc: 0.0405
top acc: 0.0099 ::: bot acc: 0.0484
top acc: 0.0160 ::: bot acc: 0.0441
top acc: 0.0120 ::: bot acc: 0.0391
top acc: 0.0064 ::: bot acc: 0.0311
current epoch: 49
train loss is 0.021767
average val loss: 0.009117, accuracy: 0.0092
average test loss: 0.011680, accuracy: 0.0117
case acc: 0.0103574125
case acc: 0.009173783
case acc: 0.0150427865
case acc: 0.011661212
case acc: 0.010202552
case acc: 0.013480781
top acc: 0.0149 ::: bot acc: 0.0141
top acc: 0.0150 ::: bot acc: 0.0102
top acc: 0.0196 ::: bot acc: 0.0223
top acc: 0.0177 ::: bot acc: 0.0143
top acc: 0.0180 ::: bot acc: 0.0094
top acc: 0.0242 ::: bot acc: 0.0093
current epoch: 50
train loss is 0.014518
average val loss: 0.009781, accuracy: 0.0099
average test loss: 0.012144, accuracy: 0.0122
case acc: 0.011564036
case acc: 0.010217966
case acc: 0.015038818
case acc: 0.011785963
case acc: 0.01182828
case acc: 0.012910774
top acc: 0.0197 ::: bot acc: 0.0093
top acc: 0.0200 ::: bot acc: 0.0054
top acc: 0.0208 ::: bot acc: 0.0212
top acc: 0.0185 ::: bot acc: 0.0135
top acc: 0.0226 ::: bot acc: 0.0052
top acc: 0.0221 ::: bot acc: 0.0115
LME_Co_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6798 6798 6798
1.7082474 -0.6288155 0.08104724 -0.08406281
Validation: 756 756 756
Testing: 774 774 774
pre-processing time: 0.0003287792205810547
the split date is 2010-07-01
net initializing with time: 0.0028450489044189453
preparing training and testing date with time: 2.384185791015625e-07
current epoch: 1
train loss is 0.307150
average val loss: 0.151424, accuracy: 0.1514
average test loss: 0.152134, accuracy: 0.1521
case acc: 0.20839512
case acc: 0.35583934
case acc: 0.06403349
case acc: 0.14095795
case acc: 0.10074423
case acc: 0.042852707
top acc: 0.1933 ::: bot acc: 0.2234
top acc: 0.3420 ::: bot acc: 0.3695
top acc: 0.0408 ::: bot acc: 0.0867
top acc: 0.1231 ::: bot acc: 0.1577
top acc: 0.0806 ::: bot acc: 0.1176
top acc: 0.0269 ::: bot acc: 0.0593
current epoch: 2
train loss is 0.193897
average val loss: 0.095495, accuracy: 0.0952
average test loss: 0.095696, accuracy: 0.0955
case acc: 0.014238409
case acc: 0.1487032
case acc: 0.12901177
case acc: 0.051477373
case acc: 0.086194135
case acc: 0.1433477
top acc: 0.0101 ::: bot acc: 0.0234
top acc: 0.1349 ::: bot acc: 0.1622
top acc: 0.1522 ::: bot acc: 0.1064
top acc: 0.0694 ::: bot acc: 0.0350
top acc: 0.1066 ::: bot acc: 0.0690
top acc: 0.1603 ::: bot acc: 0.1266
current epoch: 3
train loss is 0.091268
average val loss: 0.133647, accuracy: 0.1336
average test loss: 0.134349, accuracy: 0.1344
case acc: 0.18479289
case acc: 0.3126727
case acc: 0.050043114
case acc: 0.124916844
case acc: 0.09475467
case acc: 0.039257944
top acc: 0.1693 ::: bot acc: 0.1996
top acc: 0.2989 ::: bot acc: 0.3260
top acc: 0.0276 ::: bot acc: 0.0723
top acc: 0.1070 ::: bot acc: 0.1413
top acc: 0.0747 ::: bot acc: 0.1119
top acc: 0.0233 ::: bot acc: 0.0556
current epoch: 4
train loss is 0.121290
average val loss: 0.095759, accuracy: 0.0965
average test loss: 0.096797, accuracy: 0.0972
case acc: 0.1401829
case acc: 0.26204237
case acc: 0.020353906
case acc: 0.08662075
case acc: 0.060677677
case acc: 0.013519283
top acc: 0.1246 ::: bot acc: 0.1551
top acc: 0.2482 ::: bot acc: 0.2753
top acc: 0.0117 ::: bot acc: 0.0357
top acc: 0.0686 ::: bot acc: 0.1030
top acc: 0.0414 ::: bot acc: 0.0775
top acc: 0.0119 ::: bot acc: 0.0225
current epoch: 5
train loss is 0.107982
average val loss: 0.085020, accuracy: 0.0860
average test loss: 0.085970, accuracy: 0.0866
case acc: 0.12191923
case acc: 0.23821121
case acc: 0.017475571
case acc: 0.07547994
case acc: 0.053997558
case acc: 0.01265651
top acc: 0.1061 ::: bot acc: 0.1369
top acc: 0.2245 ::: bot acc: 0.2514
top acc: 0.0202 ::: bot acc: 0.0261
top acc: 0.0575 ::: bot acc: 0.0917
top acc: 0.0347 ::: bot acc: 0.0708
top acc: 0.0169 ::: bot acc: 0.0172
current epoch: 6
train loss is 0.097644
average val loss: 0.083670, accuracy: 0.0845
average test loss: 0.084684, accuracy: 0.0852
case acc: 0.116209015
case acc: 0.22676685
case acc: 0.017977962
case acc: 0.07657385
case acc: 0.059451807
case acc: 0.014247453
top acc: 0.1003 ::: bot acc: 0.1313
top acc: 0.2130 ::: bot acc: 0.2400
top acc: 0.0175 ::: bot acc: 0.0290
top acc: 0.0585 ::: bot acc: 0.0926
top acc: 0.0398 ::: bot acc: 0.0765
top acc: 0.0109 ::: bot acc: 0.0243
current epoch: 7
train loss is 0.090895
average val loss: 0.084439, accuracy: 0.0851
average test loss: 0.085455, accuracy: 0.0859
case acc: 0.11253848
case acc: 0.217854
case acc: 0.019564329
case acc: 0.07962852
case acc: 0.0663353
case acc: 0.01936307
top acc: 0.0965 ::: bot acc: 0.1277
top acc: 0.2042 ::: bot acc: 0.2310
top acc: 0.0134 ::: bot acc: 0.0340
top acc: 0.0616 ::: bot acc: 0.0955
top acc: 0.0464 ::: bot acc: 0.0836
top acc: 0.0086 ::: bot acc: 0.0331
current epoch: 8
train loss is 0.085558
average val loss: 0.077586, accuracy: 0.0783
average test loss: 0.078574, accuracy: 0.0791
case acc: 0.09982967
case acc: 0.20025538
case acc: 0.018156467
case acc: 0.073485605
case acc: 0.06375657
case acc: 0.018858593
top acc: 0.0837 ::: bot acc: 0.1150
top acc: 0.1866 ::: bot acc: 0.2134
top acc: 0.0169 ::: bot acc: 0.0298
top acc: 0.0554 ::: bot acc: 0.0894
top acc: 0.0439 ::: bot acc: 0.0810
top acc: 0.0086 ::: bot acc: 0.0324
current epoch: 9
train loss is 0.079476
average val loss: 0.078917, accuracy: 0.0794
average test loss: 0.079860, accuracy: 0.0803
case acc: 0.096491545
case acc: 0.19305639
case acc: 0.01991248
case acc: 0.0769804
case acc: 0.069875024
case acc: 0.025256855
top acc: 0.0804 ::: bot acc: 0.1115
top acc: 0.1795 ::: bot acc: 0.2060
top acc: 0.0123 ::: bot acc: 0.0350
top acc: 0.0588 ::: bot acc: 0.0929
top acc: 0.0500 ::: bot acc: 0.0873
top acc: 0.0115 ::: bot acc: 0.0404
current epoch: 10
train loss is 0.079267
average val loss: 0.089388, accuracy: 0.0895
average test loss: 0.090159, accuracy: 0.0904
case acc: 0.1020728
case acc: 0.19643864
case acc: 0.029599896
case acc: 0.08984454
case acc: 0.084313594
case acc: 0.040401228
top acc: 0.0860 ::: bot acc: 0.1171
top acc: 0.1829 ::: bot acc: 0.2093
top acc: 0.0127 ::: bot acc: 0.0494
top acc: 0.0717 ::: bot acc: 0.1058
top acc: 0.0641 ::: bot acc: 0.1019
top acc: 0.0240 ::: bot acc: 0.0568
current epoch: 11
train loss is 0.075688
average val loss: 0.075056, accuracy: 0.0755
average test loss: 0.075927, accuracy: 0.0763
case acc: 0.081521444
case acc: 0.17428231
case acc: 0.021048557
case acc: 0.07670227
case acc: 0.07293873
case acc: 0.03117161
top acc: 0.0654 ::: bot acc: 0.0966
top acc: 0.1607 ::: bot acc: 0.1873
top acc: 0.0106 ::: bot acc: 0.0376
top acc: 0.0586 ::: bot acc: 0.0927
top acc: 0.0531 ::: bot acc: 0.0904
top acc: 0.0159 ::: bot acc: 0.0470
current epoch: 12
train loss is 0.071366
average val loss: 0.076518, accuracy: 0.0768
average test loss: 0.077335, accuracy: 0.0776
case acc: 0.07756604
case acc: 0.16904828
case acc: 0.024017463
case acc: 0.08016474
case acc: 0.07766695
case acc: 0.037358202
top acc: 0.0615 ::: bot acc: 0.0927
top acc: 0.1554 ::: bot acc: 0.1820
top acc: 0.0100 ::: bot acc: 0.0424
top acc: 0.0620 ::: bot acc: 0.0961
top acc: 0.0577 ::: bot acc: 0.0952
top acc: 0.0213 ::: bot acc: 0.0536
current epoch: 13
train loss is 0.067992
average val loss: 0.066676, accuracy: 0.0672
average test loss: 0.067524, accuracy: 0.0679
case acc: 0.061620835
case acc: 0.15208107
case acc: 0.019851185
case acc: 0.071578346
case acc: 0.070452504
case acc: 0.032024242
top acc: 0.0455 ::: bot acc: 0.0769
top acc: 0.1385 ::: bot acc: 0.1651
top acc: 0.0123 ::: bot acc: 0.0351
top acc: 0.0535 ::: bot acc: 0.0875
top acc: 0.0508 ::: bot acc: 0.0879
top acc: 0.0167 ::: bot acc: 0.0479
current epoch: 14
train loss is 0.062804
average val loss: 0.059963, accuracy: 0.0605
average test loss: 0.060810, accuracy: 0.0613
case acc: 0.049069792
case acc: 0.13852213
case acc: 0.018209003
case acc: 0.066084445
case acc: 0.06615498
case acc: 0.029552381
top acc: 0.0329 ::: bot acc: 0.0644
top acc: 0.1249 ::: bot acc: 0.1515
top acc: 0.0159 ::: bot acc: 0.0308
top acc: 0.0480 ::: bot acc: 0.0820
top acc: 0.0467 ::: bot acc: 0.0836
top acc: 0.0146 ::: bot acc: 0.0452
current epoch: 15
train loss is 0.058969
average val loss: 0.056683, accuracy: 0.0573
average test loss: 0.057532, accuracy: 0.0580
case acc: 0.04073622
case acc: 0.12893379
case acc: 0.018005447
case acc: 0.064325124
case acc: 0.06542475
case acc: 0.030451143
top acc: 0.0247 ::: bot acc: 0.0560
top acc: 0.1153 ::: bot acc: 0.1419
top acc: 0.0165 ::: bot acc: 0.0302
top acc: 0.0463 ::: bot acc: 0.0802
top acc: 0.0460 ::: bot acc: 0.0829
top acc: 0.0153 ::: bot acc: 0.0461
current epoch: 16
train loss is 0.054581
average val loss: 0.046368, accuracy: 0.0469
average test loss: 0.047281, accuracy: 0.0478
case acc: 0.025488498
case acc: 0.110557
case acc: 0.017282674
case acc: 0.05372956
case acc: 0.05603105
case acc: 0.023540096
top acc: 0.0128 ::: bot acc: 0.0391
top acc: 0.0970 ::: bot acc: 0.1235
top acc: 0.0258 ::: bot acc: 0.0208
top acc: 0.0357 ::: bot acc: 0.0696
top acc: 0.0369 ::: bot acc: 0.0734
top acc: 0.0102 ::: bot acc: 0.0383
current epoch: 17
train loss is 0.048587
average val loss: 0.040462, accuracy: 0.0410
average test loss: 0.041397, accuracy: 0.0417
case acc: 0.017001089
case acc: 0.09643421
case acc: 0.018133093
case acc: 0.047262065
case acc: 0.050777316
case acc: 0.020668197
top acc: 0.0097 ::: bot acc: 0.0278
top acc: 0.0829 ::: bot acc: 0.1093
top acc: 0.0307 ::: bot acc: 0.0158
top acc: 0.0292 ::: bot acc: 0.0631
top acc: 0.0319 ::: bot acc: 0.0680
top acc: 0.0087 ::: bot acc: 0.0347
current epoch: 18
train loss is 0.041771
average val loss: 0.031016, accuracy: 0.0313
average test loss: 0.031824, accuracy: 0.0316
case acc: 0.012581365
case acc: 0.07146847
case acc: 0.025667442
case acc: 0.031196257
case acc: 0.03559222
case acc: 0.013113192
top acc: 0.0229 ::: bot acc: 0.0092
top acc: 0.0580 ::: bot acc: 0.0843
top acc: 0.0452 ::: bot acc: 0.0099
top acc: 0.0150 ::: bot acc: 0.0461
top acc: 0.0176 ::: bot acc: 0.0524
top acc: 0.0127 ::: bot acc: 0.0212
current epoch: 19
train loss is 0.036597
average val loss: 0.025814, accuracy: 0.0259
average test loss: 0.026566, accuracy: 0.0265
case acc: 0.020733736
case acc: 0.046550713
case acc: 0.035236478
case acc: 0.018948333
case acc: 0.024264429
case acc: 0.013172819
top acc: 0.0356 ::: bot acc: 0.0080
top acc: 0.0330 ::: bot acc: 0.0594
top acc: 0.0568 ::: bot acc: 0.0155
top acc: 0.0101 ::: bot acc: 0.0302
top acc: 0.0098 ::: bot acc: 0.0394
top acc: 0.0233 ::: bot acc: 0.0106
current epoch: 20
train loss is 0.036153
average val loss: 0.023157, accuracy: 0.0230
average test loss: 0.023889, accuracy: 0.0236
case acc: 0.029183479
case acc: 0.020382866
case acc: 0.045318995
case acc: 0.01220794
case acc: 0.017504402
case acc: 0.01706418
top acc: 0.0449 ::: bot acc: 0.0146
top acc: 0.0086 ::: bot acc: 0.0323
top acc: 0.0676 ::: bot acc: 0.0242
top acc: 0.0196 ::: bot acc: 0.0144
top acc: 0.0121 ::: bot acc: 0.0281
top acc: 0.0318 ::: bot acc: 0.0053
current epoch: 21
train loss is 0.034901
average val loss: 0.021972, accuracy: 0.0214
average test loss: 0.022643, accuracy: 0.0222
case acc: 0.028825415
case acc: 0.009870738
case acc: 0.047839757
case acc: 0.013738871
case acc: 0.016808577
case acc: 0.016247783
top acc: 0.0445 ::: bot acc: 0.0144
top acc: 0.0140 ::: bot acc: 0.0124
top acc: 0.0701 ::: bot acc: 0.0265
top acc: 0.0266 ::: bot acc: 0.0080
top acc: 0.0129 ::: bot acc: 0.0268
top acc: 0.0305 ::: bot acc: 0.0054
current epoch: 22
train loss is 0.031798
average val loss: 0.026587, accuracy: 0.0263
average test loss: 0.026923, accuracy: 0.0269
case acc: 0.03142926
case acc: 0.024011659
case acc: 0.053768422
case acc: 0.020030443
case acc: 0.015236073
case acc: 0.016995545
top acc: 0.0473 ::: bot acc: 0.0166
top acc: 0.0375 ::: bot acc: 0.0113
top acc: 0.0763 ::: bot acc: 0.0320
top acc: 0.0365 ::: bot acc: 0.0072
top acc: 0.0158 ::: bot acc: 0.0230
top acc: 0.0317 ::: bot acc: 0.0051
current epoch: 23
train loss is 0.028007
average val loss: 0.039294, accuracy: 0.0390
average test loss: 0.039326, accuracy: 0.0394
case acc: 0.040573128
case acc: 0.0542453
case acc: 0.06693006
case acc: 0.036007844
case acc: 0.01461447
case acc: 0.023930606
top acc: 0.0566 ::: bot acc: 0.0254
top acc: 0.0677 ::: bot acc: 0.0415
top acc: 0.0897 ::: bot acc: 0.0445
top acc: 0.0537 ::: bot acc: 0.0207
top acc: 0.0269 ::: bot acc: 0.0120
top acc: 0.0405 ::: bot acc: 0.0083
current epoch: 24
train loss is 0.031573
average val loss: 0.066668, accuracy: 0.0666
average test loss: 0.066436, accuracy: 0.0664
case acc: 0.06174503
case acc: 0.095859826
case acc: 0.094677225
case acc: 0.06664572
case acc: 0.03230271
case acc: 0.04694302
top acc: 0.0779 ::: bot acc: 0.0465
top acc: 0.1093 ::: bot acc: 0.0832
top acc: 0.1177 ::: bot acc: 0.0716
top acc: 0.0847 ::: bot acc: 0.0508
top acc: 0.0521 ::: bot acc: 0.0148
top acc: 0.0640 ::: bot acc: 0.0304
current epoch: 25
train loss is 0.051211
average val loss: 0.091228, accuracy: 0.0912
average test loss: 0.090962, accuracy: 0.0909
case acc: 0.07754661
case acc: 0.12743954
case acc: 0.12034861
case acc: 0.09432237
case acc: 0.055836063
case acc: 0.07008688
top acc: 0.0937 ::: bot acc: 0.0621
top acc: 0.1409 ::: bot acc: 0.1147
top acc: 0.1435 ::: bot acc: 0.0971
top acc: 0.1123 ::: bot acc: 0.0785
top acc: 0.0760 ::: bot acc: 0.0375
top acc: 0.0872 ::: bot acc: 0.0536
current epoch: 26
train loss is 0.077214
average val loss: 0.031911, accuracy: 0.0315
average test loss: 0.032408, accuracy: 0.0325
case acc: 0.012214319
case acc: 0.060429085
case acc: 0.05771857
case acc: 0.03491666
case acc: 0.014718002
case acc: 0.014979443
top acc: 0.0218 ::: bot acc: 0.0101
top acc: 0.0739 ::: bot acc: 0.0477
top acc: 0.0803 ::: bot acc: 0.0357
top acc: 0.0525 ::: bot acc: 0.0198
top acc: 0.0166 ::: bot acc: 0.0219
top acc: 0.0283 ::: bot acc: 0.0061
current epoch: 27
train loss is 0.065850
average val loss: 0.022397, accuracy: 0.0220
average test loss: 0.023225, accuracy: 0.0230
case acc: 0.033824664
case acc: 0.01453428
case acc: 0.025328921
case acc: 0.012160838
case acc: 0.03318286
case acc: 0.018723015
top acc: 0.0185 ::: bot acc: 0.0487
top acc: 0.0266 ::: bot acc: 0.0045
top acc: 0.0446 ::: bot acc: 0.0096
top acc: 0.0192 ::: bot acc: 0.0147
top acc: 0.0159 ::: bot acc: 0.0501
top acc: 0.0080 ::: bot acc: 0.0320
current epoch: 28
train loss is 0.052573
average val loss: 0.017919, accuracy: 0.0174
average test loss: 0.019023, accuracy: 0.0186
case acc: 0.024848001
case acc: 0.009674228
case acc: 0.028727822
case acc: 0.012317275
case acc: 0.023488732
case acc: 0.012554403
top acc: 0.0122 ::: bot acc: 0.0384
top acc: 0.0150 ::: bot acc: 0.0111
top acc: 0.0490 ::: bot acc: 0.0110
top acc: 0.0227 ::: bot acc: 0.0112
top acc: 0.0094 ::: bot acc: 0.0389
top acc: 0.0144 ::: bot acc: 0.0191
current epoch: 29
train loss is 0.040599
average val loss: 0.017719, accuracy: 0.0170
average test loss: 0.018685, accuracy: 0.0182
case acc: 0.013043016
case acc: 0.01038767
case acc: 0.03750748
case acc: 0.016342824
case acc: 0.01470227
case acc: 0.017470235
top acc: 0.0104 ::: bot acc: 0.0216
top acc: 0.0092 ::: bot acc: 0.0168
top acc: 0.0589 ::: bot acc: 0.0175
top acc: 0.0316 ::: bot acc: 0.0059
top acc: 0.0162 ::: bot acc: 0.0222
top acc: 0.0326 ::: bot acc: 0.0050
current epoch: 30
train loss is 0.030810
average val loss: 0.019753, accuracy: 0.0192
average test loss: 0.020574, accuracy: 0.0202
case acc: 0.011689388
case acc: 0.016796218
case acc: 0.037831046
case acc: 0.017123045
case acc: 0.013850484
case acc: 0.023786703
top acc: 0.0134 ::: bot acc: 0.0181
top acc: 0.0066 ::: bot acc: 0.0278
top acc: 0.0593 ::: bot acc: 0.0177
top acc: 0.0327 ::: bot acc: 0.0060
top acc: 0.0229 ::: bot acc: 0.0154
top acc: 0.0404 ::: bot acc: 0.0083
current epoch: 31
train loss is 0.026390
average val loss: 0.019018, accuracy: 0.0187
average test loss: 0.019996, accuracy: 0.0202
case acc: 0.018504977
case acc: 0.03311646
case acc: 0.025508467
case acc: 0.0121253235
case acc: 0.015532928
case acc: 0.016334798
top acc: 0.0096 ::: bot acc: 0.0302
top acc: 0.0197 ::: bot acc: 0.0457
top acc: 0.0449 ::: bot acc: 0.0096
top acc: 0.0204 ::: bot acc: 0.0135
top acc: 0.0140 ::: bot acc: 0.0247
top acc: 0.0309 ::: bot acc: 0.0050
current epoch: 32
train loss is 0.031679
average val loss: 0.025598, accuracy: 0.0262
average test loss: 0.026690, accuracy: 0.0273
case acc: 0.031195851
case acc: 0.05668668
case acc: 0.016871031
case acc: 0.021001713
case acc: 0.025362086
case acc: 0.012606517
top acc: 0.0164 ::: bot acc: 0.0458
top acc: 0.0432 ::: bot acc: 0.0693
top acc: 0.0243 ::: bot acc: 0.0219
top acc: 0.0103 ::: bot acc: 0.0332
top acc: 0.0102 ::: bot acc: 0.0414
top acc: 0.0137 ::: bot acc: 0.0197
current epoch: 33
train loss is 0.041482
average val loss: 0.053647, accuracy: 0.0537
average test loss: 0.054072, accuracy: 0.0543
case acc: 0.05615854
case acc: 0.09348518
case acc: 0.034257274
case acc: 0.051311634
case acc: 0.054960083
case acc: 0.03541454
top acc: 0.0401 ::: bot acc: 0.0715
top acc: 0.0800 ::: bot acc: 0.1062
top acc: 0.0149 ::: bot acc: 0.0556
top acc: 0.0334 ::: bot acc: 0.0672
top acc: 0.0366 ::: bot acc: 0.0725
top acc: 0.0198 ::: bot acc: 0.0511
current epoch: 34
train loss is 0.040003
average val loss: 0.034103, accuracy: 0.0345
average test loss: 0.035006, accuracy: 0.0352
case acc: 0.029108167
case acc: 0.070962764
case acc: 0.020519251
case acc: 0.0334097
case acc: 0.037198436
case acc: 0.020234717
top acc: 0.0148 ::: bot acc: 0.0435
top acc: 0.0575 ::: bot acc: 0.0836
top acc: 0.0103 ::: bot acc: 0.0373
top acc: 0.0167 ::: bot acc: 0.0487
top acc: 0.0195 ::: bot acc: 0.0544
top acc: 0.0084 ::: bot acc: 0.0340
current epoch: 35
train loss is 0.034800
average val loss: 0.031136, accuracy: 0.0315
average test loss: 0.032132, accuracy: 0.0324
case acc: 0.02095627
case acc: 0.063605584
case acc: 0.020102374
case acc: 0.03198565
case acc: 0.036870323
case acc: 0.021016616
top acc: 0.0106 ::: bot acc: 0.0334
top acc: 0.0501 ::: bot acc: 0.0762
top acc: 0.0108 ::: bot acc: 0.0364
top acc: 0.0156 ::: bot acc: 0.0471
top acc: 0.0192 ::: bot acc: 0.0541
top acc: 0.0088 ::: bot acc: 0.0351
current epoch: 36
train loss is 0.030269
average val loss: 0.023129, accuracy: 0.0235
average test loss: 0.024312, accuracy: 0.0246
case acc: 0.011469638
case acc: 0.048535354
case acc: 0.01726122
case acc: 0.024284223
case acc: 0.0293672
case acc: 0.016401451
top acc: 0.0144 ::: bot acc: 0.0171
top acc: 0.0350 ::: bot acc: 0.0612
top acc: 0.0182 ::: bot acc: 0.0281
top acc: 0.0114 ::: bot acc: 0.0377
top acc: 0.0129 ::: bot acc: 0.0461
top acc: 0.0083 ::: bot acc: 0.0283
current epoch: 37
train loss is 0.023167
average val loss: 0.016446, accuracy: 0.0167
average test loss: 0.017554, accuracy: 0.0178
case acc: 0.018170046
case acc: 0.025958497
case acc: 0.018658567
case acc: 0.013605704
case acc: 0.018335402
case acc: 0.012140501
top acc: 0.0323 ::: bot acc: 0.0067
top acc: 0.0132 ::: bot acc: 0.0382
top acc: 0.0326 ::: bot acc: 0.0137
top acc: 0.0130 ::: bot acc: 0.0209
top acc: 0.0102 ::: bot acc: 0.0309
top acc: 0.0184 ::: bot acc: 0.0149
current epoch: 38
train loss is 0.019763
average val loss: 0.014527, accuracy: 0.0145
average test loss: 0.015598, accuracy: 0.0155
case acc: 0.019164396
case acc: 0.012619235
case acc: 0.02064034
case acc: 0.012165267
case acc: 0.015741011
case acc: 0.012660747
top acc: 0.0336 ::: bot acc: 0.0072
top acc: 0.0058 ::: bot acc: 0.0220
top acc: 0.0373 ::: bot acc: 0.0104
top acc: 0.0215 ::: bot acc: 0.0124
top acc: 0.0135 ::: bot acc: 0.0253
top acc: 0.0219 ::: bot acc: 0.0114
current epoch: 39
train loss is 0.018438
average val loss: 0.014621, accuracy: 0.0143
average test loss: 0.015537, accuracy: 0.0154
case acc: 0.017529724
case acc: 0.010770757
case acc: 0.022158405
case acc: 0.014350518
case acc: 0.014813085
case acc: 0.012755497
top acc: 0.0314 ::: bot acc: 0.0065
top acc: 0.0203 ::: bot acc: 0.0061
top acc: 0.0401 ::: bot acc: 0.0094
top acc: 0.0280 ::: bot acc: 0.0069
top acc: 0.0158 ::: bot acc: 0.0227
top acc: 0.0223 ::: bot acc: 0.0110
current epoch: 40
train loss is 0.015948
average val loss: 0.018886, accuracy: 0.0188
average test loss: 0.019460, accuracy: 0.0196
case acc: 0.018608112
case acc: 0.024230845
case acc: 0.026307734
case acc: 0.020522695
case acc: 0.013816322
case acc: 0.013964583
top acc: 0.0328 ::: bot acc: 0.0069
top acc: 0.0377 ::: bot acc: 0.0116
top acc: 0.0461 ::: bot acc: 0.0097
top acc: 0.0370 ::: bot acc: 0.0075
top acc: 0.0213 ::: bot acc: 0.0172
top acc: 0.0260 ::: bot acc: 0.0075
current epoch: 41
train loss is 0.017347
average val loss: 0.024387, accuracy: 0.0241
average test loss: 0.024745, accuracy: 0.0249
case acc: 0.020026244
case acc: 0.037951402
case acc: 0.032019984
case acc: 0.028125081
case acc: 0.01478746
case acc: 0.016381582
top acc: 0.0346 ::: bot acc: 0.0076
top acc: 0.0515 ::: bot acc: 0.0252
top acc: 0.0530 ::: bot acc: 0.0130
top acc: 0.0453 ::: bot acc: 0.0135
top acc: 0.0272 ::: bot acc: 0.0113
top acc: 0.0309 ::: bot acc: 0.0049
current epoch: 42
train loss is 0.020639
average val loss: 0.036052, accuracy: 0.0359
average test loss: 0.036135, accuracy: 0.0361
case acc: 0.027552016
case acc: 0.05647956
case acc: 0.044524968
case acc: 0.04180806
case acc: 0.021089306
case acc: 0.025340237
top acc: 0.0432 ::: bot acc: 0.0130
top acc: 0.0700 ::: bot acc: 0.0438
top acc: 0.0666 ::: bot acc: 0.0235
top acc: 0.0595 ::: bot acc: 0.0262
top acc: 0.0389 ::: bot acc: 0.0069
top acc: 0.0421 ::: bot acc: 0.0095
current epoch: 43
train loss is 0.028696
average val loss: 0.058757, accuracy: 0.0587
average test loss: 0.058658, accuracy: 0.0586
case acc: 0.0442923
case acc: 0.08338961
case acc: 0.06793935
case acc: 0.06640644
case acc: 0.04175127
case acc: 0.047739215
top acc: 0.0604 ::: bot acc: 0.0288
top acc: 0.0969 ::: bot acc: 0.0707
top acc: 0.0907 ::: bot acc: 0.0453
top acc: 0.0843 ::: bot acc: 0.0504
top acc: 0.0617 ::: bot acc: 0.0232
top acc: 0.0647 ::: bot acc: 0.0314
current epoch: 44
train loss is 0.039095
average val loss: 0.042440, accuracy: 0.0423
average test loss: 0.042494, accuracy: 0.0424
case acc: 0.021169214
case acc: 0.06420748
case acc: 0.05321198
case acc: 0.05219495
case acc: 0.028917145
case acc: 0.034943912
top acc: 0.0360 ::: bot acc: 0.0082
top acc: 0.0777 ::: bot acc: 0.0515
top acc: 0.0756 ::: bot acc: 0.0315
top acc: 0.0701 ::: bot acc: 0.0363
top acc: 0.0482 ::: bot acc: 0.0117
top acc: 0.0519 ::: bot acc: 0.0186
current epoch: 45
train loss is 0.038682
average val loss: 0.020723, accuracy: 0.0204
average test loss: 0.021353, accuracy: 0.0217
case acc: 0.018906003
case acc: 0.027157137
case acc: 0.027203921
case acc: 0.026461922
case acc: 0.0143438205
case acc: 0.015931495
top acc: 0.0098 ::: bot acc: 0.0308
top acc: 0.0406 ::: bot acc: 0.0145
top acc: 0.0473 ::: bot acc: 0.0100
top acc: 0.0436 ::: bot acc: 0.0121
top acc: 0.0254 ::: bot acc: 0.0132
top acc: 0.0302 ::: bot acc: 0.0051
current epoch: 46
train loss is 0.042658
average val loss: 0.023613, accuracy: 0.0238
average test loss: 0.024801, accuracy: 0.0250
case acc: 0.048169635
case acc: 0.023784364
case acc: 0.019041963
case acc: 0.016000142
case acc: 0.025602134
case acc: 0.017442094
top acc: 0.0320 ::: bot acc: 0.0636
top acc: 0.0114 ::: bot acc: 0.0359
top acc: 0.0126 ::: bot acc: 0.0340
top acc: 0.0098 ::: bot acc: 0.0261
top acc: 0.0104 ::: bot acc: 0.0418
top acc: 0.0079 ::: bot acc: 0.0300
current epoch: 47
train loss is 0.030698
average val loss: 0.020292, accuracy: 0.0207
average test loss: 0.021538, accuracy: 0.0221
case acc: 0.03350526
case acc: 0.034744114
case acc: 0.017577104
case acc: 0.015121757
case acc: 0.018972859
case acc: 0.012480105
top acc: 0.0183 ::: bot acc: 0.0484
top acc: 0.0212 ::: bot acc: 0.0474
top acc: 0.0170 ::: bot acc: 0.0294
top acc: 0.0103 ::: bot acc: 0.0244
top acc: 0.0096 ::: bot acc: 0.0322
top acc: 0.0142 ::: bot acc: 0.0192
current epoch: 48
train loss is 0.031287
average val loss: 0.040898, accuracy: 0.0410
average test loss: 0.041515, accuracy: 0.0416
case acc: 0.04708094
case acc: 0.071209356
case acc: 0.03325894
case acc: 0.036455605
case acc: 0.036480475
case acc: 0.025360692
top acc: 0.0309 ::: bot acc: 0.0625
top acc: 0.0577 ::: bot acc: 0.0839
top acc: 0.0141 ::: bot acc: 0.0546
top acc: 0.0193 ::: bot acc: 0.0520
top acc: 0.0189 ::: bot acc: 0.0539
top acc: 0.0117 ::: bot acc: 0.0400
current epoch: 49
train loss is 0.034848
average val loss: 0.034773, accuracy: 0.0349
average test loss: 0.035559, accuracy: 0.0357
case acc: 0.03249107
case acc: 0.06524526
case acc: 0.029489217
case acc: 0.032595087
case acc: 0.032286707
case acc: 0.021933842
top acc: 0.0175 ::: bot acc: 0.0474
top acc: 0.0517 ::: bot acc: 0.0779
top acc: 0.0118 ::: bot acc: 0.0501
top acc: 0.0161 ::: bot acc: 0.0478
top acc: 0.0153 ::: bot acc: 0.0494
top acc: 0.0092 ::: bot acc: 0.0361
current epoch: 50
train loss is 0.028530
average val loss: 0.024410, accuracy: 0.0246
average test loss: 0.025589, accuracy: 0.0258
case acc: 0.01667305
case acc: 0.04889534
case acc: 0.02210798
case acc: 0.024448184
case acc: 0.025489852
case acc: 0.017054025
top acc: 0.0093 ::: bot acc: 0.0278
top acc: 0.0354 ::: bot acc: 0.0616
top acc: 0.0092 ::: bot acc: 0.0403
top acc: 0.0114 ::: bot acc: 0.0380
top acc: 0.0103 ::: bot acc: 0.0417
top acc: 0.0079 ::: bot acc: 0.0294
LME_Co_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6810 6810 6810
1.7082474 -0.6288155 0.08104724 -0.08406281
Validation: 762 762 762
Testing: 750 750 750
pre-processing time: 0.0004086494445800781
the split date is 2011-01-01
net initializing with time: 0.0031859874725341797
preparing training and testing date with time: 2.384185791015625e-07
current epoch: 1
train loss is 0.321928
average val loss: 0.046546, accuracy: 0.0471
average test loss: 0.045626, accuracy: 0.0466
case acc: 0.11328221
case acc: 0.089633666
case acc: 0.01699474
case acc: 0.016197141
case acc: 0.018703345
case acc: 0.025005646
top acc: 0.0994 ::: bot acc: 0.1277
top acc: 0.0781 ::: bot acc: 0.1029
top acc: 0.0277 ::: bot acc: 0.0158
top acc: 0.0278 ::: bot acc: 0.0086
top acc: 0.0325 ::: bot acc: 0.0080
top acc: 0.0094 ::: bot acc: 0.0406
current epoch: 2
train loss is 0.109958
average val loss: 0.039966, accuracy: 0.0401
average test loss: 0.039495, accuracy: 0.0404
case acc: 0.08228095
case acc: 0.059486754
case acc: 0.025877975
case acc: 0.028689278
case acc: 0.03180799
case acc: 0.014480712
top acc: 0.0681 ::: bot acc: 0.0971
top acc: 0.0480 ::: bot acc: 0.0726
top acc: 0.0432 ::: bot acc: 0.0119
top acc: 0.0431 ::: bot acc: 0.0151
top acc: 0.0496 ::: bot acc: 0.0128
top acc: 0.0104 ::: bot acc: 0.0244
current epoch: 3
train loss is 0.092100
average val loss: 0.075592, accuracy: 0.0757
average test loss: 0.073293, accuracy: 0.0734
case acc: 0.13516322
case acc: 0.11639499
case acc: 0.043645255
case acc: 0.041337352
case acc: 0.035097625
case acc: 0.06853585
top acc: 0.1210 ::: bot acc: 0.1500
top acc: 0.1049 ::: bot acc: 0.1294
top acc: 0.0236 ::: bot acc: 0.0645
top acc: 0.0260 ::: bot acc: 0.0572
top acc: 0.0181 ::: bot acc: 0.0541
top acc: 0.0513 ::: bot acc: 0.0851
current epoch: 4
train loss is 0.099098
average val loss: 0.097659, accuracy: 0.0977
average test loss: 0.095384, accuracy: 0.0954
case acc: 0.1479412
case acc: 0.13667849
case acc: 0.06743012
case acc: 0.074030414
case acc: 0.0639078
case acc: 0.082316905
top acc: 0.1337 ::: bot acc: 0.1628
top acc: 0.1252 ::: bot acc: 0.1497
top acc: 0.0466 ::: bot acc: 0.0887
top acc: 0.0588 ::: bot acc: 0.0896
top acc: 0.0457 ::: bot acc: 0.0836
top acc: 0.0650 ::: bot acc: 0.0989
current epoch: 5
train loss is 0.085228
average val loss: 0.073973, accuracy: 0.0741
average test loss: 0.071570, accuracy: 0.0716
case acc: 0.11355548
case acc: 0.107902944
case acc: 0.04683878
case acc: 0.061081123
case acc: 0.048551477
case acc: 0.05167364
top acc: 0.0993 ::: bot acc: 0.1284
top acc: 0.0963 ::: bot acc: 0.1210
top acc: 0.0266 ::: bot acc: 0.0678
top acc: 0.0460 ::: bot acc: 0.0764
top acc: 0.0302 ::: bot acc: 0.0682
top acc: 0.0343 ::: bot acc: 0.0683
current epoch: 6
train loss is 0.067954
average val loss: 0.068853, accuracy: 0.0690
average test loss: 0.066357, accuracy: 0.0664
case acc: 0.09753192
case acc: 0.09577838
case acc: 0.0457901
case acc: 0.06545948
case acc: 0.050175086
case acc: 0.043575138
top acc: 0.0831 ::: bot acc: 0.1124
top acc: 0.0841 ::: bot acc: 0.1089
top acc: 0.0256 ::: bot acc: 0.0667
top acc: 0.0506 ::: bot acc: 0.0806
top acc: 0.0317 ::: bot acc: 0.0699
top acc: 0.0261 ::: bot acc: 0.0604
current epoch: 7
train loss is 0.060591
average val loss: 0.071523, accuracy: 0.0716
average test loss: 0.068955, accuracy: 0.0690
case acc: 0.08966093
case acc: 0.09213073
case acc: 0.052274887
case acc: 0.0773156
case acc: 0.058638316
case acc: 0.043771904
top acc: 0.0751 ::: bot acc: 0.1045
top acc: 0.0804 ::: bot acc: 0.1053
top acc: 0.0317 ::: bot acc: 0.0734
top acc: 0.0626 ::: bot acc: 0.0921
top acc: 0.0400 ::: bot acc: 0.0784
top acc: 0.0262 ::: bot acc: 0.0607
current epoch: 8
train loss is 0.054391
average val loss: 0.071602, accuracy: 0.0717
average test loss: 0.068966, accuracy: 0.0690
case acc: 0.07921214
case acc: 0.08572741
case acc: 0.056479625
case acc: 0.0863129
case acc: 0.06406494
case acc: 0.041972
top acc: 0.0647 ::: bot acc: 0.0940
top acc: 0.0740 ::: bot acc: 0.0989
top acc: 0.0358 ::: bot acc: 0.0778
top acc: 0.0717 ::: bot acc: 0.1008
top acc: 0.0453 ::: bot acc: 0.0839
top acc: 0.0244 ::: bot acc: 0.0590
current epoch: 9
train loss is 0.047159
average val loss: 0.068179, accuracy: 0.0682
average test loss: 0.065481, accuracy: 0.0655
case acc: 0.06541339
case acc: 0.07507146
case acc: 0.057587933
case acc: 0.09101769
case acc: 0.06542155
case acc: 0.038274877
top acc: 0.0509 ::: bot acc: 0.0801
top acc: 0.0633 ::: bot acc: 0.0883
top acc: 0.0369 ::: bot acc: 0.0789
top acc: 0.0766 ::: bot acc: 0.1053
top acc: 0.0465 ::: bot acc: 0.0853
top acc: 0.0207 ::: bot acc: 0.0553
current epoch: 10
train loss is 0.041809
average val loss: 0.064065, accuracy: 0.0641
average test loss: 0.061339, accuracy: 0.0613
case acc: 0.05116226
case acc: 0.06194262
case acc: 0.05891262
case acc: 0.09340852
case acc: 0.06509503
case acc: 0.037332024
top acc: 0.0367 ::: bot acc: 0.0657
top acc: 0.0501 ::: bot acc: 0.0752
top acc: 0.0381 ::: bot acc: 0.0803
top acc: 0.0791 ::: bot acc: 0.1075
top acc: 0.0461 ::: bot acc: 0.0850
top acc: 0.0198 ::: bot acc: 0.0544
current epoch: 11
train loss is 0.039718
average val loss: 0.059820, accuracy: 0.0598
average test loss: 0.057063, accuracy: 0.0570
case acc: 0.037344337
case acc: 0.047339033
case acc: 0.06010904
case acc: 0.09418362
case acc: 0.06485638
case acc: 0.038088933
top acc: 0.0229 ::: bot acc: 0.0519
top acc: 0.0355 ::: bot acc: 0.0604
top acc: 0.0393 ::: bot acc: 0.0816
top acc: 0.0799 ::: bot acc: 0.1083
top acc: 0.0459 ::: bot acc: 0.0849
top acc: 0.0206 ::: bot acc: 0.0552
current epoch: 12
train loss is 0.045235
average val loss: 0.037880, accuracy: 0.0374
average test loss: 0.035188, accuracy: 0.0344
case acc: 0.011092551
case acc: 0.013149602
case acc: 0.041500956
case acc: 0.073766746
case acc: 0.045450658
case acc: 0.021654485
top acc: 0.0100 ::: bot acc: 0.0190
top acc: 0.0042 ::: bot acc: 0.0248
top acc: 0.0218 ::: bot acc: 0.0624
top acc: 0.0595 ::: bot acc: 0.0879
top acc: 0.0265 ::: bot acc: 0.0654
top acc: 0.0071 ::: bot acc: 0.0374
current epoch: 13
train loss is 0.062891
average val loss: 0.054627, accuracy: 0.0546
average test loss: 0.056912, accuracy: 0.0569
case acc: 0.09074985
case acc: 0.09044712
case acc: 0.044419114
case acc: 0.017273031
case acc: 0.0393543
case acc: 0.058871556
top acc: 0.1051 ::: bot acc: 0.0762
top acc: 0.1023 ::: bot acc: 0.0774
top acc: 0.0644 ::: bot acc: 0.0247
top acc: 0.0293 ::: bot acc: 0.0077
top acc: 0.0584 ::: bot acc: 0.0193
top acc: 0.0764 ::: bot acc: 0.0417
current epoch: 14
train loss is 0.078445
average val loss: 0.080821, accuracy: 0.0808
average test loss: 0.083323, accuracy: 0.0833
case acc: 0.11379592
case acc: 0.12519658
case acc: 0.06899471
case acc: 0.050114308
case acc: 0.06832112
case acc: 0.07353829
top acc: 0.1282 ::: bot acc: 0.0992
top acc: 0.1371 ::: bot acc: 0.1122
top acc: 0.0896 ::: bot acc: 0.0479
top acc: 0.0645 ::: bot acc: 0.0359
top acc: 0.0874 ::: bot acc: 0.0482
top acc: 0.0910 ::: bot acc: 0.0563
current epoch: 15
train loss is 0.061733
average val loss: 0.054408, accuracy: 0.0545
average test loss: 0.056821, accuracy: 0.0569
case acc: 0.077524856
case acc: 0.09569582
case acc: 0.04455733
case acc: 0.03489967
case acc: 0.050268006
case acc: 0.038220707
top acc: 0.0919 ::: bot acc: 0.0630
top acc: 0.1076 ::: bot acc: 0.0828
top acc: 0.0646 ::: bot acc: 0.0248
top acc: 0.0490 ::: bot acc: 0.0211
top acc: 0.0695 ::: bot acc: 0.0301
top acc: 0.0557 ::: bot acc: 0.0210
current epoch: 16
train loss is 0.053597
average val loss: 0.063714, accuracy: 0.0637
average test loss: 0.066143, accuracy: 0.0662
case acc: 0.07607467
case acc: 0.09808033
case acc: 0.05728819
case acc: 0.054295484
case acc: 0.06719395
case acc: 0.04399404
top acc: 0.0905 ::: bot acc: 0.0615
top acc: 0.1100 ::: bot acc: 0.0852
top acc: 0.0777 ::: bot acc: 0.0366
top acc: 0.0686 ::: bot acc: 0.0402
top acc: 0.0864 ::: bot acc: 0.0470
top acc: 0.0614 ::: bot acc: 0.0267
current epoch: 17
train loss is 0.046450
average val loss: 0.055451, accuracy: 0.0554
average test loss: 0.057842, accuracy: 0.0578
case acc: 0.056248687
case acc: 0.08145587
case acc: 0.0537675
case acc: 0.055929177
case acc: 0.065434985
case acc: 0.034182355
top acc: 0.0706 ::: bot acc: 0.0417
top acc: 0.0934 ::: bot acc: 0.0687
top acc: 0.0741 ::: bot acc: 0.0331
top acc: 0.0702 ::: bot acc: 0.0419
top acc: 0.0847 ::: bot acc: 0.0452
top acc: 0.0515 ::: bot acc: 0.0170
current epoch: 18
train loss is 0.037712
average val loss: 0.047877, accuracy: 0.0478
average test loss: 0.050202, accuracy: 0.0502
case acc: 0.037014283
case acc: 0.06452433
case acc: 0.05192753
case acc: 0.05707628
case acc: 0.06217027
case acc: 0.028312244
top acc: 0.0514 ::: bot acc: 0.0225
top acc: 0.0765 ::: bot acc: 0.0518
top acc: 0.0722 ::: bot acc: 0.0314
top acc: 0.0713 ::: bot acc: 0.0430
top acc: 0.0814 ::: bot acc: 0.0419
top acc: 0.0454 ::: bot acc: 0.0116
current epoch: 19
train loss is 0.030139
average val loss: 0.041269, accuracy: 0.0411
average test loss: 0.043483, accuracy: 0.0434
case acc: 0.02022663
case acc: 0.048245866
case acc: 0.051063895
case acc: 0.057533767
case acc: 0.057895374
case acc: 0.02529375
top acc: 0.0336 ::: bot acc: 0.0077
top acc: 0.0602 ::: bot acc: 0.0355
top acc: 0.0714 ::: bot acc: 0.0306
top acc: 0.0717 ::: bot acc: 0.0436
top acc: 0.0772 ::: bot acc: 0.0376
top acc: 0.0422 ::: bot acc: 0.0091
current epoch: 20
train loss is 0.026982
average val loss: 0.042374, accuracy: 0.0421
average test loss: 0.044489, accuracy: 0.0443
case acc: 0.014357471
case acc: 0.039896216
case acc: 0.056556325
case acc: 0.063719936
case acc: 0.061687518
case acc: 0.029625531
top acc: 0.0257 ::: bot acc: 0.0062
top acc: 0.0519 ::: bot acc: 0.0271
top acc: 0.0770 ::: bot acc: 0.0358
top acc: 0.0779 ::: bot acc: 0.0497
top acc: 0.0810 ::: bot acc: 0.0413
top acc: 0.0468 ::: bot acc: 0.0128
current epoch: 21
train loss is 0.037057
average val loss: 0.030620, accuracy: 0.0302
average test loss: 0.031788, accuracy: 0.0316
case acc: 0.016134609
case acc: 0.014039673
case acc: 0.042898405
case acc: 0.04999524
case acc: 0.04863596
case acc: 0.0180876
top acc: 0.0060 ::: bot acc: 0.0285
top acc: 0.0240 ::: bot acc: 0.0054
top acc: 0.0627 ::: bot acc: 0.0233
top acc: 0.0642 ::: bot acc: 0.0360
top acc: 0.0679 ::: bot acc: 0.0283
top acc: 0.0331 ::: bot acc: 0.0058
current epoch: 22
train loss is 0.058315
average val loss: 0.069037, accuracy: 0.0691
average test loss: 0.066461, accuracy: 0.0665
case acc: 0.110156596
case acc: 0.09233588
case acc: 0.04657761
case acc: 0.04293185
case acc: 0.041010723
case acc: 0.066016875
top acc: 0.0958 ::: bot acc: 0.1246
top acc: 0.0804 ::: bot acc: 0.1051
top acc: 0.0264 ::: bot acc: 0.0679
top acc: 0.0287 ::: bot acc: 0.0570
top acc: 0.0222 ::: bot acc: 0.0612
top acc: 0.0486 ::: bot acc: 0.0832
current epoch: 23
train loss is 0.068788
average val loss: 0.058789, accuracy: 0.0589
average test loss: 0.056150, accuracy: 0.0563
case acc: 0.09248421
case acc: 0.08435816
case acc: 0.03762552
case acc: 0.041856114
case acc: 0.03460519
case acc: 0.046643883
top acc: 0.0781 ::: bot acc: 0.1070
top acc: 0.0724 ::: bot acc: 0.0971
top acc: 0.0183 ::: bot acc: 0.0585
top acc: 0.0276 ::: bot acc: 0.0560
top acc: 0.0165 ::: bot acc: 0.0544
top acc: 0.0293 ::: bot acc: 0.0638
current epoch: 24
train loss is 0.046284
average val loss: 0.041251, accuracy: 0.0414
average test loss: 0.038444, accuracy: 0.0387
case acc: 0.063984506
case acc: 0.060416758
case acc: 0.024677848
case acc: 0.03360016
case acc: 0.025177313
case acc: 0.024564687
top acc: 0.0495 ::: bot acc: 0.0785
top acc: 0.0485 ::: bot acc: 0.0732
top acc: 0.0098 ::: bot acc: 0.0434
top acc: 0.0196 ::: bot acc: 0.0477
top acc: 0.0093 ::: bot acc: 0.0439
top acc: 0.0087 ::: bot acc: 0.0410
current epoch: 25
train loss is 0.041910
average val loss: 0.059214, accuracy: 0.0593
average test loss: 0.056578, accuracy: 0.0566
case acc: 0.07287373
case acc: 0.07464387
case acc: 0.043289073
case acc: 0.061954852
case acc: 0.05028543
case acc: 0.03646622
top acc: 0.0584 ::: bot acc: 0.0874
top acc: 0.0627 ::: bot acc: 0.0874
top acc: 0.0233 ::: bot acc: 0.0645
top acc: 0.0477 ::: bot acc: 0.0762
top acc: 0.0310 ::: bot acc: 0.0707
top acc: 0.0191 ::: bot acc: 0.0536
current epoch: 26
train loss is 0.038830
average val loss: 0.056599, accuracy: 0.0567
average test loss: 0.053941, accuracy: 0.0539
case acc: 0.05950933
case acc: 0.0654677
case acc: 0.04414426
case acc: 0.06909358
case acc: 0.055158395
case acc: 0.030166788
top acc: 0.0450 ::: bot acc: 0.0741
top acc: 0.0535 ::: bot acc: 0.0782
top acc: 0.0241 ::: bot acc: 0.0654
top acc: 0.0548 ::: bot acc: 0.0833
top acc: 0.0359 ::: bot acc: 0.0755
top acc: 0.0131 ::: bot acc: 0.0471
current epoch: 27
train loss is 0.035177
average val loss: 0.048390, accuracy: 0.0484
average test loss: 0.045660, accuracy: 0.0456
case acc: 0.040357217
case acc: 0.04701382
case acc: 0.041150007
case acc: 0.06811323
case acc: 0.05235374
case acc: 0.024754148
top acc: 0.0259 ::: bot acc: 0.0549
top acc: 0.0350 ::: bot acc: 0.0598
top acc: 0.0214 ::: bot acc: 0.0622
top acc: 0.0538 ::: bot acc: 0.0823
top acc: 0.0330 ::: bot acc: 0.0727
top acc: 0.0089 ::: bot acc: 0.0411
current epoch: 28
train loss is 0.041084
average val loss: 0.019687, accuracy: 0.0195
average test loss: 0.018455, accuracy: 0.0180
case acc: 0.01275199
case acc: 0.009861316
case acc: 0.016511735
case acc: 0.03437493
case acc: 0.020920401
case acc: 0.013687715
top acc: 0.0227 ::: bot acc: 0.0073
top acc: 0.0162 ::: bot acc: 0.0085
top acc: 0.0130 ::: bot acc: 0.0296
top acc: 0.0203 ::: bot acc: 0.0484
top acc: 0.0075 ::: bot acc: 0.0384
top acc: 0.0243 ::: bot acc: 0.0102
current epoch: 29
train loss is 0.043276
average val loss: 0.044856, accuracy: 0.0449
average test loss: 0.047147, accuracy: 0.0471
case acc: 0.06703597
case acc: 0.07142324
case acc: 0.041642804
case acc: 0.021495886
case acc: 0.032643177
case acc: 0.048609044
top acc: 0.0815 ::: bot acc: 0.0525
top acc: 0.0834 ::: bot acc: 0.0587
top acc: 0.0613 ::: bot acc: 0.0224
top acc: 0.0345 ::: bot acc: 0.0099
top acc: 0.0519 ::: bot acc: 0.0123
top acc: 0.0660 ::: bot acc: 0.0315
current epoch: 30
train loss is 0.054670
average val loss: 0.056682, accuracy: 0.0567
average test loss: 0.059097, accuracy: 0.0591
case acc: 0.07438692
case acc: 0.0894153
case acc: 0.052376628
case acc: 0.040793307
case acc: 0.04734611
case acc: 0.05039195
top acc: 0.0888 ::: bot acc: 0.0598
top acc: 0.1014 ::: bot acc: 0.0767
top acc: 0.0726 ::: bot acc: 0.0320
top acc: 0.0550 ::: bot acc: 0.0268
top acc: 0.0667 ::: bot acc: 0.0270
top acc: 0.0677 ::: bot acc: 0.0333
current epoch: 31
train loss is 0.041536
average val loss: 0.042541, accuracy: 0.0425
average test loss: 0.044870, accuracy: 0.0449
case acc: 0.050570667
case acc: 0.071221285
case acc: 0.040457394
case acc: 0.036519025
case acc: 0.041000966
case acc: 0.029770713
top acc: 0.0650 ::: bot acc: 0.0360
top acc: 0.0832 ::: bot acc: 0.0585
top acc: 0.0601 ::: bot acc: 0.0213
top acc: 0.0506 ::: bot acc: 0.0227
top acc: 0.0603 ::: bot acc: 0.0206
top acc: 0.0470 ::: bot acc: 0.0130
current epoch: 32
train loss is 0.034991
average val loss: 0.046835, accuracy: 0.0468
average test loss: 0.049199, accuracy: 0.0492
case acc: 0.044429407
case acc: 0.06819932
case acc: 0.04811484
case acc: 0.04996592
case acc: 0.05258075
case acc: 0.031884942
top acc: 0.0589 ::: bot acc: 0.0299
top acc: 0.0802 ::: bot acc: 0.0555
top acc: 0.0682 ::: bot acc: 0.0279
top acc: 0.0642 ::: bot acc: 0.0359
top acc: 0.0719 ::: bot acc: 0.0322
top acc: 0.0491 ::: bot acc: 0.0150
current epoch: 33
train loss is 0.029747
average val loss: 0.043190, accuracy: 0.0431
average test loss: 0.045488, accuracy: 0.0454
case acc: 0.02979313
case acc: 0.0559386
case acc: 0.048914794
case acc: 0.054936655
case acc: 0.05492772
case acc: 0.028081162
top acc: 0.0442 ::: bot acc: 0.0153
top acc: 0.0679 ::: bot acc: 0.0432
top acc: 0.0691 ::: bot acc: 0.0287
top acc: 0.0692 ::: bot acc: 0.0409
top acc: 0.0743 ::: bot acc: 0.0345
top acc: 0.0451 ::: bot acc: 0.0115
current epoch: 34
train loss is 0.026658
average val loss: 0.040419, accuracy: 0.0403
average test loss: 0.042622, accuracy: 0.0425
case acc: 0.018019738
case acc: 0.042934332
case acc: 0.05072791
case acc: 0.0587463
case acc: 0.05669379
case acc: 0.027887886
top acc: 0.0308 ::: bot acc: 0.0067
top acc: 0.0549 ::: bot acc: 0.0302
top acc: 0.0709 ::: bot acc: 0.0304
top acc: 0.0730 ::: bot acc: 0.0447
top acc: 0.0761 ::: bot acc: 0.0363
top acc: 0.0449 ::: bot acc: 0.0114
current epoch: 35
train loss is 0.035696
average val loss: 0.020829, accuracy: 0.0207
average test loss: 0.020574, accuracy: 0.0210
case acc: 0.029814702
case acc: 0.009852709
case acc: 0.02177999
case acc: 0.02631729
case acc: 0.024951989
case acc: 0.013218891
top acc: 0.0156 ::: bot acc: 0.0442
top acc: 0.0064 ::: bot acc: 0.0185
top acc: 0.0375 ::: bot acc: 0.0107
top acc: 0.0399 ::: bot acc: 0.0136
top acc: 0.0434 ::: bot acc: 0.0066
top acc: 0.0123 ::: bot acc: 0.0222
current epoch: 36
train loss is 0.053120
average val loss: 0.067458, accuracy: 0.0675
average test loss: 0.064902, accuracy: 0.0649
case acc: 0.1003027
case acc: 0.08658318
case acc: 0.04858015
case acc: 0.046586625
case acc: 0.04628829
case acc: 0.06119286
top acc: 0.0860 ::: bot acc: 0.1148
top acc: 0.0745 ::: bot acc: 0.0994
top acc: 0.0282 ::: bot acc: 0.0699
top acc: 0.0324 ::: bot acc: 0.0605
top acc: 0.0270 ::: bot acc: 0.0666
top acc: 0.0439 ::: bot acc: 0.0783
current epoch: 37
train loss is 0.047530
average val loss: 0.040788, accuracy: 0.0410
average test loss: 0.037991, accuracy: 0.0383
case acc: 0.0645892
case acc: 0.058626343
case acc: 0.024295028
case acc: 0.029623957
case acc: 0.027860986
case acc: 0.024564682
top acc: 0.0502 ::: bot acc: 0.0791
top acc: 0.0466 ::: bot acc: 0.0715
top acc: 0.0094 ::: bot acc: 0.0429
top acc: 0.0162 ::: bot acc: 0.0433
top acc: 0.0108 ::: bot acc: 0.0471
top acc: 0.0088 ::: bot acc: 0.0409
current epoch: 38
train loss is 0.035504
average val loss: 0.038705, accuracy: 0.0388
average test loss: 0.035925, accuracy: 0.0361
case acc: 0.0522048
case acc: 0.0498183
case acc: 0.025371574
case acc: 0.036411297
case acc: 0.032772318
case acc: 0.020279162
top acc: 0.0378 ::: bot acc: 0.0667
top acc: 0.0378 ::: bot acc: 0.0626
top acc: 0.0099 ::: bot acc: 0.0443
top acc: 0.0223 ::: bot acc: 0.0505
top acc: 0.0148 ::: bot acc: 0.0525
top acc: 0.0064 ::: bot acc: 0.0357
current epoch: 39
train loss is 0.029945
average val loss: 0.038164, accuracy: 0.0382
average test loss: 0.035408, accuracy: 0.0355
case acc: 0.041118313
case acc: 0.04165874
case acc: 0.0287657
case acc: 0.044443905
case acc: 0.03751846
case acc: 0.01965067
top acc: 0.0268 ::: bot acc: 0.0556
top acc: 0.0296 ::: bot acc: 0.0544
top acc: 0.0117 ::: bot acc: 0.0485
top acc: 0.0302 ::: bot acc: 0.0585
top acc: 0.0189 ::: bot acc: 0.0575
top acc: 0.0062 ::: bot acc: 0.0348
current epoch: 40
train loss is 0.025262
average val loss: 0.032592, accuracy: 0.0325
average test loss: 0.029760, accuracy: 0.0297
case acc: 0.024941105
case acc: 0.026468826
case acc: 0.028619355
case acc: 0.04536608
case acc: 0.03531359
case acc: 0.017553264
top acc: 0.0114 ::: bot acc: 0.0390
top acc: 0.0144 ::: bot acc: 0.0392
top acc: 0.0116 ::: bot acc: 0.0483
top acc: 0.0311 ::: bot acc: 0.0594
top acc: 0.0170 ::: bot acc: 0.0552
top acc: 0.0061 ::: bot acc: 0.0318
current epoch: 41
train loss is 0.022544
average val loss: 0.027356, accuracy: 0.0270
average test loss: 0.024645, accuracy: 0.0241
case acc: 0.012738425
case acc: 0.011943567
case acc: 0.027579105
case acc: 0.04359708
case acc: 0.032142226
case acc: 0.016817726
top acc: 0.0067 ::: bot acc: 0.0231
top acc: 0.0043 ::: bot acc: 0.0226
top acc: 0.0111 ::: bot acc: 0.0471
top acc: 0.0293 ::: bot acc: 0.0576
top acc: 0.0142 ::: bot acc: 0.0518
top acc: 0.0062 ::: bot acc: 0.0308
current epoch: 42
train loss is 0.027607
average val loss: 0.020258, accuracy: 0.0208
average test loss: 0.019972, accuracy: 0.0202
case acc: 0.027918415
case acc: 0.030076241
case acc: 0.0150888655
case acc: 0.018821817
case acc: 0.014967812
case acc: 0.014367119
top acc: 0.0422 ::: bot acc: 0.0135
top acc: 0.0421 ::: bot acc: 0.0174
top acc: 0.0206 ::: bot acc: 0.0220
top acc: 0.0076 ::: bot acc: 0.0313
top acc: 0.0134 ::: bot acc: 0.0264
top acc: 0.0263 ::: bot acc: 0.0083
current epoch: 43
train loss is 0.039171
average val loss: 0.054472, accuracy: 0.0545
average test loss: 0.056843, accuracy: 0.0569
case acc: 0.07882701
case acc: 0.09053032
case acc: 0.04636932
case acc: 0.035642784
case acc: 0.043080322
case acc: 0.04685207
top acc: 0.0931 ::: bot acc: 0.0644
top acc: 0.1025 ::: bot acc: 0.0778
top acc: 0.0664 ::: bot acc: 0.0264
top acc: 0.0498 ::: bot acc: 0.0220
top acc: 0.0625 ::: bot acc: 0.0227
top acc: 0.0642 ::: bot acc: 0.0296
current epoch: 44
train loss is 0.053359
average val loss: 0.049013, accuracy: 0.0491
average test loss: 0.051369, accuracy: 0.0514
case acc: 0.06518396
case acc: 0.083373986
case acc: 0.042963978
case acc: 0.038953252
case acc: 0.042173717
case acc: 0.035822496
top acc: 0.0795 ::: bot acc: 0.0508
top acc: 0.0954 ::: bot acc: 0.0706
top acc: 0.0628 ::: bot acc: 0.0234
top acc: 0.0531 ::: bot acc: 0.0252
top acc: 0.0616 ::: bot acc: 0.0218
top acc: 0.0531 ::: bot acc: 0.0186
current epoch: 45
train loss is 0.042416
average val loss: 0.031038, accuracy: 0.0311
average test loss: 0.033141, accuracy: 0.0332
case acc: 0.03687747
case acc: 0.055542786
case acc: 0.029334217
case acc: 0.027659386
case acc: 0.029613866
case acc: 0.020459782
top acc: 0.0512 ::: bot acc: 0.0225
top acc: 0.0676 ::: bot acc: 0.0428
top acc: 0.0478 ::: bot acc: 0.0125
top acc: 0.0414 ::: bot acc: 0.0148
top acc: 0.0489 ::: bot acc: 0.0095
top acc: 0.0364 ::: bot acc: 0.0061
current epoch: 46
train loss is 0.027379
average val loss: 0.027856, accuracy: 0.0279
average test loss: 0.029933, accuracy: 0.0299
case acc: 0.024198927
case acc: 0.040773086
case acc: 0.030993352
case acc: 0.0299882
case acc: 0.031105356
case acc: 0.022631593
top acc: 0.0382 ::: bot acc: 0.0104
top acc: 0.0528 ::: bot acc: 0.0280
top acc: 0.0497 ::: bot acc: 0.0137
top acc: 0.0439 ::: bot acc: 0.0168
top acc: 0.0505 ::: bot acc: 0.0108
top acc: 0.0391 ::: bot acc: 0.0072
current epoch: 47
train loss is 0.019618
average val loss: 0.022572, accuracy: 0.0224
average test loss: 0.024312, accuracy: 0.0242
case acc: 0.012534622
case acc: 0.026222302
case acc: 0.028910894
case acc: 0.030023202
case acc: 0.02913473
case acc: 0.018553436
top acc: 0.0224 ::: bot acc: 0.0072
top acc: 0.0382 ::: bot acc: 0.0137
top acc: 0.0473 ::: bot acc: 0.0123
top acc: 0.0439 ::: bot acc: 0.0169
top acc: 0.0484 ::: bot acc: 0.0091
top acc: 0.0337 ::: bot acc: 0.0057
current epoch: 48
train loss is 0.014998
average val loss: 0.022824, accuracy: 0.0225
average test loss: 0.024405, accuracy: 0.0242
case acc: 0.010467374
case acc: 0.021037774
case acc: 0.03031996
case acc: 0.03364403
case acc: 0.031876698
case acc: 0.017964633
top acc: 0.0167 ::: bot acc: 0.0119
top acc: 0.0327 ::: bot acc: 0.0091
top acc: 0.0490 ::: bot acc: 0.0132
top acc: 0.0477 ::: bot acc: 0.0202
top acc: 0.0513 ::: bot acc: 0.0115
top acc: 0.0329 ::: bot acc: 0.0056
current epoch: 49
train loss is 0.019984
average val loss: 0.023908, accuracy: 0.0235
average test loss: 0.025354, accuracy: 0.0251
case acc: 0.010265377
case acc: 0.015180705
case acc: 0.032703318
case acc: 0.036048885
case acc: 0.035718754
case acc: 0.02044419
top acc: 0.0133 ::: bot acc: 0.0154
top acc: 0.0257 ::: bot acc: 0.0056
top acc: 0.0516 ::: bot acc: 0.0150
top acc: 0.0501 ::: bot acc: 0.0225
top acc: 0.0551 ::: bot acc: 0.0153
top acc: 0.0364 ::: bot acc: 0.0061
current epoch: 50
train loss is 0.029142
average val loss: 0.021201, accuracy: 0.0216
average test loss: 0.019634, accuracy: 0.0205
case acc: 0.037943218
case acc: 0.029707277
case acc: 0.015087078
case acc: 0.010300323
case acc: 0.015743935
case acc: 0.014099252
top acc: 0.0237 ::: bot acc: 0.0523
top acc: 0.0177 ::: bot acc: 0.0425
top acc: 0.0211 ::: bot acc: 0.0215
top acc: 0.0175 ::: bot acc: 0.0105
top acc: 0.0259 ::: bot acc: 0.0139
top acc: 0.0094 ::: bot acc: 0.0252
LME_Co_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6804 6804 6804
1.7082474 -0.6288155 0.10460696 -0.09017589
Validation: 756 756 756
Testing: 768 768 768
pre-processing time: 0.00041937828063964844
the split date is 2011-07-01
net initializing with time: 0.023526906967163086
preparing training and testing date with time: 2.384185791015625e-07
current epoch: 1
train loss is 0.280169
average val loss: 0.245311, accuracy: 0.2454
average test loss: 0.244686, accuracy: 0.2447
case acc: 0.43484163
case acc: 0.37054956
case acc: 0.03689368
case acc: 0.18748842
case acc: 0.38414043
case acc: 0.05431226
top acc: 0.4444 ::: bot acc: 0.4204
top acc: 0.3819 ::: bot acc: 0.3604
top acc: 0.0568 ::: bot acc: 0.0180
top acc: 0.1986 ::: bot acc: 0.1753
top acc: 0.4004 ::: bot acc: 0.3660
top acc: 0.0704 ::: bot acc: 0.0379
current epoch: 2
train loss is 0.261024
average val loss: 0.148960, accuracy: 0.1488
average test loss: 0.148899, accuracy: 0.1487
case acc: 0.22941035
case acc: 0.17110853
case acc: 0.15127714
case acc: 0.012291281
case acc: 0.18285613
case acc: 0.1451579
top acc: 0.2397 ::: bot acc: 0.2155
top acc: 0.1822 ::: bot acc: 0.1609
top acc: 0.1308 ::: bot acc: 0.1714
top acc: 0.0084 ::: bot acc: 0.0207
top acc: 0.1992 ::: bot acc: 0.1649
top acc: 0.1288 ::: bot acc: 0.1619
current epoch: 3
train loss is 0.151909
average val loss: 0.160279, accuracy: 0.1605
average test loss: 0.160384, accuracy: 0.1607
case acc: 0.29240412
case acc: 0.24064715
case acc: 0.057616286
case acc: 0.07221535
case acc: 0.25137323
case acc: 0.050210662
top acc: 0.3030 ::: bot acc: 0.2787
top acc: 0.2517 ::: bot acc: 0.2304
top acc: 0.0374 ::: bot acc: 0.0776
top acc: 0.0830 ::: bot acc: 0.0606
top acc: 0.2677 ::: bot acc: 0.2334
top acc: 0.0352 ::: bot acc: 0.0664
current epoch: 4
train loss is 0.158108
average val loss: 0.135773, accuracy: 0.1360
average test loss: 0.135868, accuracy: 0.1361
case acc: 0.23730773
case acc: 0.19246924
case acc: 0.07997709
case acc: 0.03604964
case acc: 0.20192578
case acc: 0.068723574
top acc: 0.2482 ::: bot acc: 0.2238
top acc: 0.2034 ::: bot acc: 0.1823
top acc: 0.0595 ::: bot acc: 0.1002
top acc: 0.0467 ::: bot acc: 0.0245
top acc: 0.2183 ::: bot acc: 0.1840
top acc: 0.0522 ::: bot acc: 0.0859
current epoch: 5
train loss is 0.136761
average val loss: 0.129956, accuracy: 0.1302
average test loss: 0.130070, accuracy: 0.1305
case acc: 0.23855138
case acc: 0.20109959
case acc: 0.044706807
case acc: 0.05780956
case acc: 0.20883603
case acc: 0.031917136
top acc: 0.2495 ::: bot acc: 0.2251
top acc: 0.2120 ::: bot acc: 0.1909
top acc: 0.0250 ::: bot acc: 0.0646
top acc: 0.0684 ::: bot acc: 0.0463
top acc: 0.2253 ::: bot acc: 0.1909
top acc: 0.0180 ::: bot acc: 0.0479
current epoch: 6
train loss is 0.125406
average val loss: 0.114383, accuracy: 0.1147
average test loss: 0.114483, accuracy: 0.1149
case acc: 0.20964614
case acc: 0.17943703
case acc: 0.04077632
case acc: 0.04845498
case acc: 0.18552074
case acc: 0.025782397
top acc: 0.2207 ::: bot acc: 0.1963
top acc: 0.1904 ::: bot acc: 0.1693
top acc: 0.0216 ::: bot acc: 0.0604
top acc: 0.0590 ::: bot acc: 0.0370
top acc: 0.2020 ::: bot acc: 0.1676
top acc: 0.0132 ::: bot acc: 0.0413
current epoch: 7
train loss is 0.113638
average val loss: 0.105118, accuracy: 0.1056
average test loss: 0.104767, accuracy: 0.1055
case acc: 0.19441158
case acc: 0.17154048
case acc: 0.025192015
case acc: 0.052656073
case acc: 0.17592978
case acc: 0.013259725
top acc: 0.2057 ::: bot acc: 0.1812
top acc: 0.1824 ::: bot acc: 0.1614
top acc: 0.0103 ::: bot acc: 0.0428
top acc: 0.0632 ::: bot acc: 0.0411
top acc: 0.1924 ::: bot acc: 0.1579
top acc: 0.0133 ::: bot acc: 0.0220
current epoch: 8
train loss is 0.101102
average val loss: 0.090940, accuracy: 0.0915
average test loss: 0.090436, accuracy: 0.0912
case acc: 0.16582802
case acc: 0.15023977
case acc: 0.022439728
case acc: 0.04286543
case acc: 0.15294552
case acc: 0.013102839
top acc: 0.1773 ::: bot acc: 0.1528
top acc: 0.1611 ::: bot acc: 0.1402
top acc: 0.0089 ::: bot acc: 0.0395
top acc: 0.0534 ::: bot acc: 0.0314
top acc: 0.1695 ::: bot acc: 0.1350
top acc: 0.0187 ::: bot acc: 0.0169
current epoch: 9
train loss is 0.089583
average val loss: 0.089510, accuracy: 0.0901
average test loss: 0.088563, accuracy: 0.0893
case acc: 0.15424979
case acc: 0.14613909
case acc: 0.014782732
case acc: 0.050061937
case acc: 0.14707483
case acc: 0.023757977
top acc: 0.1658 ::: bot acc: 0.1412
top acc: 0.1569 ::: bot acc: 0.1361
top acc: 0.0219 ::: bot acc: 0.0190
top acc: 0.0606 ::: bot acc: 0.0386
top acc: 0.1636 ::: bot acc: 0.1291
top acc: 0.0395 ::: bot acc: 0.0088
current epoch: 10
train loss is 0.079614
average val loss: 0.078852, accuracy: 0.0794
average test loss: 0.077881, accuracy: 0.0785
case acc: 0.12865531
case acc: 0.1281638
case acc: 0.015944147
case acc: 0.04298097
case acc: 0.12744811
case acc: 0.02804489
top acc: 0.1403 ::: bot acc: 0.1157
top acc: 0.1389 ::: bot acc: 0.1181
top acc: 0.0275 ::: bot acc: 0.0134
top acc: 0.0535 ::: bot acc: 0.0315
top acc: 0.1440 ::: bot acc: 0.1094
top acc: 0.0442 ::: bot acc: 0.0122
current epoch: 11
train loss is 0.068798
average val loss: 0.073035, accuracy: 0.0734
average test loss: 0.072105, accuracy: 0.0725
case acc: 0.1083061
case acc: 0.11556485
case acc: 0.021340368
case acc: 0.04081429
case acc: 0.113142475
case acc: 0.035762288
top acc: 0.1200 ::: bot acc: 0.0954
top acc: 0.1264 ::: bot acc: 0.1055
top acc: 0.0378 ::: bot acc: 0.0090
top acc: 0.0514 ::: bot acc: 0.0293
top acc: 0.1298 ::: bot acc: 0.0950
top acc: 0.0524 ::: bot acc: 0.0189
current epoch: 12
train loss is 0.060856
average val loss: 0.069929, accuracy: 0.0701
average test loss: 0.069014, accuracy: 0.0691
case acc: 0.09118438
case acc: 0.10639126
case acc: 0.031015163
case acc: 0.041290767
case acc: 0.1022735
case acc: 0.04265032
top acc: 0.1030 ::: bot acc: 0.0784
top acc: 0.1172 ::: bot acc: 0.0963
top acc: 0.0502 ::: bot acc: 0.0132
top acc: 0.0518 ::: bot acc: 0.0298
top acc: 0.1189 ::: bot acc: 0.0842
top acc: 0.0596 ::: bot acc: 0.0253
current epoch: 13
train loss is 0.053004
average val loss: 0.058287, accuracy: 0.0584
average test loss: 0.057368, accuracy: 0.0574
case acc: 0.06628772
case acc: 0.08955544
case acc: 0.0337924
case acc: 0.033243112
case acc: 0.0836993
case acc: 0.038012262
top acc: 0.0783 ::: bot acc: 0.0536
top acc: 0.1004 ::: bot acc: 0.0794
top acc: 0.0532 ::: bot acc: 0.0154
top acc: 0.0437 ::: bot acc: 0.0218
top acc: 0.1004 ::: bot acc: 0.0656
top acc: 0.0548 ::: bot acc: 0.0209
current epoch: 14
train loss is 0.044305
average val loss: 0.053330, accuracy: 0.0534
average test loss: 0.052415, accuracy: 0.0524
case acc: 0.050266467
case acc: 0.080832675
case acc: 0.042257033
case acc: 0.031932887
case acc: 0.072879046
case acc: 0.036184583
top acc: 0.0624 ::: bot acc: 0.0376
top acc: 0.0916 ::: bot acc: 0.0706
top acc: 0.0622 ::: bot acc: 0.0226
top acc: 0.0424 ::: bot acc: 0.0205
top acc: 0.0896 ::: bot acc: 0.0548
top acc: 0.0529 ::: bot acc: 0.0192
current epoch: 15
train loss is 0.037598
average val loss: 0.047735, accuracy: 0.0477
average test loss: 0.046851, accuracy: 0.0468
case acc: 0.036537148
case acc: 0.07255942
case acc: 0.04894817
case acc: 0.02960487
case acc: 0.06255388
case acc: 0.030525599
top acc: 0.0488 ::: bot acc: 0.0239
top acc: 0.0833 ::: bot acc: 0.0623
top acc: 0.0690 ::: bot acc: 0.0289
top acc: 0.0400 ::: bot acc: 0.0182
top acc: 0.0791 ::: bot acc: 0.0448
top acc: 0.0469 ::: bot acc: 0.0142
current epoch: 16
train loss is 0.032342
average val loss: 0.045598, accuracy: 0.0455
average test loss: 0.044768, accuracy: 0.0447
case acc: 0.029186163
case acc: 0.0684074
case acc: 0.0570872
case acc: 0.030242367
case acc: 0.056517504
case acc: 0.026784297
top acc: 0.0415 ::: bot acc: 0.0168
top acc: 0.0792 ::: bot acc: 0.0582
top acc: 0.0771 ::: bot acc: 0.0370
top acc: 0.0407 ::: bot acc: 0.0189
top acc: 0.0730 ::: bot acc: 0.0390
top acc: 0.0428 ::: bot acc: 0.0111
current epoch: 17
train loss is 0.030175
average val loss: 0.059605, accuracy: 0.0595
average test loss: 0.058810, accuracy: 0.0588
case acc: 0.039654844
case acc: 0.08071594
case acc: 0.07902737
case acc: 0.046958417
case acc: 0.06755919
case acc: 0.038941115
top acc: 0.0521 ::: bot acc: 0.0271
top acc: 0.0915 ::: bot acc: 0.0705
top acc: 0.0990 ::: bot acc: 0.0590
top acc: 0.0574 ::: bot acc: 0.0356
top acc: 0.0842 ::: bot acc: 0.0496
top acc: 0.0555 ::: bot acc: 0.0220
current epoch: 18
train loss is 0.033639
average val loss: 0.078708, accuracy: 0.0787
average test loss: 0.077950, accuracy: 0.0780
case acc: 0.053856477
case acc: 0.098178566
case acc: 0.10438058
case acc: 0.06935415
case acc: 0.085060865
case acc: 0.056912437
top acc: 0.0664 ::: bot acc: 0.0414
top acc: 0.1089 ::: bot acc: 0.0880
top acc: 0.1243 ::: bot acc: 0.0844
top acc: 0.0798 ::: bot acc: 0.0580
top acc: 0.1017 ::: bot acc: 0.0670
top acc: 0.0738 ::: bot acc: 0.0393
current epoch: 19
train loss is 0.042495
average val loss: 0.094553, accuracy: 0.0945
average test loss: 0.093857, accuracy: 0.0939
case acc: 0.062575676
case acc: 0.112780035
case acc: 0.12513904
case acc: 0.08954457
case acc: 0.10111125
case acc: 0.071951
top acc: 0.0751 ::: bot acc: 0.0501
top acc: 0.1234 ::: bot acc: 0.1026
top acc: 0.1451 ::: bot acc: 0.1051
top acc: 0.1000 ::: bot acc: 0.0783
top acc: 0.1178 ::: bot acc: 0.0830
top acc: 0.0890 ::: bot acc: 0.0539
current epoch: 20
train loss is 0.059514
average val loss: 0.059880, accuracy: 0.0597
average test loss: 0.059200, accuracy: 0.0591
case acc: 0.020192306
case acc: 0.07637532
case acc: 0.08918159
case acc: 0.05884283
case acc: 0.06903395
case acc: 0.04088159
top acc: 0.0324 ::: bot acc: 0.0086
top acc: 0.0870 ::: bot acc: 0.0663
top acc: 0.1091 ::: bot acc: 0.0691
top acc: 0.0692 ::: bot acc: 0.0476
top acc: 0.0856 ::: bot acc: 0.0511
top acc: 0.0574 ::: bot acc: 0.0240
current epoch: 21
train loss is 0.064805
average val loss: 0.021569, accuracy: 0.0221
average test loss: 0.020927, accuracy: 0.0209
case acc: 0.055206515
case acc: 0.007642456
case acc: 0.017067518
case acc: 0.01295284
case acc: 0.012716724
case acc: 0.019581378
top acc: 0.0425 ::: bot acc: 0.0676
top acc: 0.0128 ::: bot acc: 0.0079
top acc: 0.0305 ::: bot acc: 0.0103
top acc: 0.0053 ::: bot acc: 0.0228
top acc: 0.0177 ::: bot acc: 0.0171
top acc: 0.0084 ::: bot acc: 0.0347
current epoch: 22
train loss is 0.050733
average val loss: 0.020649, accuracy: 0.0213
average test loss: 0.019998, accuracy: 0.0205
case acc: 0.053233057
case acc: 0.009159426
case acc: 0.014809196
case acc: 0.02035098
case acc: 0.012564976
case acc: 0.012913938
top acc: 0.0405 ::: bot acc: 0.0656
top acc: 0.0052 ::: bot acc: 0.0161
top acc: 0.0150 ::: bot acc: 0.0250
top acc: 0.0109 ::: bot acc: 0.0311
top acc: 0.0146 ::: bot acc: 0.0201
top acc: 0.0127 ::: bot acc: 0.0224
current epoch: 23
train loss is 0.036802
average val loss: 0.020963, accuracy: 0.0213
average test loss: 0.020481, accuracy: 0.0209
case acc: 0.043281883
case acc: 0.010247479
case acc: 0.019327767
case acc: 0.023501944
case acc: 0.0125898225
case acc: 0.016185176
top acc: 0.0305 ::: bot acc: 0.0556
top acc: 0.0045 ::: bot acc: 0.0180
top acc: 0.0084 ::: bot acc: 0.0350
top acc: 0.0136 ::: bot acc: 0.0344
top acc: 0.0167 ::: bot acc: 0.0180
top acc: 0.0284 ::: bot acc: 0.0080
current epoch: 24
train loss is 0.028764
average val loss: 0.029736, accuracy: 0.0299
average test loss: 0.029803, accuracy: 0.0301
case acc: 0.0476856
case acc: 0.023212083
case acc: 0.039532647
case acc: 0.04066033
case acc: 0.016155165
case acc: 0.013556897
top acc: 0.0349 ::: bot acc: 0.0599
top acc: 0.0130 ::: bot acc: 0.0331
top acc: 0.0212 ::: bot acc: 0.0588
top acc: 0.0302 ::: bot acc: 0.0519
top acc: 0.0072 ::: bot acc: 0.0305
top acc: 0.0219 ::: bot acc: 0.0132
current epoch: 25
train loss is 0.032045
average val loss: 0.047726, accuracy: 0.0477
average test loss: 0.048215, accuracy: 0.0483
case acc: 0.05915417
case acc: 0.04402404
case acc: 0.06792341
case acc: 0.06597988
case acc: 0.03373327
case acc: 0.01911171
top acc: 0.0464 ::: bot acc: 0.0714
top acc: 0.0335 ::: bot acc: 0.0541
top acc: 0.0480 ::: bot acc: 0.0880
top acc: 0.0556 ::: bot acc: 0.0772
top acc: 0.0179 ::: bot acc: 0.0514
top acc: 0.0082 ::: bot acc: 0.0342
current epoch: 26
train loss is 0.055102
average val loss: 0.026116, accuracy: 0.0260
average test loss: 0.026007, accuracy: 0.0262
case acc: 0.023749195
case acc: 0.017104397
case acc: 0.043827843
case acc: 0.043761976
case acc: 0.01411034
case acc: 0.014374268
top acc: 0.0120 ::: bot acc: 0.0354
top acc: 0.0076 ::: bot acc: 0.0267
top acc: 0.0248 ::: bot acc: 0.0635
top acc: 0.0333 ::: bot acc: 0.0550
top acc: 0.0082 ::: bot acc: 0.0269
top acc: 0.0244 ::: bot acc: 0.0107
current epoch: 27
train loss is 0.063168
average val loss: 0.051519, accuracy: 0.0517
average test loss: 0.051029, accuracy: 0.0510
case acc: 0.057515867
case acc: 0.05934821
case acc: 0.034694076
case acc: 0.027564062
case acc: 0.061224997
case acc: 0.06544225
top acc: 0.0703 ::: bot acc: 0.0453
top acc: 0.0698 ::: bot acc: 0.0493
top acc: 0.0541 ::: bot acc: 0.0158
top acc: 0.0380 ::: bot acc: 0.0164
top acc: 0.0777 ::: bot acc: 0.0435
top acc: 0.0824 ::: bot acc: 0.0476
current epoch: 28
train loss is 0.043663
average val loss: 0.034218, accuracy: 0.0342
average test loss: 0.033637, accuracy: 0.0336
case acc: 0.037785925
case acc: 0.045398444
case acc: 0.028099326
case acc: 0.014909975
case acc: 0.04272253
case acc: 0.032391176
top acc: 0.0506 ::: bot acc: 0.0256
top acc: 0.0559 ::: bot acc: 0.0353
top acc: 0.0468 ::: bot acc: 0.0108
top acc: 0.0242 ::: bot acc: 0.0060
top acc: 0.0588 ::: bot acc: 0.0258
top acc: 0.0486 ::: bot acc: 0.0161
current epoch: 29
train loss is 0.030271
average val loss: 0.031054, accuracy: 0.0309
average test loss: 0.030358, accuracy: 0.0303
case acc: 0.030972004
case acc: 0.0449123
case acc: 0.03525047
case acc: 0.0157275
case acc: 0.03784314
case acc: 0.017201526
top acc: 0.0438 ::: bot acc: 0.0189
top acc: 0.0554 ::: bot acc: 0.0348
top acc: 0.0547 ::: bot acc: 0.0163
top acc: 0.0252 ::: bot acc: 0.0065
top acc: 0.0538 ::: bot acc: 0.0212
top acc: 0.0304 ::: bot acc: 0.0071
current epoch: 30
train loss is 0.024449
average val loss: 0.041932, accuracy: 0.0419
average test loss: 0.041366, accuracy: 0.0414
case acc: 0.03916859
case acc: 0.057940457
case acc: 0.057116553
case acc: 0.029846024
case acc: 0.04656659
case acc: 0.018022003
top acc: 0.0520 ::: bot acc: 0.0270
top acc: 0.0684 ::: bot acc: 0.0479
top acc: 0.0771 ::: bot acc: 0.0370
top acc: 0.0403 ::: bot acc: 0.0187
top acc: 0.0628 ::: bot acc: 0.0294
top acc: 0.0317 ::: bot acc: 0.0070
current epoch: 31
train loss is 0.025259
average val loss: 0.066436, accuracy: 0.0664
average test loss: 0.065969, accuracy: 0.0660
case acc: 0.05693204
case acc: 0.082077295
case acc: 0.09331697
case acc: 0.058628798
case acc: 0.06803842
case acc: 0.037069887
top acc: 0.0698 ::: bot acc: 0.0448
top acc: 0.0926 ::: bot acc: 0.0720
top acc: 0.1133 ::: bot acc: 0.0732
top acc: 0.0691 ::: bot acc: 0.0475
top acc: 0.0846 ::: bot acc: 0.0501
top acc: 0.0534 ::: bot acc: 0.0204
current epoch: 32
train loss is 0.045946
average val loss: 0.072194, accuracy: 0.0721
average test loss: 0.071726, accuracy: 0.0717
case acc: 0.052747715
case acc: 0.08589562
case acc: 0.10602528
case acc: 0.06879341
case acc: 0.07277537
case acc: 0.044239853
top acc: 0.0655 ::: bot acc: 0.0406
top acc: 0.0964 ::: bot acc: 0.0759
top acc: 0.1260 ::: bot acc: 0.0859
top acc: 0.0793 ::: bot acc: 0.0577
top acc: 0.0894 ::: bot acc: 0.0547
top acc: 0.0608 ::: bot acc: 0.0271
current epoch: 33
train loss is 0.060989
average val loss: 0.020105, accuracy: 0.0203
average test loss: 0.019331, accuracy: 0.0189
case acc: 0.023303736
case acc: 0.015657546
case acc: 0.03570557
case acc: 0.00852768
case acc: 0.014689004
case acc: 0.015427149
top acc: 0.0118 ::: bot acc: 0.0349
top acc: 0.0261 ::: bot acc: 0.0057
top acc: 0.0552 ::: bot acc: 0.0167
top acc: 0.0140 ::: bot acc: 0.0076
top acc: 0.0245 ::: bot acc: 0.0106
top acc: 0.0080 ::: bot acc: 0.0287
current epoch: 34
train loss is 0.047551
average val loss: 0.019820, accuracy: 0.0202
average test loss: 0.019382, accuracy: 0.0195
case acc: 0.03979688
case acc: 0.009989008
case acc: 0.015195681
case acc: 0.01960188
case acc: 0.014842646
case acc: 0.017341536
top acc: 0.0270 ::: bot acc: 0.0520
top acc: 0.0044 ::: bot acc: 0.0176
top acc: 0.0255 ::: bot acc: 0.0146
top acc: 0.0103 ::: bot acc: 0.0302
top acc: 0.0075 ::: bot acc: 0.0283
top acc: 0.0075 ::: bot acc: 0.0318
current epoch: 35
train loss is 0.031590
average val loss: 0.015536, accuracy: 0.0157
average test loss: 0.014547, accuracy: 0.0145
case acc: 0.021558927
case acc: 0.0074563385
case acc: 0.015455289
case acc: 0.012756621
case acc: 0.0130087305
case acc: 0.017055089
top acc: 0.0106 ::: bot acc: 0.0328
top acc: 0.0120 ::: bot acc: 0.0085
top acc: 0.0264 ::: bot acc: 0.0137
top acc: 0.0052 ::: bot acc: 0.0224
top acc: 0.0195 ::: bot acc: 0.0153
top acc: 0.0302 ::: bot acc: 0.0070
current epoch: 36
train loss is 0.023643
average val loss: 0.016643, accuracy: 0.0168
average test loss: 0.015989, accuracy: 0.0163
case acc: 0.02108666
case acc: 0.0091868285
case acc: 0.017365295
case acc: 0.021251895
case acc: 0.012543021
case acc: 0.01636884
top acc: 0.0103 ::: bot acc: 0.0323
top acc: 0.0050 ::: bot acc: 0.0161
top acc: 0.0098 ::: bot acc: 0.0314
top acc: 0.0117 ::: bot acc: 0.0319
top acc: 0.0150 ::: bot acc: 0.0198
top acc: 0.0289 ::: bot acc: 0.0076
current epoch: 37
train loss is 0.020436
average val loss: 0.023434, accuracy: 0.0235
average test loss: 0.023403, accuracy: 0.0236
case acc: 0.024666343
case acc: 0.017920092
case acc: 0.03367608
case acc: 0.035853233
case acc: 0.016275583
case acc: 0.012922082
top acc: 0.0129 ::: bot acc: 0.0363
top acc: 0.0083 ::: bot acc: 0.0275
top acc: 0.0161 ::: bot acc: 0.0526
top acc: 0.0254 ::: bot acc: 0.0470
top acc: 0.0072 ::: bot acc: 0.0306
top acc: 0.0124 ::: bot acc: 0.0225
current epoch: 38
train loss is 0.023359
average val loss: 0.030829, accuracy: 0.0308
average test loss: 0.031097, accuracy: 0.0311
case acc: 0.024765896
case acc: 0.026052037
case acc: 0.04712063
case acc: 0.048323162
case acc: 0.023246521
case acc: 0.017030356
top acc: 0.0129 ::: bot acc: 0.0364
top acc: 0.0158 ::: bot acc: 0.0359
top acc: 0.0278 ::: bot acc: 0.0669
top acc: 0.0379 ::: bot acc: 0.0595
top acc: 0.0095 ::: bot acc: 0.0399
top acc: 0.0075 ::: bot acc: 0.0314
current epoch: 39
train loss is 0.029260
average val loss: 0.036190, accuracy: 0.0360
average test loss: 0.036567, accuracy: 0.0366
case acc: 0.022019017
case acc: 0.031371944
case acc: 0.055927567
case acc: 0.058503117
case acc: 0.029937636
case acc: 0.021620063
top acc: 0.0109 ::: bot acc: 0.0333
top acc: 0.0210 ::: bot acc: 0.0413
top acc: 0.0362 ::: bot acc: 0.0759
top acc: 0.0480 ::: bot acc: 0.0697
top acc: 0.0146 ::: bot acc: 0.0473
top acc: 0.0097 ::: bot acc: 0.0371
current epoch: 40
train loss is 0.047780
average val loss: 0.027021, accuracy: 0.0270
average test loss: 0.026291, accuracy: 0.0264
case acc: 0.045241363
case acc: 0.028853562
case acc: 0.015460495
case acc: 0.007939791
case acc: 0.027400447
case acc: 0.03332135
top acc: 0.0581 ::: bot acc: 0.0331
top acc: 0.0394 ::: bot acc: 0.0189
top acc: 0.0265 ::: bot acc: 0.0135
top acc: 0.0078 ::: bot acc: 0.0139
top acc: 0.0426 ::: bot acc: 0.0123
top acc: 0.0495 ::: bot acc: 0.0171
current epoch: 41
train loss is 0.048156
average val loss: 0.044781, accuracy: 0.0448
average test loss: 0.044343, accuracy: 0.0443
case acc: 0.065548256
case acc: 0.053884298
case acc: 0.038168106
case acc: 0.022258898
case acc: 0.04665923
case acc: 0.039154794
top acc: 0.0784 ::: bot acc: 0.0534
top acc: 0.0644 ::: bot acc: 0.0439
top acc: 0.0577 ::: bot acc: 0.0188
top acc: 0.0325 ::: bot acc: 0.0115
top acc: 0.0629 ::: bot acc: 0.0295
top acc: 0.0556 ::: bot acc: 0.0224
current epoch: 42
train loss is 0.033889
average val loss: 0.044967, accuracy: 0.0450
average test loss: 0.044557, accuracy: 0.0446
case acc: 0.05830529
case acc: 0.05678888
case acc: 0.05063357
case acc: 0.028693214
case acc: 0.046428192
case acc: 0.026490472
top acc: 0.0711 ::: bot acc: 0.0462
top acc: 0.0673 ::: bot acc: 0.0468
top acc: 0.0706 ::: bot acc: 0.0305
top acc: 0.0392 ::: bot acc: 0.0175
top acc: 0.0627 ::: bot acc: 0.0292
top acc: 0.0422 ::: bot acc: 0.0112
current epoch: 43
train loss is 0.029263
average val loss: 0.061226, accuracy: 0.0612
average test loss: 0.060771, accuracy: 0.0608
case acc: 0.064418636
case acc: 0.07357207
case acc: 0.08005565
case acc: 0.051292837
case acc: 0.061028123
case acc: 0.03465636
top acc: 0.0772 ::: bot acc: 0.0523
top acc: 0.0841 ::: bot acc: 0.0636
top acc: 0.1000 ::: bot acc: 0.0600
top acc: 0.0618 ::: bot acc: 0.0401
top acc: 0.0775 ::: bot acc: 0.0433
top acc: 0.0508 ::: bot acc: 0.0183
current epoch: 44
train loss is 0.045285
average val loss: 0.054325, accuracy: 0.0542
average test loss: 0.053883, accuracy: 0.0540
case acc: 0.04691703
case acc: 0.065325975
case acc: 0.080065556
case acc: 0.049596462
case acc: 0.054132067
case acc: 0.027685104
top acc: 0.0597 ::: bot acc: 0.0347
top acc: 0.0759 ::: bot acc: 0.0553
top acc: 0.1000 ::: bot acc: 0.0600
top acc: 0.0601 ::: bot acc: 0.0384
top acc: 0.0705 ::: bot acc: 0.0366
top acc: 0.0434 ::: bot acc: 0.0122
current epoch: 45
train loss is 0.051895
average val loss: 0.017216, accuracy: 0.0173
average test loss: 0.016200, accuracy: 0.0158
case acc: 0.012691574
case acc: 0.0144397095
case acc: 0.030209845
case acc: 0.008699127
case acc: 0.014770282
case acc: 0.013902914
top acc: 0.0068 ::: bot acc: 0.0215
top acc: 0.0248 ::: bot acc: 0.0048
top acc: 0.0491 ::: bot acc: 0.0122
top acc: 0.0143 ::: bot acc: 0.0075
top acc: 0.0247 ::: bot acc: 0.0105
top acc: 0.0090 ::: bot acc: 0.0259
current epoch: 46
train loss is 0.032927
average val loss: 0.017105, accuracy: 0.0169
average test loss: 0.015982, accuracy: 0.0156
case acc: 0.010875098
case acc: 0.01426787
case acc: 0.0259444
case acc: 0.0093603255
case acc: 0.017295204
case acc: 0.016118951
top acc: 0.0074 ::: bot acc: 0.0185
top acc: 0.0246 ::: bot acc: 0.0047
top acc: 0.0440 ::: bot acc: 0.0098
top acc: 0.0159 ::: bot acc: 0.0063
top acc: 0.0294 ::: bot acc: 0.0085
top acc: 0.0283 ::: bot acc: 0.0078
current epoch: 47
train loss is 0.024795
average val loss: 0.015369, accuracy: 0.0153
average test loss: 0.014151, accuracy: 0.0139
case acc: 0.012072658
case acc: 0.009425582
case acc: 0.01670339
case acc: 0.00785153
case acc: 0.016116653
case acc: 0.021002265
top acc: 0.0069 ::: bot acc: 0.0205
top acc: 0.0182 ::: bot acc: 0.0030
top acc: 0.0299 ::: bot acc: 0.0104
top acc: 0.0100 ::: bot acc: 0.0118
top acc: 0.0275 ::: bot acc: 0.0089
top acc: 0.0355 ::: bot acc: 0.0080
current epoch: 48
train loss is 0.017945
average val loss: 0.014152, accuracy: 0.0142
average test loss: 0.013112, accuracy: 0.0133
case acc: 0.0154451355
case acc: 0.0076100933
case acc: 0.01598441
case acc: 0.012271104
case acc: 0.013336111
case acc: 0.015420853
top acc: 0.0075 ::: bot acc: 0.0252
top acc: 0.0090 ::: bot acc: 0.0115
top acc: 0.0119 ::: bot acc: 0.0283
top acc: 0.0049 ::: bot acc: 0.0220
top acc: 0.0208 ::: bot acc: 0.0140
top acc: 0.0269 ::: bot acc: 0.0087
current epoch: 49
train loss is 0.016998
average val loss: 0.016767, accuracy: 0.0169
average test loss: 0.016210, accuracy: 0.0165
case acc: 0.016554622
case acc: 0.010804325
case acc: 0.025364716
case acc: 0.021042297
case acc: 0.012568377
case acc: 0.012420658
top acc: 0.0080 ::: bot acc: 0.0267
top acc: 0.0044 ::: bot acc: 0.0188
top acc: 0.0106 ::: bot acc: 0.0429
top acc: 0.0113 ::: bot acc: 0.0319
top acc: 0.0138 ::: bot acc: 0.0210
top acc: 0.0155 ::: bot acc: 0.0193
current epoch: 50
train loss is 0.017274
average val loss: 0.021446, accuracy: 0.0215
average test loss: 0.021297, accuracy: 0.0214
case acc: 0.017112333
case acc: 0.017140478
case acc: 0.034801885
case acc: 0.030935237
case acc: 0.015407791
case acc: 0.013073938
top acc: 0.0083 ::: bot acc: 0.0274
top acc: 0.0076 ::: bot acc: 0.0266
top acc: 0.0171 ::: bot acc: 0.0538
top acc: 0.0204 ::: bot acc: 0.0422
top acc: 0.0073 ::: bot acc: 0.0293
top acc: 0.0113 ::: bot acc: 0.0235
