['code/train/analyze_alstm.py', 'result/validation/alstm', 'r2_h10_b256_tune.log', 'para']
fnames: ['result/validation/alstm/r2_h10_b256_tune.log']
27 27
{'drop_out': 0.2, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.029936 0.027948 0.038739 0.036508 0.039709] 0.034568
va_acc: [0.0294 0.0281 0.0405 0.0368 0.0386] 0.03468
te_loss: [0.030178 0.035794 0.039541 0.04276  0.036684] 0.036991399999999994
te_acc: [0.0312 0.0359 0.041  0.0421 0.0372] 0.03748
{'drop_out': 0.4, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.029094 0.028197 0.036364 0.036326 0.039549] 0.033906
va_acc: [0.0284 0.0285 0.0353 0.0366 0.0383] 0.03342
te_loss: [0.029922 0.035944 0.037155 0.042688 0.036775] 0.0364968
te_acc: [0.0307 0.0362 0.0361 0.0423 0.0361] 0.03628
{'drop_out': 0.6, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.028877 0.028238 0.03911  0.035995 0.038775] 0.034199
va_acc: [0.0281 0.0282 0.0407 0.0362 0.0375] 0.034140000000000004
te_loss: [0.030282 0.036075 0.039923 0.04315  0.03562 ] 0.03701
te_acc: [0.031  0.036  0.0415 0.043  0.0356] 0.03742
{'drop_out': 0.2, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.0286   0.026764 0.040285 0.037457 0.038916] 0.0344044
va_acc: [0.0287 0.0271 0.0404 0.0382 0.0387] 0.034620000000000005
te_loss: [0.02899  0.035109 0.04121  0.044191 0.035775] 0.037055
te_acc: [0.0303 0.0351 0.0422 0.0434 0.0351] 0.037219999999999996
{'drop_out': 0.4, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.02905  0.026605 0.041685 0.037434 0.038352] 0.0346252
va_acc: [0.0299 0.0269 0.0417 0.0381 0.0381] 0.03494
te_loss: [0.031473 0.034884 0.042354 0.045862 0.035144] 0.0379434
te_acc: [0.0321 0.0349 0.0429 0.0451 0.0341] 0.03782
{'drop_out': 0.6, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.029455 0.027385 0.041113 0.0416   0.038784] 0.035667399999999995
va_acc: [0.0304 0.0277 0.0417 0.0421 0.0391] 0.036199999999999996
te_loss: [0.031986 0.035912 0.041551 0.057583 0.035695] 0.040545399999999995
te_acc: [0.0324 0.0361 0.0426 0.0573 0.0369] 0.04106
{'drop_out': 0.2, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.02834  0.027521 0.043619 0.04618  0.041227] 0.037377400000000005
va_acc: [0.0266 0.0279 0.0445 0.0461 0.0394] 0.0369
te_loss: [0.031509 0.035779 0.045139 0.057075 0.038585] 0.0416174
te_acc: [0.0313 0.0355 0.0448 0.0564 0.0382] 0.04124
{'drop_out': 0.4, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.02832  0.02806  0.037614 0.046262 0.041182] 0.036287599999999996
va_acc: [0.0267 0.0283 0.0389 0.0468 0.0392] 0.03598
te_loss: [0.030777 0.036181 0.038724 0.054954 0.038483] 0.0398238
te_acc: [0.0306 0.0346 0.0373 0.0539 0.038 ] 0.03888
{'drop_out': 0.6, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.028204 0.028234 0.045512 0.044078 0.042439] 0.0376934
va_acc: [0.0267 0.0286 0.0477 0.0436 0.045 ] 0.03832
te_loss: [0.034065 0.036355 0.047234 0.047669 0.040156] 0.0410958
te_acc: [0.0342 0.0349 0.0464 0.0471 0.0404] 0.0406
{'drop_out': 0.2, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.030175 0.028626 0.03584  0.037258 0.038122] 0.0340042
va_acc: [0.0304 0.0287 0.0355 0.0377 0.0373] 0.03391999999999999
te_loss: [0.026671 0.036824 0.036934 0.047769 0.0348  ] 0.036599599999999996
te_acc: [0.0266 0.0349 0.0365 0.0478 0.0348] 0.03612
{'drop_out': 0.4, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.030135 0.028268 0.035829 0.036683 0.038027] 0.0337884
va_acc: [0.0303 0.0279 0.0356 0.0372 0.0375] 0.0337
te_loss: [0.026724 0.03619  0.036883 0.044902 0.034684] 0.035876599999999995
te_acc: [0.0269 0.0348 0.0364 0.0451 0.0347] 0.03558
{'drop_out': 0.6, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.027406 0.028083 0.035939 0.03662  0.038671] 0.0333438
va_acc: [0.0273 0.0279 0.0355 0.0367 0.0371] 0.0329
te_loss: [0.028149 0.036253 0.036937 0.043885 0.035544] 0.036153599999999994
te_acc: [0.0287 0.0345 0.0365 0.0443 0.0353] 0.03586
{'drop_out': 0.2, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.028964 0.029043 0.037681 0.03808  0.039314] 0.034616400000000005
va_acc: [0.0302 0.0288 0.038  0.0377 0.0394] 0.03482
te_loss: [0.030964 0.036831 0.037899 0.042445 0.036263] 0.036880399999999994
te_acc: [0.0319 0.035  0.0379 0.042  0.0356] 0.03648
{'drop_out': 0.4, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.028361 0.029888 0.040039 0.03784  0.039271] 0.0350798
va_acc: [0.0279 0.03   0.0402 0.0377 0.0388] 0.03491999999999999
te_loss: [0.028614 0.03767  0.039568 0.046938 0.036199] 0.037797800000000006
te_acc: [0.0295 0.0356 0.0399 0.0467 0.0381] 0.037959999999999994
{'drop_out': 0.6, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.028967 0.029739 0.03857  0.037742 0.037881] 0.0345798
va_acc: [0.0301 0.0296 0.0393 0.0387 0.0376] 0.035059999999999994
te_loss: [0.031258 0.037431 0.038519 0.047079 0.034516] 0.0377606
te_acc: [0.0319 0.0354 0.0383 0.0468 0.0356] 0.0376
{'drop_out': 0.2, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.026945 0.03044  0.03788  0.038655 0.040868] 0.0349576
va_acc: [0.0273 0.031  0.0372 0.0387 0.0401] 0.034859999999999995
te_loss: [0.02967  0.037984 0.038704 0.050998 0.038362] 0.0391436
te_acc: [0.0301 0.0382 0.0392 0.0508 0.0382] 0.0393
{'drop_out': 0.4, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.027102 0.036169 0.038127 0.038907 0.040825] 0.036225999999999994
va_acc: [0.0272 0.034  0.0373 0.0393 0.0401] 0.03558
te_loss: [0.031032 0.043323 0.038627 0.052491 0.038283] 0.0407512
te_acc: [0.0314 0.0388 0.0392 0.0522 0.0386] 0.04004
{'drop_out': 0.6, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.027354 0.037034 0.038907 0.038605 0.041526] 0.0366852
va_acc: [0.0274 0.0367 0.0395 0.039  0.0399] 0.0365
te_loss: [0.030157 0.043068 0.040249 0.052259 0.039085] 0.0409636
te_acc: [0.0304 0.0445 0.0404 0.052  0.0392] 0.04129999999999999
{'drop_out': 0.2, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.029221 0.028876 0.035908 0.037387 0.037888] 0.033856000000000004
va_acc: [0.0294 0.0283 0.0354 0.0379 0.0377] 0.033740000000000006
te_loss: [0.026542 0.03646  0.036977 0.047755 0.034503] 0.036447400000000005
te_acc: [0.0266 0.0351 0.0366 0.0476 0.0344] 0.03606
{'drop_out': 0.4, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.030773 0.028792 0.035832 0.036779 0.038071] 0.0340494
va_acc: [0.0309 0.0281 0.0357 0.0372 0.0373] 0.03384
te_loss: [0.026592 0.036382 0.036919 0.044091 0.034734] 0.0357436
te_acc: [0.0265 0.035  0.0364 0.0444 0.0346] 0.03538
{'drop_out': 0.6, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.027592 0.028891 0.036035 0.036706 0.037994] 0.033443600000000004
va_acc: [0.0275 0.0283 0.0353 0.0373 0.0371] 0.033100000000000004
te_loss: [0.027617 0.03643  0.037025 0.046222 0.03469 ] 0.03639679999999999
te_acc: [0.0282 0.0351 0.0367 0.0465 0.0344] 0.036180000000000004
{'drop_out': 0.2, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.028098 0.030313 0.038944 0.037532 0.040615] 0.0351004
va_acc: [0.0288 0.0302 0.0394 0.0375 0.0411] 0.0354
te_loss: [0.031263 0.037708 0.038781 0.045768 0.038039] 0.03831180000000001
te_acc: [0.0321 0.0387 0.039  0.0453 0.0377] 0.038560000000000004
{'drop_out': 0.4, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.029636 0.029923 0.040414 0.037651 0.037708] 0.0350664
va_acc: [0.0306 0.0299 0.041  0.0376 0.0381] 0.03544
te_loss: [0.032691 0.037586 0.041485 0.044997 0.034351] 0.038222
te_acc: [0.0334 0.0355 0.0416 0.0445 0.0341] 0.03781999999999999
{'drop_out': 0.6, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.030494 0.030395 0.039718 0.037249 0.03765 ] 0.0351012
va_acc: [0.0314 0.0301 0.0404 0.038  0.0379] 0.03556
te_loss: [0.037818 0.037853 0.040828 0.047772 0.034286] 0.039711399999999994
te_acc: [0.0385 0.0381 0.0403 0.0477 0.0343] 0.039779999999999996
{'drop_out': 0.2, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.027072 0.037092 0.037412 0.038713 0.040202] 0.036098200000000004
va_acc: [0.0276 0.0347 0.0364 0.0389 0.0393] 0.03538
te_loss: [0.028551 0.043974 0.038358 0.051865 0.037559] 0.040061400000000004
te_acc: [0.029  0.0394 0.039  0.0518 0.0368] 0.0392
{'drop_out': 0.4, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.027025 0.038171 0.037493 0.038962 0.040326] 0.0363954
va_acc: [0.0272 0.0397 0.0369 0.0391 0.0392] 0.036419999999999994
te_loss: [0.029308 0.044023 0.038264 0.052447 0.037616] 0.0403316
te_acc: [0.0297 0.0465 0.0386 0.0523 0.0369] 0.0408
{'drop_out': 0.6, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.027083 0.033809 0.037219 0.038807 0.04073 ] 0.03552960000000001
va_acc: [0.0273 0.0343 0.0369 0.0392 0.0394] 0.03541999999999999
te_loss: [0.029292 0.040724 0.038171 0.052717 0.037971] 0.039775
te_acc: [0.0296 0.0412 0.0384 0.0526 0.0374] 0.03984
('drop_out', [0.2, 0.4, 0.6])
drop_out
number of paras: 9
number of paras: 9
number of paras: 9
[0.2, 0.4, 0.6]
va_loss: [0.03499807 0.03504713 0.03513811]
va_acc: [0.03492444 0.03491556 0.03524444]
te_loss: [0.03812311 0.03810964 0.03882358]
te_acc: [0.03796222 0.03784    0.03884889]
te_tp: [0.04719963 0.04715722 0.0475913 ]
---------------------------------------------
('hidden', [20, 30])
hidden
number of paras: 9
number of paras: 9
[20, 30]
va_loss: [0.03491567 0.03636116]
va_acc: [0.03521778 0.03615111]
te_loss: [0.03824753 0.04039593]
te_acc: [0.03825556 0.04013333]
te_tp: [0.04751    0.04815907]
---------------------------------------------
('embedding_size', [5])
('batch', [256])
('lag', [3, 4, 5])
lag
number of paras: 9
number of paras: 9
number of paras: 9
[3, 4, 5]
va_loss: [0.03541427 0.03480902 0.03496002]
va_acc: [0.03546667 0.03469556 0.03492222]
te_loss: [0.038731   0.03799189 0.03833344]
te_acc: [0.03866667 0.03780444 0.03818   ]
te_tp: [0.04762278 0.04703019 0.04729519]
---------------------------------------------
