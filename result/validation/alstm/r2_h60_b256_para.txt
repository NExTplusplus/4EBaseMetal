['code/train/analyze_alstm.py', 'result/validation/alstm', 'r2_h60_b256_tune.log', 'para']
fnames: ['result/validation/alstm/r2_h60_b256_tune.log']
27 27
{'drop_out': 0.2, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.074818 0.06075  0.077991 0.071863 0.09532 ] 0.0761484
va_acc: [0.0773 0.0675 0.0756 0.0715 0.0969] 0.07776
te_loss: [0.068487 0.092046 0.076065 0.09811  0.109241] 0.0887898
te_acc: [0.0687 0.0905 0.0756 0.098  0.1081] 0.08818
{'drop_out': 0.4, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.074347 0.060514 0.078632 0.070801 0.089686] 0.074796
va_acc: [0.0767 0.0673 0.0762 0.0706 0.0914] 0.07644
te_loss: [0.069153 0.091832 0.076551 0.09957  0.103842] 0.08818959999999999
te_acc: [0.0696 0.0903 0.0761 0.0994 0.1014] 0.08736
{'drop_out': 0.6, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.071822 0.059221 0.07875  0.06456  0.087934] 0.0724574
va_acc: [0.0753 0.0661 0.0763 0.0639 0.0894] 0.0742
te_loss: [0.07414  0.090425 0.076625 0.108529 0.102184] 0.0903806
te_acc: [0.0741 0.0891 0.0762 0.1087 0.1003] 0.08968000000000001
{'drop_out': 0.2, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.070195 0.057109 0.073409 0.079689 0.066624] 0.0694052
va_acc: [0.0793 0.0559 0.0721 0.0803 0.0693] 0.07138
te_loss: [0.098178 0.084681 0.074163 0.090378 0.078063] 0.08509259999999999
te_acc: [0.0979 0.0805 0.076  0.0876 0.074 ] 0.08320000000000001
{'drop_out': 0.4, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.068846 0.056999 0.073453 0.08183  0.066151] 0.06945580000000001
va_acc: [0.075  0.0558 0.0721 0.0823 0.0695] 0.07094
te_loss: [0.092357 0.084411 0.074144 0.088434 0.077044] 0.08327799999999999
te_acc: [0.0921 0.0802 0.0759 0.0861 0.074 ] 0.08166
{'drop_out': 0.6, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.069143 0.057253 0.07314  0.080213 0.066111] 0.06917200000000001
va_acc: [0.0763 0.0561 0.0713 0.0807 0.0694] 0.07076
te_loss: [0.106441 0.084566 0.074365 0.089994 0.076709] 0.08641499999999999
te_acc: [0.1062 0.0802 0.0761 0.0876 0.0736] 0.08474000000000001
{'drop_out': 0.2, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.072429 0.059531 0.073365 0.058732 0.066145] 0.0660404
va_acc: [0.0754 0.0614 0.0695 0.057  0.064 ] 0.06546
te_loss: [0.070264 0.091246 0.074724 0.123764 0.077079] 0.0874154
te_acc: [0.0712 0.0875 0.0739 0.1233 0.0783] 0.08684
{'drop_out': 0.4, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.074434 0.057002 0.073428 0.058305 0.065501] 0.065734
va_acc: [0.0782 0.0586 0.0692 0.0564 0.0628] 0.06504000000000001
te_loss: [0.066549 0.088338 0.074373 0.125455 0.074884] 0.0859198
te_acc: [0.0674 0.0847 0.0732 0.125  0.0766] 0.08538
{'drop_out': 0.6, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.072964 0.05504  0.073379 0.058446 0.065598] 0.06508539999999999
va_acc: [0.077  0.0563 0.0692 0.0563 0.0627] 0.0643
te_loss: [0.069262 0.085516 0.074461 0.125431 0.075616] 0.0860572
te_acc: [0.0699 0.0822 0.0735 0.125  0.0771] 0.08554
{'drop_out': 0.2, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.073391 0.060069 0.078086 0.069275 0.091338] 0.0744318
va_acc: [0.0762 0.0672 0.0753 0.0685 0.0931] 0.07606
te_loss: [0.07061  0.091342 0.076171 0.101182 0.105456] 0.08895220000000001
te_acc: [0.0707 0.0899 0.0756 0.1015 0.1034] 0.08821999999999999
{'drop_out': 0.4, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.071568 0.059594 0.078818 0.066834 0.085331] 0.072429
va_acc: [0.0747 0.0664 0.0761 0.066  0.0886] 0.07436000000000001
te_loss: [0.073993 0.090884 0.076658 0.104783 0.098733] 0.08901020000000001
te_acc: [0.0743 0.0894 0.0761 0.1051 0.1061] 0.09019999999999999
{'drop_out': 0.6, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.070036 0.059034 0.078352 0.064674 0.084039] 0.071227
va_acc: [0.074  0.0658 0.0757 0.0632 0.0885] 0.07343999999999999
te_loss: [0.077876 0.090254 0.076304 0.108014 0.096803] 0.08985019999999999
te_acc: [0.0778 0.0889 0.0758 0.1088 0.1063] 0.09152
{'drop_out': 0.2, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.069168 0.057277 0.073206 0.077918 0.067029] 0.0689196
va_acc: [0.0774 0.056  0.0711 0.0786 0.0705] 0.07072
te_loss: [0.100252 0.085212 0.073812 0.09195  0.078584] 0.08596200000000001
te_acc: [0.1001 0.0809 0.0748 0.0895 0.0752] 0.08410000000000001
{'drop_out': 0.4, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.069953 0.057292 0.072984 0.077995 0.065944] 0.0688336
va_acc: [0.0782 0.0561 0.071  0.0787 0.0693] 0.07065999999999999
te_loss: [0.093796 0.085334 0.073994 0.091887 0.077222] 0.08444660000000001
te_acc: [0.0935 0.081  0.0751 0.0897 0.0747] 0.0828
{'drop_out': 0.6, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.068405 0.057816 0.072938 0.079908 0.066015] 0.0690164
va_acc: [0.0747 0.0566 0.0708 0.0805 0.0691] 0.07034
te_loss: [0.105656 0.086794 0.074114 0.090145 0.077367] 0.08681520000000001
te_acc: [0.1054 0.0823 0.0754 0.0875 0.0745] 0.08502000000000001
{'drop_out': 0.2, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.074428 0.057086 0.073584 0.057443 0.066618] 0.06583180000000001
va_acc: [0.0772 0.0591 0.0693 0.0562 0.0629] 0.06494000000000001
te_loss: [0.067395 0.088471 0.074389 0.128302 0.077042] 0.0871198
te_acc: [0.0682 0.0849 0.0734 0.1281 0.0784] 0.08660000000000001
{'drop_out': 0.4, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.076283 0.055475 0.07373  0.060123 0.065982] 0.06631859999999999
va_acc: [0.0797 0.0569 0.0692 0.0589 0.0622] 0.06538
te_loss: [0.063581 0.086082 0.074343 0.119375 0.075547] 0.08378559999999999
te_acc: [0.0645 0.0825 0.0733 0.1191 0.0772] 0.08332
{'drop_out': 0.6, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.077728 0.054715 0.073863 0.060197 0.065899] 0.0664804
va_acc: [0.081  0.0566 0.0694 0.0587 0.0627] 0.06568
te_loss: [0.061818 0.084989 0.074239 0.119777 0.076361] 0.0834368
te_acc: [0.0627 0.082  0.0732 0.1194 0.0775] 0.08296
{'drop_out': 0.2, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.075138 0.059757 0.0783   0.069124 0.088575] 0.0741788
va_acc: [0.077  0.067  0.0753 0.0679 0.0875] 0.07494
te_loss: [0.067044 0.091123 0.076282 0.101095 0.103011] 0.08771100000000001
te_acc: [0.0676 0.0897 0.0758 0.1018 0.1   ] 0.08697999999999999
{'drop_out': 0.4, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.073599 0.059171 0.078979 0.065239 0.085205] 0.07243859999999999
va_acc: [0.076  0.0674 0.0761 0.064  0.0841] 0.07352
te_loss: [0.069602 0.090291 0.076781 0.106973 0.099666] 0.0886626
te_acc: [0.0697 0.0896 0.0763 0.1076 0.0981] 0.08826
{'drop_out': 0.6, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.070552 0.058677 0.078843 0.062912 0.082982] 0.0707932
va_acc: [0.074  0.0668 0.0761 0.062  0.0838] 0.07254
te_loss: [0.076282 0.08973  0.076685 0.111338 0.096554] 0.0901178
te_acc: [0.0765 0.0892 0.0762 0.1118 0.1023] 0.0912
{'drop_out': 0.2, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.069184 0.057212 0.073362 0.076816 0.06686 ] 0.0686868
va_acc: [0.0762 0.056  0.0723 0.0773 0.0661] 0.06958
te_loss: [0.089882 0.085335 0.074175 0.092992 0.079386] 0.08435400000000001
te_acc: [0.0898 0.0811 0.0761 0.0908 0.0785] 0.08326
{'drop_out': 0.4, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.070382 0.057348 0.07291  0.073928 0.067385] 0.06839060000000001
va_acc: [0.0775 0.0562 0.0701 0.0745 0.0664] 0.06894
te_loss: [0.087587 0.085661 0.073683 0.096093 0.080079] 0.0846206
te_acc: [0.0873 0.0813 0.0742 0.0942 0.0796] 0.08332
{'drop_out': 0.6, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.068066 0.057574 0.072803 0.07569  0.065876] 0.0680018
va_acc: [0.075  0.0563 0.0703 0.0762 0.0656] 0.06867999999999999
te_loss: [0.104212 0.08638  0.073851 0.09414  0.077898] 0.0872962
te_acc: [0.104  0.0819 0.0746 0.0921 0.0778] 0.08608
{'drop_out': 0.2, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.074164 0.059458 0.073496 0.057387 0.070443] 0.06698960000000001
va_acc: [0.0768 0.062  0.0686 0.0561 0.0727] 0.06724
te_loss: [0.067054 0.091236 0.074269 0.128955 0.079508] 0.0882044
te_acc: [0.068  0.0877 0.073  0.1289 0.0856] 0.08864000000000001
{'drop_out': 0.4, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.079037 0.05701  0.073912 0.058117 0.069914] 0.067598
va_acc: [0.0821 0.059  0.0684 0.0566 0.0707] 0.06736
te_loss: [0.060004 0.088461 0.074148 0.126438 0.079846] 0.08577939999999999
te_acc: [0.0611 0.0849 0.0725 0.1263 0.0843] 0.08582
{'drop_out': 0.6, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.076327 0.055692 0.073605 0.058284 0.070282] 0.06683800000000001
va_acc: [0.0799 0.0576 0.0687 0.0568 0.0709] 0.06678
te_loss: [0.063674 0.086626 0.074172 0.125712 0.080473] 0.0861314
te_acc: [0.0645 0.0832 0.0729 0.1256 0.0848] 0.0862
('drop_out', [0.2, 0.4, 0.6])
drop_out
number of paras: 9
number of paras: 9
number of paras: 9
[0.2, 0.4, 0.6]
va_loss: [0.07007027 0.06955491 0.06878573]
va_acc: [0.07089778 0.07029333 0.06963556]
te_loss: [0.0870668  0.08596582 0.08738893]
te_acc: [0.08622444 0.08534667 0.08699333]
te_tp: [0.09574685 0.09506241 0.09669537]
---------------------------------------------
('hidden', [20, 30])
hidden
number of paras: 9
number of paras: 9
[20, 30]
va_loss: [0.06887576 0.06632402]
va_acc: [0.07022222 0.06579778]
te_loss: [0.08536447 0.08598331]
te_acc: [0.08379778 0.0857    ]
te_tp: [0.094335   0.09538574]
---------------------------------------------
('embedding_size', [5])
('batch', [256])
('lag', [3, 4, 5])
lag
number of paras: 9
number of paras: 9
number of paras: 9
[3, 4, 5]
va_loss: [0.06981051 0.06927647 0.06932393]
va_acc: [0.07069778 0.07017556 0.06995333]
te_loss: [0.08683756 0.08659762 0.08698638]
te_acc: [0.08584222 0.08608222 0.08664   ]
te_tp: [0.09557481 0.09594926 0.09598056]
---------------------------------------------
