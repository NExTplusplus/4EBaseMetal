['code/train/analyze_alstm.py', 'result/validation/alstm', 'r2_h5_b256_tune.log', 'para']
fnames: ['result/validation/alstm/r2_h5_b256_tune.log']
27 27
{'drop_out': 0.2, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.023256 0.02283  0.025668 0.028246 0.028013] 0.025602600000000003
va_acc: [0.0237 0.0214 0.0258 0.0285 0.0278] 0.02544
te_loss: [0.021111 0.027377 0.027372 0.031788 0.025449] 0.026619400000000005
te_acc: [0.0213 0.0261 0.0279 0.0325 0.025 ] 0.02656
{'drop_out': 0.4, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.020209 0.022753 0.025853 0.030299 0.028269] 0.0254766
va_acc: [0.0206 0.0224 0.0259 0.0308 0.028 ] 0.025539999999999997
te_loss: [0.020432 0.028114 0.027676 0.032081 0.025785] 0.026817599999999997
te_acc: [0.021  0.0286 0.028  0.0319 0.0252] 0.02694
{'drop_out': 0.6, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.020059 0.022119 0.026056 0.029333 0.028159] 0.0251452
va_acc: [0.0204 0.0213 0.0262 0.0299 0.028 ] 0.02516
te_loss: [0.020038 0.027012 0.027825 0.03334  0.025625] 0.026768000000000004
te_acc: [0.0205 0.0263 0.0281 0.0332 0.0251] 0.026640000000000004
{'drop_out': 0.2, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.021807 0.030009 0.029078 0.029765 0.028477] 0.027827199999999996
va_acc: [0.0222 0.0308 0.0298 0.0308 0.0289] 0.028500000000000004
te_loss: [0.020593 0.034963 0.030429 0.033677 0.026012] 0.0291348
te_acc: [0.0211 0.0342 0.0313 0.0334 0.0267] 0.029339999999999998
{'drop_out': 0.4, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.023126 0.019914 0.031212 0.028977 0.028406] 0.026327
va_acc: [0.0227 0.0196 0.0316 0.0301 0.0287] 0.02654
te_loss: [0.021819 0.025401 0.033001 0.031593 0.025913] 0.027545399999999998
te_acc: [0.0214 0.0259 0.0335 0.0313 0.0265] 0.02772
{'drop_out': 0.6, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.021533 0.020256 0.026364 0.028816 0.02845 ] 0.0250838
va_acc: [0.022  0.0197 0.0266 0.0297 0.0287] 0.02534
te_loss: [0.022802 0.025359 0.028149 0.031035 0.025967] 0.026662399999999996
te_acc: [0.0233 0.0258 0.0285 0.0306 0.0266] 0.02696
{'drop_out': 0.2, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.019998 0.027614 0.027303 0.035652 0.027866] 0.0276866
va_acc: [0.0196 0.027  0.0266 0.0378 0.028 ] 0.027800000000000002
te_loss: [0.021507 0.03236  0.028418 0.038292 0.025274] 0.029170199999999997
te_acc: [0.0214 0.0325 0.0288 0.0393 0.0258] 0.029559999999999996
{'drop_out': 0.4, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.019808 0.026999 0.025441 0.040443 0.027787] 0.028095600000000005
va_acc: [0.0195 0.026  0.0256 0.0406 0.0278] 0.027899999999999998
te_loss: [0.020595 0.03126  0.027299 0.045471 0.025188] 0.0299626
te_acc: [0.0205 0.0312 0.0281 0.0464 0.0256] 0.030359999999999998
{'drop_out': 0.6, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 3}
va_loss: [0.0216   0.027323 0.025605 0.041835 0.028269] 0.028926399999999998
va_acc: [0.022  0.0268 0.0257 0.0416 0.0284] 0.0289
te_loss: [0.021634 0.032165 0.027188 0.04707  0.025727] 0.0307568
te_acc: [0.0223 0.0323 0.0281 0.0476 0.026 ] 0.031259999999999996
{'drop_out': 0.2, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.022319 0.021195 0.026376 0.030768 0.027985] 0.0257286
va_acc: [0.0228 0.0203 0.0264 0.031  0.0276] 0.025619999999999997
te_loss: [0.020449 0.026488 0.028327 0.029661 0.025446] 0.0260742
te_acc: [0.0208 0.0263 0.0287 0.0296 0.0249] 0.02606
{'drop_out': 0.4, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.020811 0.021059 0.025858 0.029886 0.028177] 0.025158200000000002
va_acc: [0.0212 0.0202 0.0259 0.0304 0.0279] 0.025119999999999996
te_loss: [0.020084 0.026157 0.027673 0.0303   0.025664] 0.025975599999999998
te_acc: [0.0207 0.0256 0.0281 0.0301 0.0251] 0.02592
{'drop_out': 0.6, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.019975 0.022165 0.026161 0.030599 0.028346] 0.025449199999999998
va_acc: [0.0203 0.0217 0.0263 0.0311 0.028 ] 0.025480000000000003
te_loss: [0.020167 0.02727  0.027844 0.030673 0.02588 ] 0.026366800000000003
te_acc: [0.0206 0.0272 0.0283 0.0303 0.0252] 0.02632
{'drop_out': 0.2, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.021661 0.029264 0.02537  0.029464 0.02862 ] 0.0268758
va_acc: [0.0222 0.0302 0.0254 0.0304 0.0291] 0.027460000000000002
te_loss: [0.021978 0.034202 0.027059 0.033202 0.026208] 0.028529800000000004
te_acc: [0.0225 0.0333 0.0272 0.0328 0.027 ] 0.028560000000000002
{'drop_out': 0.4, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.023362 0.0196   0.025263 0.029257 0.028242] 0.025144800000000002
va_acc: [0.0242 0.019  0.0253 0.03   0.0285] 0.0254
te_loss: [0.024806 0.024833 0.02714  0.031431 0.02565 ] 0.026772
te_acc: [0.0251 0.0249 0.0272 0.0309 0.0261] 0.026840000000000003
{'drop_out': 0.6, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.023068 0.019831 0.028541 0.030788 0.028325] 0.0261106
va_acc: [0.0235 0.0192 0.0286 0.0319 0.0286] 0.02636
te_loss: [0.021395 0.025081 0.030694 0.035395 0.025792] 0.027671400000000002
te_acc: [0.022  0.0254 0.031  0.0352 0.0261] 0.027940000000000003
{'drop_out': 0.2, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.023267 0.028552 0.025695 0.033768 0.027725] 0.027801399999999997
va_acc: [0.0235 0.0266 0.0258 0.0354 0.0278] 0.02782
te_loss: [0.026637 0.032864 0.027344 0.035531 0.025078] 0.0294908
te_acc: [0.0268 0.0314 0.0283 0.0366 0.0255] 0.029719999999999996
{'drop_out': 0.4, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.020436 0.027553 0.025111 0.037351 0.027795] 0.027649199999999995
va_acc: [0.0201 0.0262 0.0249 0.0395 0.028 ] 0.027739999999999997
te_loss: [0.022605 0.031838 0.026888 0.041753 0.025119] 0.0296406
te_acc: [0.0226 0.0314 0.0266 0.0428 0.0256] 0.0298
{'drop_out': 0.6, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 4}
va_loss: [0.019537 0.029042 0.025638 0.037018 0.027769] 0.027800799999999997
va_acc: [0.0192 0.0289 0.0258 0.0381 0.028 ] 0.027999999999999997
te_loss: [0.020166 0.033902 0.027389 0.041308 0.02511 ] 0.029575
te_acc: [0.0202 0.0342 0.0283 0.0425 0.0257] 0.030180000000000002
{'drop_out': 0.2, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.021857 0.022753 0.025931 0.030182 0.02802 ] 0.0257486
va_acc: [0.0224 0.022  0.026  0.0308 0.0278] 0.025799999999999997
te_loss: [0.020711 0.028005 0.027299 0.031906 0.025448] 0.026673799999999998
te_acc: [0.0213 0.0283 0.028  0.0318 0.025 ] 0.026879999999999998
{'drop_out': 0.4, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.020362 0.023974 0.025915 0.029079 0.028332] 0.0255324
va_acc: [0.0207 0.0238 0.026  0.0294 0.0281] 0.0256
te_loss: [0.020593 0.029214 0.027325 0.030259 0.025853] 0.026648800000000007
te_acc: [0.0211 0.0298 0.0279 0.031  0.0253] 0.02702
{'drop_out': 0.6, 'hidden': 10, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.019727 0.021862 0.026172 0.029861 0.028127] 0.0251498
va_acc: [0.02   0.0214 0.0262 0.0305 0.0277] 0.02516
te_loss: [0.020186 0.026672 0.028099 0.030865 0.025596] 0.0262836
te_acc: [0.0204 0.0261 0.0284 0.0306 0.025 ] 0.0261
{'drop_out': 0.2, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.022412 0.027187 0.02527  0.029382 0.028749] 0.026600000000000002
va_acc: [0.0229 0.0281 0.0254 0.0301 0.0292] 0.027139999999999997
te_loss: [0.020826 0.032273 0.027123 0.032038 0.026379] 0.027727800000000004
te_acc: [0.0214 0.0314 0.0272 0.0315 0.0272] 0.027739999999999997
{'drop_out': 0.4, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.024574 0.019479 0.027219 0.028987 0.028123] 0.0256764
va_acc: [0.0255 0.0191 0.0276 0.0297 0.0284] 0.02606
te_loss: [0.025487 0.024893 0.029002 0.031444 0.025545] 0.0272742
te_acc: [0.0257 0.0252 0.0295 0.031  0.0258] 0.02744
{'drop_out': 0.6, 'hidden': 20, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.02455  0.019516 0.025317 0.030872 0.02928 ] 0.025907000000000003
va_acc: [0.0253 0.0189 0.0253 0.0321 0.0298] 0.026279999999999998
te_loss: [0.026243 0.02478  0.027164 0.034866 0.026994] 0.0280094
te_acc: [0.0265 0.0249 0.027  0.0347 0.0279] 0.028200000000000003
{'drop_out': 0.2, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.02004  0.027012 0.026274 0.035706 0.028315] 0.027469399999999998
va_acc: [0.0199 0.0265 0.0265 0.0379 0.0285] 0.027860000000000003
te_loss: [0.021659 0.031708 0.027966 0.039011 0.025872] 0.029243200000000004
te_acc: [0.0215 0.032  0.029  0.0402 0.0261] 0.02976
{'drop_out': 0.4, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.020343 0.027075 0.025966 0.035308 0.030502] 0.027838800000000004
va_acc: [0.02   0.0262 0.026  0.0372 0.0304] 0.027960000000000002
te_loss: [0.019701 0.031766 0.027919 0.038441 0.028439] 0.0292532
te_acc: [0.0195 0.0318 0.0287 0.0395 0.0282] 0.02954
{'drop_out': 0.6, 'hidden': 30, 'embedding_size': 5, 'batch': 256, 'lag': 5}
va_loss: [0.022186 0.027194 0.026066 0.036934 0.028182] 0.028112400000000003
va_acc: [0.0219 0.0262 0.0262 0.038  0.0283] 0.02812
te_loss: [0.025047 0.0318   0.027695 0.041184 0.025689] 0.030282999999999997
te_acc: [0.0252 0.0319 0.0287 0.0422 0.0264] 0.03088
('drop_out', [0.2, 0.4, 0.6])
drop_out
number of paras: 9
number of paras: 9
number of paras: 9
[0.2, 0.4, 0.6]
va_loss: [0.02681558 0.02632211 0.02640947]
va_acc: [0.02704889 0.02642889 0.02653333]
te_loss: [0.02807378 0.02776556 0.02804182]
te_acc: [0.02824222 0.02795333 0.02827556]
te_tp: [0.03493796 0.03483741 0.03506537]
---------------------------------------------
('hidden', [20, 30])
hidden
number of paras: 9
number of paras: 9
[20, 30]
va_loss: [0.02617251 0.02793118]
va_acc: [0.02656444 0.02801111]
te_loss: [0.02770302 0.02970838]
te_acc: [0.02786    0.03011778]
te_tp: [0.03466685 0.03617759]
---------------------------------------------
('embedding_size', [5])
('batch', [256])
('lag', [3, 4, 5])
lag
number of paras: 9
number of paras: 9
number of paras: 9
[3, 4, 5]
va_loss: [0.02668567 0.02641318 0.02644831]
va_acc: [0.02679111 0.02655556 0.02666444]
te_loss: [0.02815969 0.02778847 0.027933  ]
te_acc: [0.02837111 0.02792667 0.02817333]
te_tp: [0.03505185 0.03481444 0.03497444]
---------------------------------------------
