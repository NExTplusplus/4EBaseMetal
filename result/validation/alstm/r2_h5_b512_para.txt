['code/train/analyze_alstm.py', 'result/validation/alstm', 'r2_h5_b512_tune.log', 'para']
fnames: ['result/validation/alstm/r2_h5_b512_tune.log']
27 27
{'drop_out': 0.2, 'hidden': 10, 'embedding_size': 5, 'batch': 512, 'lag': 3}
va_loss: [0.023599 0.019786 0.027508 0.026924 0.034792] 0.0265218
va_acc: [0.0239 0.0199 0.0277 0.0266 0.034 ] 0.02642
te_loss: [0.020782 0.02551  0.029241 0.030915 0.033205] 0.0279306
te_acc: [0.0213 0.0257 0.0299 0.0307 0.032 ] 0.02792
{'drop_out': 0.4, 'hidden': 10, 'embedding_size': 5, 'batch': 512, 'lag': 3}
va_loss: [0.020679 0.018935 0.026947 0.0265   0.034799] 0.025571999999999994
va_acc: [0.0207 0.019  0.0274 0.0262 0.0339] 0.025439999999999997
te_loss: [0.019087 0.024512 0.028304 0.029765 0.033198] 0.026973199999999996
te_acc: [0.0191 0.0245 0.0292 0.0296 0.0319] 0.026860000000000002
{'drop_out': 0.6, 'hidden': 10, 'embedding_size': 5, 'batch': 512, 'lag': 3}
va_loss: [0.019549 0.019008 0.027328 0.02648  0.034643] 0.025401600000000003
va_acc: [0.0197 0.0191 0.0276 0.0262 0.0338] 0.025280000000000004
te_loss: [0.020372 0.024645 0.028942 0.029616 0.033045] 0.027323999999999998
te_acc: [0.0203 0.0247 0.0297 0.0294 0.0317] 0.02716
{'drop_out': 0.2, 'hidden': 20, 'embedding_size': 5, 'batch': 512, 'lag': 3}
va_loss: [0.024829 0.019052 0.025397 0.027332 0.028473] 0.0250166
va_acc: [0.0257 0.0192 0.0249 0.0275 0.0285] 0.02516
te_loss: [0.024567 0.02439  0.026978 0.029112 0.025952] 0.026199800000000002
te_acc: [0.0249 0.0243 0.027  0.0288 0.0263] 0.026259999999999995
{'drop_out': 0.4, 'hidden': 20, 'embedding_size': 5, 'batch': 512, 'lag': 3}
va_loss: [0.025089 0.019158 0.025647 0.027173 0.028493] 0.025112000000000002
va_acc: [0.0255 0.0194 0.0256 0.0274 0.0286] 0.0253
te_loss: [0.023446 0.024792 0.027537 0.030544 0.025969] 0.026457600000000005
te_acc: [0.024  0.0247 0.0277 0.0302 0.0262] 0.02656
{'drop_out': 0.6, 'hidden': 20, 'embedding_size': 5, 'batch': 512, 'lag': 3}
va_loss: [0.025328 0.018948 0.025603 0.027134 0.028578] 0.025118199999999997
va_acc: [0.0257 0.019  0.0254 0.0273 0.0287] 0.02522
te_loss: [0.023532 0.024426 0.027357 0.030436 0.026095] 0.0263692
te_acc: [0.0242 0.0243 0.0275 0.0301 0.0263] 0.026479999999999997
{'drop_out': 0.2, 'hidden': 30, 'embedding_size': 5, 'batch': 512, 'lag': 3}
va_loss: [0.021081 0.02194  0.02646  0.029597 0.02979 ] 0.0257736
va_acc: [0.0213 0.0211 0.0263 0.0283 0.0299] 0.025380000000000003
te_loss: [0.023037 0.026464 0.028185 0.032766 0.027561] 0.027602599999999998
te_acc: [0.0232 0.0259 0.0287 0.0327 0.0282] 0.027739999999999997
{'drop_out': 0.4, 'hidden': 30, 'embedding_size': 5, 'batch': 512, 'lag': 3}
va_loss: [0.020894 0.019406 0.024332 0.029583 0.029637] 0.024770399999999998
va_acc: [0.0206 0.0198 0.0242 0.0288 0.0299] 0.02466
te_loss: [0.019759 0.024919 0.026421 0.03391  0.027387] 0.026479199999999998
te_acc: [0.0194 0.0249 0.0265 0.0349 0.0281] 0.02676
{'drop_out': 0.6, 'hidden': 30, 'embedding_size': 5, 'batch': 512, 'lag': 3}
va_loss: [0.020149 0.019446 0.038807 0.029087 0.029881] 0.027474
va_acc: [0.0201 0.0197 0.0378 0.0279 0.03  ] 0.027100000000000003
te_loss: [0.02183  0.024939 0.038626 0.033272 0.027673] 0.029268
te_acc: [0.0221 0.0249 0.0379 0.0335 0.0284] 0.029360000000000004
{'drop_out': 0.2, 'hidden': 10, 'embedding_size': 5, 'batch': 512, 'lag': 4}
va_loss: [0.019887 0.018956 0.027482 0.026815 0.034177] 0.025463400000000004
va_acc: [0.0201 0.0191 0.0276 0.0265 0.0333] 0.02532
te_loss: [0.020569 0.024387 0.029398 0.030387 0.032514] 0.027451000000000003
te_acc: [0.0206 0.0244 0.0298 0.0302 0.0312] 0.027240000000000004
{'drop_out': 0.4, 'hidden': 10, 'embedding_size': 5, 'batch': 512, 'lag': 4}
va_loss: [0.020272 0.018942 0.02682  0.02646  0.033693] 0.0252374
va_acc: [0.0204 0.0189 0.0272 0.0261 0.0328] 0.02508
te_loss: [0.019345 0.024448 0.028327 0.029981 0.03198 ] 0.026816200000000002
te_acc: [0.0194 0.0243 0.0292 0.0298 0.0306] 0.02666
{'drop_out': 0.6, 'hidden': 10, 'embedding_size': 5, 'batch': 512, 'lag': 4}
va_loss: [0.020309 0.018962 0.028186 0.026538 0.033648] 0.025528600000000002
va_acc: [0.0201 0.019  0.0275 0.0262 0.0328] 0.025119999999999996
te_loss: [0.021422 0.024444 0.029522 0.029011 0.031912] 0.027262200000000004
te_acc: [0.0214 0.0242 0.0306 0.0289 0.0306] 0.027139999999999997
{'drop_out': 0.2, 'hidden': 20, 'embedding_size': 5, 'batch': 512, 'lag': 4}
va_loss: [0.022842 0.018973 0.025399 0.027026 0.028475] 0.024543000000000002
va_acc: [0.0234 0.0192 0.0248 0.0271 0.0286] 0.02462
te_loss: [0.021807 0.024426 0.026925 0.030155 0.025942] 0.025851000000000002
te_acc: [0.0225 0.0244 0.0269 0.0306 0.0263] 0.026140000000000004
{'drop_out': 0.4, 'hidden': 20, 'embedding_size': 5, 'batch': 512, 'lag': 4}
va_loss: [0.025362 0.018951 0.025532 0.027655 0.028571] 0.0252142
va_acc: [0.026  0.0191 0.0252 0.0277 0.0287] 0.02534
te_loss: [0.024423 0.024454 0.027316 0.033312 0.026075] 0.027116000000000008
te_acc: [0.0248 0.0243 0.0273 0.0338 0.0263] 0.027299999999999998
{'drop_out': 0.6, 'hidden': 20, 'embedding_size': 5, 'batch': 512, 'lag': 4}
va_loss: [0.024419 0.019372 0.025308 0.027208 0.028525] 0.024966399999999996
va_acc: [0.0249 0.0196 0.0251 0.0275 0.0286] 0.025139999999999996
te_loss: [0.023163 0.02507  0.027126 0.03052  0.026003] 0.0263764
te_acc: [0.0239 0.0249 0.0271 0.0302 0.0263] 0.026479999999999997
{'drop_out': 0.2, 'hidden': 30, 'embedding_size': 5, 'batch': 512, 'lag': 4}
va_loss: [0.021181 0.019916 0.030843 0.028186 0.028499] 0.025724999999999998
va_acc: [0.0213 0.0196 0.0309 0.0273 0.0286] 0.02554
te_loss: [0.022924 0.025    0.031687 0.032351 0.025976] 0.0275876
te_acc: [0.0229 0.0247 0.0323 0.0323 0.0264] 0.02772
{'drop_out': 0.4, 'hidden': 30, 'embedding_size': 5, 'batch': 512, 'lag': 4}
va_loss: [0.019666 0.01934  0.027484 0.028537 0.029786] 0.0249626
va_acc: [0.0198 0.0195 0.0274 0.0275 0.0301] 0.02486
te_loss: [0.019547 0.02476  0.029274 0.031117 0.027596] 0.026458800000000005
te_acc: [0.0199 0.0247 0.0299 0.031  0.0286] 0.02682
{'drop_out': 0.6, 'hidden': 30, 'embedding_size': 5, 'batch': 512, 'lag': 4}
va_loss: [0.019759 0.019404 0.025775 0.029085 0.0312  ] 0.0250446
va_acc: [0.0199 0.0195 0.0258 0.0279 0.0316] 0.024940000000000004
te_loss: [0.020846 0.024802 0.02769  0.030677 0.029185] 0.026639999999999997
te_acc: [0.0212 0.0247 0.0279 0.0305 0.0306] 0.026979999999999997
{'drop_out': 0.2, 'hidden': 10, 'embedding_size': 5, 'batch': 512, 'lag': 5}
va_loss: [0.020719 0.018891 0.02712  0.026531 0.034455] 0.0255432
va_acc: [0.0206 0.0189 0.0275 0.0262 0.0336] 0.02536
te_loss: [0.019059 0.024408 0.028344 0.029624 0.032853] 0.0268576
te_acc: [0.0191 0.0244 0.0294 0.0295 0.0316] 0.0268
{'drop_out': 0.4, 'hidden': 10, 'embedding_size': 5, 'batch': 512, 'lag': 5}
va_loss: [0.02009  0.019033 0.026846 0.027028 0.033526] 0.0253046
va_acc: [0.02   0.0192 0.0274 0.0268 0.0327] 0.02522
te_loss: [0.019132 0.024647 0.028255 0.028062 0.031797] 0.026378600000000002
te_acc: [0.0191 0.0247 0.0291 0.0279 0.0305] 0.02626
{'drop_out': 0.6, 'hidden': 10, 'embedding_size': 5, 'batch': 512, 'lag': 5}
va_loss: [0.020241 0.018875 0.027571 0.026752 0.033273] 0.025342399999999998
va_acc: [0.0201 0.0189 0.0281 0.0265 0.0324] 0.0252
te_loss: [0.021746 0.02438  0.028754 0.028262 0.031509] 0.026930199999999998
te_acc: [0.0217 0.0244 0.0298 0.0281 0.0302] 0.026839999999999996
{'drop_out': 0.2, 'hidden': 20, 'embedding_size': 5, 'batch': 512, 'lag': 5}
va_loss: [0.025571 0.019062 0.025486 0.027045 0.028594] 0.025151600000000003
va_acc: [0.0267 0.0193 0.0249 0.0272 0.0287] 0.02536
te_loss: [0.027365 0.024621 0.026989 0.029622 0.026112] 0.0269418
te_acc: [0.0284 0.0245 0.027  0.0293 0.0263] 0.027099999999999996
{'drop_out': 0.4, 'hidden': 20, 'embedding_size': 5, 'batch': 512, 'lag': 5}
va_loss: [0.024783 0.018987 0.025368 0.027215 0.028488] 0.024968200000000003
va_acc: [0.0258 0.0192 0.0251 0.0275 0.0286] 0.025239999999999995
te_loss: [0.025647 0.024465 0.026988 0.031095 0.025968] 0.0268326
te_acc: [0.0255 0.0244 0.027  0.0308 0.0264] 0.02682
{'drop_out': 0.6, 'hidden': 20, 'embedding_size': 5, 'batch': 512, 'lag': 5}
va_loss: [0.02307  0.019088 0.025358 0.027618 0.028422] 0.0247112
va_acc: [0.0241 0.0192 0.0253 0.028  0.0285] 0.025019999999999997
te_loss: [0.024129 0.024403 0.027169 0.032491 0.025926] 0.026823600000000003
te_acc: [0.0243 0.0242 0.0273 0.0322 0.0263] 0.026860000000000002
{'drop_out': 0.2, 'hidden': 30, 'embedding_size': 5, 'batch': 512, 'lag': 5}
va_loss: [0.021115 0.019303 0.025483 0.029692 0.028254] 0.024769399999999997
va_acc: [0.0212 0.0193 0.0252 0.029  0.0284] 0.024620000000000003
te_loss: [0.022975 0.02463  0.027326 0.031591 0.02569 ] 0.026442399999999998
te_acc: [0.023  0.0245 0.0279 0.0326 0.026 ] 0.026799999999999997
{'drop_out': 0.4, 'hidden': 30, 'embedding_size': 5, 'batch': 512, 'lag': 5}
va_loss: [0.019721 0.019261 0.029459 0.029024 0.029041] 0.025301200000000003
va_acc: [0.0198 0.0194 0.0295 0.028  0.0292] 0.025179999999999998
te_loss: [0.020784 0.024743 0.031015 0.029384 0.026675] 0.0265202
te_acc: [0.0212 0.0247 0.032  0.0293 0.0273] 0.026899999999999997
{'drop_out': 0.6, 'hidden': 30, 'embedding_size': 5, 'batch': 512, 'lag': 5}
va_loss: [0.019604 0.019602 0.025198 0.0292   0.031458] 0.0250124
va_acc: [0.0197 0.0194 0.0252 0.0281 0.0318] 0.02484
te_loss: [0.020039 0.024793 0.027025 0.030287 0.02947 ] 0.0263228
te_acc: [0.0204 0.0245 0.0272 0.0301 0.0306] 0.02656
('drop_out', [0.2, 0.4, 0.6])
drop_out
number of paras: 9
number of paras: 9
number of paras: 9
[0.2, 0.4, 0.6]
va_loss: [0.02538973 0.02516029 0.02539993]
va_acc: [0.02530889 0.02514667 0.02531778]
te_loss: [0.02698493 0.02667027 0.02703516]
te_acc: [0.02708    0.02677111 0.02709556]
te_tp: [0.03412593 0.03397352 0.03411574]
---------------------------------------------
('hidden', [20, 30])
hidden
number of paras: 9
number of paras: 9
[20, 30]
va_loss: [0.02497793 0.02542591]
va_acc: [0.02515556 0.02523556]
te_loss: [0.026552   0.02703573]
te_acc: [0.02666667 0.02729333]
te_tp: [0.03407741 0.03416296]
---------------------------------------------
('embedding_size', [5])
('batch', [512])
('lag', [3, 4, 5])
lag
number of paras: 9
number of paras: 9
number of paras: 9
[3, 4, 5]
va_loss: [0.02564002 0.02518724 0.02512269]
va_acc: [0.02555111 0.02510667 0.02511556]
te_loss: [0.02717824 0.02683991 0.0266722 ]
te_acc: [0.02723333 0.02694222 0.02677111]
te_tp: [0.03418574 0.03401352 0.03401593]
---------------------------------------------
