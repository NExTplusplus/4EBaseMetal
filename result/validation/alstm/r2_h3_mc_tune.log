
		{"drop_out": 0.4, "drop_out_mc": 0.05, "repeat_mc": 50, "hidden": 20, "embedding_size": 5, "batch": 512, "lag": 4}
{'generate_norm_params': 'v1', 'generate_tech_params': 'v3', 'generate_strat_params': None, 'generate_SD_params': 'v1', 'deal_with_abnormal_value': 'v2', 'labelling': 'v3', 'process_missing_value': 'v1', 'strategy_signal': None, 'normalize_without_1d_return': 'v1', 'technical_indication': 'v4', 'supply_and_demand': None, 'remove_unused_columns': 'v6', 'price_normalization': 'v3', 'scaling': None, 'construct': 'v4'}
LME_Co_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6780 6780 6780
1.8562728 -0.6288155 0.15869391 -0.16256663
Validation: 756 756 756
Testing: 774 774 774
pre-processing time: 0.0007772445678710938
the split date is 2009-07-01
net initializing with time: 0.007984399795532227
preparing training and testing date with time: 2.384185791015625e-07
current epoch: 1
train loss is 0.433662
average val loss: 0.288573, accuracy: 0.2886
average test loss: 0.284902, accuracy: 0.2849
case acc: 0.22398554
case acc: 0.3678977
case acc: 0.260163
case acc: 0.118679725
case acc: 0.4391105
case acc: 0.29957658
top acc: 0.2368 ::: bot acc: 0.2096
top acc: 0.3865 ::: bot acc: 0.3495
top acc: 0.2876 ::: bot acc: 0.2344
top acc: 0.1386 ::: bot acc: 0.0976
top acc: 0.4594 ::: bot acc: 0.4177
top acc: 0.3149 ::: bot acc: 0.2826
current epoch: 2
train loss is 0.163374
average val loss: 0.087235, accuracy: 0.0886
average test loss: 0.086242, accuracy: 0.0871
case acc: 0.029100887
case acc: 0.113601044
case acc: 0.021558957
case acc: 0.13077462
case acc: 0.18099186
case acc: 0.046377756
top acc: 0.0168 ::: bot acc: 0.0432
top acc: 0.1324 ::: bot acc: 0.0951
top acc: 0.0390 ::: bot acc: 0.0151
top acc: 0.1110 ::: bot acc: 0.1515
top acc: 0.2011 ::: bot acc: 0.1598
top acc: 0.0618 ::: bot acc: 0.0295
current epoch: 3
train loss is 0.130990
average val loss: 0.082934, accuracy: 0.0828
average test loss: 0.083784, accuracy: 0.0848
case acc: 0.09287211
case acc: 0.039604202
case acc: 0.052277286
case acc: 0.18655504
case acc: 0.12102815
case acc: 0.01646203
top acc: 0.0801 ::: bot acc: 0.1071
top acc: 0.0587 ::: bot acc: 0.0210
top acc: 0.0265 ::: bot acc: 0.0773
top acc: 0.1672 ::: bot acc: 0.2069
top acc: 0.1409 ::: bot acc: 0.1001
top acc: 0.0068 ::: bot acc: 0.0300
current epoch: 4
train loss is 0.130900
average val loss: 0.126823, accuracy: 0.1272
average test loss: 0.124204, accuracy: 0.1244
case acc: 0.052007925
case acc: 0.1852177
case acc: 0.092064366
case acc: 0.042531073
case acc: 0.24778865
case acc: 0.1266113
top acc: 0.0648 ::: bot acc: 0.0379
top acc: 0.2045 ::: bot acc: 0.1663
top acc: 0.1199 ::: bot acc: 0.0659
top acc: 0.0243 ::: bot acc: 0.0622
top acc: 0.2675 ::: bot acc: 0.2270
top acc: 0.1422 ::: bot acc: 0.1097
current epoch: 5
train loss is 0.097026
average val loss: 0.071769, accuracy: 0.0730
average test loss: 0.071555, accuracy: 0.0731
case acc: 0.059582837
case acc: 0.06806695
case acc: 0.024209255
case acc: 0.14758255
case acc: 0.12128002
case acc: 0.01797407
top acc: 0.0467 ::: bot acc: 0.0737
top acc: 0.0874 ::: bot acc: 0.0491
top acc: 0.0134 ::: bot acc: 0.0419
top acc: 0.1285 ::: bot acc: 0.1676
top acc: 0.1409 ::: bot acc: 0.1005
top acc: 0.0292 ::: bot acc: 0.0098
current epoch: 6
train loss is 0.093419
average val loss: 0.066903, accuracy: 0.0678
average test loss: 0.066995, accuracy: 0.0684
case acc: 0.067825094
case acc: 0.048787665
case acc: 0.028827934
case acc: 0.15005565
case acc: 0.10089951
case acc: 0.013803174
top acc: 0.0549 ::: bot acc: 0.0818
top acc: 0.0682 ::: bot acc: 0.0298
top acc: 0.0121 ::: bot acc: 0.0495
top acc: 0.1311 ::: bot acc: 0.1700
top acc: 0.1205 ::: bot acc: 0.0802
top acc: 0.0216 ::: bot acc: 0.0120
current epoch: 7
train loss is 0.099329
average val loss: 0.079041, accuracy: 0.0795
average test loss: 0.076987, accuracy: 0.0767
case acc: 0.010419249
case acc: 0.10938845
case acc: 0.042476863
case acc: 0.08351437
case acc: 0.1473087
case acc: 0.06684117
top acc: 0.0101 ::: bot acc: 0.0170
top acc: 0.1288 ::: bot acc: 0.0904
top acc: 0.0691 ::: bot acc: 0.0187
top acc: 0.0646 ::: bot acc: 0.1034
top acc: 0.1669 ::: bot acc: 0.1266
top acc: 0.0824 ::: bot acc: 0.0499
current epoch: 8
train loss is 0.079920
average val loss: 0.059880, accuracy: 0.0614
average test loss: 0.058971, accuracy: 0.0603
case acc: 0.043486886
case acc: 0.06413789
case acc: 0.019676475
case acc: 0.121097356
case acc: 0.088646024
case acc: 0.024869317
top acc: 0.0305 ::: bot acc: 0.0575
top acc: 0.0836 ::: bot acc: 0.0451
top acc: 0.0306 ::: bot acc: 0.0236
top acc: 0.1022 ::: bot acc: 0.1410
top acc: 0.1082 ::: bot acc: 0.0680
top acc: 0.0382 ::: bot acc: 0.0125
current epoch: 9
train loss is 0.075021
average val loss: 0.053608, accuracy: 0.0553
average test loss: 0.052985, accuracy: 0.0544
case acc: 0.052083705
case acc: 0.04718679
case acc: 0.020284798
case acc: 0.12598185
case acc: 0.0643823
case acc: 0.016729735
top acc: 0.0390 ::: bot acc: 0.0660
top acc: 0.0667 ::: bot acc: 0.0281
top acc: 0.0234 ::: bot acc: 0.0308
top acc: 0.1072 ::: bot acc: 0.1457
top acc: 0.0838 ::: bot acc: 0.0438
top acc: 0.0277 ::: bot acc: 0.0093
current epoch: 10
train loss is 0.074824
average val loss: 0.052254, accuracy: 0.0536
average test loss: 0.051037, accuracy: 0.0520
case acc: 0.036964778
case acc: 0.0566772
case acc: 0.021810967
case acc: 0.108637154
case acc: 0.062351383
case acc: 0.025783336
top acc: 0.0238 ::: bot acc: 0.0508
top acc: 0.0762 ::: bot acc: 0.0375
top acc: 0.0393 ::: bot acc: 0.0159
top acc: 0.0900 ::: bot acc: 0.1282
top acc: 0.0817 ::: bot acc: 0.0418
top acc: 0.0395 ::: bot acc: 0.0130
current epoch: 11
train loss is 0.070176
average val loss: 0.049121, accuracy: 0.0503
average test loss: 0.047800, accuracy: 0.0486
case acc: 0.032691933
case acc: 0.057200618
case acc: 0.024116747
case acc: 0.10285756
case acc: 0.04877373
case acc: 0.02572212
top acc: 0.0196 ::: bot acc: 0.0465
top acc: 0.0768 ::: bot acc: 0.0380
top acc: 0.0444 ::: bot acc: 0.0130
top acc: 0.0843 ::: bot acc: 0.1224
top acc: 0.0679 ::: bot acc: 0.0286
top acc: 0.0395 ::: bot acc: 0.0129
current epoch: 12
train loss is 0.065450
average val loss: 0.046858, accuracy: 0.0478
average test loss: 0.045454, accuracy: 0.0459
case acc: 0.027077269
case acc: 0.0597212
case acc: 0.028091306
case acc: 0.09539858
case acc: 0.03826572
case acc: 0.026971167
top acc: 0.0142 ::: bot acc: 0.0408
top acc: 0.0794 ::: bot acc: 0.0405
top acc: 0.0511 ::: bot acc: 0.0114
top acc: 0.0769 ::: bot acc: 0.1149
top acc: 0.0567 ::: bot acc: 0.0194
top acc: 0.0410 ::: bot acc: 0.0136
current epoch: 13
train loss is 0.060448
average val loss: 0.043884, accuracy: 0.0448
average test loss: 0.042482, accuracy: 0.0428
case acc: 0.025519071
case acc: 0.056586035
case acc: 0.03002682
case acc: 0.09029621
case acc: 0.028570112
case acc: 0.026088083
top acc: 0.0127 ::: bot acc: 0.0392
top acc: 0.0763 ::: bot acc: 0.0373
top acc: 0.0540 ::: bot acc: 0.0115
top acc: 0.0717 ::: bot acc: 0.1098
top acc: 0.0455 ::: bot acc: 0.0127
top acc: 0.0400 ::: bot acc: 0.0131
current epoch: 14
train loss is 0.057508
average val loss: 0.043057, accuracy: 0.0437
average test loss: 0.041467, accuracy: 0.0415
case acc: 0.01953102
case acc: 0.057221953
case acc: 0.036002208
case acc: 0.07869517
case acc: 0.027165065
case acc: 0.030482538
top acc: 0.0078 ::: bot acc: 0.0326
top acc: 0.0769 ::: bot acc: 0.0379
top acc: 0.0617 ::: bot acc: 0.0139
top acc: 0.0601 ::: bot acc: 0.0983
top acc: 0.0438 ::: bot acc: 0.0118
top acc: 0.0452 ::: bot acc: 0.0161
current epoch: 15
train loss is 0.055827
average val loss: 0.042617, accuracy: 0.0431
average test loss: 0.040806, accuracy: 0.0407
case acc: 0.01526315
case acc: 0.055956785
case acc: 0.042033877
case acc: 0.066406764
case acc: 0.028968297
case acc: 0.035316143
top acc: 0.0058 ::: bot acc: 0.0272
top acc: 0.0757 ::: bot acc: 0.0366
top acc: 0.0687 ::: bot acc: 0.0181
top acc: 0.0477 ::: bot acc: 0.0860
top acc: 0.0461 ::: bot acc: 0.0127
top acc: 0.0505 ::: bot acc: 0.0201
current epoch: 16
train loss is 0.052986
average val loss: 0.040463, accuracy: 0.0409
average test loss: 0.038642, accuracy: 0.0385
case acc: 0.01566114
case acc: 0.048379097
case acc: 0.043136578
case acc: 0.05860743
case acc: 0.029426068
case acc: 0.035556592
top acc: 0.0059 ::: bot acc: 0.0277
top acc: 0.0681 ::: bot acc: 0.0290
top acc: 0.0700 ::: bot acc: 0.0189
top acc: 0.0400 ::: bot acc: 0.0782
top acc: 0.0467 ::: bot acc: 0.0129
top acc: 0.0507 ::: bot acc: 0.0202
current epoch: 17
train loss is 0.049158
average val loss: 0.035946, accuracy: 0.0365
average test loss: 0.034414, accuracy: 0.0344
case acc: 0.021934675
case acc: 0.034112938
case acc: 0.037802108
case acc: 0.05763316
case acc: 0.025315115
case acc: 0.029409302
top acc: 0.0094 ::: bot acc: 0.0354
top acc: 0.0537 ::: bot acc: 0.0152
top acc: 0.0639 ::: bot acc: 0.0149
top acc: 0.0390 ::: bot acc: 0.0772
top acc: 0.0414 ::: bot acc: 0.0110
top acc: 0.0440 ::: bot acc: 0.0153
current epoch: 18
train loss is 0.046152
average val loss: 0.031416, accuracy: 0.0324
average test loss: 0.030394, accuracy: 0.0305
case acc: 0.031970587
case acc: 0.020200133
case acc: 0.030280646
case acc: 0.06011308
case acc: 0.019406807
case acc: 0.021202099
top acc: 0.0189 ::: bot acc: 0.0456
top acc: 0.0374 ::: bot acc: 0.0061
top acc: 0.0545 ::: bot acc: 0.0114
top acc: 0.0414 ::: bot acc: 0.0797
top acc: 0.0327 ::: bot acc: 0.0107
top acc: 0.0342 ::: bot acc: 0.0105
current epoch: 19
train loss is 0.043654
average val loss: 0.028787, accuracy: 0.0301
average test loss: 0.028555, accuracy: 0.0288
case acc: 0.04027748
case acc: 0.014990251
case acc: 0.02484645
case acc: 0.062516935
case acc: 0.015067611
case acc: 0.014958186
top acc: 0.0273 ::: bot acc: 0.0539
top acc: 0.0249 ::: bot acc: 0.0144
top acc: 0.0458 ::: bot acc: 0.0123
top acc: 0.0437 ::: bot acc: 0.0822
top acc: 0.0231 ::: bot acc: 0.0169
top acc: 0.0251 ::: bot acc: 0.0100
current epoch: 20
train loss is 0.042868
average val loss: 0.027967, accuracy: 0.0294
average test loss: 0.028330, accuracy: 0.0284
case acc: 0.043941256
case acc: 0.0145001095
case acc: 0.022354478
case acc: 0.062352993
case acc: 0.014700653
case acc: 0.012664992
top acc: 0.0309 ::: bot acc: 0.0576
top acc: 0.0191 ::: bot acc: 0.0201
top acc: 0.0407 ::: bot acc: 0.0150
top acc: 0.0435 ::: bot acc: 0.0820
top acc: 0.0145 ::: bot acc: 0.0254
top acc: 0.0193 ::: bot acc: 0.0141
current epoch: 21
train loss is 0.042059
average val loss: 0.026921, accuracy: 0.0282
average test loss: 0.027255, accuracy: 0.0272
case acc: 0.040485352
case acc: 0.014618035
case acc: 0.023005994
case acc: 0.056615166
case acc: 0.015574575
case acc: 0.012804852
top acc: 0.0274 ::: bot acc: 0.0542
top acc: 0.0227 ::: bot acc: 0.0166
top acc: 0.0421 ::: bot acc: 0.0141
top acc: 0.0379 ::: bot acc: 0.0763
top acc: 0.0110 ::: bot acc: 0.0289
top acc: 0.0198 ::: bot acc: 0.0137
current epoch: 22
train loss is 0.041310
average val loss: 0.025791, accuracy: 0.0268
average test loss: 0.025624, accuracy: 0.0253
case acc: 0.03250609
case acc: 0.016725723
case acc: 0.026153708
case acc: 0.046587974
case acc: 0.015139544
case acc: 0.01487765
top acc: 0.0194 ::: bot acc: 0.0462
top acc: 0.0310 ::: bot acc: 0.0085
top acc: 0.0482 ::: bot acc: 0.0114
top acc: 0.0284 ::: bot acc: 0.0659
top acc: 0.0126 ::: bot acc: 0.0273
top acc: 0.0248 ::: bot acc: 0.0103
current epoch: 23
train loss is 0.040120
average val loss: 0.025608, accuracy: 0.0261
average test loss: 0.024798, accuracy: 0.0243
case acc: 0.023792047
case acc: 0.022506475
case acc: 0.031044165
case acc: 0.03553412
case acc: 0.014420973
case acc: 0.018660586
top acc: 0.0110 ::: bot acc: 0.0374
top acc: 0.0408 ::: bot acc: 0.0062
top acc: 0.0556 ::: bot acc: 0.0113
top acc: 0.0185 ::: bot acc: 0.0542
top acc: 0.0166 ::: bot acc: 0.0233
top acc: 0.0308 ::: bot acc: 0.0098
current epoch: 24
train loss is 0.039323
average val loss: 0.026818, accuracy: 0.0267
average test loss: 0.025269, accuracy: 0.0248
case acc: 0.015472071
case acc: 0.031282324
case acc: 0.038496517
case acc: 0.023549916
case acc: 0.015473268
case acc: 0.024580386
top acc: 0.0056 ::: bot acc: 0.0276
top acc: 0.0508 ::: bot acc: 0.0127
top acc: 0.0648 ::: bot acc: 0.0153
top acc: 0.0104 ::: bot acc: 0.0403
top acc: 0.0242 ::: bot acc: 0.0158
top acc: 0.0384 ::: bot acc: 0.0123
current epoch: 25
train loss is 0.038824
average val loss: 0.029828, accuracy: 0.0292
average test loss: 0.027339, accuracy: 0.0267
case acc: 0.010767942
case acc: 0.038036227
case acc: 0.045996446
case acc: 0.014813818
case acc: 0.020136056
case acc: 0.030572819
top acc: 0.0076 ::: bot acc: 0.0195
top acc: 0.0578 ::: bot acc: 0.0189
top acc: 0.0732 ::: bot acc: 0.0209
top acc: 0.0123 ::: bot acc: 0.0262
top acc: 0.0341 ::: bot acc: 0.0102
top acc: 0.0454 ::: bot acc: 0.0163
current epoch: 26
train loss is 0.037281
average val loss: 0.028760, accuracy: 0.0281
average test loss: 0.026217, accuracy: 0.0256
case acc: 0.012007067
case acc: 0.03327124
case acc: 0.044787508
case acc: 0.013859928
case acc: 0.021606637
case acc: 0.028246433
top acc: 0.0063 ::: bot acc: 0.0221
top acc: 0.0529 ::: bot acc: 0.0144
top acc: 0.0719 ::: bot acc: 0.0199
top acc: 0.0172 ::: bot acc: 0.0211
top acc: 0.0363 ::: bot acc: 0.0101
top acc: 0.0428 ::: bot acc: 0.0145
current epoch: 27
train loss is 0.035097
average val loss: 0.026417, accuracy: 0.0260
average test loss: 0.024061, accuracy: 0.0236
case acc: 0.015693476
case acc: 0.025108116
case acc: 0.04078808
case acc: 0.013956725
case acc: 0.022083627
case acc: 0.023781028
top acc: 0.0056 ::: bot acc: 0.0280
top acc: 0.0439 ::: bot acc: 0.0078
top acc: 0.0674 ::: bot acc: 0.0169
top acc: 0.0195 ::: bot acc: 0.0188
top acc: 0.0371 ::: bot acc: 0.0101
top acc: 0.0375 ::: bot acc: 0.0119
current epoch: 28
train loss is 0.033209
average val loss: 0.024367, accuracy: 0.0243
average test loss: 0.022324, accuracy: 0.0220
case acc: 0.021187047
case acc: 0.017557103
case acc: 0.035830896
case acc: 0.014249615
case acc: 0.023701856
case acc: 0.01951054
top acc: 0.0086 ::: bot acc: 0.0347
top acc: 0.0328 ::: bot acc: 0.0075
top acc: 0.0617 ::: bot acc: 0.0135
top acc: 0.0214 ::: bot acc: 0.0169
top acc: 0.0394 ::: bot acc: 0.0103
top acc: 0.0320 ::: bot acc: 0.0100
current epoch: 29
train loss is 0.032921
average val loss: 0.024916, accuracy: 0.0251
average test loss: 0.023076, accuracy: 0.0229
case acc: 0.02533166
case acc: 0.014504214
case acc: 0.03281702
case acc: 0.015751915
case acc: 0.030734643
case acc: 0.01846276
top acc: 0.0124 ::: bot acc: 0.0390
top acc: 0.0213 ::: bot acc: 0.0178
top acc: 0.0580 ::: bot acc: 0.0119
top acc: 0.0266 ::: bot acc: 0.0121
top acc: 0.0484 ::: bot acc: 0.0134
top acc: 0.0306 ::: bot acc: 0.0097
current epoch: 30
train loss is 0.035382
average val loss: 0.027783, accuracy: 0.0282
average test loss: 0.026460, accuracy: 0.0263
case acc: 0.032490972
case acc: 0.020980459
case acc: 0.027967233
case acc: 0.017421803
case acc: 0.04140629
case acc: 0.01740162
top acc: 0.0194 ::: bot acc: 0.0463
top acc: 0.0083 ::: bot acc: 0.0368
top acc: 0.0513 ::: bot acc: 0.0107
top acc: 0.0304 ::: bot acc: 0.0097
top acc: 0.0604 ::: bot acc: 0.0215
top acc: 0.0292 ::: bot acc: 0.0095
current epoch: 31
train loss is 0.046619
average val loss: 0.044767, accuracy: 0.0455
average test loss: 0.047347, accuracy: 0.0484
case acc: 0.08611042
case acc: 0.087271295
case acc: 0.03410219
case acc: 0.03334798
case acc: 0.016556371
case acc: 0.032824703
top acc: 0.0729 ::: bot acc: 0.1000
top acc: 0.0675 ::: bot acc: 0.1066
top acc: 0.0142 ::: bot acc: 0.0570
top acc: 0.0168 ::: bot acc: 0.0516
top acc: 0.0272 ::: bot acc: 0.0132
top acc: 0.0169 ::: bot acc: 0.0499
current epoch: 32
train loss is 0.080669
average val loss: 0.110481, accuracy: 0.1105
average test loss: 0.114546, accuracy: 0.1145
case acc: 0.15446214
case acc: 0.16588007
case acc: 0.10091959
case acc: 0.10470251
case acc: 0.06336389
case acc: 0.097937934
top acc: 0.1411 ::: bot acc: 0.1683
top acc: 0.1461 ::: bot acc: 0.1853
top acc: 0.0728 ::: bot acc: 0.1279
top acc: 0.0861 ::: bot acc: 0.1240
top acc: 0.0441 ::: bot acc: 0.0839
top acc: 0.0817 ::: bot acc: 0.1152
current epoch: 33
train loss is 0.079939
average val loss: 0.053094, accuracy: 0.0535
average test loss: 0.056748, accuracy: 0.0568
case acc: 0.086090505
case acc: 0.084205754
case acc: 0.042337224
case acc: 0.058475338
case acc: 0.030389372
case acc: 0.039525174
top acc: 0.0728 ::: bot acc: 0.0999
top acc: 0.0645 ::: bot acc: 0.1036
top acc: 0.0186 ::: bot acc: 0.0672
top acc: 0.0399 ::: bot acc: 0.0777
top acc: 0.0118 ::: bot acc: 0.0505
top acc: 0.0235 ::: bot acc: 0.0566
current epoch: 34
train loss is 0.048896
average val loss: 0.042339, accuracy: 0.0433
average test loss: 0.045778, accuracy: 0.0460
case acc: 0.06446925
case acc: 0.044447314
case acc: 0.0313652
case acc: 0.05994005
case acc: 0.04547073
case acc: 0.03058523
top acc: 0.0513 ::: bot acc: 0.0782
top acc: 0.0249 ::: bot acc: 0.0637
top acc: 0.0130 ::: bot acc: 0.0535
top acc: 0.0413 ::: bot acc: 0.0792
top acc: 0.0263 ::: bot acc: 0.0659
top acc: 0.0149 ::: bot acc: 0.0475
current epoch: 35
train loss is 0.037221
average val loss: 0.022651, accuracy: 0.0239
average test loss: 0.023706, accuracy: 0.0236
case acc: 0.030127898
case acc: 0.014486939
case acc: 0.02001518
case acc: 0.037558794
case acc: 0.02752989
case acc: 0.0120846275
top acc: 0.0170 ::: bot acc: 0.0438
top acc: 0.0178 ::: bot acc: 0.0214
top acc: 0.0309 ::: bot acc: 0.0245
top acc: 0.0204 ::: bot acc: 0.0560
top acc: 0.0095 ::: bot acc: 0.0474
top acc: 0.0147 ::: bot acc: 0.0188
current epoch: 36
train loss is 0.033752
average val loss: 0.022135, accuracy: 0.0217
average test loss: 0.020536, accuracy: 0.0198
case acc: 0.011390936
case acc: 0.023681656
case acc: 0.028315801
case acc: 0.01834584
case acc: 0.014290026
case acc: 0.022778744
top acc: 0.0065 ::: bot acc: 0.0210
top acc: 0.0422 ::: bot acc: 0.0068
top acc: 0.0518 ::: bot acc: 0.0108
top acc: 0.0095 ::: bot acc: 0.0327
top acc: 0.0166 ::: bot acc: 0.0230
top acc: 0.0364 ::: bot acc: 0.0110
current epoch: 37
train loss is 0.032641
average val loss: 0.022633, accuracy: 0.0220
average test loss: 0.020646, accuracy: 0.0199
case acc: 0.010635938
case acc: 0.02670137
case acc: 0.029485004
case acc: 0.015091427
case acc: 0.014320652
case acc: 0.023129016
top acc: 0.0076 ::: bot acc: 0.0192
top acc: 0.0457 ::: bot acc: 0.0089
top acc: 0.0535 ::: bot acc: 0.0109
top acc: 0.0112 ::: bot acc: 0.0270
top acc: 0.0208 ::: bot acc: 0.0189
top acc: 0.0368 ::: bot acc: 0.0112
current epoch: 38
train loss is 0.032232
average val loss: 0.023206, accuracy: 0.0225
average test loss: 0.021027, accuracy: 0.0202
case acc: 0.010312361
case acc: 0.029979896
case acc: 0.030625857
case acc: 0.013743724
case acc: 0.014357565
case acc: 0.022259593
top acc: 0.0087 ::: bot acc: 0.0182
top acc: 0.0493 ::: bot acc: 0.0115
top acc: 0.0550 ::: bot acc: 0.0112
top acc: 0.0157 ::: bot acc: 0.0222
top acc: 0.0210 ::: bot acc: 0.0187
top acc: 0.0357 ::: bot acc: 0.0108
current epoch: 39
train loss is 0.032192
average val loss: 0.027293, accuracy: 0.0267
average test loss: 0.024447, accuracy: 0.0237
case acc: 0.010019395
case acc: 0.0380668
case acc: 0.036405757
case acc: 0.015507486
case acc: 0.01646569
case acc: 0.025922505
top acc: 0.0152 ::: bot acc: 0.0117
top acc: 0.0578 ::: bot acc: 0.0188
top acc: 0.0624 ::: bot acc: 0.0139
top acc: 0.0262 ::: bot acc: 0.0120
top acc: 0.0270 ::: bot acc: 0.0133
top acc: 0.0402 ::: bot acc: 0.0128
current epoch: 40
train loss is 0.032532
average val loss: 0.032645, accuracy: 0.0323
average test loss: 0.029171, accuracy: 0.0285
case acc: 0.011829818
case acc: 0.043670826
case acc: 0.042699695
case acc: 0.021919066
case acc: 0.021217009
case acc: 0.029939651
top acc: 0.0206 ::: bot acc: 0.0068
top acc: 0.0635 ::: bot acc: 0.0243
top acc: 0.0696 ::: bot acc: 0.0184
top acc: 0.0378 ::: bot acc: 0.0081
top acc: 0.0358 ::: bot acc: 0.0101
top acc: 0.0448 ::: bot acc: 0.0156
current epoch: 41
train loss is 0.031849
average val loss: 0.033398, accuracy: 0.0330
average test loss: 0.029874, accuracy: 0.0292
case acc: 0.011067455
case acc: 0.04029251
case acc: 0.043267436
case acc: 0.02710671
case acc: 0.025165576
case acc: 0.028598456
top acc: 0.0187 ::: bot acc: 0.0083
top acc: 0.0600 ::: bot acc: 0.0210
top acc: 0.0702 ::: bot acc: 0.0188
top acc: 0.0440 ::: bot acc: 0.0112
top acc: 0.0414 ::: bot acc: 0.0107
top acc: 0.0433 ::: bot acc: 0.0146
current epoch: 42
train loss is 0.029650
average val loss: 0.030290, accuracy: 0.0299
average test loss: 0.027036, accuracy: 0.0264
case acc: 0.009997826
case acc: 0.029534247
case acc: 0.038809024
case acc: 0.028602514
case acc: 0.027816843
case acc: 0.023373678
top acc: 0.0109 ::: bot acc: 0.0160
top acc: 0.0488 ::: bot acc: 0.0112
top acc: 0.0652 ::: bot acc: 0.0155
top acc: 0.0457 ::: bot acc: 0.0123
top acc: 0.0449 ::: bot acc: 0.0117
top acc: 0.0371 ::: bot acc: 0.0114
current epoch: 43
train loss is 0.028236
average val loss: 0.028067, accuracy: 0.0280
average test loss: 0.025331, accuracy: 0.0248
case acc: 0.01354672
case acc: 0.018292338
case acc: 0.033624537
case acc: 0.030167
case acc: 0.033894297
case acc: 0.019095983
top acc: 0.0054 ::: bot acc: 0.0248
top acc: 0.0341 ::: bot acc: 0.0069
top acc: 0.0589 ::: bot acc: 0.0124
top acc: 0.0474 ::: bot acc: 0.0135
top acc: 0.0519 ::: bot acc: 0.0158
top acc: 0.0316 ::: bot acc: 0.0095
current epoch: 44
train loss is 0.031752
average val loss: 0.027262, accuracy: 0.0278
average test loss: 0.025646, accuracy: 0.0255
case acc: 0.024618948
case acc: 0.01684004
case acc: 0.025750412
case acc: 0.028877862
case acc: 0.042032026
case acc: 0.014635783
top acc: 0.0117 ::: bot acc: 0.0382
top acc: 0.0108 ::: bot acc: 0.0294
top acc: 0.0476 ::: bot acc: 0.0114
top acc: 0.0460 ::: bot acc: 0.0125
top acc: 0.0610 ::: bot acc: 0.0222
top acc: 0.0246 ::: bot acc: 0.0102
current epoch: 45
train loss is 0.048495
average val loss: 0.063418, accuracy: 0.0633
average test loss: 0.067014, accuracy: 0.0671
case acc: 0.10590946
case acc: 0.108674265
case acc: 0.060545035
case acc: 0.04428796
case acc: 0.019563045
case acc: 0.063677296
top acc: 0.0927 ::: bot acc: 0.1196
top acc: 0.0889 ::: bot acc: 0.1281
top acc: 0.0331 ::: bot acc: 0.0872
top acc: 0.0266 ::: bot acc: 0.0631
top acc: 0.0070 ::: bot acc: 0.0367
top acc: 0.0474 ::: bot acc: 0.0809
current epoch: 46
train loss is 0.087239
average val loss: 0.060438, accuracy: 0.0603
average test loss: 0.064037, accuracy: 0.0641
case acc: 0.09941453
case acc: 0.10151204
case acc: 0.058731936
case acc: 0.047107555
case acc: 0.020071909
case acc: 0.057895113
top acc: 0.0862 ::: bot acc: 0.1132
top acc: 0.0818 ::: bot acc: 0.1209
top acc: 0.0315 ::: bot acc: 0.0853
top acc: 0.0292 ::: bot acc: 0.0659
top acc: 0.0069 ::: bot acc: 0.0375
top acc: 0.0416 ::: bot acc: 0.0750
current epoch: 47
train loss is 0.059290
average val loss: 0.041235, accuracy: 0.0416
average test loss: 0.044718, accuracy: 0.0449
case acc: 0.069317885
case acc: 0.054965913
case acc: 0.03865695
case acc: 0.04124705
case acc: 0.025889752
case acc: 0.03928583
top acc: 0.0561 ::: bot acc: 0.0830
top acc: 0.0352 ::: bot acc: 0.0743
top acc: 0.0164 ::: bot acc: 0.0628
top acc: 0.0238 ::: bot acc: 0.0598
top acc: 0.0083 ::: bot acc: 0.0455
top acc: 0.0233 ::: bot acc: 0.0563
current epoch: 48
train loss is 0.039795
average val loss: 0.026778, accuracy: 0.0279
average test loss: 0.029484, accuracy: 0.0298
case acc: 0.044265766
case acc: 0.021351626
case acc: 0.025276938
case acc: 0.035675995
case acc: 0.028800055
case acc: 0.023260491
top acc: 0.0311 ::: bot acc: 0.0580
top acc: 0.0081 ::: bot acc: 0.0374
top acc: 0.0132 ::: bot acc: 0.0443
top acc: 0.0190 ::: bot acc: 0.0539
top acc: 0.0106 ::: bot acc: 0.0487
top acc: 0.0089 ::: bot acc: 0.0395
current epoch: 49
train loss is 0.032396
average val loss: 0.016973, accuracy: 0.0171
average test loss: 0.016384, accuracy: 0.0163
case acc: 0.018457532
case acc: 0.014893813
case acc: 0.020751972
case acc: 0.01630901
case acc: 0.0141312
case acc: 0.013456007
top acc: 0.0067 ::: bot acc: 0.0315
top acc: 0.0242 ::: bot acc: 0.0149
top acc: 0.0356 ::: bot acc: 0.0198
top acc: 0.0098 ::: bot acc: 0.0295
top acc: 0.0188 ::: bot acc: 0.0208
top acc: 0.0220 ::: bot acc: 0.0118
current epoch: 50
train loss is 0.027814
average val loss: 0.017179, accuracy: 0.0177
average test loss: 0.017044, accuracy: 0.0174
case acc: 0.02361006
case acc: 0.016008168
case acc: 0.019958604
case acc: 0.015938794
case acc: 0.0159517
case acc: 0.012796594
top acc: 0.0107 ::: bot acc: 0.0372
top acc: 0.0120 ::: bot acc: 0.0275
top acc: 0.0304 ::: bot acc: 0.0250
top acc: 0.0100 ::: bot acc: 0.0288
top acc: 0.0258 ::: bot acc: 0.0142
top acc: 0.0202 ::: bot acc: 0.0133
LME_Co_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6804 6804 6804
1.8562728 -0.6288155 0.12137239 -0.16228472
Validation: 762 762 762
Testing: 744 744 744
pre-processing time: 0.0003898143768310547
the split date is 2010-01-01
net initializing with time: 0.0030031204223632812
preparing training and testing date with time: 2.384185791015625e-07
current epoch: 1
train loss is 0.166971
average val loss: 0.038839, accuracy: 0.0386
average test loss: 0.040810, accuracy: 0.0409
case acc: 0.030177195
case acc: 0.01634293
case acc: 0.03792255
case acc: 0.025446553
case acc: 0.028854415
case acc: 0.10642692
top acc: 0.0141 ::: bot acc: 0.0479
top acc: 0.0280 ::: bot acc: 0.0137
top acc: 0.0688 ::: bot acc: 0.0122
top acc: 0.0169 ::: bot acc: 0.0427
top acc: 0.0493 ::: bot acc: 0.0111
top acc: 0.1387 ::: bot acc: 0.0762
current epoch: 2
train loss is 0.061546
average val loss: 0.095496, accuracy: 0.0951
average test loss: 0.097017, accuracy: 0.0977
case acc: 0.14208694
case acc: 0.107882306
case acc: 0.086174436
case acc: 0.1277433
case acc: 0.09269694
case acc: 0.029339481
top acc: 0.1184 ::: bot acc: 0.1638
top acc: 0.0877 ::: bot acc: 0.1269
top acc: 0.0498 ::: bot acc: 0.1233
top acc: 0.0991 ::: bot acc: 0.1550
top acc: 0.0694 ::: bot acc: 0.1166
top acc: 0.0174 ::: bot acc: 0.0488
current epoch: 3
train loss is 0.077552
average val loss: 0.134437, accuracy: 0.1344
average test loss: 0.135427, accuracy: 0.1355
case acc: 0.17649932
case acc: 0.14380704
case acc: 0.12698923
case acc: 0.16591151
case acc: 0.130807
case acc: 0.06925476
top acc: 0.1524 ::: bot acc: 0.1985
top acc: 0.1236 ::: bot acc: 0.1632
top acc: 0.0912 ::: bot acc: 0.1637
top acc: 0.1383 ::: bot acc: 0.1926
top acc: 0.1082 ::: bot acc: 0.1538
top acc: 0.0403 ::: bot acc: 0.0969
current epoch: 4
train loss is 0.091977
average val loss: 0.116841, accuracy: 0.1168
average test loss: 0.117738, accuracy: 0.1179
case acc: 0.15370001
case acc: 0.12277572
case acc: 0.11015317
case acc: 0.14986883
case acc: 0.111526765
case acc: 0.059400238
top acc: 0.1294 ::: bot acc: 0.1759
top acc: 0.1026 ::: bot acc: 0.1423
top acc: 0.0745 ::: bot acc: 0.1467
top acc: 0.1228 ::: bot acc: 0.1763
top acc: 0.0892 ::: bot acc: 0.1342
top acc: 0.0317 ::: bot acc: 0.0863
current epoch: 5
train loss is 0.098184
average val loss: 0.059022, accuracy: 0.0586
average test loss: 0.060682, accuracy: 0.0613
case acc: 0.089276485
case acc: 0.060280398
case acc: 0.052755628
case acc: 0.09203967
case acc: 0.050790027
case acc: 0.02242685
top acc: 0.0649 ::: bot acc: 0.1115
top acc: 0.0399 ::: bot acc: 0.0798
top acc: 0.0197 ::: bot acc: 0.0880
top acc: 0.0648 ::: bot acc: 0.1185
top acc: 0.0285 ::: bot acc: 0.0737
top acc: 0.0238 ::: bot acc: 0.0348
current epoch: 6
train loss is 0.067649
average val loss: 0.075386, accuracy: 0.0753
average test loss: 0.076510, accuracy: 0.0768
case acc: 0.10158617
case acc: 0.07433598
case acc: 0.07010326
case acc: 0.11011667
case acc: 0.06671491
case acc: 0.038045604
top acc: 0.0772 ::: bot acc: 0.1238
top acc: 0.0540 ::: bot acc: 0.0939
top acc: 0.0346 ::: bot acc: 0.1067
top acc: 0.0831 ::: bot acc: 0.1364
top acc: 0.0443 ::: bot acc: 0.0895
top acc: 0.0168 ::: bot acc: 0.0617
current epoch: 7
train loss is 0.067607
average val loss: 0.072252, accuracy: 0.0722
average test loss: 0.073298, accuracy: 0.0735
case acc: 0.09342458
case acc: 0.06789481
case acc: 0.068153195
case acc: 0.10725337
case acc: 0.06188153
case acc: 0.04250477
top acc: 0.0691 ::: bot acc: 0.1157
top acc: 0.0475 ::: bot acc: 0.0875
top acc: 0.0329 ::: bot acc: 0.1046
top acc: 0.0805 ::: bot acc: 0.1333
top acc: 0.0396 ::: bot acc: 0.0845
top acc: 0.0191 ::: bot acc: 0.0672
current epoch: 8
train loss is 0.062985
average val loss: 0.068281, accuracy: 0.0682
average test loss: 0.069280, accuracy: 0.0694
case acc: 0.084657185
case acc: 0.06078493
case acc: 0.06535284
case acc: 0.10386333
case acc: 0.056141343
case acc: 0.045684196
top acc: 0.0602 ::: bot acc: 0.1070
top acc: 0.0404 ::: bot acc: 0.0805
top acc: 0.0305 ::: bot acc: 0.1017
top acc: 0.0772 ::: bot acc: 0.1299
top acc: 0.0339 ::: bot acc: 0.0787
top acc: 0.0209 ::: bot acc: 0.0710
current epoch: 9
train loss is 0.055743
average val loss: 0.065543, accuracy: 0.0655
average test loss: 0.066498, accuracy: 0.0666
case acc: 0.077603996
case acc: 0.055166546
case acc: 0.06368774
case acc: 0.10202015
case acc: 0.05167769
case acc: 0.049188975
top acc: 0.0532 ::: bot acc: 0.1000
top acc: 0.0348 ::: bot acc: 0.0749
top acc: 0.0291 ::: bot acc: 0.0999
top acc: 0.0754 ::: bot acc: 0.1280
top acc: 0.0295 ::: bot acc: 0.0742
top acc: 0.0231 ::: bot acc: 0.0750
current epoch: 10
train loss is 0.048722
average val loss: 0.062763, accuracy: 0.0627
average test loss: 0.063723, accuracy: 0.0637
case acc: 0.07120245
case acc: 0.050122418
case acc: 0.06196039
case acc: 0.09979078
case acc: 0.0476079
case acc: 0.051615667
top acc: 0.0470 ::: bot acc: 0.0936
top acc: 0.0297 ::: bot acc: 0.0699
top acc: 0.0276 ::: bot acc: 0.0981
top acc: 0.0733 ::: bot acc: 0.1257
top acc: 0.0256 ::: bot acc: 0.0700
top acc: 0.0250 ::: bot acc: 0.0777
current epoch: 11
train loss is 0.043201
average val loss: 0.053135, accuracy: 0.0531
average test loss: 0.054381, accuracy: 0.0543
case acc: 0.058688752
case acc: 0.03921923
case acc: 0.053767342
case acc: 0.08995988
case acc: 0.03739934
case acc: 0.046545416
top acc: 0.0349 ::: bot acc: 0.0810
top acc: 0.0195 ::: bot acc: 0.0587
top acc: 0.0209 ::: bot acc: 0.0892
top acc: 0.0637 ::: bot acc: 0.1158
top acc: 0.0162 ::: bot acc: 0.0593
top acc: 0.0213 ::: bot acc: 0.0719
current epoch: 12
train loss is 0.037449
average val loss: 0.046594, accuracy: 0.0466
average test loss: 0.048118, accuracy: 0.0480
case acc: 0.050816253
case acc: 0.033195242
case acc: 0.048567176
case acc: 0.08101961
case acc: 0.031847563
case acc: 0.04233957
top acc: 0.0275 ::: bot acc: 0.0729
top acc: 0.0146 ::: bot acc: 0.0522
top acc: 0.0173 ::: bot acc: 0.0832
top acc: 0.0549 ::: bot acc: 0.1068
top acc: 0.0121 ::: bot acc: 0.0529
top acc: 0.0187 ::: bot acc: 0.0668
current epoch: 13
train loss is 0.035318
average val loss: 0.041998, accuracy: 0.0420
average test loss: 0.043786, accuracy: 0.0436
case acc: 0.04573345
case acc: 0.029805241
case acc: 0.04532662
case acc: 0.072570354
case acc: 0.028785532
case acc: 0.039556157
top acc: 0.0235 ::: bot acc: 0.0673
top acc: 0.0123 ::: bot acc: 0.0483
top acc: 0.0152 ::: bot acc: 0.0793
top acc: 0.0464 ::: bot acc: 0.0984
top acc: 0.0104 ::: bot acc: 0.0493
top acc: 0.0171 ::: bot acc: 0.0634
current epoch: 14
train loss is 0.033590
average val loss: 0.037451, accuracy: 0.0375
average test loss: 0.039557, accuracy: 0.0395
case acc: 0.041411385
case acc: 0.027186261
case acc: 0.0420815
case acc: 0.06335242
case acc: 0.026442792
case acc: 0.0363036
top acc: 0.0204 ::: bot acc: 0.0622
top acc: 0.0109 ::: bot acc: 0.0450
top acc: 0.0134 ::: bot acc: 0.0754
top acc: 0.0372 ::: bot acc: 0.0892
top acc: 0.0096 ::: bot acc: 0.0463
top acc: 0.0156 ::: bot acc: 0.0593
current epoch: 15
train loss is 0.031808
average val loss: 0.033183, accuracy: 0.0333
average test loss: 0.035645, accuracy: 0.0356
case acc: 0.037509345
case acc: 0.024776356
case acc: 0.03904539
case acc: 0.05461172
case acc: 0.024374496
case acc: 0.03339372
top acc: 0.0178 ::: bot acc: 0.0576
top acc: 0.0098 ::: bot acc: 0.0419
top acc: 0.0122 ::: bot acc: 0.0715
top acc: 0.0289 ::: bot acc: 0.0803
top acc: 0.0093 ::: bot acc: 0.0434
top acc: 0.0150 ::: bot acc: 0.0552
current epoch: 16
train loss is 0.030544
average val loss: 0.029625, accuracy: 0.0297
average test loss: 0.032454, accuracy: 0.0325
case acc: 0.03464516
case acc: 0.023135874
case acc: 0.036517154
case acc: 0.046963744
case acc: 0.023029935
case acc: 0.030576473
top acc: 0.0161 ::: bot acc: 0.0542
top acc: 0.0092 ::: bot acc: 0.0398
top acc: 0.0117 ::: bot acc: 0.0679
top acc: 0.0225 ::: bot acc: 0.0720
top acc: 0.0095 ::: bot acc: 0.0413
top acc: 0.0150 ::: bot acc: 0.0509
current epoch: 17
train loss is 0.029286
average val loss: 0.026359, accuracy: 0.0265
average test loss: 0.029573, accuracy: 0.0297
case acc: 0.03206356
case acc: 0.021579705
case acc: 0.034333587
case acc: 0.04035612
case acc: 0.021748077
case acc: 0.027935503
top acc: 0.0148 ::: bot acc: 0.0510
top acc: 0.0087 ::: bot acc: 0.0377
top acc: 0.0122 ::: bot acc: 0.0644
top acc: 0.0181 ::: bot acc: 0.0644
top acc: 0.0098 ::: bot acc: 0.0393
top acc: 0.0157 ::: bot acc: 0.0467
current epoch: 18
train loss is 0.028370
average val loss: 0.025917, accuracy: 0.0260
average test loss: 0.029171, accuracy: 0.0293
case acc: 0.03207074
case acc: 0.02228199
case acc: 0.034238245
case acc: 0.037086193
case acc: 0.022365933
case acc: 0.027579198
top acc: 0.0148 ::: bot acc: 0.0510
top acc: 0.0089 ::: bot acc: 0.0386
top acc: 0.0123 ::: bot acc: 0.0643
top acc: 0.0161 ::: bot acc: 0.0605
top acc: 0.0097 ::: bot acc: 0.0403
top acc: 0.0158 ::: bot acc: 0.0461
current epoch: 19
train loss is 0.027870
average val loss: 0.021335, accuracy: 0.0215
average test loss: 0.025265, accuracy: 0.0253
case acc: 0.027429793
case acc: 0.018981194
case acc: 0.03132394
case acc: 0.029904576
case acc: 0.019438628
case acc: 0.024849407
top acc: 0.0129 ::: bot acc: 0.0450
top acc: 0.0094 ::: bot acc: 0.0335
top acc: 0.0147 ::: bot acc: 0.0588
top acc: 0.0124 ::: bot acc: 0.0516
top acc: 0.0110 ::: bot acc: 0.0352
top acc: 0.0185 ::: bot acc: 0.0407
current epoch: 20
train loss is 0.027001
average val loss: 0.021691, accuracy: 0.0218
average test loss: 0.025550, accuracy: 0.0255
case acc: 0.027837368
case acc: 0.019575182
case acc: 0.031728644
case acc: 0.02861922
case acc: 0.020117423
case acc: 0.025336284
top acc: 0.0130 ::: bot acc: 0.0456
top acc: 0.0088 ::: bot acc: 0.0346
top acc: 0.0142 ::: bot acc: 0.0596
top acc: 0.0120 ::: bot acc: 0.0500
top acc: 0.0105 ::: bot acc: 0.0365
top acc: 0.0179 ::: bot acc: 0.0417
current epoch: 21
train loss is 0.026717
average val loss: 0.020134, accuracy: 0.0202
average test loss: 0.024221, accuracy: 0.0242
case acc: 0.0261057
case acc: 0.01855526
case acc: 0.030815743
case acc: 0.025695106
case acc: 0.019165706
case acc: 0.02461473
top acc: 0.0127 ::: bot acc: 0.0431
top acc: 0.0096 ::: bot acc: 0.0327
top acc: 0.0153 ::: bot acc: 0.0577
top acc: 0.0115 ::: bot acc: 0.0458
top acc: 0.0112 ::: bot acc: 0.0347
top acc: 0.0188 ::: bot acc: 0.0402
current epoch: 22
train loss is 0.026380
average val loss: 0.017362, accuracy: 0.0174
average test loss: 0.021922, accuracy: 0.0219
case acc: 0.022828523
case acc: 0.016288664
case acc: 0.029100182
case acc: 0.022471515
case acc: 0.0173993
case acc: 0.023148086
top acc: 0.0133 ::: bot acc: 0.0379
top acc: 0.0124 ::: bot acc: 0.0279
top acc: 0.0187 ::: bot acc: 0.0535
top acc: 0.0135 ::: bot acc: 0.0401
top acc: 0.0149 ::: bot acc: 0.0301
top acc: 0.0214 ::: bot acc: 0.0367
current epoch: 23
train loss is 0.025898
average val loss: 0.016581, accuracy: 0.0167
average test loss: 0.021287, accuracy: 0.0212
case acc: 0.021704772
case acc: 0.015592639
case acc: 0.028601103
case acc: 0.02172842
case acc: 0.017030673
case acc: 0.022833792
top acc: 0.0140 ::: bot acc: 0.0359
top acc: 0.0140 ::: bot acc: 0.0261
top acc: 0.0201 ::: bot acc: 0.0520
top acc: 0.0146 ::: bot acc: 0.0384
top acc: 0.0167 ::: bot acc: 0.0284
top acc: 0.0221 ::: bot acc: 0.0359
current epoch: 24
train loss is 0.025578
average val loss: 0.018138, accuracy: 0.0182
average test loss: 0.022533, accuracy: 0.0225
case acc: 0.023537569
case acc: 0.016909584
case acc: 0.0295629
case acc: 0.023174958
case acc: 0.017851636
case acc: 0.023708485
top acc: 0.0129 ::: bot acc: 0.0392
top acc: 0.0112 ::: bot acc: 0.0294
top acc: 0.0177 ::: bot acc: 0.0547
top acc: 0.0126 ::: bot acc: 0.0416
top acc: 0.0134 ::: bot acc: 0.0317
top acc: 0.0203 ::: bot acc: 0.0381
current epoch: 25
train loss is 0.025429
average val loss: 0.018271, accuracy: 0.0183
average test loss: 0.022641, accuracy: 0.0226
case acc: 0.023853505
case acc: 0.017271843
case acc: 0.029553402
case acc: 0.023126397
case acc: 0.018135035
case acc: 0.023538345
top acc: 0.0127 ::: bot acc: 0.0397
top acc: 0.0107 ::: bot acc: 0.0302
top acc: 0.0177 ::: bot acc: 0.0547
top acc: 0.0127 ::: bot acc: 0.0415
top acc: 0.0127 ::: bot acc: 0.0325
top acc: 0.0208 ::: bot acc: 0.0376
current epoch: 26
train loss is 0.025259
average val loss: 0.017600, accuracy: 0.0176
average test loss: 0.022093, accuracy: 0.0220
case acc: 0.023045678
case acc: 0.016767155
case acc: 0.029090526
case acc: 0.022288952
case acc: 0.0177898
case acc: 0.023189666
top acc: 0.0130 ::: bot acc: 0.0383
top acc: 0.0114 ::: bot acc: 0.0291
top acc: 0.0187 ::: bot acc: 0.0535
top acc: 0.0137 ::: bot acc: 0.0397
top acc: 0.0137 ::: bot acc: 0.0315
top acc: 0.0215 ::: bot acc: 0.0367
current epoch: 27
train loss is 0.025099
average val loss: 0.016935, accuracy: 0.0170
average test loss: 0.021554, accuracy: 0.0215
case acc: 0.022049118
case acc: 0.016099697
case acc: 0.028683452
case acc: 0.02162769
case acc: 0.017386403
case acc: 0.023037752
top acc: 0.0136 ::: bot acc: 0.0366
top acc: 0.0125 ::: bot acc: 0.0275
top acc: 0.0197 ::: bot acc: 0.0524
top acc: 0.0148 ::: bot acc: 0.0382
top acc: 0.0151 ::: bot acc: 0.0301
top acc: 0.0219 ::: bot acc: 0.0364
current epoch: 28
train loss is 0.024892
average val loss: 0.014939, accuracy: 0.0151
average test loss: 0.019955, accuracy: 0.0199
case acc: 0.019230122
case acc: 0.014599439
case acc: 0.027388737
case acc: 0.01998826
case acc: 0.016584938
case acc: 0.021717947
top acc: 0.0166 ::: bot acc: 0.0309
top acc: 0.0179 ::: bot acc: 0.0220
top acc: 0.0246 ::: bot acc: 0.0474
top acc: 0.0193 ::: bot acc: 0.0334
top acc: 0.0205 ::: bot acc: 0.0246
top acc: 0.0258 ::: bot acc: 0.0322
current epoch: 29
train loss is 0.024691
average val loss: 0.015726, accuracy: 0.0158
average test loss: 0.020592, accuracy: 0.0206
case acc: 0.020400504
case acc: 0.015055451
case acc: 0.027823651
case acc: 0.021073954
case acc: 0.016813733
case acc: 0.022167157
top acc: 0.0149 ::: bot acc: 0.0334
top acc: 0.0155 ::: bot acc: 0.0244
top acc: 0.0225 ::: bot acc: 0.0495
top acc: 0.0158 ::: bot acc: 0.0369
top acc: 0.0181 ::: bot acc: 0.0270
top acc: 0.0240 ::: bot acc: 0.0340
current epoch: 30
train loss is 0.024614
average val loss: 0.016476, accuracy: 0.0166
average test loss: 0.021180, accuracy: 0.0212
case acc: 0.021493608
case acc: 0.015704343
case acc: 0.028074164
case acc: 0.022170447
case acc: 0.01715103
case acc: 0.022325424
top acc: 0.0139 ::: bot acc: 0.0355
top acc: 0.0134 ::: bot acc: 0.0265
top acc: 0.0213 ::: bot acc: 0.0506
top acc: 0.0137 ::: bot acc: 0.0396
top acc: 0.0161 ::: bot acc: 0.0290
top acc: 0.0236 ::: bot acc: 0.0344
current epoch: 31
train loss is 0.024506
average val loss: 0.019864, accuracy: 0.0199
average test loss: 0.023944, accuracy: 0.0239
case acc: 0.025514854
case acc: 0.018793957
case acc: 0.02998852
case acc: 0.025613744
case acc: 0.019637926
case acc: 0.023999805
top acc: 0.0126 ::: bot acc: 0.0422
top acc: 0.0090 ::: bot acc: 0.0333
top acc: 0.0166 ::: bot acc: 0.0559
top acc: 0.0116 ::: bot acc: 0.0457
top acc: 0.0108 ::: bot acc: 0.0357
top acc: 0.0200 ::: bot acc: 0.0387
current epoch: 32
train loss is 0.024897
average val loss: 0.021763, accuracy: 0.0218
average test loss: 0.025542, accuracy: 0.0255
case acc: 0.02756635
case acc: 0.02095956
case acc: 0.031222409
case acc: 0.026310816
case acc: 0.021738177
case acc: 0.025287833
top acc: 0.0128 ::: bot acc: 0.0451
top acc: 0.0086 ::: bot acc: 0.0367
top acc: 0.0146 ::: bot acc: 0.0587
top acc: 0.0116 ::: bot acc: 0.0468
top acc: 0.0099 ::: bot acc: 0.0392
top acc: 0.0181 ::: bot acc: 0.0416
current epoch: 33
train loss is 0.025098
average val loss: 0.020947, accuracy: 0.0209
average test loss: 0.024852, accuracy: 0.0247
case acc: 0.026329473
case acc: 0.020278083
case acc: 0.030989908
case acc: 0.023588933
case acc: 0.021328561
case acc: 0.025667904
top acc: 0.0126 ::: bot acc: 0.0434
top acc: 0.0085 ::: bot acc: 0.0358
top acc: 0.0149 ::: bot acc: 0.0582
top acc: 0.0122 ::: bot acc: 0.0424
top acc: 0.0100 ::: bot acc: 0.0386
top acc: 0.0176 ::: bot acc: 0.0424
current epoch: 34
train loss is 0.025502
average val loss: 0.015344, accuracy: 0.0154
average test loss: 0.020225, accuracy: 0.0200
case acc: 0.018976627
case acc: 0.014768273
case acc: 0.027554132
case acc: 0.01915472
case acc: 0.01673265
case acc: 0.022755623
top acc: 0.0171 ::: bot acc: 0.0302
top acc: 0.0166 ::: bot acc: 0.0233
top acc: 0.0235 ::: bot acc: 0.0484
top acc: 0.0239 ::: bot acc: 0.0287
top acc: 0.0186 ::: bot acc: 0.0265
top acc: 0.0223 ::: bot acc: 0.0356
current epoch: 35
train loss is 0.025928
average val loss: 0.023333, accuracy: 0.0235
average test loss: 0.025986, accuracy: 0.0263
case acc: 0.02503377
case acc: 0.02669757
case acc: 0.028520275
case acc: 0.027791448
case acc: 0.026957605
case acc: 0.022528736
top acc: 0.0459 ::: bot acc: 0.0103
top acc: 0.0454 ::: bot acc: 0.0100
top acc: 0.0478 ::: bot acc: 0.0240
top acc: 0.0487 ::: bot acc: 0.0126
top acc: 0.0470 ::: bot acc: 0.0091
top acc: 0.0428 ::: bot acc: 0.0152
current epoch: 36
train loss is 0.031056
average val loss: 0.021339, accuracy: 0.0214
average test loss: 0.024356, accuracy: 0.0248
case acc: 0.023645114
case acc: 0.026180264
case acc: 0.027955677
case acc: 0.022430595
case acc: 0.026577728
case acc: 0.021770673
top acc: 0.0440 ::: bot acc: 0.0100
top acc: 0.0448 ::: bot acc: 0.0097
top acc: 0.0458 ::: bot acc: 0.0260
top acc: 0.0395 ::: bot acc: 0.0150
top acc: 0.0465 ::: bot acc: 0.0089
top acc: 0.0403 ::: bot acc: 0.0176
current epoch: 37
train loss is 0.032168
average val loss: 0.026747, accuracy: 0.0269
average test loss: 0.029764, accuracy: 0.0298
case acc: 0.031261574
case acc: 0.023943637
case acc: 0.034341026
case acc: 0.034748774
case acc: 0.024436517
case acc: 0.02995207
top acc: 0.0143 ::: bot acc: 0.0499
top acc: 0.0095 ::: bot acc: 0.0407
top acc: 0.0120 ::: bot acc: 0.0646
top acc: 0.0147 ::: bot acc: 0.0579
top acc: 0.0094 ::: bot acc: 0.0435
top acc: 0.0153 ::: bot acc: 0.0499
current epoch: 38
train loss is 0.026520
average val loss: 0.028258, accuracy: 0.0283
average test loss: 0.031047, accuracy: 0.0311
case acc: 0.034916684
case acc: 0.028153257
case acc: 0.034540888
case acc: 0.033237826
case acc: 0.027953312
case acc: 0.028054083
top acc: 0.0162 ::: bot acc: 0.0544
top acc: 0.0115 ::: bot acc: 0.0460
top acc: 0.0118 ::: bot acc: 0.0650
top acc: 0.0138 ::: bot acc: 0.0561
top acc: 0.0098 ::: bot acc: 0.0486
top acc: 0.0159 ::: bot acc: 0.0467
current epoch: 39
train loss is 0.028212
average val loss: 0.014283, accuracy: 0.0143
average test loss: 0.019318, accuracy: 0.0192
case acc: 0.017983768
case acc: 0.014432257
case acc: 0.026525812
case acc: 0.019104382
case acc: 0.01650324
case acc: 0.020864364
top acc: 0.0203 ::: bot acc: 0.0270
top acc: 0.0201 ::: bot acc: 0.0198
top acc: 0.0305 ::: bot acc: 0.0413
top acc: 0.0259 ::: bot acc: 0.0269
top acc: 0.0223 ::: bot acc: 0.0228
top acc: 0.0318 ::: bot acc: 0.0260
current epoch: 40
train loss is 0.024997
average val loss: 0.017666, accuracy: 0.0177
average test loss: 0.021402, accuracy: 0.0215
case acc: 0.018838631
case acc: 0.019512456
case acc: 0.026863595
case acc: 0.021719221
case acc: 0.020652888
case acc: 0.021209968
top acc: 0.0360 ::: bot acc: 0.0117
top acc: 0.0357 ::: bot acc: 0.0080
top acc: 0.0412 ::: bot acc: 0.0306
top acc: 0.0379 ::: bot acc: 0.0161
top acc: 0.0374 ::: bot acc: 0.0093
top acc: 0.0381 ::: bot acc: 0.0198
current epoch: 41
train loss is 0.026220
average val loss: 0.015315, accuracy: 0.0154
average test loss: 0.019724, accuracy: 0.0199
case acc: 0.01725601
case acc: 0.017011533
case acc: 0.026450781
case acc: 0.019062797
case acc: 0.01863682
case acc: 0.020834144
top acc: 0.0306 ::: bot acc: 0.0167
top acc: 0.0312 ::: bot acc: 0.0095
top acc: 0.0361 ::: bot acc: 0.0356
top acc: 0.0283 ::: bot acc: 0.0244
top acc: 0.0330 ::: bot acc: 0.0122
top acc: 0.0331 ::: bot acc: 0.0247
current epoch: 42
train loss is 0.026405
average val loss: 0.019609, accuracy: 0.0197
average test loss: 0.023701, accuracy: 0.0237
case acc: 0.024671376
case acc: 0.018177105
case acc: 0.029311128
case acc: 0.026872259
case acc: 0.019206269
case acc: 0.024090838
top acc: 0.0127 ::: bot acc: 0.0408
top acc: 0.0095 ::: bot acc: 0.0321
top acc: 0.0177 ::: bot acc: 0.0543
top acc: 0.0116 ::: bot acc: 0.0478
top acc: 0.0109 ::: bot acc: 0.0349
top acc: 0.0197 ::: bot acc: 0.0389
current epoch: 43
train loss is 0.025508
average val loss: 0.028682, accuracy: 0.0287
average test loss: 0.031384, accuracy: 0.0315
case acc: 0.03544674
case acc: 0.028794238
case acc: 0.03449105
case acc: 0.033897735
case acc: 0.028592817
case acc: 0.027837796
top acc: 0.0165 ::: bot acc: 0.0550
top acc: 0.0118 ::: bot acc: 0.0468
top acc: 0.0119 ::: bot acc: 0.0649
top acc: 0.0141 ::: bot acc: 0.0570
top acc: 0.0100 ::: bot acc: 0.0494
top acc: 0.0159 ::: bot acc: 0.0464
current epoch: 44
train loss is 0.028443
average val loss: 0.014247, accuracy: 0.0143
average test loss: 0.019243, accuracy: 0.0192
case acc: 0.017714944
case acc: 0.014403434
case acc: 0.026432464
case acc: 0.019106215
case acc: 0.016513214
case acc: 0.020839468
top acc: 0.0214 ::: bot acc: 0.0259
top acc: 0.0210 ::: bot acc: 0.0188
top acc: 0.0321 ::: bot acc: 0.0396
top acc: 0.0262 ::: bot acc: 0.0266
top acc: 0.0232 ::: bot acc: 0.0218
top acc: 0.0338 ::: bot acc: 0.0241
current epoch: 45
train loss is 0.024558
average val loss: 0.017118, accuracy: 0.0172
average test loss: 0.020972, accuracy: 0.0210
case acc: 0.01841053
case acc: 0.018725965
case acc: 0.026809402
case acc: 0.020983042
case acc: 0.019978892
case acc: 0.0211918
top acc: 0.0350 ::: bot acc: 0.0125
top acc: 0.0344 ::: bot acc: 0.0082
top acc: 0.0407 ::: bot acc: 0.0311
top acc: 0.0362 ::: bot acc: 0.0173
top acc: 0.0362 ::: bot acc: 0.0098
top acc: 0.0379 ::: bot acc: 0.0200
current epoch: 46
train loss is 0.025566
average val loss: 0.014501, accuracy: 0.0147
average test loss: 0.019282, accuracy: 0.0194
case acc: 0.017017178
case acc: 0.015398399
case acc: 0.02640639
case acc: 0.019176118
case acc: 0.017360458
case acc: 0.02091926
top acc: 0.0271 ::: bot acc: 0.0202
top acc: 0.0274 ::: bot acc: 0.0124
top acc: 0.0335 ::: bot acc: 0.0384
top acc: 0.0250 ::: bot acc: 0.0279
top acc: 0.0292 ::: bot acc: 0.0158
top acc: 0.0309 ::: bot acc: 0.0271
current epoch: 47
train loss is 0.024971
average val loss: 0.018706, accuracy: 0.0188
average test loss: 0.022943, accuracy: 0.0230
case acc: 0.023636991
case acc: 0.01755413
case acc: 0.028737688
case acc: 0.025799766
case acc: 0.018650606
case acc: 0.023525842
top acc: 0.0129 ::: bot acc: 0.0392
top acc: 0.0102 ::: bot acc: 0.0308
top acc: 0.0191 ::: bot acc: 0.0527
top acc: 0.0115 ::: bot acc: 0.0462
top acc: 0.0116 ::: bot acc: 0.0337
top acc: 0.0208 ::: bot acc: 0.0375
current epoch: 48
train loss is 0.024689
average val loss: 0.024926, accuracy: 0.0250
average test loss: 0.028188, accuracy: 0.0283
case acc: 0.031042274
case acc: 0.024759123
case acc: 0.03221197
case acc: 0.030517481
case acc: 0.025077526
case acc: 0.026250327
top acc: 0.0143 ::: bot acc: 0.0496
top acc: 0.0099 ::: bot acc: 0.0417
top acc: 0.0134 ::: bot acc: 0.0608
top acc: 0.0126 ::: bot acc: 0.0527
top acc: 0.0093 ::: bot acc: 0.0445
top acc: 0.0170 ::: bot acc: 0.0434
current epoch: 49
train loss is 0.026722
average val loss: 0.014185, accuracy: 0.0142
average test loss: 0.019245, accuracy: 0.0192
case acc: 0.017695077
case acc: 0.014384867
case acc: 0.02648818
case acc: 0.019170184
case acc: 0.016507164
case acc: 0.020895237
top acc: 0.0214 ::: bot acc: 0.0259
top acc: 0.0207 ::: bot acc: 0.0190
top acc: 0.0311 ::: bot acc: 0.0407
top acc: 0.0251 ::: bot acc: 0.0278
top acc: 0.0228 ::: bot acc: 0.0222
top acc: 0.0316 ::: bot acc: 0.0264
current epoch: 50
train loss is 0.024518
average val loss: 0.018168, accuracy: 0.0182
average test loss: 0.021798, accuracy: 0.0219
case acc: 0.019663021
case acc: 0.020212956
case acc: 0.027178288
case acc: 0.02169318
case acc: 0.021221275
case acc: 0.021431493
top acc: 0.0377 ::: bot acc: 0.0108
top acc: 0.0368 ::: bot acc: 0.0078
top acc: 0.0427 ::: bot acc: 0.0291
top acc: 0.0378 ::: bot acc: 0.0162
top acc: 0.0385 ::: bot acc: 0.0089
top acc: 0.0391 ::: bot acc: 0.0189
LME_Co_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6780 6780 6780
1.7082474 -0.6288155 0.12137239 -0.1537469
Validation: 756 756 756
Testing: 774 774 774
pre-processing time: 0.0003325939178466797
the split date is 2010-07-01
net initializing with time: 0.0029604434967041016
preparing training and testing date with time: 4.76837158203125e-07
current epoch: 1
train loss is 0.321543
average val loss: 0.154027, accuracy: 0.1542
average test loss: 0.155215, accuracy: 0.1553
case acc: 0.21192421
case acc: 0.357798
case acc: 0.07055182
case acc: 0.14108516
case acc: 0.10513931
case acc: 0.045440245
top acc: 0.1892 ::: bot acc: 0.2342
top acc: 0.3361 ::: bot acc: 0.3782
top acc: 0.0411 ::: bot acc: 0.1006
top acc: 0.1070 ::: bot acc: 0.1729
top acc: 0.0723 ::: bot acc: 0.1343
top acc: 0.0204 ::: bot acc: 0.0710
current epoch: 2
train loss is 0.204999
average val loss: 0.106107, accuracy: 0.1054
average test loss: 0.106068, accuracy: 0.1054
case acc: 0.018787872
case acc: 0.12908457
case acc: 0.14499018
case acc: 0.072884396
case acc: 0.103021376
case acc: 0.16371696
top acc: 0.0317 ::: bot acc: 0.0136
top acc: 0.1073 ::: bot acc: 0.1495
top acc: 0.1770 ::: bot acc: 0.1134
top acc: 0.1065 ::: bot acc: 0.0415
top acc: 0.1364 ::: bot acc: 0.0738
top acc: 0.1935 ::: bot acc: 0.1358
current epoch: 3
train loss is 0.083822
average val loss: 0.139785, accuracy: 0.1401
average test loss: 0.140981, accuracy: 0.1411
case acc: 0.19193779
case acc: 0.31815237
case acc: 0.060512234
case acc: 0.1284218
case acc: 0.10255779
case acc: 0.04524656
top acc: 0.1689 ::: bot acc: 0.2143
top acc: 0.2964 ::: bot acc: 0.3387
top acc: 0.0326 ::: bot acc: 0.0901
top acc: 0.0945 ::: bot acc: 0.1602
top acc: 0.0698 ::: bot acc: 0.1314
top acc: 0.0201 ::: bot acc: 0.0708
current epoch: 4
train loss is 0.118392
average val loss: 0.114002, accuracy: 0.1149
average test loss: 0.115411, accuracy: 0.1158
case acc: 0.15996064
case acc: 0.28156298
case acc: 0.040176153
case acc: 0.10323109
case acc: 0.08103777
case acc: 0.029025577
top acc: 0.1367 ::: bot acc: 0.1825
top acc: 0.2601 ::: bot acc: 0.3021
top acc: 0.0189 ::: bot acc: 0.0663
top acc: 0.0693 ::: bot acc: 0.1349
top acc: 0.0499 ::: bot acc: 0.1091
top acc: 0.0134 ::: bot acc: 0.0499
current epoch: 5
train loss is 0.110585
average val loss: 0.091863, accuracy: 0.0934
average test loss: 0.093398, accuracy: 0.0939
case acc: 0.12852667
case acc: 0.2455804
case acc: 0.025798779
case acc: 0.07956858
case acc: 0.062156115
case acc: 0.021963615
top acc: 0.1052 ::: bot acc: 0.1510
top acc: 0.2242 ::: bot acc: 0.2661
top acc: 0.0208 ::: bot acc: 0.0435
top acc: 0.0462 ::: bot acc: 0.1109
top acc: 0.0331 ::: bot acc: 0.0891
top acc: 0.0268 ::: bot acc: 0.0312
current epoch: 6
train loss is 0.098586
average val loss: 0.088881, accuracy: 0.0904
average test loss: 0.090408, accuracy: 0.0908
case acc: 0.12052505
case acc: 0.23203178
case acc: 0.0259203
case acc: 0.07843234
case acc: 0.0653257
case acc: 0.022836564
top acc: 0.0971 ::: bot acc: 0.1430
top acc: 0.2107 ::: bot acc: 0.2526
top acc: 0.0205 ::: bot acc: 0.0439
top acc: 0.0451 ::: bot acc: 0.1096
top acc: 0.0357 ::: bot acc: 0.0926
top acc: 0.0220 ::: bot acc: 0.0362
current epoch: 7
train loss is 0.091131
average val loss: 0.084814, accuracy: 0.0863
average test loss: 0.086344, accuracy: 0.0867
case acc: 0.111272134
case acc: 0.21700786
case acc: 0.025570327
case acc: 0.07571856
case acc: 0.06687197
case acc: 0.023817033
top acc: 0.0879 ::: bot acc: 0.1337
top acc: 0.1956 ::: bot acc: 0.2376
top acc: 0.0215 ::: bot acc: 0.0428
top acc: 0.0425 ::: bot acc: 0.1069
top acc: 0.0369 ::: bot acc: 0.0942
top acc: 0.0187 ::: bot acc: 0.0395
current epoch: 8
train loss is 0.085128
average val loss: 0.081021, accuracy: 0.0825
average test loss: 0.082537, accuracy: 0.0829
case acc: 0.102403715
case acc: 0.2027524
case acc: 0.025392942
case acc: 0.073310055
case acc: 0.068185024
case acc: 0.025152551
top acc: 0.0791 ::: bot acc: 0.1248
top acc: 0.1814 ::: bot acc: 0.2233
top acc: 0.0221 ::: bot acc: 0.0422
top acc: 0.0403 ::: bot acc: 0.1043
top acc: 0.0381 ::: bot acc: 0.0955
top acc: 0.0164 ::: bot acc: 0.0426
current epoch: 9
train loss is 0.081417
average val loss: 0.082040, accuracy: 0.0833
average test loss: 0.083545, accuracy: 0.0838
case acc: 0.099226765
case acc: 0.19560058
case acc: 0.027559333
case acc: 0.07668991
case acc: 0.07406023
case acc: 0.029470092
top acc: 0.0760 ::: bot acc: 0.1217
top acc: 0.1743 ::: bot acc: 0.2161
top acc: 0.0180 ::: bot acc: 0.0476
top acc: 0.0434 ::: bot acc: 0.1079
top acc: 0.0431 ::: bot acc: 0.1017
top acc: 0.0130 ::: bot acc: 0.0508
current epoch: 10
train loss is 0.081443
average val loss: 0.089079, accuracy: 0.0899
average test loss: 0.090494, accuracy: 0.0907
case acc: 0.10200712
case acc: 0.19628912
case acc: 0.034696944
case acc: 0.086454034
case acc: 0.085206814
case acc: 0.039666515
top acc: 0.0787 ::: bot acc: 0.1245
top acc: 0.1750 ::: bot acc: 0.2168
top acc: 0.0164 ::: bot acc: 0.0592
top acc: 0.0525 ::: bot acc: 0.1180
top acc: 0.0529 ::: bot acc: 0.1135
top acc: 0.0164 ::: bot acc: 0.0643
current epoch: 11
train loss is 0.079062
average val loss: 0.081993, accuracy: 0.0829
average test loss: 0.083470, accuracy: 0.0836
case acc: 0.0888202
case acc: 0.18184035
case acc: 0.031514738
case acc: 0.0809548
case acc: 0.08115684
case acc: 0.037573855
top acc: 0.0655 ::: bot acc: 0.1113
top acc: 0.1605 ::: bot acc: 0.2024
top acc: 0.0157 ::: bot acc: 0.0548
top acc: 0.0474 ::: bot acc: 0.1124
top acc: 0.0493 ::: bot acc: 0.1092
top acc: 0.0154 ::: bot acc: 0.0617
current epoch: 12
train loss is 0.074369
average val loss: 0.077784, accuracy: 0.0787
average test loss: 0.079293, accuracy: 0.0794
case acc: 0.07886388
case acc: 0.17077862
case acc: 0.03055931
case acc: 0.07840615
case acc: 0.0800282
case acc: 0.03787554
top acc: 0.0556 ::: bot acc: 0.1014
top acc: 0.1494 ::: bot acc: 0.1914
top acc: 0.0157 ::: bot acc: 0.0534
top acc: 0.0450 ::: bot acc: 0.1098
top acc: 0.0484 ::: bot acc: 0.1079
top acc: 0.0154 ::: bot acc: 0.0621
current epoch: 13
train loss is 0.069846
average val loss: 0.069246, accuracy: 0.0704
average test loss: 0.070882, accuracy: 0.0710
case acc: 0.06405662
case acc: 0.1548552
case acc: 0.027217304
case acc: 0.07116043
case acc: 0.07419682
case acc: 0.034300417
top acc: 0.0409 ::: bot acc: 0.0866
top acc: 0.1334 ::: bot acc: 0.1755
top acc: 0.0186 ::: bot acc: 0.0469
top acc: 0.0385 ::: bot acc: 0.1022
top acc: 0.0434 ::: bot acc: 0.1017
top acc: 0.0139 ::: bot acc: 0.0574
current epoch: 14
train loss is 0.066435
average val loss: 0.068225, accuracy: 0.0692
average test loss: 0.069900, accuracy: 0.0699
case acc: 0.058097906
case acc: 0.14780168
case acc: 0.028189844
case acc: 0.07201393
case acc: 0.076153524
case acc: 0.037189085
top acc: 0.0350 ::: bot acc: 0.0806
top acc: 0.1263 ::: bot acc: 0.1685
top acc: 0.0173 ::: bot acc: 0.0491
top acc: 0.0393 ::: bot acc: 0.1032
top acc: 0.0452 ::: bot acc: 0.1037
top acc: 0.0150 ::: bot acc: 0.0611
current epoch: 15
train loss is 0.061451
average val loss: 0.058185, accuracy: 0.0595
average test loss: 0.059959, accuracy: 0.0599
case acc: 0.042161446
case acc: 0.12981811
case acc: 0.02493068
case acc: 0.062825486
case acc: 0.0678847
case acc: 0.031782936
top acc: 0.0204 ::: bot acc: 0.0640
top acc: 0.1083 ::: bot acc: 0.1505
top acc: 0.0246 ::: bot acc: 0.0403
top acc: 0.0319 ::: bot acc: 0.0931
top acc: 0.0380 ::: bot acc: 0.0949
top acc: 0.0130 ::: bot acc: 0.0540
current epoch: 16
train loss is 0.056669
average val loss: 0.052113, accuracy: 0.0535
average test loss: 0.053923, accuracy: 0.0537
case acc: 0.03165154
case acc: 0.1159627
case acc: 0.024174232
case acc: 0.057595357
case acc: 0.0633788
case acc: 0.02965167
top acc: 0.0119 ::: bot acc: 0.0525
top acc: 0.0944 ::: bot acc: 0.1367
top acc: 0.0292 ::: bot acc: 0.0357
top acc: 0.0281 ::: bot acc: 0.0872
top acc: 0.0340 ::: bot acc: 0.0901
top acc: 0.0127 ::: bot acc: 0.0510
current epoch: 17
train loss is 0.051578
average val loss: 0.045834, accuracy: 0.0471
average test loss: 0.047647, accuracy: 0.0474
case acc: 0.02332384
case acc: 0.10094329
case acc: 0.023859663
case acc: 0.051281065
case acc: 0.05776619
case acc: 0.027170677
top acc: 0.0101 ::: bot acc: 0.0409
top acc: 0.0794 ::: bot acc: 0.1216
top acc: 0.0348 ::: bot acc: 0.0302
top acc: 0.0239 ::: bot acc: 0.0798
top acc: 0.0293 ::: bot acc: 0.0840
top acc: 0.0138 ::: bot acc: 0.0467
current epoch: 18
train loss is 0.046088
average val loss: 0.037756, accuracy: 0.0386
average test loss: 0.039431, accuracy: 0.0391
case acc: 0.016982574
case acc: 0.08015061
case acc: 0.025633598
case acc: 0.04081941
case acc: 0.047705945
case acc: 0.023257421
top acc: 0.0198 ::: bot acc: 0.0258
top acc: 0.0586 ::: bot acc: 0.1008
top acc: 0.0453 ::: bot acc: 0.0200
top acc: 0.0184 ::: bot acc: 0.0668
top acc: 0.0221 ::: bot acc: 0.0726
top acc: 0.0207 ::: bot acc: 0.0373
current epoch: 19
train loss is 0.041047
average val loss: 0.031167, accuracy: 0.0312
average test loss: 0.032518, accuracy: 0.0325
case acc: 0.019418135
case acc: 0.054938458
case acc: 0.032417644
case acc: 0.030361498
case acc: 0.03647517
case acc: 0.02116527
top acc: 0.0353 ::: bot acc: 0.0113
top acc: 0.0335 ::: bot acc: 0.0756
top acc: 0.0584 ::: bot acc: 0.0143
top acc: 0.0205 ::: bot acc: 0.0501
top acc: 0.0176 ::: bot acc: 0.0580
top acc: 0.0330 ::: bot acc: 0.0250
current epoch: 20
train loss is 0.038408
average val loss: 0.028023, accuracy: 0.0274
average test loss: 0.029083, accuracy: 0.0289
case acc: 0.026636
case acc: 0.029247006
case acc: 0.04194375
case acc: 0.02411851
case acc: 0.028091682
case acc: 0.023519007
top acc: 0.0469 ::: bot acc: 0.0098
top acc: 0.0103 ::: bot acc: 0.0486
top acc: 0.0709 ::: bot acc: 0.0178
top acc: 0.0339 ::: bot acc: 0.0327
top acc: 0.0206 ::: bot acc: 0.0439
top acc: 0.0444 ::: bot acc: 0.0142
current epoch: 21
train loss is 0.037287
average val loss: 0.026663, accuracy: 0.0255
average test loss: 0.027632, accuracy: 0.0274
case acc: 0.027216101
case acc: 0.017124826
case acc: 0.04518273
case acc: 0.02450586
case acc: 0.026248202
case acc: 0.024121143
top acc: 0.0477 ::: bot acc: 0.0100
top acc: 0.0134 ::: bot acc: 0.0287
top acc: 0.0746 ::: bot acc: 0.0201
top acc: 0.0427 ::: bot acc: 0.0240
top acc: 0.0234 ::: bot acc: 0.0397
top acc: 0.0458 ::: bot acc: 0.0132
current epoch: 22
train loss is 0.035133
average val loss: 0.027500, accuracy: 0.0263
average test loss: 0.028134, accuracy: 0.0281
case acc: 0.026948623
case acc: 0.01770688
case acc: 0.047994487
case acc: 0.026759189
case acc: 0.025272306
case acc: 0.024015825
top acc: 0.0473 ::: bot acc: 0.0098
top acc: 0.0330 ::: bot acc: 0.0096
top acc: 0.0777 ::: bot acc: 0.0223
top acc: 0.0502 ::: bot acc: 0.0170
top acc: 0.0255 ::: bot acc: 0.0372
top acc: 0.0456 ::: bot acc: 0.0132
current epoch: 23
train loss is 0.032424
average val loss: 0.034598, accuracy: 0.0339
average test loss: 0.034649, accuracy: 0.0351
case acc: 0.03192515
case acc: 0.036852736
case acc: 0.05671589
case acc: 0.03432313
case acc: 0.023269285
case acc: 0.027357528
top acc: 0.0534 ::: bot acc: 0.0126
top acc: 0.0583 ::: bot acc: 0.0166
top acc: 0.0874 ::: bot acc: 0.0289
top acc: 0.0640 ::: bot acc: 0.0122
top acc: 0.0341 ::: bot acc: 0.0285
top acc: 0.0519 ::: bot acc: 0.0107
current epoch: 24
train loss is 0.032939
average val loss: 0.048130, accuracy: 0.0477
average test loss: 0.047759, accuracy: 0.0480
case acc: 0.0412513
case acc: 0.065359324
case acc: 0.071050264
case acc: 0.049815115
case acc: 0.02417742
case acc: 0.03615344
top acc: 0.0636 ::: bot acc: 0.0203
top acc: 0.0870 ::: bot acc: 0.0447
top acc: 0.1029 ::: bot acc: 0.0410
top acc: 0.0829 ::: bot acc: 0.0209
top acc: 0.0482 ::: bot acc: 0.0144
top acc: 0.0640 ::: bot acc: 0.0127
current epoch: 25
train loss is 0.040213
average val loss: 0.074585, accuracy: 0.0744
average test loss: 0.074053, accuracy: 0.0739
case acc: 0.06126889
case acc: 0.10314965
case acc: 0.098534696
case acc: 0.079263106
case acc: 0.041511387
case acc: 0.059423026
top acc: 0.0843 ::: bot acc: 0.0390
top acc: 0.1247 ::: bot acc: 0.0826
top acc: 0.1310 ::: bot acc: 0.0672
top acc: 0.1138 ::: bot acc: 0.0476
top acc: 0.0746 ::: bot acc: 0.0136
top acc: 0.0893 ::: bot acc: 0.0323
current epoch: 26
train loss is 0.058005
average val loss: 0.078092, accuracy: 0.0780
average test loss: 0.077579, accuracy: 0.0774
case acc: 0.056465194
case acc: 0.109684855
case acc: 0.10319099
case acc: 0.08572922
case acc: 0.045645382
case acc: 0.06347228
top acc: 0.0795 ::: bot acc: 0.0343
top acc: 0.1312 ::: bot acc: 0.0892
top acc: 0.1358 ::: bot acc: 0.0716
top acc: 0.1204 ::: bot acc: 0.0539
top acc: 0.0790 ::: bot acc: 0.0172
top acc: 0.0935 ::: bot acc: 0.0362
current epoch: 27
train loss is 0.070055
average val loss: 0.044869, accuracy: 0.0441
average test loss: 0.044820, accuracy: 0.0447
case acc: 0.019193143
case acc: 0.068676785
case acc: 0.068304196
case acc: 0.05389649
case acc: 0.023753887
case acc: 0.03456429
top acc: 0.0352 ::: bot acc: 0.0113
top acc: 0.0901 ::: bot acc: 0.0482
top acc: 0.1001 ::: bot acc: 0.0385
top acc: 0.0875 ::: bot acc: 0.0242
top acc: 0.0469 ::: bot acc: 0.0155
top acc: 0.0623 ::: bot acc: 0.0119
current epoch: 28
train loss is 0.068635
average val loss: 0.026276, accuracy: 0.0257
average test loss: 0.027658, accuracy: 0.0280
case acc: 0.03944453
case acc: 0.017863961
case acc: 0.029917428
case acc: 0.024804352
case acc: 0.03367289
case acc: 0.022276517
top acc: 0.0178 ::: bot acc: 0.0612
top acc: 0.0335 ::: bot acc: 0.0091
top acc: 0.0544 ::: bot acc: 0.0149
top acc: 0.0443 ::: bot acc: 0.0224
top acc: 0.0173 ::: bot acc: 0.0540
top acc: 0.0252 ::: bot acc: 0.0327
current epoch: 29
train loss is 0.061084
average val loss: 0.031133, accuracy: 0.0315
average test loss: 0.032980, accuracy: 0.0333
case acc: 0.053907905
case acc: 0.025753586
case acc: 0.02371275
case acc: 0.027115185
case acc: 0.043052502
case acc: 0.025993811
top acc: 0.0306 ::: bot acc: 0.0765
top acc: 0.0084 ::: bot acc: 0.0442
top acc: 0.0343 ::: bot acc: 0.0308
top acc: 0.0247 ::: bot acc: 0.0429
top acc: 0.0196 ::: bot acc: 0.0669
top acc: 0.0151 ::: bot acc: 0.0440
current epoch: 30
train loss is 0.047568
average val loss: 0.028439, accuracy: 0.0289
average test loss: 0.030283, accuracy: 0.0309
case acc: 0.040824432
case acc: 0.036457766
case acc: 0.024006326
case acc: 0.026268186
case acc: 0.03571369
case acc: 0.022211729
top acc: 0.0190 ::: bot acc: 0.0627
top acc: 0.0161 ::: bot acc: 0.0564
top acc: 0.0384 ::: bot acc: 0.0267
top acc: 0.0263 ::: bot acc: 0.0408
top acc: 0.0175 ::: bot acc: 0.0569
top acc: 0.0255 ::: bot acc: 0.0325
current epoch: 31
train loss is 0.041663
average val loss: 0.032584, accuracy: 0.0335
average test loss: 0.034445, accuracy: 0.0353
case acc: 0.039793316
case acc: 0.056810565
case acc: 0.02391118
case acc: 0.030682597
case acc: 0.037830736
case acc: 0.022625228
top acc: 0.0181 ::: bot acc: 0.0616
top acc: 0.0353 ::: bot acc: 0.0773
top acc: 0.0304 ::: bot acc: 0.0347
top acc: 0.0204 ::: bot acc: 0.0504
top acc: 0.0179 ::: bot acc: 0.0599
top acc: 0.0235 ::: bot acc: 0.0344
current epoch: 32
train loss is 0.044810
average val loss: 0.051932, accuracy: 0.0525
average test loss: 0.053504, accuracy: 0.0539
case acc: 0.056897216
case acc: 0.090479665
case acc: 0.03510451
case acc: 0.049683113
case acc: 0.056852415
case acc: 0.034149755
top acc: 0.0336 ::: bot acc: 0.0795
top acc: 0.0690 ::: bot acc: 0.1110
top acc: 0.0145 ::: bot acc: 0.0611
top acc: 0.0227 ::: bot acc: 0.0778
top acc: 0.0290 ::: bot acc: 0.0829
top acc: 0.0135 ::: bot acc: 0.0571
current epoch: 33
train loss is 0.050297
average val loss: 0.055477, accuracy: 0.0559
average test loss: 0.057002, accuracy: 0.0572
case acc: 0.05351023
case acc: 0.09499071
case acc: 0.03978512
case acc: 0.0548419
case acc: 0.061660483
case acc: 0.038679644
top acc: 0.0303 ::: bot acc: 0.0761
top acc: 0.0734 ::: bot acc: 0.1155
top acc: 0.0167 ::: bot acc: 0.0671
top acc: 0.0262 ::: bot acc: 0.0838
top acc: 0.0330 ::: bot acc: 0.0881
top acc: 0.0153 ::: bot acc: 0.0630
current epoch: 34
train loss is 0.042464
average val loss: 0.034805, accuracy: 0.0357
average test loss: 0.036699, accuracy: 0.0370
case acc: 0.02548342
case acc: 0.06567868
case acc: 0.026054554
case acc: 0.036653176
case acc: 0.04269382
case acc: 0.025342772
top acc: 0.0098 ::: bot acc: 0.0443
top acc: 0.0441 ::: bot acc: 0.0862
top acc: 0.0207 ::: bot acc: 0.0445
top acc: 0.0179 ::: bot acc: 0.0607
top acc: 0.0194 ::: bot acc: 0.0665
top acc: 0.0159 ::: bot acc: 0.0427
current epoch: 35
train loss is 0.034465
average val loss: 0.028766, accuracy: 0.0295
average test loss: 0.030747, accuracy: 0.0310
case acc: 0.018206434
case acc: 0.050645724
case acc: 0.02421809
case acc: 0.031623382
case acc: 0.037755147
case acc: 0.023436107
top acc: 0.0151 ::: bot acc: 0.0307
top acc: 0.0291 ::: bot acc: 0.0712
top acc: 0.0276 ::: bot acc: 0.0375
top acc: 0.0197 ::: bot acc: 0.0523
top acc: 0.0179 ::: bot acc: 0.0598
top acc: 0.0202 ::: bot acc: 0.0376
current epoch: 36
train loss is 0.030225
average val loss: 0.023759, accuracy: 0.0240
average test loss: 0.025611, accuracy: 0.0257
case acc: 0.0167523
case acc: 0.034392487
case acc: 0.023819132
case acc: 0.026334519
case acc: 0.03120728
case acc: 0.02167798
top acc: 0.0271 ::: bot acc: 0.0187
top acc: 0.0142 ::: bot acc: 0.0543
top acc: 0.0364 ::: bot acc: 0.0287
top acc: 0.0261 ::: bot acc: 0.0411
top acc: 0.0173 ::: bot acc: 0.0502
top acc: 0.0281 ::: bot acc: 0.0298
current epoch: 37
train loss is 0.026995
average val loss: 0.021440, accuracy: 0.0212
average test loss: 0.023031, accuracy: 0.0229
case acc: 0.018571965
case acc: 0.021578748
case acc: 0.025068143
case acc: 0.024059016
case acc: 0.026892811
case acc: 0.021182619
top acc: 0.0335 ::: bot acc: 0.0124
top acc: 0.0079 ::: bot acc: 0.0382
top acc: 0.0435 ::: bot acc: 0.0216
top acc: 0.0359 ::: bot acc: 0.0308
top acc: 0.0214 ::: bot acc: 0.0417
top acc: 0.0348 ::: bot acc: 0.0231
current epoch: 38
train loss is 0.025429
average val loss: 0.021205, accuracy: 0.0206
average test loss: 0.022465, accuracy: 0.0223
case acc: 0.019678563
case acc: 0.015882064
case acc: 0.0272324
case acc: 0.025026126
case acc: 0.024390131
case acc: 0.021833641
top acc: 0.0362 ::: bot acc: 0.0103
top acc: 0.0191 ::: bot acc: 0.0231
top acc: 0.0490 ::: bot acc: 0.0172
top acc: 0.0450 ::: bot acc: 0.0217
top acc: 0.0274 ::: bot acc: 0.0348
top acc: 0.0398 ::: bot acc: 0.0180
current epoch: 39
train loss is 0.024390
average val loss: 0.022944, accuracy: 0.0223
average test loss: 0.023707, accuracy: 0.0237
case acc: 0.020139048
case acc: 0.017723134
case acc: 0.029679332
case acc: 0.028030133
case acc: 0.02322231
case acc: 0.023267625
top acc: 0.0372 ::: bot acc: 0.0097
top acc: 0.0332 ::: bot acc: 0.0094
top acc: 0.0539 ::: bot acc: 0.0147
top acc: 0.0534 ::: bot acc: 0.0146
top acc: 0.0334 ::: bot acc: 0.0289
top acc: 0.0441 ::: bot acc: 0.0141
current epoch: 40
train loss is 0.023961
average val loss: 0.026105, accuracy: 0.0256
average test loss: 0.026433, accuracy: 0.0266
case acc: 0.020574858
case acc: 0.025705528
case acc: 0.032831606
case acc: 0.03232834
case acc: 0.022677688
case acc: 0.025372744
top acc: 0.0381 ::: bot acc: 0.0093
top acc: 0.0455 ::: bot acc: 0.0088
top acc: 0.0588 ::: bot acc: 0.0144
top acc: 0.0610 ::: bot acc: 0.0122
top acc: 0.0390 ::: bot acc: 0.0233
top acc: 0.0484 ::: bot acc: 0.0118
current epoch: 41
train loss is 0.024712
average val loss: 0.029430, accuracy: 0.0289
average test loss: 0.029517, accuracy: 0.0296
case acc: 0.02069147
case acc: 0.03394847
case acc: 0.036007777
case acc: 0.036767244
case acc: 0.022968866
case acc: 0.027469624
top acc: 0.0383 ::: bot acc: 0.0092
top acc: 0.0552 ::: bot acc: 0.0141
top acc: 0.0632 ::: bot acc: 0.0152
top acc: 0.0674 ::: bot acc: 0.0127
top acc: 0.0437 ::: bot acc: 0.0186
top acc: 0.0522 ::: bot acc: 0.0105
current epoch: 42
train loss is 0.026009
average val loss: 0.033874, accuracy: 0.0333
average test loss: 0.033764, accuracy: 0.0338
case acc: 0.021620832
case acc: 0.042881466
case acc: 0.040441725
case acc: 0.042533882
case acc: 0.024555484
case acc: 0.03087523
top acc: 0.0399 ::: bot acc: 0.0089
top acc: 0.0645 ::: bot acc: 0.0222
top acc: 0.0690 ::: bot acc: 0.0169
top acc: 0.0745 ::: bot acc: 0.0157
top acc: 0.0494 ::: bot acc: 0.0130
top acc: 0.0574 ::: bot acc: 0.0104
current epoch: 43
train loss is 0.028080
average val loss: 0.039260, accuracy: 0.0388
average test loss: 0.039051, accuracy: 0.0390
case acc: 0.023199847
case acc: 0.051181156
case acc: 0.04633488
case acc: 0.049328074
case acc: 0.027964817
case acc: 0.036074806
top acc: 0.0423 ::: bot acc: 0.0088
top acc: 0.0728 ::: bot acc: 0.0305
top acc: 0.0758 ::: bot acc: 0.0209
top acc: 0.0823 ::: bot acc: 0.0205
top acc: 0.0563 ::: bot acc: 0.0095
top acc: 0.0641 ::: bot acc: 0.0127
current epoch: 44
train loss is 0.030805
average val loss: 0.041601, accuracy: 0.0411
average test loss: 0.041389, accuracy: 0.0412
case acc: 0.021951934
case acc: 0.05332416
case acc: 0.049244706
case acc: 0.052917738
case acc: 0.030275263
case acc: 0.03948539
top acc: 0.0405 ::: bot acc: 0.0088
top acc: 0.0750 ::: bot acc: 0.0327
top acc: 0.0791 ::: bot acc: 0.0231
top acc: 0.0863 ::: bot acc: 0.0234
top acc: 0.0602 ::: bot acc: 0.0085
top acc: 0.0681 ::: bot acc: 0.0147
current epoch: 45
train loss is 0.032331
average val loss: 0.037240, accuracy: 0.0366
average test loss: 0.037199, accuracy: 0.0370
case acc: 0.017543763
case acc: 0.044500243
case acc: 0.044912685
case acc: 0.049117073
case acc: 0.02851069
case acc: 0.037345972
top acc: 0.0306 ::: bot acc: 0.0153
top acc: 0.0661 ::: bot acc: 0.0238
top acc: 0.0742 ::: bot acc: 0.0198
top acc: 0.0821 ::: bot acc: 0.0204
top acc: 0.0572 ::: bot acc: 0.0092
top acc: 0.0656 ::: bot acc: 0.0134
current epoch: 46
train loss is 0.031942
average val loss: 0.029495, accuracy: 0.0288
average test loss: 0.029804, accuracy: 0.0297
case acc: 0.017991528
case acc: 0.02802871
case acc: 0.035916824
case acc: 0.040001687
case acc: 0.024533838
case acc: 0.031539984
top acc: 0.0161 ::: bot acc: 0.0298
top acc: 0.0484 ::: bot acc: 0.0100
top acc: 0.0630 ::: bot acc: 0.0152
top acc: 0.0715 ::: bot acc: 0.0142
top acc: 0.0493 ::: bot acc: 0.0131
top acc: 0.0583 ::: bot acc: 0.0106
current epoch: 47
train loss is 0.032416
average val loss: 0.023191, accuracy: 0.0227
average test loss: 0.024231, accuracy: 0.0243
case acc: 0.025468446
case acc: 0.015737318
case acc: 0.026818201
case acc: 0.02981269
case acc: 0.022686541
case acc: 0.025505576
top acc: 0.0099 ::: bot acc: 0.0442
top acc: 0.0239 ::: bot acc: 0.0184
top acc: 0.0480 ::: bot acc: 0.0180
top acc: 0.0569 ::: bot acc: 0.0130
top acc: 0.0391 ::: bot acc: 0.0232
top acc: 0.0487 ::: bot acc: 0.0116
current epoch: 48
train loss is 0.035410
average val loss: 0.027083, accuracy: 0.0275
average test loss: 0.029125, accuracy: 0.0300
case acc: 0.043470014
case acc: 0.03722392
case acc: 0.025611544
case acc: 0.024582073
case acc: 0.027495414
case acc: 0.02149909
top acc: 0.0213 ::: bot acc: 0.0655
top acc: 0.0166 ::: bot acc: 0.0574
top acc: 0.0220 ::: bot acc: 0.0433
top acc: 0.0302 ::: bot acc: 0.0363
top acc: 0.0203 ::: bot acc: 0.0432
top acc: 0.0296 ::: bot acc: 0.0282
current epoch: 49
train loss is 0.039993
average val loss: 0.054733, accuracy: 0.0550
average test loss: 0.056245, accuracy: 0.0568
case acc: 0.070053436
case acc: 0.087217316
case acc: 0.05072837
case acc: 0.04752744
case acc: 0.049635004
case acc: 0.03558604
top acc: 0.0468 ::: bot acc: 0.0926
top acc: 0.0656 ::: bot acc: 0.1079
top acc: 0.0239 ::: bot acc: 0.0800
top acc: 0.0214 ::: bot acc: 0.0752
top acc: 0.0234 ::: bot acc: 0.0748
top acc: 0.0139 ::: bot acc: 0.0590
current epoch: 50
train loss is 0.050346
average val loss: 0.050701, accuracy: 0.0510
average test loss: 0.052313, accuracy: 0.0528
case acc: 0.056465518
case acc: 0.085064985
case acc: 0.048696302
case acc: 0.046089154
case acc: 0.04689034
case acc: 0.033626836
top acc: 0.0332 ::: bot acc: 0.0790
top acc: 0.0634 ::: bot acc: 0.1058
top acc: 0.0226 ::: bot acc: 0.0776
top acc: 0.0206 ::: bot acc: 0.0735
top acc: 0.0215 ::: bot acc: 0.0717
top acc: 0.0134 ::: bot acc: 0.0564
LME_Co_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6804 6804 6804
1.7082474 -0.6288155 0.12137239 -0.15229516
Validation: 762 762 762
Testing: 750 750 750
pre-processing time: 0.0003371238708496094
the split date is 2011-01-01
net initializing with time: 0.0028328895568847656
preparing training and testing date with time: 2.384185791015625e-07
current epoch: 1
train loss is 0.297792
average val loss: 0.085393, accuracy: 0.0862
average test loss: 0.078548, accuracy: 0.0794
case acc: 0.1602088
case acc: 0.13499391
case acc: 0.04341605
case acc: 0.033284005
case acc: 0.034337964
case acc: 0.07043736
top acc: 0.1359 ::: bot acc: 0.1843
top acc: 0.1141 ::: bot acc: 0.1550
top acc: 0.0166 ::: bot acc: 0.0746
top acc: 0.0120 ::: bot acc: 0.0586
top acc: 0.0142 ::: bot acc: 0.0612
top acc: 0.0411 ::: bot acc: 0.0994
current epoch: 2
train loss is 0.104875
average val loss: 0.055993, accuracy: 0.0573
average test loss: 0.051346, accuracy: 0.0533
case acc: 0.11576809
case acc: 0.09347393
case acc: 0.027830705
case acc: 0.020488147
case acc: 0.025056835
case acc: 0.037348054
top acc: 0.0913 ::: bot acc: 0.1401
top acc: 0.0727 ::: bot acc: 0.1135
top acc: 0.0291 ::: bot acc: 0.0446
top acc: 0.0230 ::: bot acc: 0.0328
top acc: 0.0342 ::: bot acc: 0.0332
top acc: 0.0120 ::: bot acc: 0.0645
current epoch: 3
train loss is 0.093411
average val loss: 0.081823, accuracy: 0.0824
average test loss: 0.074642, accuracy: 0.0753
case acc: 0.13716187
case acc: 0.11954217
case acc: 0.04664488
case acc: 0.045102548
case acc: 0.040933426
case acc: 0.062176775
top acc: 0.1126 ::: bot acc: 0.1615
top acc: 0.0988 ::: bot acc: 0.1397
top acc: 0.0179 ::: bot acc: 0.0787
top acc: 0.0195 ::: bot acc: 0.0725
top acc: 0.0148 ::: bot acc: 0.0707
top acc: 0.0328 ::: bot acc: 0.0913
current epoch: 4
train loss is 0.091244
average val loss: 0.079427, accuracy: 0.0799
average test loss: 0.072159, accuracy: 0.0727
case acc: 0.12500522
case acc: 0.11300763
case acc: 0.04692858
case acc: 0.052371174
case acc: 0.045076035
case acc: 0.053581674
top acc: 0.1005 ::: bot acc: 0.1494
top acc: 0.0922 ::: bot acc: 0.1332
top acc: 0.0180 ::: bot acc: 0.0791
top acc: 0.0259 ::: bot acc: 0.0801
top acc: 0.0167 ::: bot acc: 0.0761
top acc: 0.0244 ::: bot acc: 0.0826
current epoch: 5
train loss is 0.080019
average val loss: 0.073837, accuracy: 0.0743
average test loss: 0.066523, accuracy: 0.0670
case acc: 0.10914669
case acc: 0.10153086
case acc: 0.045072693
case acc: 0.0559471
case acc: 0.046228543
case acc: 0.044274718
top acc: 0.0846 ::: bot acc: 0.1337
top acc: 0.0807 ::: bot acc: 0.1218
top acc: 0.0174 ::: bot acc: 0.0766
top acc: 0.0291 ::: bot acc: 0.0837
top acc: 0.0173 ::: bot acc: 0.0776
top acc: 0.0166 ::: bot acc: 0.0726
current epoch: 6
train loss is 0.069407
average val loss: 0.069673, accuracy: 0.0700
average test loss: 0.062329, accuracy: 0.0628
case acc: 0.09461352
case acc: 0.09048484
case acc: 0.0448942
case acc: 0.060153574
case acc: 0.047737747
case acc: 0.03881034
top acc: 0.0700 ::: bot acc: 0.1193
top acc: 0.0696 ::: bot acc: 0.1109
top acc: 0.0174 ::: bot acc: 0.0763
top acc: 0.0330 ::: bot acc: 0.0880
top acc: 0.0181 ::: bot acc: 0.0796
top acc: 0.0127 ::: bot acc: 0.0664
current epoch: 7
train loss is 0.060522
average val loss: 0.071933, accuracy: 0.0722
average test loss: 0.064526, accuracy: 0.0648
case acc: 0.087047845
case acc: 0.08616498
case acc: 0.050185833
case acc: 0.070585184
case acc: 0.054355107
case acc: 0.040226474
top acc: 0.0625 ::: bot acc: 0.1117
top acc: 0.0653 ::: bot acc: 0.1067
top acc: 0.0197 ::: bot acc: 0.0831
top acc: 0.0432 ::: bot acc: 0.0985
top acc: 0.0224 ::: bot acc: 0.0874
top acc: 0.0135 ::: bot acc: 0.0681
current epoch: 8
train loss is 0.056405
average val loss: 0.066910, accuracy: 0.0671
average test loss: 0.059479, accuracy: 0.0597
case acc: 0.071704715
case acc: 0.073421374
case acc: 0.049798734
case acc: 0.07291099
case acc: 0.05363711
case acc: 0.036743607
top acc: 0.0473 ::: bot acc: 0.0963
top acc: 0.0524 ::: bot acc: 0.0940
top acc: 0.0194 ::: bot acc: 0.0827
top acc: 0.0456 ::: bot acc: 0.1006
top acc: 0.0217 ::: bot acc: 0.0867
top acc: 0.0118 ::: bot acc: 0.0637
current epoch: 9
train loss is 0.049151
average val loss: 0.063122, accuracy: 0.0631
average test loss: 0.055676, accuracy: 0.0558
case acc: 0.058147542
case acc: 0.061342087
case acc: 0.050732933
case acc: 0.07550982
case acc: 0.053507507
case acc: 0.03559724
top acc: 0.0341 ::: bot acc: 0.0826
top acc: 0.0404 ::: bot acc: 0.0820
top acc: 0.0201 ::: bot acc: 0.0838
top acc: 0.0483 ::: bot acc: 0.1032
top acc: 0.0216 ::: bot acc: 0.0867
top acc: 0.0115 ::: bot acc: 0.0622
current epoch: 10
train loss is 0.043881
average val loss: 0.056696, accuracy: 0.0565
average test loss: 0.049338, accuracy: 0.0492
case acc: 0.042332135
case acc: 0.045696035
case acc: 0.049293276
case acc: 0.07387515
case acc: 0.050214075
case acc: 0.033854783
top acc: 0.0188 ::: bot acc: 0.0665
top acc: 0.0247 ::: bot acc: 0.0664
top acc: 0.0192 ::: bot acc: 0.0821
top acc: 0.0467 ::: bot acc: 0.1015
top acc: 0.0191 ::: bot acc: 0.0830
top acc: 0.0115 ::: bot acc: 0.0596
current epoch: 11
train loss is 0.040325
average val loss: 0.052373, accuracy: 0.0518
average test loss: 0.045308, accuracy: 0.0446
case acc: 0.030221984
case acc: 0.032289993
case acc: 0.04908909
case acc: 0.07296488
case acc: 0.0489734
case acc: 0.03393946
top acc: 0.0085 ::: bot acc: 0.0535
top acc: 0.0122 ::: bot acc: 0.0527
top acc: 0.0191 ::: bot acc: 0.0819
top acc: 0.0458 ::: bot acc: 0.1005
top acc: 0.0183 ::: bot acc: 0.0816
top acc: 0.0116 ::: bot acc: 0.0597
current epoch: 12
train loss is 0.039845
average val loss: 0.045867, accuracy: 0.0449
average test loss: 0.039751, accuracy: 0.0385
case acc: 0.020960473
case acc: 0.019523732
case acc: 0.04563728
case acc: 0.06759734
case acc: 0.04559236
case acc: 0.031842396
top acc: 0.0108 ::: bot acc: 0.0386
top acc: 0.0079 ::: bot acc: 0.0358
top acc: 0.0176 ::: bot acc: 0.0775
top acc: 0.0405 ::: bot acc: 0.0952
top acc: 0.0162 ::: bot acc: 0.0776
top acc: 0.0120 ::: bot acc: 0.0564
current epoch: 13
train loss is 0.048132
average val loss: 0.031547, accuracy: 0.0312
average test loss: 0.029651, accuracy: 0.0289
case acc: 0.02414169
case acc: 0.025460962
case acc: 0.030293586
case acc: 0.04169478
case acc: 0.029821433
case acc: 0.022055164
top acc: 0.0439 ::: bot acc: 0.0090
top acc: 0.0442 ::: bot acc: 0.0091
top acc: 0.0207 ::: bot acc: 0.0532
top acc: 0.0168 ::: bot acc: 0.0681
top acc: 0.0167 ::: bot acc: 0.0539
top acc: 0.0235 ::: bot acc: 0.0358
current epoch: 14
train loss is 0.062275
average val loss: 0.058418, accuracy: 0.0587
average test loss: 0.064894, accuracy: 0.0649
case acc: 0.092562996
case acc: 0.10602144
case acc: 0.051992457
case acc: 0.03575163
case acc: 0.04914059
case acc: 0.053926058
top acc: 0.1170 ::: bot acc: 0.0679
top acc: 0.1270 ::: bot acc: 0.0851
top acc: 0.0871 ::: bot acc: 0.0192
top acc: 0.0610 ::: bot acc: 0.0122
top acc: 0.0829 ::: bot acc: 0.0159
top acc: 0.0833 ::: bot acc: 0.0255
current epoch: 15
train loss is 0.080905
average val loss: 0.084011, accuracy: 0.0841
average test loss: 0.090917, accuracy: 0.0909
case acc: 0.11324748
case acc: 0.13745461
case acc: 0.07711203
case acc: 0.0698822
case acc: 0.0780144
case acc: 0.0697516
top acc: 0.1377 ::: bot acc: 0.0885
top acc: 0.1584 ::: bot acc: 0.1165
top acc: 0.1135 ::: bot acc: 0.0415
top acc: 0.0970 ::: bot acc: 0.0422
top acc: 0.1124 ::: bot acc: 0.0434
top acc: 0.0996 ::: bot acc: 0.0404
current epoch: 16
train loss is 0.065484
average val loss: 0.058027, accuracy: 0.0581
average test loss: 0.064549, accuracy: 0.0647
case acc: 0.076375425
case acc: 0.10559007
case acc: 0.05395822
case acc: 0.0534832
case acc: 0.059275113
case acc: 0.039490122
top acc: 0.1009 ::: bot acc: 0.0516
top acc: 0.1266 ::: bot acc: 0.0845
top acc: 0.0892 ::: bot acc: 0.0208
top acc: 0.0804 ::: bot acc: 0.0261
top acc: 0.0937 ::: bot acc: 0.0247
top acc: 0.0674 ::: bot acc: 0.0141
current epoch: 17
train loss is 0.051570
average val loss: 0.055793, accuracy: 0.0558
average test loss: 0.062297, accuracy: 0.0624
case acc: 0.063032895
case acc: 0.09349445
case acc: 0.056686774
case acc: 0.059477564
case acc: 0.062957056
case acc: 0.03890663
top acc: 0.0875 ::: bot acc: 0.0383
top acc: 0.1146 ::: bot acc: 0.0723
top acc: 0.0921 ::: bot acc: 0.0231
top acc: 0.0865 ::: bot acc: 0.0319
top acc: 0.0975 ::: bot acc: 0.0282
top acc: 0.0667 ::: bot acc: 0.0139
current epoch: 18
train loss is 0.046091
average val loss: 0.054075, accuracy: 0.0540
average test loss: 0.060605, accuracy: 0.0607
case acc: 0.05027784
case acc: 0.081862725
case acc: 0.06039086
case acc: 0.065900154
case acc: 0.06630792
case acc: 0.03948805
top acc: 0.0746 ::: bot acc: 0.0258
top acc: 0.1031 ::: bot acc: 0.0605
top acc: 0.0959 ::: bot acc: 0.0264
top acc: 0.0928 ::: bot acc: 0.0384
top acc: 0.1009 ::: bot acc: 0.0315
top acc: 0.0673 ::: bot acc: 0.0144
current epoch: 19
train loss is 0.041307
average val loss: 0.048746, accuracy: 0.0485
average test loss: 0.055145, accuracy: 0.0552
case acc: 0.03491377
case acc: 0.06624416
case acc: 0.060072783
case acc: 0.06753455
case acc: 0.065241784
case acc: 0.03696264
top acc: 0.0582 ::: bot acc: 0.0126
top acc: 0.0875 ::: bot acc: 0.0449
top acc: 0.0955 ::: bot acc: 0.0261
top acc: 0.0945 ::: bot acc: 0.0400
top acc: 0.0999 ::: bot acc: 0.0303
top acc: 0.0643 ::: bot acc: 0.0130
current epoch: 20
train loss is 0.039097
average val loss: 0.042540, accuracy: 0.0420
average test loss: 0.048525, accuracy: 0.0484
case acc: 0.022520484
case acc: 0.048491184
case acc: 0.057401996
case acc: 0.06582279
case acc: 0.062408734
case acc: 0.03374564
top acc: 0.0410 ::: bot acc: 0.0099
top acc: 0.0696 ::: bot acc: 0.0272
top acc: 0.0927 ::: bot acc: 0.0238
top acc: 0.0928 ::: bot acc: 0.0382
top acc: 0.0971 ::: bot acc: 0.0275
top acc: 0.0601 ::: bot acc: 0.0116
current epoch: 21
train loss is 0.045144
average val loss: 0.027943, accuracy: 0.0272
average test loss: 0.030779, accuracy: 0.0307
case acc: 0.023491614
case acc: 0.017259978
case acc: 0.037700158
case acc: 0.042283606
case acc: 0.041259926
case acc: 0.022296436
top acc: 0.0076 ::: bot acc: 0.0443
top acc: 0.0304 ::: bot acc: 0.0122
top acc: 0.0690 ::: bot acc: 0.0124
top acc: 0.0684 ::: bot acc: 0.0165
top acc: 0.0738 ::: bot acc: 0.0108
top acc: 0.0380 ::: bot acc: 0.0213
current epoch: 22
train loss is 0.057085
average val loss: 0.060116, accuracy: 0.0608
average test loss: 0.052919, accuracy: 0.0538
case acc: 0.09217335
case acc: 0.07299284
case acc: 0.03942122
case acc: 0.033151884
case acc: 0.03463797
case acc: 0.050174963
top acc: 0.0676 ::: bot acc: 0.1174
top acc: 0.0519 ::: bot acc: 0.0944
top acc: 0.0157 ::: bot acc: 0.0692
top acc: 0.0119 ::: bot acc: 0.0579
top acc: 0.0127 ::: bot acc: 0.0634
top acc: 0.0211 ::: bot acc: 0.0793
current epoch: 23
train loss is 0.061571
average val loss: 0.076837, accuracy: 0.0771
average test loss: 0.069329, accuracy: 0.0696
case acc: 0.10405696
case acc: 0.097054295
case acc: 0.052474156
case acc: 0.057461143
case acc: 0.051357035
case acc: 0.05504993
top acc: 0.0796 ::: bot acc: 0.1292
top acc: 0.0759 ::: bot acc: 0.1185
top acc: 0.0210 ::: bot acc: 0.0859
top acc: 0.0307 ::: bot acc: 0.0850
top acc: 0.0195 ::: bot acc: 0.0850
top acc: 0.0255 ::: bot acc: 0.0843
current epoch: 24
train loss is 0.053926
average val loss: 0.061137, accuracy: 0.0615
average test loss: 0.053772, accuracy: 0.0544
case acc: 0.07758433
case acc: 0.07691156
case acc: 0.041217115
case acc: 0.05155465
case acc: 0.04411102
case acc: 0.034750927
top acc: 0.0531 ::: bot acc: 0.1028
top acc: 0.0558 ::: bot acc: 0.0983
top acc: 0.0161 ::: bot acc: 0.0716
top acc: 0.0252 ::: bot acc: 0.0789
top acc: 0.0149 ::: bot acc: 0.0764
top acc: 0.0122 ::: bot acc: 0.0606
current epoch: 25
train loss is 0.045143
average val loss: 0.055801, accuracy: 0.0561
average test loss: 0.048507, accuracy: 0.0490
case acc: 0.06118129
case acc: 0.062282406
case acc: 0.040648434
case acc: 0.053999335
case acc: 0.044575017
case acc: 0.03142891
top acc: 0.0368 ::: bot acc: 0.0864
top acc: 0.0412 ::: bot acc: 0.0837
top acc: 0.0159 ::: bot acc: 0.0708
top acc: 0.0274 ::: bot acc: 0.0815
top acc: 0.0152 ::: bot acc: 0.0769
top acc: 0.0123 ::: bot acc: 0.0556
current epoch: 26
train loss is 0.039404
average val loss: 0.049296, accuracy: 0.0493
average test loss: 0.042139, accuracy: 0.0424
case acc: 0.0438107
case acc: 0.04465859
case acc: 0.039707802
case acc: 0.05358831
case acc: 0.042638596
case acc: 0.029718025
top acc: 0.0200 ::: bot acc: 0.0687
top acc: 0.0236 ::: bot acc: 0.0660
top acc: 0.0157 ::: bot acc: 0.0695
top acc: 0.0270 ::: bot acc: 0.0810
top acc: 0.0143 ::: bot acc: 0.0745
top acc: 0.0128 ::: bot acc: 0.0528
current epoch: 27
train loss is 0.036045
average val loss: 0.037568, accuracy: 0.0370
average test loss: 0.031681, accuracy: 0.0310
case acc: 0.023694454
case acc: 0.022176579
case acc: 0.03432859
case acc: 0.045143828
case acc: 0.03516425
case acc: 0.02542765
top acc: 0.0075 ::: bot acc: 0.0449
top acc: 0.0067 ::: bot acc: 0.0408
top acc: 0.0162 ::: bot acc: 0.0613
top acc: 0.0196 ::: bot acc: 0.0720
top acc: 0.0125 ::: bot acc: 0.0642
top acc: 0.0154 ::: bot acc: 0.0452
current epoch: 28
train loss is 0.032946
average val loss: 0.028051, accuracy: 0.0275
average test loss: 0.025393, accuracy: 0.0246
case acc: 0.018697707
case acc: 0.016768148
case acc: 0.028670162
case acc: 0.03321461
case acc: 0.028320635
case acc: 0.021905774
top acc: 0.0292 ::: bot acc: 0.0205
top acc: 0.0289 ::: bot acc: 0.0136
top acc: 0.0239 ::: bot acc: 0.0491
top acc: 0.0118 ::: bot acc: 0.0581
top acc: 0.0189 ::: bot acc: 0.0509
top acc: 0.0239 ::: bot acc: 0.0352
current epoch: 29
train loss is 0.037814
average val loss: 0.028796, accuracy: 0.0297
average test loss: 0.032483, accuracy: 0.0328
case acc: 0.04222289
case acc: 0.051135458
case acc: 0.029518906
case acc: 0.019909319
case acc: 0.027730264
case acc: 0.026573332
top acc: 0.0664 ::: bot acc: 0.0178
top acc: 0.0722 ::: bot acc: 0.0298
top acc: 0.0537 ::: bot acc: 0.0193
top acc: 0.0306 ::: bot acc: 0.0241
top acc: 0.0486 ::: bot acc: 0.0207
top acc: 0.0488 ::: bot acc: 0.0126
current epoch: 30
train loss is 0.047504
average val loss: 0.058913, accuracy: 0.0591
average test loss: 0.065597, accuracy: 0.0657
case acc: 0.08038445
case acc: 0.10029981
case acc: 0.056835752
case acc: 0.05104399
case acc: 0.056008138
case acc: 0.04955736
top acc: 0.1050 ::: bot acc: 0.0551
top acc: 0.1214 ::: bot acc: 0.0789
top acc: 0.0925 ::: bot acc: 0.0233
top acc: 0.0780 ::: bot acc: 0.0238
top acc: 0.0904 ::: bot acc: 0.0215
top acc: 0.0785 ::: bot acc: 0.0219
current epoch: 31
train loss is 0.056898
average val loss: 0.059015, accuracy: 0.0591
average test loss: 0.065698, accuracy: 0.0658
case acc: 0.07130268
case acc: 0.097876206
case acc: 0.058943845
case acc: 0.060810596
case acc: 0.06193477
case acc: 0.044037763
top acc: 0.0959 ::: bot acc: 0.0461
top acc: 0.1190 ::: bot acc: 0.0765
top acc: 0.0947 ::: bot acc: 0.0250
top acc: 0.0880 ::: bot acc: 0.0330
top acc: 0.0964 ::: bot acc: 0.0271
top acc: 0.0724 ::: bot acc: 0.0175
current epoch: 32
train loss is 0.051598
average val loss: 0.035081, accuracy: 0.0352
average test loss: 0.040809, accuracy: 0.0411
case acc: 0.03495619
case acc: 0.06155067
case acc: 0.039508935
case acc: 0.04246395
case acc: 0.04309423
case acc: 0.025276372
top acc: 0.0583 ::: bot acc: 0.0123
top acc: 0.0827 ::: bot acc: 0.0401
top acc: 0.0717 ::: bot acc: 0.0129
top acc: 0.0687 ::: bot acc: 0.0165
top acc: 0.0760 ::: bot acc: 0.0117
top acc: 0.0461 ::: bot acc: 0.0142
current epoch: 33
train loss is 0.040472
average val loss: 0.029346, accuracy: 0.0292
average test loss: 0.034664, accuracy: 0.0348
case acc: 0.022902697
case acc: 0.041603416
case acc: 0.03846043
case acc: 0.03971413
case acc: 0.04053011
case acc: 0.02573684
top acc: 0.0415 ::: bot acc: 0.0099
top acc: 0.0624 ::: bot acc: 0.0207
top acc: 0.0702 ::: bot acc: 0.0128
top acc: 0.0656 ::: bot acc: 0.0144
top acc: 0.0727 ::: bot acc: 0.0107
top acc: 0.0471 ::: bot acc: 0.0135
current epoch: 34
train loss is 0.035598
average val loss: 0.023964, accuracy: 0.0236
average test loss: 0.027652, accuracy: 0.0276
case acc: 0.018200293
case acc: 0.021231903
case acc: 0.034408942
case acc: 0.032398205
case acc: 0.035033602
case acc: 0.024590664
top acc: 0.0221 ::: bot acc: 0.0277
top acc: 0.0381 ::: bot acc: 0.0085
top acc: 0.0639 ::: bot acc: 0.0133
top acc: 0.0567 ::: bot acc: 0.0104
top acc: 0.0646 ::: bot acc: 0.0104
top acc: 0.0446 ::: bot acc: 0.0152
current epoch: 35
train loss is 0.034017
average val loss: 0.024428, accuracy: 0.0247
average test loss: 0.023828, accuracy: 0.0243
case acc: 0.028291127
case acc: 0.019005613
case acc: 0.027737722
case acc: 0.021741308
case acc: 0.027691117
case acc: 0.02157119
top acc: 0.0073 ::: bot acc: 0.0518
top acc: 0.0083 ::: bot acc: 0.0354
top acc: 0.0479 ::: bot acc: 0.0253
top acc: 0.0374 ::: bot acc: 0.0174
top acc: 0.0485 ::: bot acc: 0.0209
top acc: 0.0333 ::: bot acc: 0.0258
current epoch: 36
train loss is 0.037482
average val loss: 0.045095, accuracy: 0.0457
average test loss: 0.038646, accuracy: 0.0399
case acc: 0.06001466
case acc: 0.05761346
case acc: 0.032255977
case acc: 0.031289008
case acc: 0.029647077
case acc: 0.028491667
top acc: 0.0356 ::: bot acc: 0.0852
top acc: 0.0365 ::: bot acc: 0.0791
top acc: 0.0180 ::: bot acc: 0.0574
top acc: 0.0113 ::: bot acc: 0.0555
top acc: 0.0172 ::: bot acc: 0.0537
top acc: 0.0133 ::: bot acc: 0.0507
current epoch: 37
train loss is 0.046121
average val loss: 0.066540, accuracy: 0.0668
average test loss: 0.059028, accuracy: 0.0593
case acc: 0.076760545
case acc: 0.08350725
case acc: 0.04891607
case acc: 0.05982366
case acc: 0.04786028
case acc: 0.03918434
top acc: 0.0522 ::: bot acc: 0.1020
top acc: 0.0624 ::: bot acc: 0.1049
top acc: 0.0187 ::: bot acc: 0.0819
top acc: 0.0329 ::: bot acc: 0.0874
top acc: 0.0170 ::: bot acc: 0.0809
top acc: 0.0132 ::: bot acc: 0.0667
current epoch: 38
train loss is 0.048365
average val loss: 0.042990, accuracy: 0.0433
average test loss: 0.036648, accuracy: 0.0372
case acc: 0.04077788
case acc: 0.050444964
case acc: 0.03303962
case acc: 0.04287246
case acc: 0.033250004
case acc: 0.022763744
top acc: 0.0170 ::: bot acc: 0.0656
top acc: 0.0294 ::: bot acc: 0.0718
top acc: 0.0172 ::: bot acc: 0.0590
top acc: 0.0177 ::: bot acc: 0.0696
top acc: 0.0132 ::: bot acc: 0.0610
top acc: 0.0205 ::: bot acc: 0.0386
current epoch: 39
train loss is 0.042425
average val loss: 0.026736, accuracy: 0.0267
average test loss: 0.023747, accuracy: 0.0235
case acc: 0.019087166
case acc: 0.019293299
case acc: 0.026831137
case acc: 0.028326474
case acc: 0.025825944
case acc: 0.021767024
top acc: 0.0170 ::: bot acc: 0.0329
top acc: 0.0079 ::: bot acc: 0.0360
top acc: 0.0311 ::: bot acc: 0.0421
top acc: 0.0114 ::: bot acc: 0.0511
top acc: 0.0275 ::: bot acc: 0.0418
top acc: 0.0348 ::: bot acc: 0.0244
current epoch: 40
train loss is 0.034274
average val loss: 0.022458, accuracy: 0.0224
average test loss: 0.022802, accuracy: 0.0225
case acc: 0.020929083
case acc: 0.018540356
case acc: 0.026357744
case acc: 0.021660259
case acc: 0.02554169
case acc: 0.021979187
top acc: 0.0373 ::: bot acc: 0.0127
top acc: 0.0334 ::: bot acc: 0.0099
top acc: 0.0385 ::: bot acc: 0.0348
top acc: 0.0164 ::: bot acc: 0.0388
top acc: 0.0383 ::: bot acc: 0.0309
top acc: 0.0363 ::: bot acc: 0.0229
current epoch: 41
train loss is 0.032909
average val loss: 0.027265, accuracy: 0.0279
average test loss: 0.031776, accuracy: 0.0322
case acc: 0.03747806
case acc: 0.044936508
case acc: 0.03062708
case acc: 0.022734866
case acc: 0.031281266
case acc: 0.02603281
top acc: 0.0614 ::: bot acc: 0.0139
top acc: 0.0658 ::: bot acc: 0.0238
top acc: 0.0565 ::: bot acc: 0.0173
top acc: 0.0400 ::: bot acc: 0.0152
top acc: 0.0577 ::: bot acc: 0.0130
top acc: 0.0477 ::: bot acc: 0.0131
current epoch: 42
train loss is 0.036601
average val loss: 0.044129, accuracy: 0.0444
average test loss: 0.050489, accuracy: 0.0507
case acc: 0.056921028
case acc: 0.07481476
case acc: 0.04512068
case acc: 0.043580234
case acc: 0.04805327
case acc: 0.035736185
top acc: 0.0817 ::: bot acc: 0.0316
top acc: 0.0958 ::: bot acc: 0.0534
top acc: 0.0791 ::: bot acc: 0.0151
top acc: 0.0701 ::: bot acc: 0.0173
top acc: 0.0818 ::: bot acc: 0.0147
top acc: 0.0626 ::: bot acc: 0.0122
current epoch: 43
train loss is 0.042352
average val loss: 0.050307, accuracy: 0.0503
average test loss: 0.056856, accuracy: 0.0570
case acc: 0.05483731
case acc: 0.078538634
case acc: 0.053307652
case acc: 0.058444507
case acc: 0.058622487
case acc: 0.038274523
top acc: 0.0796 ::: bot acc: 0.0295
top acc: 0.0995 ::: bot acc: 0.0571
top acc: 0.0887 ::: bot acc: 0.0204
top acc: 0.0857 ::: bot acc: 0.0306
top acc: 0.0931 ::: bot acc: 0.0240
top acc: 0.0657 ::: bot acc: 0.0136
current epoch: 44
train loss is 0.042313
average val loss: 0.029485, accuracy: 0.0293
average test loss: 0.034683, accuracy: 0.0350
case acc: 0.023902155
case acc: 0.04375092
case acc: 0.036565717
case acc: 0.04133047
case acc: 0.040761884
case acc: 0.023478452
top acc: 0.0435 ::: bot acc: 0.0091
top acc: 0.0646 ::: bot acc: 0.0226
top acc: 0.0674 ::: bot acc: 0.0129
top acc: 0.0676 ::: bot acc: 0.0155
top acc: 0.0730 ::: bot acc: 0.0107
top acc: 0.0418 ::: bot acc: 0.0174
current epoch: 45
train loss is 0.037232
average val loss: 0.022231, accuracy: 0.0223
average test loss: 0.023314, accuracy: 0.0237
case acc: 0.02073052
case acc: 0.016636403
case acc: 0.028177332
case acc: 0.025970083
case acc: 0.029139847
case acc: 0.021332344
top acc: 0.0117 ::: bot acc: 0.0384
top acc: 0.0283 ::: bot acc: 0.0142
top acc: 0.0494 ::: bot acc: 0.0239
top acc: 0.0471 ::: bot acc: 0.0107
top acc: 0.0528 ::: bot acc: 0.0167
top acc: 0.0273 ::: bot acc: 0.0319
current epoch: 46
train loss is 0.035105
average val loss: 0.032005, accuracy: 0.0326
average test loss: 0.027341, accuracy: 0.0284
case acc: 0.04084695
case acc: 0.030362854
case acc: 0.027389029
case acc: 0.02042288
case acc: 0.025567787
case acc: 0.025575627
top acc: 0.0169 ::: bot acc: 0.0658
top acc: 0.0107 ::: bot acc: 0.0511
top acc: 0.0286 ::: bot acc: 0.0447
top acc: 0.0201 ::: bot acc: 0.0349
top acc: 0.0295 ::: bot acc: 0.0398
top acc: 0.0151 ::: bot acc: 0.0456
current epoch: 47
train loss is 0.036821
average val loss: 0.050006, accuracy: 0.0504
average test loss: 0.042869, accuracy: 0.0437
case acc: 0.059046637
case acc: 0.059903726
case acc: 0.036957737
case acc: 0.038260564
case acc: 0.035252154
case acc: 0.032510716
top acc: 0.0345 ::: bot acc: 0.0843
top acc: 0.0389 ::: bot acc: 0.0813
top acc: 0.0155 ::: bot acc: 0.0656
top acc: 0.0143 ::: bot acc: 0.0645
top acc: 0.0126 ::: bot acc: 0.0642
top acc: 0.0121 ::: bot acc: 0.0574
current epoch: 48
train loss is 0.039289
average val loss: 0.050567, accuracy: 0.0509
average test loss: 0.043376, accuracy: 0.0439
case acc: 0.050895132
case acc: 0.058084376
case acc: 0.038855728
case acc: 0.046769276
case acc: 0.039264426
case acc: 0.029777767
top acc: 0.0266 ::: bot acc: 0.0761
top acc: 0.0371 ::: bot acc: 0.0795
top acc: 0.0156 ::: bot acc: 0.0684
top acc: 0.0207 ::: bot acc: 0.0740
top acc: 0.0129 ::: bot acc: 0.0700
top acc: 0.0126 ::: bot acc: 0.0531
current epoch: 49
train loss is 0.039900
average val loss: 0.030166, accuracy: 0.0302
average test loss: 0.025868, accuracy: 0.0257
case acc: 0.0213459
case acc: 0.024466302
case acc: 0.02813719
case acc: 0.031025548
case acc: 0.027753461
case acc: 0.021344023
top acc: 0.0104 ::: bot acc: 0.0400
top acc: 0.0072 ::: bot acc: 0.0441
top acc: 0.0261 ::: bot acc: 0.0472
top acc: 0.0112 ::: bot acc: 0.0552
top acc: 0.0204 ::: bot acc: 0.0493
top acc: 0.0293 ::: bot acc: 0.0300
current epoch: 50
train loss is 0.033568
average val loss: 0.022243, accuracy: 0.0223
average test loss: 0.023067, accuracy: 0.0227
case acc: 0.021914018
case acc: 0.018071102
case acc: 0.026612671
case acc: 0.020944417
case acc: 0.025548732
case acc: 0.023197278
top acc: 0.0395 ::: bot acc: 0.0112
top acc: 0.0323 ::: bot acc: 0.0104
top acc: 0.0416 ::: bot acc: 0.0317
top acc: 0.0185 ::: bot acc: 0.0366
top acc: 0.0384 ::: bot acc: 0.0308
top acc: 0.0410 ::: bot acc: 0.0183
LME_Co_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6786 6786 6786
1.7082474 -0.6288155 0.12137239 -0.15229516
Validation: 756 756 756
Testing: 768 768 768
pre-processing time: 0.0002391338348388672
the split date is 2011-07-01
net initializing with time: 0.002946615219116211
preparing training and testing date with time: 2.384185791015625e-07
current epoch: 1
train loss is 0.278111
average val loss: 0.200242, accuracy: 0.2012
average test loss: 0.199808, accuracy: 0.2013
case acc: 0.37892386
case acc: 0.3123871
case acc: 0.03290242
case acc: 0.13088804
case acc: 0.32962975
case acc: 0.022898111
top acc: 0.4032 ::: bot acc: 0.3540
top acc: 0.3349 ::: bot acc: 0.2914
top acc: 0.0179 ::: bot acc: 0.0571
top acc: 0.1509 ::: bot acc: 0.1078
top acc: 0.3548 ::: bot acc: 0.3019
top acc: 0.0253 ::: bot acc: 0.0335
current epoch: 2
train loss is 0.269350
average val loss: 0.150615, accuracy: 0.1509
average test loss: 0.150545, accuracy: 0.1503
case acc: 0.2173462
case acc: 0.15706256
case acc: 0.16943017
case acc: 0.024254683
case acc: 0.17214328
case acc: 0.16126926
top acc: 0.2421 ::: bot acc: 0.1930
top acc: 0.1788 ::: bot acc: 0.1368
top acc: 0.1359 ::: bot acc: 0.2027
top acc: 0.0102 ::: bot acc: 0.0435
top acc: 0.1980 ::: bot acc: 0.1437
top acc: 0.1308 ::: bot acc: 0.1912
current epoch: 3
train loss is 0.156265
average val loss: 0.154923, accuracy: 0.1557
average test loss: 0.155181, accuracy: 0.1560
case acc: 0.27223438
case acc: 0.2184411
case acc: 0.08613959
case acc: 0.04987722
case acc: 0.23269744
case acc: 0.0763997
top acc: 0.2972 ::: bot acc: 0.2482
top acc: 0.2399 ::: bot acc: 0.1985
top acc: 0.0530 ::: bot acc: 0.1192
top acc: 0.0683 ::: bot acc: 0.0296
top acc: 0.2589 ::: bot acc: 0.2042
top acc: 0.0482 ::: bot acc: 0.1053
current epoch: 4
train loss is 0.161445
average val loss: 0.133441, accuracy: 0.1339
average test loss: 0.133325, accuracy: 0.1336
case acc: 0.22130427
case acc: 0.17429832
case acc: 0.10530275
case acc: 0.022109501
case acc: 0.18737194
case acc: 0.09144692
top acc: 0.2463 ::: bot acc: 0.1973
top acc: 0.1957 ::: bot acc: 0.1544
top acc: 0.0715 ::: bot acc: 0.1387
top acc: 0.0354 ::: bot acc: 0.0122
top acc: 0.2136 ::: bot acc: 0.1587
top acc: 0.0620 ::: bot acc: 0.1211
current epoch: 5
train loss is 0.138005
average val loss: 0.130539, accuracy: 0.1314
average test loss: 0.130832, accuracy: 0.1319
case acc: 0.23469868
case acc: 0.19506054
case acc: 0.05955431
case acc: 0.050865926
case acc: 0.20642586
case acc: 0.04453577
top acc: 0.2596 ::: bot acc: 0.2107
top acc: 0.2165 ::: bot acc: 0.1752
top acc: 0.0295 ::: bot acc: 0.0912
top acc: 0.0692 ::: bot acc: 0.0306
top acc: 0.2326 ::: bot acc: 0.1777
top acc: 0.0210 ::: bot acc: 0.0714
current epoch: 6
train loss is 0.131000
average val loss: 0.111572, accuracy: 0.1122
average test loss: 0.111768, accuracy: 0.1125
case acc: 0.19427183
case acc: 0.16175826
case acc: 0.0669364
case acc: 0.031241953
case acc: 0.17160186
case acc: 0.049242456
top acc: 0.2191 ::: bot acc: 0.1702
top acc: 0.1832 ::: bot acc: 0.1419
top acc: 0.0353 ::: bot acc: 0.0993
top acc: 0.0479 ::: bot acc: 0.0145
top acc: 0.1978 ::: bot acc: 0.1428
top acc: 0.0244 ::: bot acc: 0.0769
current epoch: 7
train loss is 0.117351
average val loss: 0.103265, accuracy: 0.1042
average test loss: 0.103207, accuracy: 0.1043
case acc: 0.1842396
case acc: 0.15903242
case acc: 0.04690926
case acc: 0.039451916
case acc: 0.16718033
case acc: 0.02918791
top acc: 0.2091 ::: bot acc: 0.1601
top acc: 0.1805 ::: bot acc: 0.1392
top acc: 0.0207 ::: bot acc: 0.0766
top acc: 0.0572 ::: bot acc: 0.0204
top acc: 0.1934 ::: bot acc: 0.1383
top acc: 0.0139 ::: bot acc: 0.0522
current epoch: 8
train loss is 0.103553
average val loss: 0.090911, accuracy: 0.0918
average test loss: 0.090554, accuracy: 0.0919
case acc: 0.16007286
case acc: 0.14212017
case acc: 0.040658638
case acc: 0.034667864
case acc: 0.14866903
case acc: 0.024964197
top acc: 0.1849 ::: bot acc: 0.1359
top acc: 0.1635 ::: bot acc: 0.1223
top acc: 0.0174 ::: bot acc: 0.0690
top acc: 0.0518 ::: bot acc: 0.0169
top acc: 0.1749 ::: bot acc: 0.1197
top acc: 0.0194 ::: bot acc: 0.0429
current epoch: 9
train loss is 0.093574
average val loss: 0.082485, accuracy: 0.0833
average test loss: 0.081680, accuracy: 0.0834
case acc: 0.14205119
case acc: 0.13149717
case acc: 0.03145487
case acc: 0.035219133
case acc: 0.13637537
case acc: 0.023541752
top acc: 0.1669 ::: bot acc: 0.1179
top acc: 0.1529 ::: bot acc: 0.1118
top acc: 0.0173 ::: bot acc: 0.0553
top acc: 0.0523 ::: bot acc: 0.0173
top acc: 0.1627 ::: bot acc: 0.1073
top acc: 0.0338 ::: bot acc: 0.0287
current epoch: 10
train loss is 0.082137
average val loss: 0.073356, accuracy: 0.0741
average test loss: 0.072271, accuracy: 0.0739
case acc: 0.12056002
case acc: 0.11749661
case acc: 0.02687319
case acc: 0.032478407
case acc: 0.12074585
case acc: 0.024977839
top acc: 0.1454 ::: bot acc: 0.0964
top acc: 0.1388 ::: bot acc: 0.0978
top acc: 0.0227 ::: bot acc: 0.0457
top acc: 0.0492 ::: bot acc: 0.0154
top acc: 0.1472 ::: bot acc: 0.0916
top acc: 0.0430 ::: bot acc: 0.0203
current epoch: 11
train loss is 0.072617
average val loss: 0.066741, accuracy: 0.0675
average test loss: 0.065512, accuracy: 0.0669
case acc: 0.10174307
case acc: 0.106243
case acc: 0.024614472
case acc: 0.031745527
case acc: 0.107843965
case acc: 0.029194698
top acc: 0.1267 ::: bot acc: 0.0777
top acc: 0.1274 ::: bot acc: 0.0866
top acc: 0.0336 ::: bot acc: 0.0341
top acc: 0.0483 ::: bot acc: 0.0149
top acc: 0.1344 ::: bot acc: 0.0787
top acc: 0.0529 ::: bot acc: 0.0140
current epoch: 12
train loss is 0.063508
average val loss: 0.058699, accuracy: 0.0594
average test loss: 0.057412, accuracy: 0.0586
case acc: 0.080480516
case acc: 0.09275676
case acc: 0.025460357
case acc: 0.02854304
case acc: 0.092671536
case acc: 0.03158656
top acc: 0.1054 ::: bot acc: 0.0566
top acc: 0.1138 ::: bot acc: 0.0732
top acc: 0.0419 ::: bot acc: 0.0262
top acc: 0.0444 ::: bot acc: 0.0129
top acc: 0.1193 ::: bot acc: 0.0634
top acc: 0.0570 ::: bot acc: 0.0130
current epoch: 13
train loss is 0.055500
average val loss: 0.052827, accuracy: 0.0534
average test loss: 0.051608, accuracy: 0.0525
case acc: 0.06247869
case acc: 0.08243346
case acc: 0.028632473
case acc: 0.027188655
case acc: 0.080647305
case acc: 0.03343703
top acc: 0.0875 ::: bot acc: 0.0388
top acc: 0.1033 ::: bot acc: 0.0631
top acc: 0.0518 ::: bot acc: 0.0178
top acc: 0.0428 ::: bot acc: 0.0121
top acc: 0.1075 ::: bot acc: 0.0512
top acc: 0.0598 ::: bot acc: 0.0131
current epoch: 14
train loss is 0.048167
average val loss: 0.048172, accuracy: 0.0485
average test loss: 0.047105, accuracy: 0.0475
case acc: 0.04715468
case acc: 0.074229926
case acc: 0.033548504
case acc: 0.026479552
case acc: 0.07059808
case acc: 0.03316103
top acc: 0.0723 ::: bot acc: 0.0237
top acc: 0.0949 ::: bot acc: 0.0550
top acc: 0.0616 ::: bot acc: 0.0131
top acc: 0.0420 ::: bot acc: 0.0117
top acc: 0.0975 ::: bot acc: 0.0413
top acc: 0.0595 ::: bot acc: 0.0129
current epoch: 15
train loss is 0.041786
average val loss: 0.043902, accuracy: 0.0440
average test loss: 0.042906, accuracy: 0.0429
case acc: 0.034637436
case acc: 0.06677893
case acc: 0.038397405
case acc: 0.025388196
case acc: 0.06150814
case acc: 0.03086391
top acc: 0.0592 ::: bot acc: 0.0131
top acc: 0.0874 ::: bot acc: 0.0476
top acc: 0.0697 ::: bot acc: 0.0114
top acc: 0.0406 ::: bot acc: 0.0111
top acc: 0.0883 ::: bot acc: 0.0328
top acc: 0.0560 ::: bot acc: 0.0129
current epoch: 16
train loss is 0.037138
average val loss: 0.042613, accuracy: 0.0426
average test loss: 0.041655, accuracy: 0.0414
case acc: 0.028150424
case acc: 0.0630095
case acc: 0.04510326
case acc: 0.02644093
case acc: 0.05618625
case acc: 0.02946327
top acc: 0.0515 ::: bot acc: 0.0094
top acc: 0.0835 ::: bot acc: 0.0439
top acc: 0.0790 ::: bot acc: 0.0130
top acc: 0.0419 ::: bot acc: 0.0115
top acc: 0.0829 ::: bot acc: 0.0279
top acc: 0.0538 ::: bot acc: 0.0132
current epoch: 17
train loss is 0.034480
average val loss: 0.050301, accuracy: 0.0503
average test loss: 0.049594, accuracy: 0.0494
case acc: 0.031584345
case acc: 0.06993252
case acc: 0.06154379
case acc: 0.03665633
case acc: 0.06176191
case acc: 0.035152733
top acc: 0.0559 ::: bot acc: 0.0111
top acc: 0.0904 ::: bot acc: 0.0508
top acc: 0.0965 ::: bot acc: 0.0274
top acc: 0.0535 ::: bot acc: 0.0189
top acc: 0.0888 ::: bot acc: 0.0329
top acc: 0.0621 ::: bot acc: 0.0135
current epoch: 18
train loss is 0.036746
average val loss: 0.065515, accuracy: 0.0655
average test loss: 0.065034, accuracy: 0.0651
case acc: 0.041929394
case acc: 0.084299356
case acc: 0.08380847
case acc: 0.055253938
case acc: 0.075977005
case acc: 0.04911922
top acc: 0.0673 ::: bot acc: 0.0194
top acc: 0.1048 ::: bot acc: 0.0651
top acc: 0.1189 ::: bot acc: 0.0494
top acc: 0.0729 ::: bot acc: 0.0361
top acc: 0.1035 ::: bot acc: 0.0463
top acc: 0.0784 ::: bot acc: 0.0225
current epoch: 19
train loss is 0.042768
average val loss: 0.075574, accuracy: 0.0755
average test loss: 0.075110, accuracy: 0.0751
case acc: 0.0453519
case acc: 0.092990495
case acc: 0.09841852
case acc: 0.069103464
case acc: 0.08621854
case acc: 0.05838567
top acc: 0.0710 ::: bot acc: 0.0225
top acc: 0.1134 ::: bot acc: 0.0738
top acc: 0.1335 ::: bot acc: 0.0640
top acc: 0.0870 ::: bot acc: 0.0493
top acc: 0.1138 ::: bot acc: 0.0565
top acc: 0.0888 ::: bot acc: 0.0296
current epoch: 20
train loss is 0.051904
average val loss: 0.063254, accuracy: 0.0631
average test loss: 0.062720, accuracy: 0.0626
case acc: 0.02732668
case acc: 0.07835695
case acc: 0.08534597
case acc: 0.060147494
case acc: 0.07521476
case acc: 0.04919228
top acc: 0.0509 ::: bot acc: 0.0089
top acc: 0.0987 ::: bot acc: 0.0593
top acc: 0.1205 ::: bot acc: 0.0509
top acc: 0.0779 ::: bot acc: 0.0407
top acc: 0.1028 ::: bot acc: 0.0455
top acc: 0.0785 ::: bot acc: 0.0226
current epoch: 21
train loss is 0.056309
average val loss: 0.031582, accuracy: 0.0318
average test loss: 0.030517, accuracy: 0.0304
case acc: 0.029304262
case acc: 0.031505823
case acc: 0.038621478
case acc: 0.021318972
case acc: 0.036671977
case acc: 0.024969079
top acc: 0.0144 ::: bot acc: 0.0467
top acc: 0.0517 ::: bot acc: 0.0128
top acc: 0.0702 ::: bot acc: 0.0115
top acc: 0.0353 ::: bot acc: 0.0095
top acc: 0.0615 ::: bot acc: 0.0127
top acc: 0.0440 ::: bot acc: 0.0192
current epoch: 22
train loss is 0.058433
average val loss: 0.040519, accuracy: 0.0412
average test loss: 0.040485, accuracy: 0.0406
case acc: 0.07670057
case acc: 0.029178848
case acc: 0.037182502
case acc: 0.040535454
case acc: 0.025824983
case acc: 0.03441027
top acc: 0.0517 ::: bot acc: 0.0989
top acc: 0.0126 ::: bot acc: 0.0464
top acc: 0.0146 ::: bot acc: 0.0655
top acc: 0.0234 ::: bot acc: 0.0599
top acc: 0.0117 ::: bot acc: 0.0490
top acc: 0.0145 ::: bot acc: 0.0601
current epoch: 23
train loss is 0.041581
average val loss: 0.034610, accuracy: 0.0352
average test loss: 0.034073, accuracy: 0.0346
case acc: 0.060900085
case acc: 0.025270537
case acc: 0.038520113
case acc: 0.03705826
case acc: 0.022022093
case acc: 0.023553655
top acc: 0.0370 ::: bot acc: 0.0826
top acc: 0.0108 ::: bot acc: 0.0415
top acc: 0.0149 ::: bot acc: 0.0674
top acc: 0.0203 ::: bot acc: 0.0562
top acc: 0.0170 ::: bot acc: 0.0404
top acc: 0.0255 ::: bot acc: 0.0375
current epoch: 24
train loss is 0.035330
average val loss: 0.044044, accuracy: 0.0444
average test loss: 0.044113, accuracy: 0.0444
case acc: 0.064546905
case acc: 0.037717257
case acc: 0.056789346
case acc: 0.054001227
case acc: 0.02874121
case acc: 0.024412429
top acc: 0.0404 ::: bot acc: 0.0863
top acc: 0.0182 ::: bot acc: 0.0564
top acc: 0.0262 ::: bot acc: 0.0891
top acc: 0.0362 ::: bot acc: 0.0736
top acc: 0.0112 ::: bot acc: 0.0535
top acc: 0.0212 ::: bot acc: 0.0418
current epoch: 25
train loss is 0.042348
average val loss: 0.057014, accuracy: 0.0572
average test loss: 0.057448, accuracy: 0.0575
case acc: 0.069706365
case acc: 0.05257125
case acc: 0.07658261
case acc: 0.07379986
case acc: 0.041529283
case acc: 0.031022673
top acc: 0.0452 ::: bot acc: 0.0916
top acc: 0.0323 ::: bot acc: 0.0716
top acc: 0.0424 ::: bot acc: 0.1106
top acc: 0.0560 ::: bot acc: 0.0934
top acc: 0.0176 ::: bot acc: 0.0694
top acc: 0.0140 ::: bot acc: 0.0553
current epoch: 26
train loss is 0.068055
average val loss: 0.027359, accuracy: 0.0272
average test loss: 0.025775, accuracy: 0.0253
case acc: 0.017867893
case acc: 0.02005814
case acc: 0.025650417
case acc: 0.014709802
case acc: 0.031162862
case acc: 0.04214219
top acc: 0.0341 ::: bot acc: 0.0141
top acc: 0.0381 ::: bot acc: 0.0056
top acc: 0.0298 ::: bot acc: 0.0397
top acc: 0.0101 ::: bot acc: 0.0279
top acc: 0.0537 ::: bot acc: 0.0119
top acc: 0.0704 ::: bot acc: 0.0177
current epoch: 27
train loss is 0.047838
average val loss: 0.029755, accuracy: 0.0297
average test loss: 0.028427, accuracy: 0.0281
case acc: 0.025703005
case acc: 0.030719794
case acc: 0.02605972
case acc: 0.01373335
case acc: 0.036153637
case acc: 0.03610155
top acc: 0.0489 ::: bot acc: 0.0082
top acc: 0.0508 ::: bot acc: 0.0120
top acc: 0.0443 ::: bot acc: 0.0251
top acc: 0.0186 ::: bot acc: 0.0191
top acc: 0.0607 ::: bot acc: 0.0127
top acc: 0.0630 ::: bot acc: 0.0143
current epoch: 28
train loss is 0.039957
average val loss: 0.031384, accuracy: 0.0314
average test loss: 0.030198, accuracy: 0.0300
case acc: 0.03052913
case acc: 0.038075168
case acc: 0.030799253
case acc: 0.0152496975
case acc: 0.037809283
case acc: 0.027251795
top acc: 0.0550 ::: bot acc: 0.0104
top acc: 0.0584 ::: bot acc: 0.0189
top acc: 0.0566 ::: bot acc: 0.0152
top acc: 0.0245 ::: bot acc: 0.0132
top acc: 0.0628 ::: bot acc: 0.0135
top acc: 0.0500 ::: bot acc: 0.0140
current epoch: 29
train loss is 0.033759
average val loss: 0.039377, accuracy: 0.0395
average test loss: 0.038602, accuracy: 0.0384
case acc: 0.039822098
case acc: 0.051797673
case acc: 0.043921284
case acc: 0.023483645
case acc: 0.04542488
case acc: 0.025836337
top acc: 0.0653 ::: bot acc: 0.0177
top acc: 0.0722 ::: bot acc: 0.0326
top acc: 0.0774 ::: bot acc: 0.0126
top acc: 0.0385 ::: bot acc: 0.0097
top acc: 0.0716 ::: bot acc: 0.0186
top acc: 0.0468 ::: bot acc: 0.0161
current epoch: 30
train loss is 0.031003
average val loss: 0.056803, accuracy: 0.0569
average test loss: 0.056443, accuracy: 0.0566
case acc: 0.054184422
case acc: 0.07245377
case acc: 0.07368639
case acc: 0.044928797
case acc: 0.06167813
case acc: 0.03281281
top acc: 0.0799 ::: bot acc: 0.0316
top acc: 0.0929 ::: bot acc: 0.0532
top acc: 0.1086 ::: bot acc: 0.0393
top acc: 0.0623 ::: bot acc: 0.0265
top acc: 0.0888 ::: bot acc: 0.0331
top acc: 0.0587 ::: bot acc: 0.0130
current epoch: 31
train loss is 0.038864
average val loss: 0.079639, accuracy: 0.0797
average test loss: 0.079357, accuracy: 0.0796
case acc: 0.068406925
case acc: 0.09474569
case acc: 0.107148275
case acc: 0.07240802
case acc: 0.08277667
case acc: 0.05182372
top acc: 0.0942 ::: bot acc: 0.0458
top acc: 0.1152 ::: bot acc: 0.0755
top acc: 0.1421 ::: bot acc: 0.0728
top acc: 0.0904 ::: bot acc: 0.0526
top acc: 0.1103 ::: bot acc: 0.0533
top acc: 0.0811 ::: bot acc: 0.0250
current epoch: 32
train loss is 0.060954
average val loss: 0.037047, accuracy: 0.0371
average test loss: 0.035970, accuracy: 0.0356
case acc: 0.01874556
case acc: 0.044692323
case acc: 0.05818887
case acc: 0.029789198
case acc: 0.039079808
case acc: 0.023391629
top acc: 0.0370 ::: bot acc: 0.0114
top acc: 0.0652 ::: bot acc: 0.0254
top acc: 0.0930 ::: bot acc: 0.0241
top acc: 0.0460 ::: bot acc: 0.0136
top acc: 0.0643 ::: bot acc: 0.0143
top acc: 0.0381 ::: bot acc: 0.0244
current epoch: 33
train loss is 0.050539
average val loss: 0.024964, accuracy: 0.0251
average test loss: 0.023189, accuracy: 0.0228
case acc: 0.026629316
case acc: 0.017844766
case acc: 0.03204694
case acc: 0.013788935
case acc: 0.023387674
case acc: 0.023337603
top acc: 0.0137 ::: bot acc: 0.0430
top acc: 0.0343 ::: bot acc: 0.0069
top acc: 0.0589 ::: bot acc: 0.0144
top acc: 0.0190 ::: bot acc: 0.0187
top acc: 0.0392 ::: bot acc: 0.0179
top acc: 0.0261 ::: bot acc: 0.0365
current epoch: 34
train loss is 0.040443
average val loss: 0.023636, accuracy: 0.0238
average test loss: 0.021686, accuracy: 0.0217
case acc: 0.03056167
case acc: 0.014223218
case acc: 0.025393229
case acc: 0.015581004
case acc: 0.021549879
case acc: 0.023016278
top acc: 0.0146 ::: bot acc: 0.0484
top acc: 0.0225 ::: bot acc: 0.0173
top acc: 0.0403 ::: bot acc: 0.0291
top acc: 0.0090 ::: bot acc: 0.0298
top acc: 0.0323 ::: bot acc: 0.0247
top acc: 0.0332 ::: bot acc: 0.0293
current epoch: 35
train loss is 0.031954
average val loss: 0.024462, accuracy: 0.0246
average test loss: 0.022777, accuracy: 0.0231
case acc: 0.030444456
case acc: 0.01563819
case acc: 0.026829766
case acc: 0.02148417
case acc: 0.0207899
case acc: 0.023547046
top acc: 0.0145 ::: bot acc: 0.0482
top acc: 0.0142 ::: bot acc: 0.0256
top acc: 0.0241 ::: bot acc: 0.0454
top acc: 0.0080 ::: bot acc: 0.0390
top acc: 0.0278 ::: bot acc: 0.0293
top acc: 0.0390 ::: bot acc: 0.0235
current epoch: 36
train loss is 0.026761
average val loss: 0.029654, accuracy: 0.0297
average test loss: 0.028820, accuracy: 0.0293
case acc: 0.034537364
case acc: 0.023370586
case acc: 0.037677363
case acc: 0.035353277
case acc: 0.021998836
case acc: 0.023004506
top acc: 0.0166 ::: bot acc: 0.0533
top acc: 0.0106 ::: bot acc: 0.0389
top acc: 0.0145 ::: bot acc: 0.0663
top acc: 0.0188 ::: bot acc: 0.0544
top acc: 0.0165 ::: bot acc: 0.0406
top acc: 0.0313 ::: bot acc: 0.0313
current epoch: 37
train loss is 0.030824
average val loss: 0.037420, accuracy: 0.0374
average test loss: 0.037268, accuracy: 0.0375
case acc: 0.03716116
case acc: 0.032096557
case acc: 0.052338924
case acc: 0.04990635
case acc: 0.028021667
case acc: 0.02549146
top acc: 0.0181 ::: bot acc: 0.0564
top acc: 0.0143 ::: bot acc: 0.0500
top acc: 0.0231 ::: bot acc: 0.0840
top acc: 0.0320 ::: bot acc: 0.0696
top acc: 0.0109 ::: bot acc: 0.0524
top acc: 0.0180 ::: bot acc: 0.0450
current epoch: 38
train loss is 0.043413
average val loss: 0.025495, accuracy: 0.0253
average test loss: 0.023941, accuracy: 0.0241
case acc: 0.018039305
case acc: 0.015921019
case acc: 0.03490059
case acc: 0.03194172
case acc: 0.020695463
case acc: 0.023069903
top acc: 0.0228 ::: bot acc: 0.0255
top acc: 0.0134 ::: bot acc: 0.0264
top acc: 0.0143 ::: bot acc: 0.0623
top acc: 0.0159 ::: bot acc: 0.0508
top acc: 0.0248 ::: bot acc: 0.0323
top acc: 0.0336 ::: bot acc: 0.0290
current epoch: 39
train loss is 0.045967
average val loss: 0.035920, accuracy: 0.0361
average test loss: 0.035137, accuracy: 0.0352
case acc: 0.047022972
case acc: 0.039386675
case acc: 0.030546747
case acc: 0.017693602
case acc: 0.04028807
case acc: 0.03628446
top acc: 0.0728 ::: bot acc: 0.0245
top acc: 0.0598 ::: bot acc: 0.0202
top acc: 0.0561 ::: bot acc: 0.0155
top acc: 0.0297 ::: bot acc: 0.0101
top acc: 0.0658 ::: bot acc: 0.0149
top acc: 0.0631 ::: bot acc: 0.0146
current epoch: 40
train loss is 0.040946
average val loss: 0.047351, accuracy: 0.0475
average test loss: 0.047042, accuracy: 0.0470
case acc: 0.059145935
case acc: 0.057031512
case acc: 0.04703366
case acc: 0.031627495
case acc: 0.052012064
case acc: 0.035329774
top acc: 0.0849 ::: bot acc: 0.0366
top acc: 0.0775 ::: bot acc: 0.0378
top acc: 0.0813 ::: bot acc: 0.0141
top acc: 0.0480 ::: bot acc: 0.0150
top acc: 0.0786 ::: bot acc: 0.0244
top acc: 0.0618 ::: bot acc: 0.0142
current epoch: 41
train loss is 0.034135
average val loss: 0.059877, accuracy: 0.0600
average test loss: 0.059658, accuracy: 0.0599
case acc: 0.06454948
case acc: 0.07184422
case acc: 0.07219669
case acc: 0.049723953
case acc: 0.063349105
case acc: 0.037745267
top acc: 0.0903 ::: bot acc: 0.0420
top acc: 0.0923 ::: bot acc: 0.0526
top acc: 0.1072 ::: bot acc: 0.0377
top acc: 0.0671 ::: bot acc: 0.0310
top acc: 0.0905 ::: bot acc: 0.0346
top acc: 0.0649 ::: bot acc: 0.0153
current epoch: 42
train loss is 0.042537
average val loss: 0.065220, accuracy: 0.0653
average test loss: 0.065042, accuracy: 0.0653
case acc: 0.059605286
case acc: 0.076195285
case acc: 0.08622067
case acc: 0.06015563
case acc: 0.06790649
case acc: 0.04146232
top acc: 0.0854 ::: bot acc: 0.0370
top acc: 0.0967 ::: bot acc: 0.0569
top acc: 0.1212 ::: bot acc: 0.0518
top acc: 0.0779 ::: bot acc: 0.0408
top acc: 0.0953 ::: bot acc: 0.0388
top acc: 0.0694 ::: bot acc: 0.0175
current epoch: 43
train loss is 0.053542
average val loss: 0.027729, accuracy: 0.0279
average test loss: 0.026161, accuracy: 0.0257
case acc: 0.017245648
case acc: 0.026464071
case acc: 0.039354734
case acc: 0.019574687
case acc: 0.028510524
case acc: 0.02294047
top acc: 0.0286 ::: bot acc: 0.0198
top acc: 0.0462 ::: bot acc: 0.0087
top acc: 0.0711 ::: bot acc: 0.0115
top acc: 0.0330 ::: bot acc: 0.0091
top acc: 0.0495 ::: bot acc: 0.0124
top acc: 0.0306 ::: bot acc: 0.0318
current epoch: 44
train loss is 0.037606
average val loss: 0.024302, accuracy: 0.0244
average test loss: 0.022337, accuracy: 0.0221
case acc: 0.019721668
case acc: 0.018311284
case acc: 0.030770015
case acc: 0.015433487
case acc: 0.025189342
case acc: 0.023332596
top acc: 0.0182 ::: bot acc: 0.0304
top acc: 0.0352 ::: bot acc: 0.0065
top acc: 0.0565 ::: bot acc: 0.0153
top acc: 0.0251 ::: bot acc: 0.0127
top acc: 0.0437 ::: bot acc: 0.0143
top acc: 0.0379 ::: bot acc: 0.0244
current epoch: 45
train loss is 0.031005
average val loss: 0.022821, accuracy: 0.0228
average test loss: 0.020657, accuracy: 0.0206
case acc: 0.022644695
case acc: 0.014570328
case acc: 0.025370128
case acc: 0.013474282
case acc: 0.0229615
case acc: 0.024525138
top acc: 0.0149 ::: bot acc: 0.0364
top acc: 0.0251 ::: bot acc: 0.0146
top acc: 0.0403 ::: bot acc: 0.0291
top acc: 0.0161 ::: bot acc: 0.0216
top acc: 0.0381 ::: bot acc: 0.0189
top acc: 0.0433 ::: bot acc: 0.0191
current epoch: 46
train loss is 0.026213
average val loss: 0.023940, accuracy: 0.0240
average test loss: 0.022203, accuracy: 0.0225
case acc: 0.027055357
case acc: 0.016459065
case acc: 0.028165735
case acc: 0.018837105
case acc: 0.020764954
case acc: 0.02350299
top acc: 0.0137 ::: bot acc: 0.0435
top acc: 0.0126 ::: bot acc: 0.0276
top acc: 0.0198 ::: bot acc: 0.0496
top acc: 0.0075 ::: bot acc: 0.0354
top acc: 0.0282 ::: bot acc: 0.0288
top acc: 0.0392 ::: bot acc: 0.0232
current epoch: 47
train loss is 0.024808
average val loss: 0.030608, accuracy: 0.0306
average test loss: 0.029889, accuracy: 0.0303
case acc: 0.03315539
case acc: 0.02613916
case acc: 0.04220283
case acc: 0.034162927
case acc: 0.022748388
case acc: 0.023232779
top acc: 0.0159 ::: bot acc: 0.0515
top acc: 0.0112 ::: bot acc: 0.0427
top acc: 0.0164 ::: bot acc: 0.0721
top acc: 0.0178 ::: bot acc: 0.0531
top acc: 0.0144 ::: bot acc: 0.0428
top acc: 0.0261 ::: bot acc: 0.0363
current epoch: 48
train loss is 0.031571
average val loss: 0.034477, accuracy: 0.0343
average test loss: 0.034068, accuracy: 0.0343
case acc: 0.03089293
case acc: 0.03009562
case acc: 0.050832324
case acc: 0.04296103
case acc: 0.02595589
case acc: 0.024987709
top acc: 0.0148 ::: bot acc: 0.0486
top acc: 0.0132 ::: bot acc: 0.0476
top acc: 0.0220 ::: bot acc: 0.0823
top acc: 0.0254 ::: bot acc: 0.0625
top acc: 0.0112 ::: bot acc: 0.0492
top acc: 0.0189 ::: bot acc: 0.0438
current epoch: 49
train loss is 0.043006
average val loss: 0.023471, accuracy: 0.0233
average test loss: 0.021468, accuracy: 0.0212
case acc: 0.019489767
case acc: 0.014529
case acc: 0.028066095
case acc: 0.018101165
case acc: 0.0225118
case acc: 0.024391737
top acc: 0.0391 ::: bot acc: 0.0096
top acc: 0.0250 ::: bot acc: 0.0146
top acc: 0.0202 ::: bot acc: 0.0493
top acc: 0.0076 ::: bot acc: 0.0342
top acc: 0.0366 ::: bot acc: 0.0205
top acc: 0.0427 ::: bot acc: 0.0198
current epoch: 50
train loss is 0.040160
average val loss: 0.035184, accuracy: 0.0354
average test loss: 0.034427, accuracy: 0.0346
case acc: 0.047277153
case acc: 0.037523072
case acc: 0.03124131
case acc: 0.020216238
case acc: 0.038854636
case acc: 0.03228324
top acc: 0.0731 ::: bot acc: 0.0248
top acc: 0.0579 ::: bot acc: 0.0183
top acc: 0.0574 ::: bot acc: 0.0149
top acc: 0.0339 ::: bot acc: 0.0091
top acc: 0.0641 ::: bot acc: 0.0141
top acc: 0.0579 ::: bot acc: 0.0130

		{"drop_out": 0.4, "drop_out_mc": 0.1, "repeat_mc": 50, "hidden": 20, "embedding_size": 5, "batch": 512, "lag": 4}
{'generate_norm_params': 'v1', 'generate_tech_params': 'v3', 'generate_strat_params': None, 'generate_SD_params': 'v1', 'deal_with_abnormal_value': 'v2', 'labelling': 'v3', 'process_missing_value': 'v1', 'strategy_signal': None, 'normalize_without_1d_return': 'v1', 'technical_indication': 'v4', 'supply_and_demand': None, 'remove_unused_columns': 'v6', 'price_normalization': 'v3', 'scaling': None, 'construct': 'v4'}
LME_Co_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6780 6780 6780
1.8562728 -0.6288155 0.15869391 -0.16256663
Validation: 756 756 756
Testing: 774 774 774
pre-processing time: 0.00030922889709472656
the split date is 2009-07-01
net initializing with time: 0.00446772575378418
preparing training and testing date with time: 2.384185791015625e-07
current epoch: 1
train loss is 0.433662
average val loss: 0.288573, accuracy: 0.2886
average test loss: 0.284902, accuracy: 0.2849
case acc: 0.22398554
case acc: 0.3678977
case acc: 0.260163
case acc: 0.118679725
case acc: 0.4391105
case acc: 0.29957658
top acc: 0.2368 ::: bot acc: 0.2096
top acc: 0.3865 ::: bot acc: 0.3495
top acc: 0.2876 ::: bot acc: 0.2344
top acc: 0.1386 ::: bot acc: 0.0976
top acc: 0.4594 ::: bot acc: 0.4177
top acc: 0.3149 ::: bot acc: 0.2826
current epoch: 2
train loss is 0.163374
average val loss: 0.087235, accuracy: 0.0886
average test loss: 0.086242, accuracy: 0.0871
case acc: 0.029100887
case acc: 0.113601044
case acc: 0.021558957
case acc: 0.13077462
case acc: 0.18099186
case acc: 0.046377756
top acc: 0.0168 ::: bot acc: 0.0432
top acc: 0.1324 ::: bot acc: 0.0951
top acc: 0.0390 ::: bot acc: 0.0151
top acc: 0.1110 ::: bot acc: 0.1515
top acc: 0.2011 ::: bot acc: 0.1598
top acc: 0.0618 ::: bot acc: 0.0295
current epoch: 3
train loss is 0.130990
average val loss: 0.082934, accuracy: 0.0828
average test loss: 0.083784, accuracy: 0.0848
case acc: 0.09287211
case acc: 0.039604202
case acc: 0.052277286
case acc: 0.18655504
case acc: 0.12102815
case acc: 0.01646203
top acc: 0.0801 ::: bot acc: 0.1071
top acc: 0.0587 ::: bot acc: 0.0210
top acc: 0.0265 ::: bot acc: 0.0773
top acc: 0.1672 ::: bot acc: 0.2069
top acc: 0.1409 ::: bot acc: 0.1001
top acc: 0.0068 ::: bot acc: 0.0300
current epoch: 4
train loss is 0.130900
average val loss: 0.126823, accuracy: 0.1272
average test loss: 0.124204, accuracy: 0.1244
case acc: 0.052007925
case acc: 0.1852177
case acc: 0.092064366
case acc: 0.042531073
case acc: 0.24778865
case acc: 0.1266113
top acc: 0.0648 ::: bot acc: 0.0379
top acc: 0.2045 ::: bot acc: 0.1663
top acc: 0.1199 ::: bot acc: 0.0659
top acc: 0.0243 ::: bot acc: 0.0622
top acc: 0.2675 ::: bot acc: 0.2270
top acc: 0.1422 ::: bot acc: 0.1097
current epoch: 5
train loss is 0.097026
average val loss: 0.071769, accuracy: 0.0730
average test loss: 0.071555, accuracy: 0.0731
case acc: 0.059582837
case acc: 0.06806695
case acc: 0.024209255
case acc: 0.14758255
case acc: 0.12128002
case acc: 0.01797407
top acc: 0.0467 ::: bot acc: 0.0737
top acc: 0.0874 ::: bot acc: 0.0491
top acc: 0.0134 ::: bot acc: 0.0419
top acc: 0.1285 ::: bot acc: 0.1676
top acc: 0.1409 ::: bot acc: 0.1005
top acc: 0.0292 ::: bot acc: 0.0098
current epoch: 6
train loss is 0.093419
average val loss: 0.066903, accuracy: 0.0678
average test loss: 0.066995, accuracy: 0.0684
case acc: 0.067825094
case acc: 0.048787665
case acc: 0.028827934
case acc: 0.15005565
case acc: 0.10089951
case acc: 0.013803174
top acc: 0.0549 ::: bot acc: 0.0818
top acc: 0.0682 ::: bot acc: 0.0298
top acc: 0.0121 ::: bot acc: 0.0495
top acc: 0.1311 ::: bot acc: 0.1700
top acc: 0.1205 ::: bot acc: 0.0802
top acc: 0.0216 ::: bot acc: 0.0120
current epoch: 7
train loss is 0.099329
average val loss: 0.079041, accuracy: 0.0795
average test loss: 0.076987, accuracy: 0.0767
case acc: 0.010419249
case acc: 0.10938845
case acc: 0.042476863
case acc: 0.08351437
case acc: 0.1473087
case acc: 0.06684117
top acc: 0.0101 ::: bot acc: 0.0170
top acc: 0.1288 ::: bot acc: 0.0904
top acc: 0.0691 ::: bot acc: 0.0187
top acc: 0.0646 ::: bot acc: 0.1034
top acc: 0.1669 ::: bot acc: 0.1266
top acc: 0.0824 ::: bot acc: 0.0499
current epoch: 8
train loss is 0.079920
average val loss: 0.059880, accuracy: 0.0614
average test loss: 0.058971, accuracy: 0.0603
case acc: 0.043486886
case acc: 0.06413789
case acc: 0.019676475
case acc: 0.121097356
case acc: 0.088646024
case acc: 0.024869317
top acc: 0.0305 ::: bot acc: 0.0575
top acc: 0.0836 ::: bot acc: 0.0451
top acc: 0.0306 ::: bot acc: 0.0236
top acc: 0.1022 ::: bot acc: 0.1410
top acc: 0.1082 ::: bot acc: 0.0680
top acc: 0.0382 ::: bot acc: 0.0125
current epoch: 9
train loss is 0.075021
average val loss: 0.053608, accuracy: 0.0553
average test loss: 0.052985, accuracy: 0.0544
case acc: 0.052083705
case acc: 0.04718679
case acc: 0.020284798
case acc: 0.12598185
case acc: 0.0643823
case acc: 0.016729735
top acc: 0.0390 ::: bot acc: 0.0660
top acc: 0.0667 ::: bot acc: 0.0281
top acc: 0.0234 ::: bot acc: 0.0308
top acc: 0.1072 ::: bot acc: 0.1457
top acc: 0.0838 ::: bot acc: 0.0438
top acc: 0.0277 ::: bot acc: 0.0093
current epoch: 10
train loss is 0.074824
average val loss: 0.052254, accuracy: 0.0536
average test loss: 0.051037, accuracy: 0.0520
case acc: 0.036964778
case acc: 0.0566772
case acc: 0.021810967
case acc: 0.108637154
case acc: 0.062351383
case acc: 0.025783336
top acc: 0.0238 ::: bot acc: 0.0508
top acc: 0.0762 ::: bot acc: 0.0375
top acc: 0.0393 ::: bot acc: 0.0159
top acc: 0.0900 ::: bot acc: 0.1282
top acc: 0.0817 ::: bot acc: 0.0418
top acc: 0.0395 ::: bot acc: 0.0130
current epoch: 11
train loss is 0.070176
average val loss: 0.049121, accuracy: 0.0503
average test loss: 0.047800, accuracy: 0.0486
case acc: 0.032691933
case acc: 0.057200618
case acc: 0.024116747
case acc: 0.10285756
case acc: 0.04877373
case acc: 0.02572212
top acc: 0.0196 ::: bot acc: 0.0465
top acc: 0.0768 ::: bot acc: 0.0380
top acc: 0.0444 ::: bot acc: 0.0130
top acc: 0.0843 ::: bot acc: 0.1224
top acc: 0.0679 ::: bot acc: 0.0286
top acc: 0.0395 ::: bot acc: 0.0129
current epoch: 12
train loss is 0.065450
average val loss: 0.046858, accuracy: 0.0478
average test loss: 0.045454, accuracy: 0.0459
case acc: 0.027077269
case acc: 0.0597212
case acc: 0.028091306
case acc: 0.09539858
case acc: 0.03826572
case acc: 0.026971167
top acc: 0.0142 ::: bot acc: 0.0408
top acc: 0.0794 ::: bot acc: 0.0405
top acc: 0.0511 ::: bot acc: 0.0114
top acc: 0.0769 ::: bot acc: 0.1149
top acc: 0.0567 ::: bot acc: 0.0194
top acc: 0.0410 ::: bot acc: 0.0136
current epoch: 13
train loss is 0.060448
average val loss: 0.043884, accuracy: 0.0448
average test loss: 0.042482, accuracy: 0.0428
case acc: 0.025519071
case acc: 0.056586035
case acc: 0.03002682
case acc: 0.09029621
case acc: 0.028570112
case acc: 0.026088083
top acc: 0.0127 ::: bot acc: 0.0392
top acc: 0.0763 ::: bot acc: 0.0373
top acc: 0.0540 ::: bot acc: 0.0115
top acc: 0.0717 ::: bot acc: 0.1098
top acc: 0.0455 ::: bot acc: 0.0127
top acc: 0.0400 ::: bot acc: 0.0131
current epoch: 14
train loss is 0.057508
average val loss: 0.043057, accuracy: 0.0437
average test loss: 0.041467, accuracy: 0.0415
case acc: 0.01953102
case acc: 0.057221953
case acc: 0.036002208
case acc: 0.07869517
case acc: 0.027165065
case acc: 0.030482538
top acc: 0.0078 ::: bot acc: 0.0326
top acc: 0.0769 ::: bot acc: 0.0379
top acc: 0.0617 ::: bot acc: 0.0139
top acc: 0.0601 ::: bot acc: 0.0983
top acc: 0.0438 ::: bot acc: 0.0118
top acc: 0.0452 ::: bot acc: 0.0161
current epoch: 15
train loss is 0.055827
average val loss: 0.042617, accuracy: 0.0431
average test loss: 0.040806, accuracy: 0.0407
case acc: 0.01526315
case acc: 0.055956785
case acc: 0.042033877
case acc: 0.066406764
case acc: 0.028968297
case acc: 0.035316143
top acc: 0.0058 ::: bot acc: 0.0272
top acc: 0.0757 ::: bot acc: 0.0366
top acc: 0.0687 ::: bot acc: 0.0181
top acc: 0.0477 ::: bot acc: 0.0860
top acc: 0.0461 ::: bot acc: 0.0127
top acc: 0.0505 ::: bot acc: 0.0201
current epoch: 16
train loss is 0.052986
average val loss: 0.040463, accuracy: 0.0409
average test loss: 0.038642, accuracy: 0.0385
case acc: 0.01566114
case acc: 0.048379097
case acc: 0.043136578
case acc: 0.05860743
case acc: 0.029426068
case acc: 0.035556592
top acc: 0.0059 ::: bot acc: 0.0277
top acc: 0.0681 ::: bot acc: 0.0290
top acc: 0.0700 ::: bot acc: 0.0189
top acc: 0.0400 ::: bot acc: 0.0782
top acc: 0.0467 ::: bot acc: 0.0129
top acc: 0.0507 ::: bot acc: 0.0202
current epoch: 17
train loss is 0.049158
average val loss: 0.035946, accuracy: 0.0365
average test loss: 0.034414, accuracy: 0.0344
case acc: 0.021934675
case acc: 0.034112938
case acc: 0.037802108
case acc: 0.05763316
case acc: 0.025315115
case acc: 0.029409302
top acc: 0.0094 ::: bot acc: 0.0354
top acc: 0.0537 ::: bot acc: 0.0152
top acc: 0.0639 ::: bot acc: 0.0149
top acc: 0.0390 ::: bot acc: 0.0772
top acc: 0.0414 ::: bot acc: 0.0110
top acc: 0.0440 ::: bot acc: 0.0153
current epoch: 18
train loss is 0.046152
average val loss: 0.031416, accuracy: 0.0324
average test loss: 0.030394, accuracy: 0.0305
case acc: 0.031970587
case acc: 0.020200133
case acc: 0.030280646
case acc: 0.06011308
case acc: 0.019406807
case acc: 0.021202099
top acc: 0.0189 ::: bot acc: 0.0456
top acc: 0.0374 ::: bot acc: 0.0061
top acc: 0.0545 ::: bot acc: 0.0114
top acc: 0.0414 ::: bot acc: 0.0797
top acc: 0.0327 ::: bot acc: 0.0107
top acc: 0.0342 ::: bot acc: 0.0105
current epoch: 19
train loss is 0.043654
average val loss: 0.028787, accuracy: 0.0301
average test loss: 0.028555, accuracy: 0.0288
case acc: 0.04027748
case acc: 0.014990251
case acc: 0.02484645
case acc: 0.062516935
case acc: 0.015067611
case acc: 0.014958186
top acc: 0.0273 ::: bot acc: 0.0539
top acc: 0.0249 ::: bot acc: 0.0144
top acc: 0.0458 ::: bot acc: 0.0123
top acc: 0.0437 ::: bot acc: 0.0822
top acc: 0.0231 ::: bot acc: 0.0169
top acc: 0.0251 ::: bot acc: 0.0100
current epoch: 20
train loss is 0.042868
average val loss: 0.027967, accuracy: 0.0294
average test loss: 0.028330, accuracy: 0.0284
case acc: 0.043941256
case acc: 0.0145001095
case acc: 0.022354478
case acc: 0.062352993
case acc: 0.014700653
case acc: 0.012664992
top acc: 0.0309 ::: bot acc: 0.0576
top acc: 0.0191 ::: bot acc: 0.0201
top acc: 0.0407 ::: bot acc: 0.0150
top acc: 0.0435 ::: bot acc: 0.0820
top acc: 0.0145 ::: bot acc: 0.0254
top acc: 0.0193 ::: bot acc: 0.0141
current epoch: 21
train loss is 0.042059
average val loss: 0.026921, accuracy: 0.0282
average test loss: 0.027255, accuracy: 0.0272
case acc: 0.040485352
case acc: 0.014618035
case acc: 0.023005994
case acc: 0.056615166
case acc: 0.015574575
case acc: 0.012804852
top acc: 0.0274 ::: bot acc: 0.0542
top acc: 0.0227 ::: bot acc: 0.0166
top acc: 0.0421 ::: bot acc: 0.0141
top acc: 0.0379 ::: bot acc: 0.0763
top acc: 0.0110 ::: bot acc: 0.0289
top acc: 0.0198 ::: bot acc: 0.0137
current epoch: 22
train loss is 0.041310
average val loss: 0.025791, accuracy: 0.0268
average test loss: 0.025624, accuracy: 0.0253
case acc: 0.03250609
case acc: 0.016725723
case acc: 0.026153708
case acc: 0.046587974
case acc: 0.015139544
case acc: 0.01487765
top acc: 0.0194 ::: bot acc: 0.0462
top acc: 0.0310 ::: bot acc: 0.0085
top acc: 0.0482 ::: bot acc: 0.0114
top acc: 0.0284 ::: bot acc: 0.0659
top acc: 0.0126 ::: bot acc: 0.0273
top acc: 0.0248 ::: bot acc: 0.0103
current epoch: 23
train loss is 0.040120
average val loss: 0.025608, accuracy: 0.0261
average test loss: 0.024798, accuracy: 0.0243
case acc: 0.023792047
case acc: 0.022506475
case acc: 0.031044165
case acc: 0.03553412
case acc: 0.014420973
case acc: 0.018660586
top acc: 0.0110 ::: bot acc: 0.0374
top acc: 0.0408 ::: bot acc: 0.0062
top acc: 0.0556 ::: bot acc: 0.0113
top acc: 0.0185 ::: bot acc: 0.0542
top acc: 0.0166 ::: bot acc: 0.0233
top acc: 0.0308 ::: bot acc: 0.0098
current epoch: 24
train loss is 0.039323
average val loss: 0.026818, accuracy: 0.0267
average test loss: 0.025269, accuracy: 0.0248
case acc: 0.015472071
case acc: 0.031282324
case acc: 0.038496517
case acc: 0.023549916
case acc: 0.015473268
case acc: 0.024580386
top acc: 0.0056 ::: bot acc: 0.0276
top acc: 0.0508 ::: bot acc: 0.0127
top acc: 0.0648 ::: bot acc: 0.0153
top acc: 0.0104 ::: bot acc: 0.0403
top acc: 0.0242 ::: bot acc: 0.0158
top acc: 0.0384 ::: bot acc: 0.0123
current epoch: 25
train loss is 0.038824
average val loss: 0.029828, accuracy: 0.0292
average test loss: 0.027339, accuracy: 0.0267
case acc: 0.010767942
case acc: 0.038036227
case acc: 0.045996446
case acc: 0.014813818
case acc: 0.020136056
case acc: 0.030572819
top acc: 0.0076 ::: bot acc: 0.0195
top acc: 0.0578 ::: bot acc: 0.0189
top acc: 0.0732 ::: bot acc: 0.0209
top acc: 0.0123 ::: bot acc: 0.0262
top acc: 0.0341 ::: bot acc: 0.0102
top acc: 0.0454 ::: bot acc: 0.0163
current epoch: 26
train loss is 0.037281
average val loss: 0.028760, accuracy: 0.0281
average test loss: 0.026217, accuracy: 0.0256
case acc: 0.012007067
case acc: 0.03327124
case acc: 0.044787508
case acc: 0.013859928
case acc: 0.021606637
case acc: 0.028246433
top acc: 0.0063 ::: bot acc: 0.0221
top acc: 0.0529 ::: bot acc: 0.0144
top acc: 0.0719 ::: bot acc: 0.0199
top acc: 0.0172 ::: bot acc: 0.0211
top acc: 0.0363 ::: bot acc: 0.0101
top acc: 0.0428 ::: bot acc: 0.0145
current epoch: 27
train loss is 0.035097
average val loss: 0.026417, accuracy: 0.0260
average test loss: 0.024061, accuracy: 0.0236
case acc: 0.015693476
case acc: 0.025108116
case acc: 0.04078808
case acc: 0.013956725
case acc: 0.022083627
case acc: 0.023781028
top acc: 0.0056 ::: bot acc: 0.0280
top acc: 0.0439 ::: bot acc: 0.0078
top acc: 0.0674 ::: bot acc: 0.0169
top acc: 0.0195 ::: bot acc: 0.0188
top acc: 0.0371 ::: bot acc: 0.0101
top acc: 0.0375 ::: bot acc: 0.0119
current epoch: 28
train loss is 0.033209
average val loss: 0.024367, accuracy: 0.0243
average test loss: 0.022324, accuracy: 0.0220
case acc: 0.021187047
case acc: 0.017557103
case acc: 0.035830896
case acc: 0.014249615
case acc: 0.023701856
case acc: 0.01951054
top acc: 0.0086 ::: bot acc: 0.0347
top acc: 0.0328 ::: bot acc: 0.0075
top acc: 0.0617 ::: bot acc: 0.0135
top acc: 0.0214 ::: bot acc: 0.0169
top acc: 0.0394 ::: bot acc: 0.0103
top acc: 0.0320 ::: bot acc: 0.0100
current epoch: 29
train loss is 0.032921
average val loss: 0.024916, accuracy: 0.0251
average test loss: 0.023076, accuracy: 0.0229
case acc: 0.02533166
case acc: 0.014504214
case acc: 0.03281702
case acc: 0.015751915
case acc: 0.030734643
case acc: 0.01846276
top acc: 0.0124 ::: bot acc: 0.0390
top acc: 0.0213 ::: bot acc: 0.0178
top acc: 0.0580 ::: bot acc: 0.0119
top acc: 0.0266 ::: bot acc: 0.0121
top acc: 0.0484 ::: bot acc: 0.0134
top acc: 0.0306 ::: bot acc: 0.0097
current epoch: 30
train loss is 0.035382
average val loss: 0.027783, accuracy: 0.0282
average test loss: 0.026460, accuracy: 0.0263
case acc: 0.032490972
case acc: 0.020980459
case acc: 0.027967233
case acc: 0.017421803
case acc: 0.04140629
case acc: 0.01740162
top acc: 0.0194 ::: bot acc: 0.0463
top acc: 0.0083 ::: bot acc: 0.0368
top acc: 0.0513 ::: bot acc: 0.0107
top acc: 0.0304 ::: bot acc: 0.0097
top acc: 0.0604 ::: bot acc: 0.0215
top acc: 0.0292 ::: bot acc: 0.0095
current epoch: 31
train loss is 0.046619
average val loss: 0.044767, accuracy: 0.0455
average test loss: 0.047347, accuracy: 0.0484
case acc: 0.08611042
case acc: 0.087271295
case acc: 0.03410219
case acc: 0.03334798
case acc: 0.016556371
case acc: 0.032824703
top acc: 0.0729 ::: bot acc: 0.1000
top acc: 0.0675 ::: bot acc: 0.1066
top acc: 0.0142 ::: bot acc: 0.0570
top acc: 0.0168 ::: bot acc: 0.0516
top acc: 0.0272 ::: bot acc: 0.0132
top acc: 0.0169 ::: bot acc: 0.0499
current epoch: 32
train loss is 0.080669
average val loss: 0.110481, accuracy: 0.1105
average test loss: 0.114546, accuracy: 0.1145
case acc: 0.15446214
case acc: 0.16588007
case acc: 0.10091959
case acc: 0.10470251
case acc: 0.06336389
case acc: 0.097937934
top acc: 0.1411 ::: bot acc: 0.1683
top acc: 0.1461 ::: bot acc: 0.1853
top acc: 0.0728 ::: bot acc: 0.1279
top acc: 0.0861 ::: bot acc: 0.1240
top acc: 0.0441 ::: bot acc: 0.0839
top acc: 0.0817 ::: bot acc: 0.1152
current epoch: 33
train loss is 0.079939
average val loss: 0.053094, accuracy: 0.0535
average test loss: 0.056748, accuracy: 0.0568
case acc: 0.086090505
case acc: 0.084205754
case acc: 0.042337224
case acc: 0.058475338
case acc: 0.030389372
case acc: 0.039525174
top acc: 0.0728 ::: bot acc: 0.0999
top acc: 0.0645 ::: bot acc: 0.1036
top acc: 0.0186 ::: bot acc: 0.0672
top acc: 0.0399 ::: bot acc: 0.0777
top acc: 0.0118 ::: bot acc: 0.0505
top acc: 0.0235 ::: bot acc: 0.0566
current epoch: 34
train loss is 0.048896
average val loss: 0.042339, accuracy: 0.0433
average test loss: 0.045778, accuracy: 0.0460
case acc: 0.06446925
case acc: 0.044447314
case acc: 0.0313652
case acc: 0.05994005
case acc: 0.04547073
case acc: 0.03058523
top acc: 0.0513 ::: bot acc: 0.0782
top acc: 0.0249 ::: bot acc: 0.0637
top acc: 0.0130 ::: bot acc: 0.0535
top acc: 0.0413 ::: bot acc: 0.0792
top acc: 0.0263 ::: bot acc: 0.0659
top acc: 0.0149 ::: bot acc: 0.0475
current epoch: 35
train loss is 0.037221
average val loss: 0.022651, accuracy: 0.0239
average test loss: 0.023706, accuracy: 0.0236
case acc: 0.030127898
case acc: 0.014486939
case acc: 0.02001518
case acc: 0.037558794
case acc: 0.02752989
case acc: 0.0120846275
top acc: 0.0170 ::: bot acc: 0.0438
top acc: 0.0178 ::: bot acc: 0.0214
top acc: 0.0309 ::: bot acc: 0.0245
top acc: 0.0204 ::: bot acc: 0.0560
top acc: 0.0095 ::: bot acc: 0.0474
top acc: 0.0147 ::: bot acc: 0.0188
current epoch: 36
train loss is 0.033752
average val loss: 0.022135, accuracy: 0.0217
average test loss: 0.020536, accuracy: 0.0198
case acc: 0.011390936
case acc: 0.023681656
case acc: 0.028315801
case acc: 0.01834584
case acc: 0.014290026
case acc: 0.022778744
top acc: 0.0065 ::: bot acc: 0.0210
top acc: 0.0422 ::: bot acc: 0.0068
top acc: 0.0518 ::: bot acc: 0.0108
top acc: 0.0095 ::: bot acc: 0.0327
top acc: 0.0166 ::: bot acc: 0.0230
top acc: 0.0364 ::: bot acc: 0.0110
current epoch: 37
train loss is 0.032641
average val loss: 0.022633, accuracy: 0.0220
average test loss: 0.020646, accuracy: 0.0199
case acc: 0.010635938
case acc: 0.02670137
case acc: 0.029485004
case acc: 0.015091427
case acc: 0.014320652
case acc: 0.023129016
top acc: 0.0076 ::: bot acc: 0.0192
top acc: 0.0457 ::: bot acc: 0.0089
top acc: 0.0535 ::: bot acc: 0.0109
top acc: 0.0112 ::: bot acc: 0.0270
top acc: 0.0208 ::: bot acc: 0.0189
top acc: 0.0368 ::: bot acc: 0.0112
current epoch: 38
train loss is 0.032232
average val loss: 0.023206, accuracy: 0.0225
average test loss: 0.021027, accuracy: 0.0202
case acc: 0.010312361
case acc: 0.029979896
case acc: 0.030625857
case acc: 0.013743724
case acc: 0.014357565
case acc: 0.022259593
top acc: 0.0087 ::: bot acc: 0.0182
top acc: 0.0493 ::: bot acc: 0.0115
top acc: 0.0550 ::: bot acc: 0.0112
top acc: 0.0157 ::: bot acc: 0.0222
top acc: 0.0210 ::: bot acc: 0.0187
top acc: 0.0357 ::: bot acc: 0.0108
current epoch: 39
train loss is 0.032192
average val loss: 0.027293, accuracy: 0.0267
average test loss: 0.024447, accuracy: 0.0237
case acc: 0.010019395
case acc: 0.0380668
case acc: 0.036405757
case acc: 0.015507486
case acc: 0.01646569
case acc: 0.025922505
top acc: 0.0152 ::: bot acc: 0.0117
top acc: 0.0578 ::: bot acc: 0.0188
top acc: 0.0624 ::: bot acc: 0.0139
top acc: 0.0262 ::: bot acc: 0.0120
top acc: 0.0270 ::: bot acc: 0.0133
top acc: 0.0402 ::: bot acc: 0.0128
current epoch: 40
train loss is 0.032532
average val loss: 0.032645, accuracy: 0.0323
average test loss: 0.029171, accuracy: 0.0285
case acc: 0.011829818
case acc: 0.043670826
case acc: 0.042699695
case acc: 0.021919066
case acc: 0.021217009
case acc: 0.029939651
top acc: 0.0206 ::: bot acc: 0.0068
top acc: 0.0635 ::: bot acc: 0.0243
top acc: 0.0696 ::: bot acc: 0.0184
top acc: 0.0378 ::: bot acc: 0.0081
top acc: 0.0358 ::: bot acc: 0.0101
top acc: 0.0448 ::: bot acc: 0.0156
current epoch: 41
train loss is 0.031849
average val loss: 0.033398, accuracy: 0.0330
average test loss: 0.029874, accuracy: 0.0292
case acc: 0.011067455
case acc: 0.04029251
case acc: 0.043267436
case acc: 0.02710671
case acc: 0.025165576
case acc: 0.028598456
top acc: 0.0187 ::: bot acc: 0.0083
top acc: 0.0600 ::: bot acc: 0.0210
top acc: 0.0702 ::: bot acc: 0.0188
top acc: 0.0440 ::: bot acc: 0.0112
top acc: 0.0414 ::: bot acc: 0.0107
top acc: 0.0433 ::: bot acc: 0.0146
current epoch: 42
train loss is 0.029650
average val loss: 0.030290, accuracy: 0.0299
average test loss: 0.027036, accuracy: 0.0264
case acc: 0.009997826
case acc: 0.029534247
case acc: 0.038809024
case acc: 0.028602514
case acc: 0.027816843
case acc: 0.023373678
top acc: 0.0109 ::: bot acc: 0.0160
top acc: 0.0488 ::: bot acc: 0.0112
top acc: 0.0652 ::: bot acc: 0.0155
top acc: 0.0457 ::: bot acc: 0.0123
top acc: 0.0449 ::: bot acc: 0.0117
top acc: 0.0371 ::: bot acc: 0.0114
current epoch: 43
train loss is 0.028236
average val loss: 0.028067, accuracy: 0.0280
average test loss: 0.025331, accuracy: 0.0248
case acc: 0.01354672
case acc: 0.018292338
case acc: 0.033624537
case acc: 0.030167
case acc: 0.033894297
case acc: 0.019095983
top acc: 0.0054 ::: bot acc: 0.0248
top acc: 0.0341 ::: bot acc: 0.0069
top acc: 0.0589 ::: bot acc: 0.0124
top acc: 0.0474 ::: bot acc: 0.0135
top acc: 0.0519 ::: bot acc: 0.0158
top acc: 0.0316 ::: bot acc: 0.0095
current epoch: 44
train loss is 0.031752
average val loss: 0.027262, accuracy: 0.0278
average test loss: 0.025646, accuracy: 0.0255
case acc: 0.024618948
case acc: 0.01684004
case acc: 0.025750412
case acc: 0.028877862
case acc: 0.042032026
case acc: 0.014635783
top acc: 0.0117 ::: bot acc: 0.0382
top acc: 0.0108 ::: bot acc: 0.0294
top acc: 0.0476 ::: bot acc: 0.0114
top acc: 0.0460 ::: bot acc: 0.0125
top acc: 0.0610 ::: bot acc: 0.0222
top acc: 0.0246 ::: bot acc: 0.0102
current epoch: 45
train loss is 0.048495
average val loss: 0.063418, accuracy: 0.0633
average test loss: 0.067014, accuracy: 0.0671
case acc: 0.10590946
case acc: 0.108674265
case acc: 0.060545035
case acc: 0.04428796
case acc: 0.019563045
case acc: 0.063677296
top acc: 0.0927 ::: bot acc: 0.1196
top acc: 0.0889 ::: bot acc: 0.1281
top acc: 0.0331 ::: bot acc: 0.0872
top acc: 0.0266 ::: bot acc: 0.0631
top acc: 0.0070 ::: bot acc: 0.0367
top acc: 0.0474 ::: bot acc: 0.0809
current epoch: 46
train loss is 0.087239
average val loss: 0.060438, accuracy: 0.0603
average test loss: 0.064037, accuracy: 0.0641
case acc: 0.09941453
case acc: 0.10151204
case acc: 0.058731936
case acc: 0.047107555
case acc: 0.020071909
case acc: 0.057895113
top acc: 0.0862 ::: bot acc: 0.1132
top acc: 0.0818 ::: bot acc: 0.1209
top acc: 0.0315 ::: bot acc: 0.0853
top acc: 0.0292 ::: bot acc: 0.0659
top acc: 0.0069 ::: bot acc: 0.0375
top acc: 0.0416 ::: bot acc: 0.0750
current epoch: 47
train loss is 0.059290
average val loss: 0.041235, accuracy: 0.0416
average test loss: 0.044718, accuracy: 0.0449
case acc: 0.069317885
case acc: 0.054965913
case acc: 0.03865695
case acc: 0.04124705
case acc: 0.025889752
case acc: 0.03928583
top acc: 0.0561 ::: bot acc: 0.0830
top acc: 0.0352 ::: bot acc: 0.0743
top acc: 0.0164 ::: bot acc: 0.0628
top acc: 0.0238 ::: bot acc: 0.0598
top acc: 0.0083 ::: bot acc: 0.0455
top acc: 0.0233 ::: bot acc: 0.0563
current epoch: 48
train loss is 0.039795
average val loss: 0.026778, accuracy: 0.0279
average test loss: 0.029484, accuracy: 0.0298
case acc: 0.044265766
case acc: 0.021351626
case acc: 0.025276938
case acc: 0.035675995
case acc: 0.028800055
case acc: 0.023260491
top acc: 0.0311 ::: bot acc: 0.0580
top acc: 0.0081 ::: bot acc: 0.0374
top acc: 0.0132 ::: bot acc: 0.0443
top acc: 0.0190 ::: bot acc: 0.0539
top acc: 0.0106 ::: bot acc: 0.0487
top acc: 0.0089 ::: bot acc: 0.0395
current epoch: 49
train loss is 0.032396
average val loss: 0.016973, accuracy: 0.0171
average test loss: 0.016384, accuracy: 0.0163
case acc: 0.018457532
case acc: 0.014893813
case acc: 0.020751972
case acc: 0.01630901
case acc: 0.0141312
case acc: 0.013456007
top acc: 0.0067 ::: bot acc: 0.0315
top acc: 0.0242 ::: bot acc: 0.0149
top acc: 0.0356 ::: bot acc: 0.0198
top acc: 0.0098 ::: bot acc: 0.0295
top acc: 0.0188 ::: bot acc: 0.0208
top acc: 0.0220 ::: bot acc: 0.0118
current epoch: 50
train loss is 0.027814
average val loss: 0.017179, accuracy: 0.0177
average test loss: 0.017044, accuracy: 0.0174
case acc: 0.02361006
case acc: 0.016008168
case acc: 0.019958604
case acc: 0.015938794
case acc: 0.0159517
case acc: 0.012796594
top acc: 0.0107 ::: bot acc: 0.0372
top acc: 0.0120 ::: bot acc: 0.0275
top acc: 0.0304 ::: bot acc: 0.0250
top acc: 0.0100 ::: bot acc: 0.0288
top acc: 0.0258 ::: bot acc: 0.0142
top acc: 0.0202 ::: bot acc: 0.0133
LME_Co_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6804 6804 6804
1.8562728 -0.6288155 0.12137239 -0.16228472
Validation: 762 762 762
Testing: 744 744 744
pre-processing time: 0.00022125244140625
the split date is 2010-01-01
net initializing with time: 0.002544403076171875
preparing training and testing date with time: 2.384185791015625e-07
current epoch: 1
train loss is 0.166971
average val loss: 0.038839, accuracy: 0.0386
average test loss: 0.040810, accuracy: 0.0409
case acc: 0.030177195
case acc: 0.01634293
case acc: 0.03792255
case acc: 0.025446553
case acc: 0.028854415
case acc: 0.10642692
top acc: 0.0141 ::: bot acc: 0.0479
top acc: 0.0280 ::: bot acc: 0.0137
top acc: 0.0688 ::: bot acc: 0.0122
top acc: 0.0169 ::: bot acc: 0.0427
top acc: 0.0493 ::: bot acc: 0.0111
top acc: 0.1387 ::: bot acc: 0.0762
current epoch: 2
train loss is 0.061546
average val loss: 0.095496, accuracy: 0.0951
average test loss: 0.097017, accuracy: 0.0977
case acc: 0.14208694
case acc: 0.107882306
case acc: 0.086174436
case acc: 0.1277433
case acc: 0.09269694
case acc: 0.029339481
top acc: 0.1184 ::: bot acc: 0.1638
top acc: 0.0877 ::: bot acc: 0.1269
top acc: 0.0498 ::: bot acc: 0.1233
top acc: 0.0991 ::: bot acc: 0.1550
top acc: 0.0694 ::: bot acc: 0.1166
top acc: 0.0174 ::: bot acc: 0.0488
current epoch: 3
train loss is 0.077552
average val loss: 0.134437, accuracy: 0.1344
average test loss: 0.135427, accuracy: 0.1355
case acc: 0.17649932
case acc: 0.14380704
case acc: 0.12698923
case acc: 0.16591151
case acc: 0.130807
case acc: 0.06925476
top acc: 0.1524 ::: bot acc: 0.1985
top acc: 0.1236 ::: bot acc: 0.1632
top acc: 0.0912 ::: bot acc: 0.1637
top acc: 0.1383 ::: bot acc: 0.1926
top acc: 0.1082 ::: bot acc: 0.1538
top acc: 0.0403 ::: bot acc: 0.0969
current epoch: 4
train loss is 0.091977
average val loss: 0.116841, accuracy: 0.1168
average test loss: 0.117738, accuracy: 0.1179
case acc: 0.15370001
case acc: 0.12277572
case acc: 0.11015317
case acc: 0.14986883
case acc: 0.111526765
case acc: 0.059400238
top acc: 0.1294 ::: bot acc: 0.1759
top acc: 0.1026 ::: bot acc: 0.1423
top acc: 0.0745 ::: bot acc: 0.1467
top acc: 0.1228 ::: bot acc: 0.1763
top acc: 0.0892 ::: bot acc: 0.1342
top acc: 0.0317 ::: bot acc: 0.0863
current epoch: 5
train loss is 0.098184
average val loss: 0.059022, accuracy: 0.0586
average test loss: 0.060682, accuracy: 0.0613
case acc: 0.089276485
case acc: 0.060280398
case acc: 0.052755628
case acc: 0.09203967
case acc: 0.050790027
case acc: 0.02242685
top acc: 0.0649 ::: bot acc: 0.1115
top acc: 0.0399 ::: bot acc: 0.0798
top acc: 0.0197 ::: bot acc: 0.0880
top acc: 0.0648 ::: bot acc: 0.1185
top acc: 0.0285 ::: bot acc: 0.0737
top acc: 0.0238 ::: bot acc: 0.0348
current epoch: 6
train loss is 0.067649
average val loss: 0.075386, accuracy: 0.0753
average test loss: 0.076510, accuracy: 0.0768
case acc: 0.10158617
case acc: 0.07433598
case acc: 0.07010326
case acc: 0.11011667
case acc: 0.06671491
case acc: 0.038045604
top acc: 0.0772 ::: bot acc: 0.1238
top acc: 0.0540 ::: bot acc: 0.0939
top acc: 0.0346 ::: bot acc: 0.1067
top acc: 0.0831 ::: bot acc: 0.1364
top acc: 0.0443 ::: bot acc: 0.0895
top acc: 0.0168 ::: bot acc: 0.0617
current epoch: 7
train loss is 0.067607
average val loss: 0.072252, accuracy: 0.0722
average test loss: 0.073298, accuracy: 0.0735
case acc: 0.09342458
case acc: 0.06789481
case acc: 0.068153195
case acc: 0.10725337
case acc: 0.06188153
case acc: 0.04250477
top acc: 0.0691 ::: bot acc: 0.1157
top acc: 0.0475 ::: bot acc: 0.0875
top acc: 0.0329 ::: bot acc: 0.1046
top acc: 0.0805 ::: bot acc: 0.1333
top acc: 0.0396 ::: bot acc: 0.0845
top acc: 0.0191 ::: bot acc: 0.0672
current epoch: 8
train loss is 0.062985
average val loss: 0.068281, accuracy: 0.0682
average test loss: 0.069280, accuracy: 0.0694
case acc: 0.084657185
case acc: 0.06078493
case acc: 0.06535284
case acc: 0.10386333
case acc: 0.056141343
case acc: 0.045684196
top acc: 0.0602 ::: bot acc: 0.1070
top acc: 0.0404 ::: bot acc: 0.0805
top acc: 0.0305 ::: bot acc: 0.1017
top acc: 0.0772 ::: bot acc: 0.1299
top acc: 0.0339 ::: bot acc: 0.0787
top acc: 0.0209 ::: bot acc: 0.0710
current epoch: 9
train loss is 0.055743
average val loss: 0.065543, accuracy: 0.0655
average test loss: 0.066498, accuracy: 0.0666
case acc: 0.077603996
case acc: 0.055166546
case acc: 0.06368774
case acc: 0.10202015
case acc: 0.05167769
case acc: 0.049188975
top acc: 0.0532 ::: bot acc: 0.1000
top acc: 0.0348 ::: bot acc: 0.0749
top acc: 0.0291 ::: bot acc: 0.0999
top acc: 0.0754 ::: bot acc: 0.1280
top acc: 0.0295 ::: bot acc: 0.0742
top acc: 0.0231 ::: bot acc: 0.0750
current epoch: 10
train loss is 0.048722
average val loss: 0.062763, accuracy: 0.0627
average test loss: 0.063723, accuracy: 0.0637
case acc: 0.07120245
case acc: 0.050122418
case acc: 0.06196039
case acc: 0.09979078
case acc: 0.0476079
case acc: 0.051615667
top acc: 0.0470 ::: bot acc: 0.0936
top acc: 0.0297 ::: bot acc: 0.0699
top acc: 0.0276 ::: bot acc: 0.0981
top acc: 0.0733 ::: bot acc: 0.1257
top acc: 0.0256 ::: bot acc: 0.0700
top acc: 0.0250 ::: bot acc: 0.0777
current epoch: 11
train loss is 0.043201
average val loss: 0.053135, accuracy: 0.0531
average test loss: 0.054381, accuracy: 0.0543
case acc: 0.058688752
case acc: 0.03921923
case acc: 0.053767342
case acc: 0.08995988
case acc: 0.03739934
case acc: 0.046545416
top acc: 0.0349 ::: bot acc: 0.0810
top acc: 0.0195 ::: bot acc: 0.0587
top acc: 0.0209 ::: bot acc: 0.0892
top acc: 0.0637 ::: bot acc: 0.1158
top acc: 0.0162 ::: bot acc: 0.0593
top acc: 0.0213 ::: bot acc: 0.0719
current epoch: 12
train loss is 0.037449
average val loss: 0.046594, accuracy: 0.0466
average test loss: 0.048118, accuracy: 0.0480
case acc: 0.050816253
case acc: 0.033195242
case acc: 0.048567176
case acc: 0.08101961
case acc: 0.031847563
case acc: 0.04233957
top acc: 0.0275 ::: bot acc: 0.0729
top acc: 0.0146 ::: bot acc: 0.0522
top acc: 0.0173 ::: bot acc: 0.0832
top acc: 0.0549 ::: bot acc: 0.1068
top acc: 0.0121 ::: bot acc: 0.0529
top acc: 0.0187 ::: bot acc: 0.0668
current epoch: 13
train loss is 0.035318
average val loss: 0.041998, accuracy: 0.0420
average test loss: 0.043786, accuracy: 0.0436
case acc: 0.04573345
case acc: 0.029805241
case acc: 0.04532662
case acc: 0.072570354
case acc: 0.028785532
case acc: 0.039556157
top acc: 0.0235 ::: bot acc: 0.0673
top acc: 0.0123 ::: bot acc: 0.0483
top acc: 0.0152 ::: bot acc: 0.0793
top acc: 0.0464 ::: bot acc: 0.0984
top acc: 0.0104 ::: bot acc: 0.0493
top acc: 0.0171 ::: bot acc: 0.0634
current epoch: 14
train loss is 0.033590
average val loss: 0.037451, accuracy: 0.0375
average test loss: 0.039557, accuracy: 0.0395
case acc: 0.041411385
case acc: 0.027186261
case acc: 0.0420815
case acc: 0.06335242
case acc: 0.026442792
case acc: 0.0363036
top acc: 0.0204 ::: bot acc: 0.0622
top acc: 0.0109 ::: bot acc: 0.0450
top acc: 0.0134 ::: bot acc: 0.0754
top acc: 0.0372 ::: bot acc: 0.0892
top acc: 0.0096 ::: bot acc: 0.0463
top acc: 0.0156 ::: bot acc: 0.0593
current epoch: 15
train loss is 0.031808
average val loss: 0.033183, accuracy: 0.0333
average test loss: 0.035645, accuracy: 0.0356
case acc: 0.037509345
case acc: 0.024776356
case acc: 0.03904539
case acc: 0.05461172
case acc: 0.024374496
case acc: 0.03339372
top acc: 0.0178 ::: bot acc: 0.0576
top acc: 0.0098 ::: bot acc: 0.0419
top acc: 0.0122 ::: bot acc: 0.0715
top acc: 0.0289 ::: bot acc: 0.0803
top acc: 0.0093 ::: bot acc: 0.0434
top acc: 0.0150 ::: bot acc: 0.0552
current epoch: 16
train loss is 0.030544
average val loss: 0.029625, accuracy: 0.0297
average test loss: 0.032454, accuracy: 0.0325
case acc: 0.03464516
case acc: 0.023135874
case acc: 0.036517154
case acc: 0.046963744
case acc: 0.023029935
case acc: 0.030576473
top acc: 0.0161 ::: bot acc: 0.0542
top acc: 0.0092 ::: bot acc: 0.0398
top acc: 0.0117 ::: bot acc: 0.0679
top acc: 0.0225 ::: bot acc: 0.0720
top acc: 0.0095 ::: bot acc: 0.0413
top acc: 0.0150 ::: bot acc: 0.0509
current epoch: 17
train loss is 0.029286
average val loss: 0.026359, accuracy: 0.0265
average test loss: 0.029573, accuracy: 0.0297
case acc: 0.03206356
case acc: 0.021579705
case acc: 0.034333587
case acc: 0.04035612
case acc: 0.021748077
case acc: 0.027935503
top acc: 0.0148 ::: bot acc: 0.0510
top acc: 0.0087 ::: bot acc: 0.0377
top acc: 0.0122 ::: bot acc: 0.0644
top acc: 0.0181 ::: bot acc: 0.0644
top acc: 0.0098 ::: bot acc: 0.0393
top acc: 0.0157 ::: bot acc: 0.0467
current epoch: 18
train loss is 0.028370
average val loss: 0.025917, accuracy: 0.0260
average test loss: 0.029171, accuracy: 0.0293
case acc: 0.03207074
case acc: 0.02228199
case acc: 0.034238245
case acc: 0.037086193
case acc: 0.022365933
case acc: 0.027579198
top acc: 0.0148 ::: bot acc: 0.0510
top acc: 0.0089 ::: bot acc: 0.0386
top acc: 0.0123 ::: bot acc: 0.0643
top acc: 0.0161 ::: bot acc: 0.0605
top acc: 0.0097 ::: bot acc: 0.0403
top acc: 0.0158 ::: bot acc: 0.0461
current epoch: 19
train loss is 0.027870
average val loss: 0.021335, accuracy: 0.0215
average test loss: 0.025265, accuracy: 0.0253
case acc: 0.027429793
case acc: 0.018981194
case acc: 0.03132394
case acc: 0.029904576
case acc: 0.019438628
case acc: 0.024849407
top acc: 0.0129 ::: bot acc: 0.0450
top acc: 0.0094 ::: bot acc: 0.0335
top acc: 0.0147 ::: bot acc: 0.0588
top acc: 0.0124 ::: bot acc: 0.0516
top acc: 0.0110 ::: bot acc: 0.0352
top acc: 0.0185 ::: bot acc: 0.0407
current epoch: 20
train loss is 0.027001
average val loss: 0.021691, accuracy: 0.0218
average test loss: 0.025550, accuracy: 0.0255
case acc: 0.027837368
case acc: 0.019575182
case acc: 0.031728644
case acc: 0.02861922
case acc: 0.020117423
case acc: 0.025336284
top acc: 0.0130 ::: bot acc: 0.0456
top acc: 0.0088 ::: bot acc: 0.0346
top acc: 0.0142 ::: bot acc: 0.0596
top acc: 0.0120 ::: bot acc: 0.0500
top acc: 0.0105 ::: bot acc: 0.0365
top acc: 0.0179 ::: bot acc: 0.0417
current epoch: 21
train loss is 0.026717
average val loss: 0.020134, accuracy: 0.0202
average test loss: 0.024221, accuracy: 0.0242
case acc: 0.0261057
case acc: 0.01855526
case acc: 0.030815743
case acc: 0.025695106
case acc: 0.019165706
case acc: 0.02461473
top acc: 0.0127 ::: bot acc: 0.0431
top acc: 0.0096 ::: bot acc: 0.0327
top acc: 0.0153 ::: bot acc: 0.0577
top acc: 0.0115 ::: bot acc: 0.0458
top acc: 0.0112 ::: bot acc: 0.0347
top acc: 0.0188 ::: bot acc: 0.0402
current epoch: 22
train loss is 0.026380
average val loss: 0.017362, accuracy: 0.0174
average test loss: 0.021922, accuracy: 0.0219
case acc: 0.022828523
case acc: 0.016288664
case acc: 0.029100182
case acc: 0.022471515
case acc: 0.0173993
case acc: 0.023148086
top acc: 0.0133 ::: bot acc: 0.0379
top acc: 0.0124 ::: bot acc: 0.0279
top acc: 0.0187 ::: bot acc: 0.0535
top acc: 0.0135 ::: bot acc: 0.0401
top acc: 0.0149 ::: bot acc: 0.0301
top acc: 0.0214 ::: bot acc: 0.0367
current epoch: 23
train loss is 0.025898
average val loss: 0.016581, accuracy: 0.0167
average test loss: 0.021287, accuracy: 0.0212
case acc: 0.021704772
case acc: 0.015592639
case acc: 0.028601103
case acc: 0.02172842
case acc: 0.017030673
case acc: 0.022833792
top acc: 0.0140 ::: bot acc: 0.0359
top acc: 0.0140 ::: bot acc: 0.0261
top acc: 0.0201 ::: bot acc: 0.0520
top acc: 0.0146 ::: bot acc: 0.0384
top acc: 0.0167 ::: bot acc: 0.0284
top acc: 0.0221 ::: bot acc: 0.0359
current epoch: 24
train loss is 0.025578
average val loss: 0.018138, accuracy: 0.0182
average test loss: 0.022533, accuracy: 0.0225
case acc: 0.023537569
case acc: 0.016909584
case acc: 0.0295629
case acc: 0.023174958
case acc: 0.017851636
case acc: 0.023708485
top acc: 0.0129 ::: bot acc: 0.0392
top acc: 0.0112 ::: bot acc: 0.0294
top acc: 0.0177 ::: bot acc: 0.0547
top acc: 0.0126 ::: bot acc: 0.0416
top acc: 0.0134 ::: bot acc: 0.0317
top acc: 0.0203 ::: bot acc: 0.0381
current epoch: 25
train loss is 0.025429
average val loss: 0.018271, accuracy: 0.0183
average test loss: 0.022641, accuracy: 0.0226
case acc: 0.023853505
case acc: 0.017271843
case acc: 0.029553402
case acc: 0.023126397
case acc: 0.018135035
case acc: 0.023538345
top acc: 0.0127 ::: bot acc: 0.0397
top acc: 0.0107 ::: bot acc: 0.0302
top acc: 0.0177 ::: bot acc: 0.0547
top acc: 0.0127 ::: bot acc: 0.0415
top acc: 0.0127 ::: bot acc: 0.0325
top acc: 0.0208 ::: bot acc: 0.0376
current epoch: 26
train loss is 0.025259
average val loss: 0.017600, accuracy: 0.0176
average test loss: 0.022093, accuracy: 0.0220
case acc: 0.023045678
case acc: 0.016767155
case acc: 0.029090526
case acc: 0.022288952
case acc: 0.0177898
case acc: 0.023189666
top acc: 0.0130 ::: bot acc: 0.0383
top acc: 0.0114 ::: bot acc: 0.0291
top acc: 0.0187 ::: bot acc: 0.0535
top acc: 0.0137 ::: bot acc: 0.0397
top acc: 0.0137 ::: bot acc: 0.0315
top acc: 0.0215 ::: bot acc: 0.0367
current epoch: 27
train loss is 0.025099
average val loss: 0.016935, accuracy: 0.0170
average test loss: 0.021554, accuracy: 0.0215
case acc: 0.022049118
case acc: 0.016099697
case acc: 0.028683452
case acc: 0.02162769
case acc: 0.017386403
case acc: 0.023037752
top acc: 0.0136 ::: bot acc: 0.0366
top acc: 0.0125 ::: bot acc: 0.0275
top acc: 0.0197 ::: bot acc: 0.0524
top acc: 0.0148 ::: bot acc: 0.0382
top acc: 0.0151 ::: bot acc: 0.0301
top acc: 0.0219 ::: bot acc: 0.0364
current epoch: 28
train loss is 0.024892
average val loss: 0.014939, accuracy: 0.0151
average test loss: 0.019955, accuracy: 0.0199
case acc: 0.019230122
case acc: 0.014599439
case acc: 0.027388737
case acc: 0.01998826
case acc: 0.016584938
case acc: 0.021717947
top acc: 0.0166 ::: bot acc: 0.0309
top acc: 0.0179 ::: bot acc: 0.0220
top acc: 0.0246 ::: bot acc: 0.0474
top acc: 0.0193 ::: bot acc: 0.0334
top acc: 0.0205 ::: bot acc: 0.0246
top acc: 0.0258 ::: bot acc: 0.0322
current epoch: 29
train loss is 0.024691
average val loss: 0.015726, accuracy: 0.0158
average test loss: 0.020592, accuracy: 0.0206
case acc: 0.020400504
case acc: 0.015055451
case acc: 0.027823651
case acc: 0.021073954
case acc: 0.016813733
case acc: 0.022167157
top acc: 0.0149 ::: bot acc: 0.0334
top acc: 0.0155 ::: bot acc: 0.0244
top acc: 0.0225 ::: bot acc: 0.0495
top acc: 0.0158 ::: bot acc: 0.0369
top acc: 0.0181 ::: bot acc: 0.0270
top acc: 0.0240 ::: bot acc: 0.0340
current epoch: 30
train loss is 0.024614
average val loss: 0.016476, accuracy: 0.0166
average test loss: 0.021180, accuracy: 0.0212
case acc: 0.021493608
case acc: 0.015704343
case acc: 0.028074164
case acc: 0.022170447
case acc: 0.01715103
case acc: 0.022325424
top acc: 0.0139 ::: bot acc: 0.0355
top acc: 0.0134 ::: bot acc: 0.0265
top acc: 0.0213 ::: bot acc: 0.0506
top acc: 0.0137 ::: bot acc: 0.0396
top acc: 0.0161 ::: bot acc: 0.0290
top acc: 0.0236 ::: bot acc: 0.0344
current epoch: 31
train loss is 0.024506
average val loss: 0.019864, accuracy: 0.0199
average test loss: 0.023944, accuracy: 0.0239
case acc: 0.025514854
case acc: 0.018793957
case acc: 0.02998852
case acc: 0.025613744
case acc: 0.019637926
case acc: 0.023999805
top acc: 0.0126 ::: bot acc: 0.0422
top acc: 0.0090 ::: bot acc: 0.0333
top acc: 0.0166 ::: bot acc: 0.0559
top acc: 0.0116 ::: bot acc: 0.0457
top acc: 0.0108 ::: bot acc: 0.0357
top acc: 0.0200 ::: bot acc: 0.0387
current epoch: 32
train loss is 0.024897
average val loss: 0.021763, accuracy: 0.0218
average test loss: 0.025542, accuracy: 0.0255
case acc: 0.02756635
case acc: 0.02095956
case acc: 0.031222409
case acc: 0.026310816
case acc: 0.021738177
case acc: 0.025287833
top acc: 0.0128 ::: bot acc: 0.0451
top acc: 0.0086 ::: bot acc: 0.0367
top acc: 0.0146 ::: bot acc: 0.0587
top acc: 0.0116 ::: bot acc: 0.0468
top acc: 0.0099 ::: bot acc: 0.0392
top acc: 0.0181 ::: bot acc: 0.0416
current epoch: 33
train loss is 0.025098
average val loss: 0.020947, accuracy: 0.0209
average test loss: 0.024852, accuracy: 0.0247
case acc: 0.026329473
case acc: 0.020278083
case acc: 0.030989908
case acc: 0.023588933
case acc: 0.021328561
case acc: 0.025667904
top acc: 0.0126 ::: bot acc: 0.0434
top acc: 0.0085 ::: bot acc: 0.0358
top acc: 0.0149 ::: bot acc: 0.0582
top acc: 0.0122 ::: bot acc: 0.0424
top acc: 0.0100 ::: bot acc: 0.0386
top acc: 0.0176 ::: bot acc: 0.0424
current epoch: 34
train loss is 0.025502
average val loss: 0.015344, accuracy: 0.0154
average test loss: 0.020225, accuracy: 0.0200
case acc: 0.018976627
case acc: 0.014768273
case acc: 0.027554132
case acc: 0.01915472
case acc: 0.01673265
case acc: 0.022755623
top acc: 0.0171 ::: bot acc: 0.0302
top acc: 0.0166 ::: bot acc: 0.0233
top acc: 0.0235 ::: bot acc: 0.0484
top acc: 0.0239 ::: bot acc: 0.0287
top acc: 0.0186 ::: bot acc: 0.0265
top acc: 0.0223 ::: bot acc: 0.0356
current epoch: 35
train loss is 0.025928
average val loss: 0.023333, accuracy: 0.0235
average test loss: 0.025986, accuracy: 0.0263
case acc: 0.02503377
case acc: 0.02669757
case acc: 0.028520275
case acc: 0.027791448
case acc: 0.026957605
case acc: 0.022528736
top acc: 0.0459 ::: bot acc: 0.0103
top acc: 0.0454 ::: bot acc: 0.0100
top acc: 0.0478 ::: bot acc: 0.0240
top acc: 0.0487 ::: bot acc: 0.0126
top acc: 0.0470 ::: bot acc: 0.0091
top acc: 0.0428 ::: bot acc: 0.0152
current epoch: 36
train loss is 0.031056
average val loss: 0.021339, accuracy: 0.0214
average test loss: 0.024356, accuracy: 0.0248
case acc: 0.023645114
case acc: 0.026180264
case acc: 0.027955677
case acc: 0.022430595
case acc: 0.026577728
case acc: 0.021770673
top acc: 0.0440 ::: bot acc: 0.0100
top acc: 0.0448 ::: bot acc: 0.0097
top acc: 0.0458 ::: bot acc: 0.0260
top acc: 0.0395 ::: bot acc: 0.0150
top acc: 0.0465 ::: bot acc: 0.0089
top acc: 0.0403 ::: bot acc: 0.0176
current epoch: 37
train loss is 0.032168
average val loss: 0.026747, accuracy: 0.0269
average test loss: 0.029764, accuracy: 0.0298
case acc: 0.031261574
case acc: 0.023943637
case acc: 0.034341026
case acc: 0.034748774
case acc: 0.024436517
case acc: 0.02995207
top acc: 0.0143 ::: bot acc: 0.0499
top acc: 0.0095 ::: bot acc: 0.0407
top acc: 0.0120 ::: bot acc: 0.0646
top acc: 0.0147 ::: bot acc: 0.0579
top acc: 0.0094 ::: bot acc: 0.0435
top acc: 0.0153 ::: bot acc: 0.0499
current epoch: 38
train loss is 0.026520
average val loss: 0.028258, accuracy: 0.0283
average test loss: 0.031047, accuracy: 0.0311
case acc: 0.034916684
case acc: 0.028153257
case acc: 0.034540888
case acc: 0.033237826
case acc: 0.027953312
case acc: 0.028054083
top acc: 0.0162 ::: bot acc: 0.0544
top acc: 0.0115 ::: bot acc: 0.0460
top acc: 0.0118 ::: bot acc: 0.0650
top acc: 0.0138 ::: bot acc: 0.0561
top acc: 0.0098 ::: bot acc: 0.0486
top acc: 0.0159 ::: bot acc: 0.0467
current epoch: 39
train loss is 0.028212
average val loss: 0.014283, accuracy: 0.0143
average test loss: 0.019318, accuracy: 0.0192
case acc: 0.017983768
case acc: 0.014432257
case acc: 0.026525812
case acc: 0.019104382
case acc: 0.01650324
case acc: 0.020864364
top acc: 0.0203 ::: bot acc: 0.0270
top acc: 0.0201 ::: bot acc: 0.0198
top acc: 0.0305 ::: bot acc: 0.0413
top acc: 0.0259 ::: bot acc: 0.0269
top acc: 0.0223 ::: bot acc: 0.0228
top acc: 0.0318 ::: bot acc: 0.0260
current epoch: 40
train loss is 0.024997
average val loss: 0.017666, accuracy: 0.0177
average test loss: 0.021402, accuracy: 0.0215
case acc: 0.018838631
case acc: 0.019512456
case acc: 0.026863595
case acc: 0.021719221
case acc: 0.020652888
case acc: 0.021209968
top acc: 0.0360 ::: bot acc: 0.0117
top acc: 0.0357 ::: bot acc: 0.0080
top acc: 0.0412 ::: bot acc: 0.0306
top acc: 0.0379 ::: bot acc: 0.0161
top acc: 0.0374 ::: bot acc: 0.0093
top acc: 0.0381 ::: bot acc: 0.0198
current epoch: 41
train loss is 0.026220
average val loss: 0.015315, accuracy: 0.0154
average test loss: 0.019724, accuracy: 0.0199
case acc: 0.01725601
case acc: 0.017011533
case acc: 0.026450781
case acc: 0.019062797
case acc: 0.01863682
case acc: 0.020834144
top acc: 0.0306 ::: bot acc: 0.0167
top acc: 0.0312 ::: bot acc: 0.0095
top acc: 0.0361 ::: bot acc: 0.0356
top acc: 0.0283 ::: bot acc: 0.0244
top acc: 0.0330 ::: bot acc: 0.0122
top acc: 0.0331 ::: bot acc: 0.0247
current epoch: 42
train loss is 0.026405
average val loss: 0.019609, accuracy: 0.0197
average test loss: 0.023701, accuracy: 0.0237
case acc: 0.024671376
case acc: 0.018177105
case acc: 0.029311128
case acc: 0.026872259
case acc: 0.019206269
case acc: 0.024090838
top acc: 0.0127 ::: bot acc: 0.0408
top acc: 0.0095 ::: bot acc: 0.0321
top acc: 0.0177 ::: bot acc: 0.0543
top acc: 0.0116 ::: bot acc: 0.0478
top acc: 0.0109 ::: bot acc: 0.0349
top acc: 0.0197 ::: bot acc: 0.0389
current epoch: 43
train loss is 0.025508
average val loss: 0.028682, accuracy: 0.0287
average test loss: 0.031384, accuracy: 0.0315
case acc: 0.03544674
case acc: 0.028794238
case acc: 0.03449105
case acc: 0.033897735
case acc: 0.028592817
case acc: 0.027837796
top acc: 0.0165 ::: bot acc: 0.0550
top acc: 0.0118 ::: bot acc: 0.0468
top acc: 0.0119 ::: bot acc: 0.0649
top acc: 0.0141 ::: bot acc: 0.0570
top acc: 0.0100 ::: bot acc: 0.0494
top acc: 0.0159 ::: bot acc: 0.0464
current epoch: 44
train loss is 0.028443
average val loss: 0.014247, accuracy: 0.0143
average test loss: 0.019243, accuracy: 0.0192
case acc: 0.017714944
case acc: 0.014403434
case acc: 0.026432464
case acc: 0.019106215
case acc: 0.016513214
case acc: 0.020839468
top acc: 0.0214 ::: bot acc: 0.0259
top acc: 0.0210 ::: bot acc: 0.0188
top acc: 0.0321 ::: bot acc: 0.0396
top acc: 0.0262 ::: bot acc: 0.0266
top acc: 0.0232 ::: bot acc: 0.0218
top acc: 0.0338 ::: bot acc: 0.0241
current epoch: 45
train loss is 0.024558
average val loss: 0.017118, accuracy: 0.0172
average test loss: 0.020972, accuracy: 0.0210
case acc: 0.01841053
case acc: 0.018725965
case acc: 0.026809402
case acc: 0.020983042
case acc: 0.019978892
case acc: 0.0211918
top acc: 0.0350 ::: bot acc: 0.0125
top acc: 0.0344 ::: bot acc: 0.0082
top acc: 0.0407 ::: bot acc: 0.0311
top acc: 0.0362 ::: bot acc: 0.0173
top acc: 0.0362 ::: bot acc: 0.0098
top acc: 0.0379 ::: bot acc: 0.0200
current epoch: 46
train loss is 0.025566
average val loss: 0.014501, accuracy: 0.0147
average test loss: 0.019282, accuracy: 0.0194
case acc: 0.017017178
case acc: 0.015398399
case acc: 0.02640639
case acc: 0.019176118
case acc: 0.017360458
case acc: 0.02091926
top acc: 0.0271 ::: bot acc: 0.0202
top acc: 0.0274 ::: bot acc: 0.0124
top acc: 0.0335 ::: bot acc: 0.0384
top acc: 0.0250 ::: bot acc: 0.0279
top acc: 0.0292 ::: bot acc: 0.0158
top acc: 0.0309 ::: bot acc: 0.0271
current epoch: 47
train loss is 0.024971
average val loss: 0.018706, accuracy: 0.0188
average test loss: 0.022943, accuracy: 0.0230
case acc: 0.023636991
case acc: 0.01755413
case acc: 0.028737688
case acc: 0.025799766
case acc: 0.018650606
case acc: 0.023525842
top acc: 0.0129 ::: bot acc: 0.0392
top acc: 0.0102 ::: bot acc: 0.0308
top acc: 0.0191 ::: bot acc: 0.0527
top acc: 0.0115 ::: bot acc: 0.0462
top acc: 0.0116 ::: bot acc: 0.0337
top acc: 0.0208 ::: bot acc: 0.0375
current epoch: 48
train loss is 0.024689
average val loss: 0.024926, accuracy: 0.0250
average test loss: 0.028188, accuracy: 0.0283
case acc: 0.031042274
case acc: 0.024759123
case acc: 0.03221197
case acc: 0.030517481
case acc: 0.025077526
case acc: 0.026250327
top acc: 0.0143 ::: bot acc: 0.0496
top acc: 0.0099 ::: bot acc: 0.0417
top acc: 0.0134 ::: bot acc: 0.0608
top acc: 0.0126 ::: bot acc: 0.0527
top acc: 0.0093 ::: bot acc: 0.0445
top acc: 0.0170 ::: bot acc: 0.0434
current epoch: 49
train loss is 0.026722
average val loss: 0.014185, accuracy: 0.0142
average test loss: 0.019245, accuracy: 0.0192
case acc: 0.017695077
case acc: 0.014384867
case acc: 0.02648818
case acc: 0.019170184
case acc: 0.016507164
case acc: 0.020895237
top acc: 0.0214 ::: bot acc: 0.0259
top acc: 0.0207 ::: bot acc: 0.0190
top acc: 0.0311 ::: bot acc: 0.0407
top acc: 0.0251 ::: bot acc: 0.0278
top acc: 0.0228 ::: bot acc: 0.0222
top acc: 0.0316 ::: bot acc: 0.0264
current epoch: 50
train loss is 0.024518
average val loss: 0.018168, accuracy: 0.0182
average test loss: 0.021798, accuracy: 0.0219
case acc: 0.019663021
case acc: 0.020212956
case acc: 0.027178288
case acc: 0.02169318
case acc: 0.021221275
case acc: 0.021431493
top acc: 0.0377 ::: bot acc: 0.0108
top acc: 0.0368 ::: bot acc: 0.0078
top acc: 0.0427 ::: bot acc: 0.0291
top acc: 0.0378 ::: bot acc: 0.0162
top acc: 0.0385 ::: bot acc: 0.0089
top acc: 0.0391 ::: bot acc: 0.0189
LME_Co_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6780 6780 6780
1.7082474 -0.6288155 0.12137239 -0.1537469
Validation: 756 756 756
Testing: 774 774 774
pre-processing time: 0.0005292892456054688
the split date is 2010-07-01
net initializing with time: 0.003871917724609375
preparing training and testing date with time: 2.384185791015625e-07
current epoch: 1
train loss is 0.321543
average val loss: 0.154027, accuracy: 0.1542
average test loss: 0.155215, accuracy: 0.1553
case acc: 0.21192421
case acc: 0.357798
case acc: 0.07055182
case acc: 0.14108516
case acc: 0.10513931
case acc: 0.045440245
top acc: 0.1892 ::: bot acc: 0.2342
top acc: 0.3361 ::: bot acc: 0.3782
top acc: 0.0411 ::: bot acc: 0.1006
top acc: 0.1070 ::: bot acc: 0.1729
top acc: 0.0723 ::: bot acc: 0.1343
top acc: 0.0204 ::: bot acc: 0.0710
current epoch: 2
train loss is 0.204999
average val loss: 0.106107, accuracy: 0.1054
average test loss: 0.106068, accuracy: 0.1054
case acc: 0.018787872
case acc: 0.12908457
case acc: 0.14499018
case acc: 0.072884396
case acc: 0.103021376
case acc: 0.16371696
top acc: 0.0317 ::: bot acc: 0.0136
top acc: 0.1073 ::: bot acc: 0.1495
top acc: 0.1770 ::: bot acc: 0.1134
top acc: 0.1065 ::: bot acc: 0.0415
top acc: 0.1364 ::: bot acc: 0.0738
top acc: 0.1935 ::: bot acc: 0.1358
current epoch: 3
train loss is 0.083822
average val loss: 0.139785, accuracy: 0.1401
average test loss: 0.140981, accuracy: 0.1411
case acc: 0.19193779
case acc: 0.31815237
case acc: 0.060512234
case acc: 0.1284218
case acc: 0.10255779
case acc: 0.04524656
top acc: 0.1689 ::: bot acc: 0.2143
top acc: 0.2964 ::: bot acc: 0.3387
top acc: 0.0326 ::: bot acc: 0.0901
top acc: 0.0945 ::: bot acc: 0.1602
top acc: 0.0698 ::: bot acc: 0.1314
top acc: 0.0201 ::: bot acc: 0.0708
current epoch: 4
train loss is 0.118392
average val loss: 0.114002, accuracy: 0.1149
average test loss: 0.115411, accuracy: 0.1158
case acc: 0.15996064
case acc: 0.28156298
case acc: 0.040176153
case acc: 0.10323109
case acc: 0.08103777
case acc: 0.029025577
top acc: 0.1367 ::: bot acc: 0.1825
top acc: 0.2601 ::: bot acc: 0.3021
top acc: 0.0189 ::: bot acc: 0.0663
top acc: 0.0693 ::: bot acc: 0.1349
top acc: 0.0499 ::: bot acc: 0.1091
top acc: 0.0134 ::: bot acc: 0.0499
current epoch: 5
train loss is 0.110585
average val loss: 0.091863, accuracy: 0.0934
average test loss: 0.093398, accuracy: 0.0939
case acc: 0.12852667
case acc: 0.2455804
case acc: 0.025798779
case acc: 0.07956858
case acc: 0.062156115
case acc: 0.021963615
top acc: 0.1052 ::: bot acc: 0.1510
top acc: 0.2242 ::: bot acc: 0.2661
top acc: 0.0208 ::: bot acc: 0.0435
top acc: 0.0462 ::: bot acc: 0.1109
top acc: 0.0331 ::: bot acc: 0.0891
top acc: 0.0268 ::: bot acc: 0.0312
current epoch: 6
train loss is 0.098586
average val loss: 0.088881, accuracy: 0.0904
average test loss: 0.090408, accuracy: 0.0908
case acc: 0.12052505
case acc: 0.23203178
case acc: 0.0259203
case acc: 0.07843234
case acc: 0.0653257
case acc: 0.022836564
top acc: 0.0971 ::: bot acc: 0.1430
top acc: 0.2107 ::: bot acc: 0.2526
top acc: 0.0205 ::: bot acc: 0.0439
top acc: 0.0451 ::: bot acc: 0.1096
top acc: 0.0357 ::: bot acc: 0.0926
top acc: 0.0220 ::: bot acc: 0.0362
current epoch: 7
train loss is 0.091131
average val loss: 0.084814, accuracy: 0.0863
average test loss: 0.086344, accuracy: 0.0867
case acc: 0.111272134
case acc: 0.21700786
case acc: 0.025570327
case acc: 0.07571856
case acc: 0.06687197
case acc: 0.023817033
top acc: 0.0879 ::: bot acc: 0.1337
top acc: 0.1956 ::: bot acc: 0.2376
top acc: 0.0215 ::: bot acc: 0.0428
top acc: 0.0425 ::: bot acc: 0.1069
top acc: 0.0369 ::: bot acc: 0.0942
top acc: 0.0187 ::: bot acc: 0.0395
current epoch: 8
train loss is 0.085128
average val loss: 0.081021, accuracy: 0.0825
average test loss: 0.082537, accuracy: 0.0829
case acc: 0.102403715
case acc: 0.2027524
case acc: 0.025392942
case acc: 0.073310055
case acc: 0.068185024
case acc: 0.025152551
top acc: 0.0791 ::: bot acc: 0.1248
top acc: 0.1814 ::: bot acc: 0.2233
top acc: 0.0221 ::: bot acc: 0.0422
top acc: 0.0403 ::: bot acc: 0.1043
top acc: 0.0381 ::: bot acc: 0.0955
top acc: 0.0164 ::: bot acc: 0.0426
current epoch: 9
train loss is 0.081417
average val loss: 0.082040, accuracy: 0.0833
average test loss: 0.083545, accuracy: 0.0838
case acc: 0.099226765
case acc: 0.19560058
case acc: 0.027559333
case acc: 0.07668991
case acc: 0.07406023
case acc: 0.029470092
top acc: 0.0760 ::: bot acc: 0.1217
top acc: 0.1743 ::: bot acc: 0.2161
top acc: 0.0180 ::: bot acc: 0.0476
top acc: 0.0434 ::: bot acc: 0.1079
top acc: 0.0431 ::: bot acc: 0.1017
top acc: 0.0130 ::: bot acc: 0.0508
current epoch: 10
train loss is 0.081443
average val loss: 0.089079, accuracy: 0.0899
average test loss: 0.090494, accuracy: 0.0907
case acc: 0.10200712
case acc: 0.19628912
case acc: 0.034696944
case acc: 0.086454034
case acc: 0.085206814
case acc: 0.039666515
top acc: 0.0787 ::: bot acc: 0.1245
top acc: 0.1750 ::: bot acc: 0.2168
top acc: 0.0164 ::: bot acc: 0.0592
top acc: 0.0525 ::: bot acc: 0.1180
top acc: 0.0529 ::: bot acc: 0.1135
top acc: 0.0164 ::: bot acc: 0.0643
current epoch: 11
train loss is 0.079062
average val loss: 0.081993, accuracy: 0.0829
average test loss: 0.083470, accuracy: 0.0836
case acc: 0.0888202
case acc: 0.18184035
case acc: 0.031514738
case acc: 0.0809548
case acc: 0.08115684
case acc: 0.037573855
top acc: 0.0655 ::: bot acc: 0.1113
top acc: 0.1605 ::: bot acc: 0.2024
top acc: 0.0157 ::: bot acc: 0.0548
top acc: 0.0474 ::: bot acc: 0.1124
top acc: 0.0493 ::: bot acc: 0.1092
top acc: 0.0154 ::: bot acc: 0.0617
current epoch: 12
train loss is 0.074369
average val loss: 0.077784, accuracy: 0.0787
average test loss: 0.079293, accuracy: 0.0794
case acc: 0.07886388
case acc: 0.17077862
case acc: 0.03055931
case acc: 0.07840615
case acc: 0.0800282
case acc: 0.03787554
top acc: 0.0556 ::: bot acc: 0.1014
top acc: 0.1494 ::: bot acc: 0.1914
top acc: 0.0157 ::: bot acc: 0.0534
top acc: 0.0450 ::: bot acc: 0.1098
top acc: 0.0484 ::: bot acc: 0.1079
top acc: 0.0154 ::: bot acc: 0.0621
current epoch: 13
train loss is 0.069846
average val loss: 0.069246, accuracy: 0.0704
average test loss: 0.070882, accuracy: 0.0710
case acc: 0.06405662
case acc: 0.1548552
case acc: 0.027217304
case acc: 0.07116043
case acc: 0.07419682
case acc: 0.034300417
top acc: 0.0409 ::: bot acc: 0.0866
top acc: 0.1334 ::: bot acc: 0.1755
top acc: 0.0186 ::: bot acc: 0.0469
top acc: 0.0385 ::: bot acc: 0.1022
top acc: 0.0434 ::: bot acc: 0.1017
top acc: 0.0139 ::: bot acc: 0.0574
current epoch: 14
train loss is 0.066435
average val loss: 0.068225, accuracy: 0.0692
average test loss: 0.069900, accuracy: 0.0699
case acc: 0.058097906
case acc: 0.14780168
case acc: 0.028189844
case acc: 0.07201393
case acc: 0.076153524
case acc: 0.037189085
top acc: 0.0350 ::: bot acc: 0.0806
top acc: 0.1263 ::: bot acc: 0.1685
top acc: 0.0173 ::: bot acc: 0.0491
top acc: 0.0393 ::: bot acc: 0.1032
top acc: 0.0452 ::: bot acc: 0.1037
top acc: 0.0150 ::: bot acc: 0.0611
current epoch: 15
train loss is 0.061451
average val loss: 0.058185, accuracy: 0.0595
average test loss: 0.059959, accuracy: 0.0599
case acc: 0.042161446
case acc: 0.12981811
case acc: 0.02493068
case acc: 0.062825486
case acc: 0.0678847
case acc: 0.031782936
top acc: 0.0204 ::: bot acc: 0.0640
top acc: 0.1083 ::: bot acc: 0.1505
top acc: 0.0246 ::: bot acc: 0.0403
top acc: 0.0319 ::: bot acc: 0.0931
top acc: 0.0380 ::: bot acc: 0.0949
top acc: 0.0130 ::: bot acc: 0.0540
current epoch: 16
train loss is 0.056669
average val loss: 0.052113, accuracy: 0.0535
average test loss: 0.053923, accuracy: 0.0537
case acc: 0.03165154
case acc: 0.1159627
case acc: 0.024174232
case acc: 0.057595357
case acc: 0.0633788
case acc: 0.02965167
top acc: 0.0119 ::: bot acc: 0.0525
top acc: 0.0944 ::: bot acc: 0.1367
top acc: 0.0292 ::: bot acc: 0.0357
top acc: 0.0281 ::: bot acc: 0.0872
top acc: 0.0340 ::: bot acc: 0.0901
top acc: 0.0127 ::: bot acc: 0.0510
current epoch: 17
train loss is 0.051578
average val loss: 0.045834, accuracy: 0.0471
average test loss: 0.047647, accuracy: 0.0474
case acc: 0.02332384
case acc: 0.10094329
case acc: 0.023859663
case acc: 0.051281065
case acc: 0.05776619
case acc: 0.027170677
top acc: 0.0101 ::: bot acc: 0.0409
top acc: 0.0794 ::: bot acc: 0.1216
top acc: 0.0348 ::: bot acc: 0.0302
top acc: 0.0239 ::: bot acc: 0.0798
top acc: 0.0293 ::: bot acc: 0.0840
top acc: 0.0138 ::: bot acc: 0.0467
current epoch: 18
train loss is 0.046088
average val loss: 0.037756, accuracy: 0.0386
average test loss: 0.039431, accuracy: 0.0391
case acc: 0.016982574
case acc: 0.08015061
case acc: 0.025633598
case acc: 0.04081941
case acc: 0.047705945
case acc: 0.023257421
top acc: 0.0198 ::: bot acc: 0.0258
top acc: 0.0586 ::: bot acc: 0.1008
top acc: 0.0453 ::: bot acc: 0.0200
top acc: 0.0184 ::: bot acc: 0.0668
top acc: 0.0221 ::: bot acc: 0.0726
top acc: 0.0207 ::: bot acc: 0.0373
current epoch: 19
train loss is 0.041047
average val loss: 0.031167, accuracy: 0.0312
average test loss: 0.032518, accuracy: 0.0325
case acc: 0.019418135
case acc: 0.054938458
case acc: 0.032417644
case acc: 0.030361498
case acc: 0.03647517
case acc: 0.02116527
top acc: 0.0353 ::: bot acc: 0.0113
top acc: 0.0335 ::: bot acc: 0.0756
top acc: 0.0584 ::: bot acc: 0.0143
top acc: 0.0205 ::: bot acc: 0.0501
top acc: 0.0176 ::: bot acc: 0.0580
top acc: 0.0330 ::: bot acc: 0.0250
current epoch: 20
train loss is 0.038408
average val loss: 0.028023, accuracy: 0.0274
average test loss: 0.029083, accuracy: 0.0289
case acc: 0.026636
case acc: 0.029247006
case acc: 0.04194375
case acc: 0.02411851
case acc: 0.028091682
case acc: 0.023519007
top acc: 0.0469 ::: bot acc: 0.0098
top acc: 0.0103 ::: bot acc: 0.0486
top acc: 0.0709 ::: bot acc: 0.0178
top acc: 0.0339 ::: bot acc: 0.0327
top acc: 0.0206 ::: bot acc: 0.0439
top acc: 0.0444 ::: bot acc: 0.0142
current epoch: 21
train loss is 0.037287
average val loss: 0.026663, accuracy: 0.0255
average test loss: 0.027632, accuracy: 0.0274
case acc: 0.027216101
case acc: 0.017124826
case acc: 0.04518273
case acc: 0.02450586
case acc: 0.026248202
case acc: 0.024121143
top acc: 0.0477 ::: bot acc: 0.0100
top acc: 0.0134 ::: bot acc: 0.0287
top acc: 0.0746 ::: bot acc: 0.0201
top acc: 0.0427 ::: bot acc: 0.0240
top acc: 0.0234 ::: bot acc: 0.0397
top acc: 0.0458 ::: bot acc: 0.0132
current epoch: 22
train loss is 0.035133
average val loss: 0.027500, accuracy: 0.0263
average test loss: 0.028134, accuracy: 0.0281
case acc: 0.026948623
case acc: 0.01770688
case acc: 0.047994487
case acc: 0.026759189
case acc: 0.025272306
case acc: 0.024015825
top acc: 0.0473 ::: bot acc: 0.0098
top acc: 0.0330 ::: bot acc: 0.0096
top acc: 0.0777 ::: bot acc: 0.0223
top acc: 0.0502 ::: bot acc: 0.0170
top acc: 0.0255 ::: bot acc: 0.0372
top acc: 0.0456 ::: bot acc: 0.0132
current epoch: 23
train loss is 0.032424
average val loss: 0.034598, accuracy: 0.0339
average test loss: 0.034649, accuracy: 0.0351
case acc: 0.03192515
case acc: 0.036852736
case acc: 0.05671589
case acc: 0.03432313
case acc: 0.023269285
case acc: 0.027357528
top acc: 0.0534 ::: bot acc: 0.0126
top acc: 0.0583 ::: bot acc: 0.0166
top acc: 0.0874 ::: bot acc: 0.0289
top acc: 0.0640 ::: bot acc: 0.0122
top acc: 0.0341 ::: bot acc: 0.0285
top acc: 0.0519 ::: bot acc: 0.0107
current epoch: 24
train loss is 0.032939
average val loss: 0.048130, accuracy: 0.0477
average test loss: 0.047759, accuracy: 0.0480
case acc: 0.0412513
case acc: 0.065359324
case acc: 0.071050264
case acc: 0.049815115
case acc: 0.02417742
case acc: 0.03615344
top acc: 0.0636 ::: bot acc: 0.0203
top acc: 0.0870 ::: bot acc: 0.0447
top acc: 0.1029 ::: bot acc: 0.0410
top acc: 0.0829 ::: bot acc: 0.0209
top acc: 0.0482 ::: bot acc: 0.0144
top acc: 0.0640 ::: bot acc: 0.0127
current epoch: 25
train loss is 0.040213
average val loss: 0.074585, accuracy: 0.0744
average test loss: 0.074053, accuracy: 0.0739
case acc: 0.06126889
case acc: 0.10314965
case acc: 0.098534696
case acc: 0.079263106
case acc: 0.041511387
case acc: 0.059423026
top acc: 0.0843 ::: bot acc: 0.0390
top acc: 0.1247 ::: bot acc: 0.0826
top acc: 0.1310 ::: bot acc: 0.0672
top acc: 0.1138 ::: bot acc: 0.0476
top acc: 0.0746 ::: bot acc: 0.0136
top acc: 0.0893 ::: bot acc: 0.0323
current epoch: 26
train loss is 0.058005
average val loss: 0.078092, accuracy: 0.0780
average test loss: 0.077579, accuracy: 0.0774
case acc: 0.056465194
case acc: 0.109684855
case acc: 0.10319099
case acc: 0.08572922
case acc: 0.045645382
case acc: 0.06347228
top acc: 0.0795 ::: bot acc: 0.0343
top acc: 0.1312 ::: bot acc: 0.0892
top acc: 0.1358 ::: bot acc: 0.0716
top acc: 0.1204 ::: bot acc: 0.0539
top acc: 0.0790 ::: bot acc: 0.0172
top acc: 0.0935 ::: bot acc: 0.0362
current epoch: 27
train loss is 0.070055
average val loss: 0.044869, accuracy: 0.0441
average test loss: 0.044820, accuracy: 0.0447
case acc: 0.019193143
case acc: 0.068676785
case acc: 0.068304196
case acc: 0.05389649
case acc: 0.023753887
case acc: 0.03456429
top acc: 0.0352 ::: bot acc: 0.0113
top acc: 0.0901 ::: bot acc: 0.0482
top acc: 0.1001 ::: bot acc: 0.0385
top acc: 0.0875 ::: bot acc: 0.0242
top acc: 0.0469 ::: bot acc: 0.0155
top acc: 0.0623 ::: bot acc: 0.0119
current epoch: 28
train loss is 0.068635
average val loss: 0.026276, accuracy: 0.0257
average test loss: 0.027658, accuracy: 0.0280
case acc: 0.03944453
case acc: 0.017863961
case acc: 0.029917428
case acc: 0.024804352
case acc: 0.03367289
case acc: 0.022276517
top acc: 0.0178 ::: bot acc: 0.0612
top acc: 0.0335 ::: bot acc: 0.0091
top acc: 0.0544 ::: bot acc: 0.0149
top acc: 0.0443 ::: bot acc: 0.0224
top acc: 0.0173 ::: bot acc: 0.0540
top acc: 0.0252 ::: bot acc: 0.0327
current epoch: 29
train loss is 0.061084
average val loss: 0.031133, accuracy: 0.0315
average test loss: 0.032980, accuracy: 0.0333
case acc: 0.053907905
case acc: 0.025753586
case acc: 0.02371275
case acc: 0.027115185
case acc: 0.043052502
case acc: 0.025993811
top acc: 0.0306 ::: bot acc: 0.0765
top acc: 0.0084 ::: bot acc: 0.0442
top acc: 0.0343 ::: bot acc: 0.0308
top acc: 0.0247 ::: bot acc: 0.0429
top acc: 0.0196 ::: bot acc: 0.0669
top acc: 0.0151 ::: bot acc: 0.0440
current epoch: 30
train loss is 0.047568
average val loss: 0.028439, accuracy: 0.0289
average test loss: 0.030283, accuracy: 0.0309
case acc: 0.040824432
case acc: 0.036457766
case acc: 0.024006326
case acc: 0.026268186
case acc: 0.03571369
case acc: 0.022211729
top acc: 0.0190 ::: bot acc: 0.0627
top acc: 0.0161 ::: bot acc: 0.0564
top acc: 0.0384 ::: bot acc: 0.0267
top acc: 0.0263 ::: bot acc: 0.0408
top acc: 0.0175 ::: bot acc: 0.0569
top acc: 0.0255 ::: bot acc: 0.0325
current epoch: 31
train loss is 0.041663
average val loss: 0.032584, accuracy: 0.0335
average test loss: 0.034445, accuracy: 0.0353
case acc: 0.039793316
case acc: 0.056810565
case acc: 0.02391118
case acc: 0.030682597
case acc: 0.037830736
case acc: 0.022625228
top acc: 0.0181 ::: bot acc: 0.0616
top acc: 0.0353 ::: bot acc: 0.0773
top acc: 0.0304 ::: bot acc: 0.0347
top acc: 0.0204 ::: bot acc: 0.0504
top acc: 0.0179 ::: bot acc: 0.0599
top acc: 0.0235 ::: bot acc: 0.0344
current epoch: 32
train loss is 0.044810
average val loss: 0.051932, accuracy: 0.0525
average test loss: 0.053504, accuracy: 0.0539
case acc: 0.056897216
case acc: 0.090479665
case acc: 0.03510451
case acc: 0.049683113
case acc: 0.056852415
case acc: 0.034149755
top acc: 0.0336 ::: bot acc: 0.0795
top acc: 0.0690 ::: bot acc: 0.1110
top acc: 0.0145 ::: bot acc: 0.0611
top acc: 0.0227 ::: bot acc: 0.0778
top acc: 0.0290 ::: bot acc: 0.0829
top acc: 0.0135 ::: bot acc: 0.0571
current epoch: 33
train loss is 0.050297
average val loss: 0.055477, accuracy: 0.0559
average test loss: 0.057002, accuracy: 0.0572
case acc: 0.05351023
case acc: 0.09499071
case acc: 0.03978512
case acc: 0.0548419
case acc: 0.061660483
case acc: 0.038679644
top acc: 0.0303 ::: bot acc: 0.0761
top acc: 0.0734 ::: bot acc: 0.1155
top acc: 0.0167 ::: bot acc: 0.0671
top acc: 0.0262 ::: bot acc: 0.0838
top acc: 0.0330 ::: bot acc: 0.0881
top acc: 0.0153 ::: bot acc: 0.0630
current epoch: 34
train loss is 0.042464
average val loss: 0.034805, accuracy: 0.0357
average test loss: 0.036699, accuracy: 0.0370
case acc: 0.02548342
case acc: 0.06567868
case acc: 0.026054554
case acc: 0.036653176
case acc: 0.04269382
case acc: 0.025342772
top acc: 0.0098 ::: bot acc: 0.0443
top acc: 0.0441 ::: bot acc: 0.0862
top acc: 0.0207 ::: bot acc: 0.0445
top acc: 0.0179 ::: bot acc: 0.0607
top acc: 0.0194 ::: bot acc: 0.0665
top acc: 0.0159 ::: bot acc: 0.0427
current epoch: 35
train loss is 0.034465
average val loss: 0.028766, accuracy: 0.0295
average test loss: 0.030747, accuracy: 0.0310
case acc: 0.018206434
case acc: 0.050645724
case acc: 0.02421809
case acc: 0.031623382
case acc: 0.037755147
case acc: 0.023436107
top acc: 0.0151 ::: bot acc: 0.0307
top acc: 0.0291 ::: bot acc: 0.0712
top acc: 0.0276 ::: bot acc: 0.0375
top acc: 0.0197 ::: bot acc: 0.0523
top acc: 0.0179 ::: bot acc: 0.0598
top acc: 0.0202 ::: bot acc: 0.0376
current epoch: 36
train loss is 0.030225
average val loss: 0.023759, accuracy: 0.0240
average test loss: 0.025611, accuracy: 0.0257
case acc: 0.0167523
case acc: 0.034392487
case acc: 0.023819132
case acc: 0.026334519
case acc: 0.03120728
case acc: 0.02167798
top acc: 0.0271 ::: bot acc: 0.0187
top acc: 0.0142 ::: bot acc: 0.0543
top acc: 0.0364 ::: bot acc: 0.0287
top acc: 0.0261 ::: bot acc: 0.0411
top acc: 0.0173 ::: bot acc: 0.0502
top acc: 0.0281 ::: bot acc: 0.0298
current epoch: 37
train loss is 0.026995
average val loss: 0.021440, accuracy: 0.0212
average test loss: 0.023031, accuracy: 0.0229
case acc: 0.018571965
case acc: 0.021578748
case acc: 0.025068143
case acc: 0.024059016
case acc: 0.026892811
case acc: 0.021182619
top acc: 0.0335 ::: bot acc: 0.0124
top acc: 0.0079 ::: bot acc: 0.0382
top acc: 0.0435 ::: bot acc: 0.0216
top acc: 0.0359 ::: bot acc: 0.0308
top acc: 0.0214 ::: bot acc: 0.0417
top acc: 0.0348 ::: bot acc: 0.0231
current epoch: 38
train loss is 0.025429
average val loss: 0.021205, accuracy: 0.0206
average test loss: 0.022465, accuracy: 0.0223
case acc: 0.019678563
case acc: 0.015882064
case acc: 0.0272324
case acc: 0.025026126
case acc: 0.024390131
case acc: 0.021833641
top acc: 0.0362 ::: bot acc: 0.0103
top acc: 0.0191 ::: bot acc: 0.0231
top acc: 0.0490 ::: bot acc: 0.0172
top acc: 0.0450 ::: bot acc: 0.0217
top acc: 0.0274 ::: bot acc: 0.0348
top acc: 0.0398 ::: bot acc: 0.0180
current epoch: 39
train loss is 0.024390
average val loss: 0.022944, accuracy: 0.0223
average test loss: 0.023707, accuracy: 0.0237
case acc: 0.020139048
case acc: 0.017723134
case acc: 0.029679332
case acc: 0.028030133
case acc: 0.02322231
case acc: 0.023267625
top acc: 0.0372 ::: bot acc: 0.0097
top acc: 0.0332 ::: bot acc: 0.0094
top acc: 0.0539 ::: bot acc: 0.0147
top acc: 0.0534 ::: bot acc: 0.0146
top acc: 0.0334 ::: bot acc: 0.0289
top acc: 0.0441 ::: bot acc: 0.0141
current epoch: 40
train loss is 0.023961
average val loss: 0.026105, accuracy: 0.0256
average test loss: 0.026433, accuracy: 0.0266
case acc: 0.020574858
case acc: 0.025705528
case acc: 0.032831606
case acc: 0.03232834
case acc: 0.022677688
case acc: 0.025372744
top acc: 0.0381 ::: bot acc: 0.0093
top acc: 0.0455 ::: bot acc: 0.0088
top acc: 0.0588 ::: bot acc: 0.0144
top acc: 0.0610 ::: bot acc: 0.0122
top acc: 0.0390 ::: bot acc: 0.0233
top acc: 0.0484 ::: bot acc: 0.0118
current epoch: 41
train loss is 0.024712
average val loss: 0.029430, accuracy: 0.0289
average test loss: 0.029517, accuracy: 0.0296
case acc: 0.02069147
case acc: 0.03394847
case acc: 0.036007777
case acc: 0.036767244
case acc: 0.022968866
case acc: 0.027469624
top acc: 0.0383 ::: bot acc: 0.0092
top acc: 0.0552 ::: bot acc: 0.0141
top acc: 0.0632 ::: bot acc: 0.0152
top acc: 0.0674 ::: bot acc: 0.0127
top acc: 0.0437 ::: bot acc: 0.0186
top acc: 0.0522 ::: bot acc: 0.0105
current epoch: 42
train loss is 0.026009
average val loss: 0.033874, accuracy: 0.0333
average test loss: 0.033764, accuracy: 0.0338
case acc: 0.021620832
case acc: 0.042881466
case acc: 0.040441725
case acc: 0.042533882
case acc: 0.024555484
case acc: 0.03087523
top acc: 0.0399 ::: bot acc: 0.0089
top acc: 0.0645 ::: bot acc: 0.0222
top acc: 0.0690 ::: bot acc: 0.0169
top acc: 0.0745 ::: bot acc: 0.0157
top acc: 0.0494 ::: bot acc: 0.0130
top acc: 0.0574 ::: bot acc: 0.0104
current epoch: 43
train loss is 0.028080
average val loss: 0.039260, accuracy: 0.0388
average test loss: 0.039051, accuracy: 0.0390
case acc: 0.023199847
case acc: 0.051181156
case acc: 0.04633488
case acc: 0.049328074
case acc: 0.027964817
case acc: 0.036074806
top acc: 0.0423 ::: bot acc: 0.0088
top acc: 0.0728 ::: bot acc: 0.0305
top acc: 0.0758 ::: bot acc: 0.0209
top acc: 0.0823 ::: bot acc: 0.0205
top acc: 0.0563 ::: bot acc: 0.0095
top acc: 0.0641 ::: bot acc: 0.0127
current epoch: 44
train loss is 0.030805
average val loss: 0.041601, accuracy: 0.0411
average test loss: 0.041389, accuracy: 0.0412
case acc: 0.021951934
case acc: 0.05332416
case acc: 0.049244706
case acc: 0.052917738
case acc: 0.030275263
case acc: 0.03948539
top acc: 0.0405 ::: bot acc: 0.0088
top acc: 0.0750 ::: bot acc: 0.0327
top acc: 0.0791 ::: bot acc: 0.0231
top acc: 0.0863 ::: bot acc: 0.0234
top acc: 0.0602 ::: bot acc: 0.0085
top acc: 0.0681 ::: bot acc: 0.0147
current epoch: 45
train loss is 0.032331
average val loss: 0.037240, accuracy: 0.0366
average test loss: 0.037199, accuracy: 0.0370
case acc: 0.017543763
case acc: 0.044500243
case acc: 0.044912685
case acc: 0.049117073
case acc: 0.02851069
case acc: 0.037345972
top acc: 0.0306 ::: bot acc: 0.0153
top acc: 0.0661 ::: bot acc: 0.0238
top acc: 0.0742 ::: bot acc: 0.0198
top acc: 0.0821 ::: bot acc: 0.0204
top acc: 0.0572 ::: bot acc: 0.0092
top acc: 0.0656 ::: bot acc: 0.0134
current epoch: 46
train loss is 0.031942
average val loss: 0.029495, accuracy: 0.0288
average test loss: 0.029804, accuracy: 0.0297
case acc: 0.017991528
case acc: 0.02802871
case acc: 0.035916824
case acc: 0.040001687
case acc: 0.024533838
case acc: 0.031539984
top acc: 0.0161 ::: bot acc: 0.0298
top acc: 0.0484 ::: bot acc: 0.0100
top acc: 0.0630 ::: bot acc: 0.0152
top acc: 0.0715 ::: bot acc: 0.0142
top acc: 0.0493 ::: bot acc: 0.0131
top acc: 0.0583 ::: bot acc: 0.0106
current epoch: 47
train loss is 0.032416
average val loss: 0.023191, accuracy: 0.0227
average test loss: 0.024231, accuracy: 0.0243
case acc: 0.025468446
case acc: 0.015737318
case acc: 0.026818201
case acc: 0.02981269
case acc: 0.022686541
case acc: 0.025505576
top acc: 0.0099 ::: bot acc: 0.0442
top acc: 0.0239 ::: bot acc: 0.0184
top acc: 0.0480 ::: bot acc: 0.0180
top acc: 0.0569 ::: bot acc: 0.0130
top acc: 0.0391 ::: bot acc: 0.0232
top acc: 0.0487 ::: bot acc: 0.0116
current epoch: 48
train loss is 0.035410
average val loss: 0.027083, accuracy: 0.0275
average test loss: 0.029125, accuracy: 0.0300
case acc: 0.043470014
case acc: 0.03722392
case acc: 0.025611544
case acc: 0.024582073
case acc: 0.027495414
case acc: 0.02149909
top acc: 0.0213 ::: bot acc: 0.0655
top acc: 0.0166 ::: bot acc: 0.0574
top acc: 0.0220 ::: bot acc: 0.0433
top acc: 0.0302 ::: bot acc: 0.0363
top acc: 0.0203 ::: bot acc: 0.0432
top acc: 0.0296 ::: bot acc: 0.0282
current epoch: 49
train loss is 0.039993
average val loss: 0.054733, accuracy: 0.0550
average test loss: 0.056245, accuracy: 0.0568
case acc: 0.070053436
case acc: 0.087217316
case acc: 0.05072837
case acc: 0.04752744
case acc: 0.049635004
case acc: 0.03558604
top acc: 0.0468 ::: bot acc: 0.0926
top acc: 0.0656 ::: bot acc: 0.1079
top acc: 0.0239 ::: bot acc: 0.0800
top acc: 0.0214 ::: bot acc: 0.0752
top acc: 0.0234 ::: bot acc: 0.0748
top acc: 0.0139 ::: bot acc: 0.0590
current epoch: 50
train loss is 0.050346
average val loss: 0.050701, accuracy: 0.0510
average test loss: 0.052313, accuracy: 0.0528
case acc: 0.056465518
case acc: 0.085064985
case acc: 0.048696302
case acc: 0.046089154
case acc: 0.04689034
case acc: 0.033626836
top acc: 0.0332 ::: bot acc: 0.0790
top acc: 0.0634 ::: bot acc: 0.1058
top acc: 0.0226 ::: bot acc: 0.0776
top acc: 0.0206 ::: bot acc: 0.0735
top acc: 0.0215 ::: bot acc: 0.0717
top acc: 0.0134 ::: bot acc: 0.0564
LME_Co_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6804 6804 6804
1.7082474 -0.6288155 0.12137239 -0.15229516
Validation: 762 762 762
Testing: 750 750 750
pre-processing time: 0.0004634857177734375
the split date is 2011-01-01
net initializing with time: 0.003314971923828125
preparing training and testing date with time: 2.384185791015625e-07
current epoch: 1
train loss is 0.297792
average val loss: 0.085393, accuracy: 0.0862
average test loss: 0.078548, accuracy: 0.0794
case acc: 0.1602088
case acc: 0.13499391
case acc: 0.04341605
case acc: 0.033284005
case acc: 0.034337964
case acc: 0.07043736
top acc: 0.1359 ::: bot acc: 0.1843
top acc: 0.1141 ::: bot acc: 0.1550
top acc: 0.0166 ::: bot acc: 0.0746
top acc: 0.0120 ::: bot acc: 0.0586
top acc: 0.0142 ::: bot acc: 0.0612
top acc: 0.0411 ::: bot acc: 0.0994
current epoch: 2
train loss is 0.104875
average val loss: 0.055993, accuracy: 0.0573
average test loss: 0.051346, accuracy: 0.0533
case acc: 0.11576809
case acc: 0.09347393
case acc: 0.027830705
case acc: 0.020488147
case acc: 0.025056835
case acc: 0.037348054
top acc: 0.0913 ::: bot acc: 0.1401
top acc: 0.0727 ::: bot acc: 0.1135
top acc: 0.0291 ::: bot acc: 0.0446
top acc: 0.0230 ::: bot acc: 0.0328
top acc: 0.0342 ::: bot acc: 0.0332
top acc: 0.0120 ::: bot acc: 0.0645
current epoch: 3
train loss is 0.093411
average val loss: 0.081823, accuracy: 0.0824
average test loss: 0.074642, accuracy: 0.0753
case acc: 0.13716187
case acc: 0.11954217
case acc: 0.04664488
case acc: 0.045102548
case acc: 0.040933426
case acc: 0.062176775
top acc: 0.1126 ::: bot acc: 0.1615
top acc: 0.0988 ::: bot acc: 0.1397
top acc: 0.0179 ::: bot acc: 0.0787
top acc: 0.0195 ::: bot acc: 0.0725
top acc: 0.0148 ::: bot acc: 0.0707
top acc: 0.0328 ::: bot acc: 0.0913
current epoch: 4
train loss is 0.091244
average val loss: 0.079427, accuracy: 0.0799
average test loss: 0.072159, accuracy: 0.0727
case acc: 0.12500522
case acc: 0.11300763
case acc: 0.04692858
case acc: 0.052371174
case acc: 0.045076035
case acc: 0.053581674
top acc: 0.1005 ::: bot acc: 0.1494
top acc: 0.0922 ::: bot acc: 0.1332
top acc: 0.0180 ::: bot acc: 0.0791
top acc: 0.0259 ::: bot acc: 0.0801
top acc: 0.0167 ::: bot acc: 0.0761
top acc: 0.0244 ::: bot acc: 0.0826
current epoch: 5
train loss is 0.080019
average val loss: 0.073837, accuracy: 0.0743
average test loss: 0.066523, accuracy: 0.0670
case acc: 0.10914669
case acc: 0.10153086
case acc: 0.045072693
case acc: 0.0559471
case acc: 0.046228543
case acc: 0.044274718
top acc: 0.0846 ::: bot acc: 0.1337
top acc: 0.0807 ::: bot acc: 0.1218
top acc: 0.0174 ::: bot acc: 0.0766
top acc: 0.0291 ::: bot acc: 0.0837
top acc: 0.0173 ::: bot acc: 0.0776
top acc: 0.0166 ::: bot acc: 0.0726
current epoch: 6
train loss is 0.069407
average val loss: 0.069673, accuracy: 0.0700
average test loss: 0.062329, accuracy: 0.0628
case acc: 0.09461352
case acc: 0.09048484
case acc: 0.0448942
case acc: 0.060153574
case acc: 0.047737747
case acc: 0.03881034
top acc: 0.0700 ::: bot acc: 0.1193
top acc: 0.0696 ::: bot acc: 0.1109
top acc: 0.0174 ::: bot acc: 0.0763
top acc: 0.0330 ::: bot acc: 0.0880
top acc: 0.0181 ::: bot acc: 0.0796
top acc: 0.0127 ::: bot acc: 0.0664
current epoch: 7
train loss is 0.060522
average val loss: 0.071933, accuracy: 0.0722
average test loss: 0.064526, accuracy: 0.0648
case acc: 0.087047845
case acc: 0.08616498
case acc: 0.050185833
case acc: 0.070585184
case acc: 0.054355107
case acc: 0.040226474
top acc: 0.0625 ::: bot acc: 0.1117
top acc: 0.0653 ::: bot acc: 0.1067
top acc: 0.0197 ::: bot acc: 0.0831
top acc: 0.0432 ::: bot acc: 0.0985
top acc: 0.0224 ::: bot acc: 0.0874
top acc: 0.0135 ::: bot acc: 0.0681
current epoch: 8
train loss is 0.056405
average val loss: 0.066910, accuracy: 0.0671
average test loss: 0.059479, accuracy: 0.0597
case acc: 0.071704715
case acc: 0.073421374
case acc: 0.049798734
case acc: 0.07291099
case acc: 0.05363711
case acc: 0.036743607
top acc: 0.0473 ::: bot acc: 0.0963
top acc: 0.0524 ::: bot acc: 0.0940
top acc: 0.0194 ::: bot acc: 0.0827
top acc: 0.0456 ::: bot acc: 0.1006
top acc: 0.0217 ::: bot acc: 0.0867
top acc: 0.0118 ::: bot acc: 0.0637
current epoch: 9
train loss is 0.049151
average val loss: 0.063122, accuracy: 0.0631
average test loss: 0.055676, accuracy: 0.0558
case acc: 0.058147542
case acc: 0.061342087
case acc: 0.050732933
case acc: 0.07550982
case acc: 0.053507507
case acc: 0.03559724
top acc: 0.0341 ::: bot acc: 0.0826
top acc: 0.0404 ::: bot acc: 0.0820
top acc: 0.0201 ::: bot acc: 0.0838
top acc: 0.0483 ::: bot acc: 0.1032
top acc: 0.0216 ::: bot acc: 0.0867
top acc: 0.0115 ::: bot acc: 0.0622
current epoch: 10
train loss is 0.043881
average val loss: 0.056696, accuracy: 0.0565
average test loss: 0.049338, accuracy: 0.0492
case acc: 0.042332135
case acc: 0.045696035
case acc: 0.049293276
case acc: 0.07387515
case acc: 0.050214075
case acc: 0.033854783
top acc: 0.0188 ::: bot acc: 0.0665
top acc: 0.0247 ::: bot acc: 0.0664
top acc: 0.0192 ::: bot acc: 0.0821
top acc: 0.0467 ::: bot acc: 0.1015
top acc: 0.0191 ::: bot acc: 0.0830
top acc: 0.0115 ::: bot acc: 0.0596
current epoch: 11
train loss is 0.040325
average val loss: 0.052373, accuracy: 0.0518
average test loss: 0.045308, accuracy: 0.0446
case acc: 0.030221984
case acc: 0.032289993
case acc: 0.04908909
case acc: 0.07296488
case acc: 0.0489734
case acc: 0.03393946
top acc: 0.0085 ::: bot acc: 0.0535
top acc: 0.0122 ::: bot acc: 0.0527
top acc: 0.0191 ::: bot acc: 0.0819
top acc: 0.0458 ::: bot acc: 0.1005
top acc: 0.0183 ::: bot acc: 0.0816
top acc: 0.0116 ::: bot acc: 0.0597
current epoch: 12
train loss is 0.039845
average val loss: 0.045867, accuracy: 0.0449
average test loss: 0.039751, accuracy: 0.0385
case acc: 0.020960473
case acc: 0.019523732
case acc: 0.04563728
case acc: 0.06759734
case acc: 0.04559236
case acc: 0.031842396
top acc: 0.0108 ::: bot acc: 0.0386
top acc: 0.0079 ::: bot acc: 0.0358
top acc: 0.0176 ::: bot acc: 0.0775
top acc: 0.0405 ::: bot acc: 0.0952
top acc: 0.0162 ::: bot acc: 0.0776
top acc: 0.0120 ::: bot acc: 0.0564
current epoch: 13
train loss is 0.048132
average val loss: 0.031547, accuracy: 0.0312
average test loss: 0.029651, accuracy: 0.0289
case acc: 0.02414169
case acc: 0.025460962
case acc: 0.030293586
case acc: 0.04169478
case acc: 0.029821433
case acc: 0.022055164
top acc: 0.0439 ::: bot acc: 0.0090
top acc: 0.0442 ::: bot acc: 0.0091
top acc: 0.0207 ::: bot acc: 0.0532
top acc: 0.0168 ::: bot acc: 0.0681
top acc: 0.0167 ::: bot acc: 0.0539
top acc: 0.0235 ::: bot acc: 0.0358
current epoch: 14
train loss is 0.062275
average val loss: 0.058418, accuracy: 0.0587
average test loss: 0.064894, accuracy: 0.0649
case acc: 0.092562996
case acc: 0.10602144
case acc: 0.051992457
case acc: 0.03575163
case acc: 0.04914059
case acc: 0.053926058
top acc: 0.1170 ::: bot acc: 0.0679
top acc: 0.1270 ::: bot acc: 0.0851
top acc: 0.0871 ::: bot acc: 0.0192
top acc: 0.0610 ::: bot acc: 0.0122
top acc: 0.0829 ::: bot acc: 0.0159
top acc: 0.0833 ::: bot acc: 0.0255
current epoch: 15
train loss is 0.080905
average val loss: 0.084011, accuracy: 0.0841
average test loss: 0.090917, accuracy: 0.0909
case acc: 0.11324748
case acc: 0.13745461
case acc: 0.07711203
case acc: 0.0698822
case acc: 0.0780144
case acc: 0.0697516
top acc: 0.1377 ::: bot acc: 0.0885
top acc: 0.1584 ::: bot acc: 0.1165
top acc: 0.1135 ::: bot acc: 0.0415
top acc: 0.0970 ::: bot acc: 0.0422
top acc: 0.1124 ::: bot acc: 0.0434
top acc: 0.0996 ::: bot acc: 0.0404
current epoch: 16
train loss is 0.065484
average val loss: 0.058027, accuracy: 0.0581
average test loss: 0.064549, accuracy: 0.0647
case acc: 0.076375425
case acc: 0.10559007
case acc: 0.05395822
case acc: 0.0534832
case acc: 0.059275113
case acc: 0.039490122
top acc: 0.1009 ::: bot acc: 0.0516
top acc: 0.1266 ::: bot acc: 0.0845
top acc: 0.0892 ::: bot acc: 0.0208
top acc: 0.0804 ::: bot acc: 0.0261
top acc: 0.0937 ::: bot acc: 0.0247
top acc: 0.0674 ::: bot acc: 0.0141
current epoch: 17
train loss is 0.051570
average val loss: 0.055793, accuracy: 0.0558
average test loss: 0.062297, accuracy: 0.0624
case acc: 0.063032895
case acc: 0.09349445
case acc: 0.056686774
case acc: 0.059477564
case acc: 0.062957056
case acc: 0.03890663
top acc: 0.0875 ::: bot acc: 0.0383
top acc: 0.1146 ::: bot acc: 0.0723
top acc: 0.0921 ::: bot acc: 0.0231
top acc: 0.0865 ::: bot acc: 0.0319
top acc: 0.0975 ::: bot acc: 0.0282
top acc: 0.0667 ::: bot acc: 0.0139
current epoch: 18
train loss is 0.046091
average val loss: 0.054075, accuracy: 0.0540
average test loss: 0.060605, accuracy: 0.0607
case acc: 0.05027784
case acc: 0.081862725
case acc: 0.06039086
case acc: 0.065900154
case acc: 0.06630792
case acc: 0.03948805
top acc: 0.0746 ::: bot acc: 0.0258
top acc: 0.1031 ::: bot acc: 0.0605
top acc: 0.0959 ::: bot acc: 0.0264
top acc: 0.0928 ::: bot acc: 0.0384
top acc: 0.1009 ::: bot acc: 0.0315
top acc: 0.0673 ::: bot acc: 0.0144
current epoch: 19
train loss is 0.041307
average val loss: 0.048746, accuracy: 0.0485
average test loss: 0.055145, accuracy: 0.0552
case acc: 0.03491377
case acc: 0.06624416
case acc: 0.060072783
case acc: 0.06753455
case acc: 0.065241784
case acc: 0.03696264
top acc: 0.0582 ::: bot acc: 0.0126
top acc: 0.0875 ::: bot acc: 0.0449
top acc: 0.0955 ::: bot acc: 0.0261
top acc: 0.0945 ::: bot acc: 0.0400
top acc: 0.0999 ::: bot acc: 0.0303
top acc: 0.0643 ::: bot acc: 0.0130
current epoch: 20
train loss is 0.039097
average val loss: 0.042540, accuracy: 0.0420
average test loss: 0.048525, accuracy: 0.0484
case acc: 0.022520484
case acc: 0.048491184
case acc: 0.057401996
case acc: 0.06582279
case acc: 0.062408734
case acc: 0.03374564
top acc: 0.0410 ::: bot acc: 0.0099
top acc: 0.0696 ::: bot acc: 0.0272
top acc: 0.0927 ::: bot acc: 0.0238
top acc: 0.0928 ::: bot acc: 0.0382
top acc: 0.0971 ::: bot acc: 0.0275
top acc: 0.0601 ::: bot acc: 0.0116
current epoch: 21
train loss is 0.045144
average val loss: 0.027943, accuracy: 0.0272
average test loss: 0.030779, accuracy: 0.0307
case acc: 0.023491614
case acc: 0.017259978
case acc: 0.037700158
case acc: 0.042283606
case acc: 0.041259926
case acc: 0.022296436
top acc: 0.0076 ::: bot acc: 0.0443
top acc: 0.0304 ::: bot acc: 0.0122
top acc: 0.0690 ::: bot acc: 0.0124
top acc: 0.0684 ::: bot acc: 0.0165
top acc: 0.0738 ::: bot acc: 0.0108
top acc: 0.0380 ::: bot acc: 0.0213
current epoch: 22
train loss is 0.057085
average val loss: 0.060116, accuracy: 0.0608
average test loss: 0.052919, accuracy: 0.0538
case acc: 0.09217335
case acc: 0.07299284
case acc: 0.03942122
case acc: 0.033151884
case acc: 0.03463797
case acc: 0.050174963
top acc: 0.0676 ::: bot acc: 0.1174
top acc: 0.0519 ::: bot acc: 0.0944
top acc: 0.0157 ::: bot acc: 0.0692
top acc: 0.0119 ::: bot acc: 0.0579
top acc: 0.0127 ::: bot acc: 0.0634
top acc: 0.0211 ::: bot acc: 0.0793
current epoch: 23
train loss is 0.061571
average val loss: 0.076837, accuracy: 0.0771
average test loss: 0.069329, accuracy: 0.0696
case acc: 0.10405696
case acc: 0.097054295
case acc: 0.052474156
case acc: 0.057461143
case acc: 0.051357035
case acc: 0.05504993
top acc: 0.0796 ::: bot acc: 0.1292
top acc: 0.0759 ::: bot acc: 0.1185
top acc: 0.0210 ::: bot acc: 0.0859
top acc: 0.0307 ::: bot acc: 0.0850
top acc: 0.0195 ::: bot acc: 0.0850
top acc: 0.0255 ::: bot acc: 0.0843
current epoch: 24
train loss is 0.053926
average val loss: 0.061137, accuracy: 0.0615
average test loss: 0.053772, accuracy: 0.0544
case acc: 0.07758433
case acc: 0.07691156
case acc: 0.041217115
case acc: 0.05155465
case acc: 0.04411102
case acc: 0.034750927
top acc: 0.0531 ::: bot acc: 0.1028
top acc: 0.0558 ::: bot acc: 0.0983
top acc: 0.0161 ::: bot acc: 0.0716
top acc: 0.0252 ::: bot acc: 0.0789
top acc: 0.0149 ::: bot acc: 0.0764
top acc: 0.0122 ::: bot acc: 0.0606
current epoch: 25
train loss is 0.045143
average val loss: 0.055801, accuracy: 0.0561
average test loss: 0.048507, accuracy: 0.0490
case acc: 0.06118129
case acc: 0.062282406
case acc: 0.040648434
case acc: 0.053999335
case acc: 0.044575017
case acc: 0.03142891
top acc: 0.0368 ::: bot acc: 0.0864
top acc: 0.0412 ::: bot acc: 0.0837
top acc: 0.0159 ::: bot acc: 0.0708
top acc: 0.0274 ::: bot acc: 0.0815
top acc: 0.0152 ::: bot acc: 0.0769
top acc: 0.0123 ::: bot acc: 0.0556
current epoch: 26
train loss is 0.039404
average val loss: 0.049296, accuracy: 0.0493
average test loss: 0.042139, accuracy: 0.0424
case acc: 0.0438107
case acc: 0.04465859
case acc: 0.039707802
case acc: 0.05358831
case acc: 0.042638596
case acc: 0.029718025
top acc: 0.0200 ::: bot acc: 0.0687
top acc: 0.0236 ::: bot acc: 0.0660
top acc: 0.0157 ::: bot acc: 0.0695
top acc: 0.0270 ::: bot acc: 0.0810
top acc: 0.0143 ::: bot acc: 0.0745
top acc: 0.0128 ::: bot acc: 0.0528
current epoch: 27
train loss is 0.036045
average val loss: 0.037568, accuracy: 0.0370
average test loss: 0.031681, accuracy: 0.0310
case acc: 0.023694454
case acc: 0.022176579
case acc: 0.03432859
case acc: 0.045143828
case acc: 0.03516425
case acc: 0.02542765
top acc: 0.0075 ::: bot acc: 0.0449
top acc: 0.0067 ::: bot acc: 0.0408
top acc: 0.0162 ::: bot acc: 0.0613
top acc: 0.0196 ::: bot acc: 0.0720
top acc: 0.0125 ::: bot acc: 0.0642
top acc: 0.0154 ::: bot acc: 0.0452
current epoch: 28
train loss is 0.032946
average val loss: 0.028051, accuracy: 0.0275
average test loss: 0.025393, accuracy: 0.0246
case acc: 0.018697707
case acc: 0.016768148
case acc: 0.028670162
case acc: 0.03321461
case acc: 0.028320635
case acc: 0.021905774
top acc: 0.0292 ::: bot acc: 0.0205
top acc: 0.0289 ::: bot acc: 0.0136
top acc: 0.0239 ::: bot acc: 0.0491
top acc: 0.0118 ::: bot acc: 0.0581
top acc: 0.0189 ::: bot acc: 0.0509
top acc: 0.0239 ::: bot acc: 0.0352
current epoch: 29
train loss is 0.037814
average val loss: 0.028796, accuracy: 0.0297
average test loss: 0.032483, accuracy: 0.0328
case acc: 0.04222289
case acc: 0.051135458
case acc: 0.029518906
case acc: 0.019909319
case acc: 0.027730264
case acc: 0.026573332
top acc: 0.0664 ::: bot acc: 0.0178
top acc: 0.0722 ::: bot acc: 0.0298
top acc: 0.0537 ::: bot acc: 0.0193
top acc: 0.0306 ::: bot acc: 0.0241
top acc: 0.0486 ::: bot acc: 0.0207
top acc: 0.0488 ::: bot acc: 0.0126
current epoch: 30
train loss is 0.047504
average val loss: 0.058913, accuracy: 0.0591
average test loss: 0.065597, accuracy: 0.0657
case acc: 0.08038445
case acc: 0.10029981
case acc: 0.056835752
case acc: 0.05104399
case acc: 0.056008138
case acc: 0.04955736
top acc: 0.1050 ::: bot acc: 0.0551
top acc: 0.1214 ::: bot acc: 0.0789
top acc: 0.0925 ::: bot acc: 0.0233
top acc: 0.0780 ::: bot acc: 0.0238
top acc: 0.0904 ::: bot acc: 0.0215
top acc: 0.0785 ::: bot acc: 0.0219
current epoch: 31
train loss is 0.056898
average val loss: 0.059015, accuracy: 0.0591
average test loss: 0.065698, accuracy: 0.0658
case acc: 0.07130268
case acc: 0.097876206
case acc: 0.058943845
case acc: 0.060810596
case acc: 0.06193477
case acc: 0.044037763
top acc: 0.0959 ::: bot acc: 0.0461
top acc: 0.1190 ::: bot acc: 0.0765
top acc: 0.0947 ::: bot acc: 0.0250
top acc: 0.0880 ::: bot acc: 0.0330
top acc: 0.0964 ::: bot acc: 0.0271
top acc: 0.0724 ::: bot acc: 0.0175
current epoch: 32
train loss is 0.051598
average val loss: 0.035081, accuracy: 0.0352
average test loss: 0.040809, accuracy: 0.0411
case acc: 0.03495619
case acc: 0.06155067
case acc: 0.039508935
case acc: 0.04246395
case acc: 0.04309423
case acc: 0.025276372
top acc: 0.0583 ::: bot acc: 0.0123
top acc: 0.0827 ::: bot acc: 0.0401
top acc: 0.0717 ::: bot acc: 0.0129
top acc: 0.0687 ::: bot acc: 0.0165
top acc: 0.0760 ::: bot acc: 0.0117
top acc: 0.0461 ::: bot acc: 0.0142
current epoch: 33
train loss is 0.040472
average val loss: 0.029346, accuracy: 0.0292
average test loss: 0.034664, accuracy: 0.0348
case acc: 0.022902697
case acc: 0.041603416
case acc: 0.03846043
case acc: 0.03971413
case acc: 0.04053011
case acc: 0.02573684
top acc: 0.0415 ::: bot acc: 0.0099
top acc: 0.0624 ::: bot acc: 0.0207
top acc: 0.0702 ::: bot acc: 0.0128
top acc: 0.0656 ::: bot acc: 0.0144
top acc: 0.0727 ::: bot acc: 0.0107
top acc: 0.0471 ::: bot acc: 0.0135
current epoch: 34
train loss is 0.035598
average val loss: 0.023964, accuracy: 0.0236
average test loss: 0.027652, accuracy: 0.0276
case acc: 0.018200293
case acc: 0.021231903
case acc: 0.034408942
case acc: 0.032398205
case acc: 0.035033602
case acc: 0.024590664
top acc: 0.0221 ::: bot acc: 0.0277
top acc: 0.0381 ::: bot acc: 0.0085
top acc: 0.0639 ::: bot acc: 0.0133
top acc: 0.0567 ::: bot acc: 0.0104
top acc: 0.0646 ::: bot acc: 0.0104
top acc: 0.0446 ::: bot acc: 0.0152
current epoch: 35
train loss is 0.034017
average val loss: 0.024428, accuracy: 0.0247
average test loss: 0.023828, accuracy: 0.0243
case acc: 0.028291127
case acc: 0.019005613
case acc: 0.027737722
case acc: 0.021741308
case acc: 0.027691117
case acc: 0.02157119
top acc: 0.0073 ::: bot acc: 0.0518
top acc: 0.0083 ::: bot acc: 0.0354
top acc: 0.0479 ::: bot acc: 0.0253
top acc: 0.0374 ::: bot acc: 0.0174
top acc: 0.0485 ::: bot acc: 0.0209
top acc: 0.0333 ::: bot acc: 0.0258
current epoch: 36
train loss is 0.037482
average val loss: 0.045095, accuracy: 0.0457
average test loss: 0.038646, accuracy: 0.0399
case acc: 0.06001466
case acc: 0.05761346
case acc: 0.032255977
case acc: 0.031289008
case acc: 0.029647077
case acc: 0.028491667
top acc: 0.0356 ::: bot acc: 0.0852
top acc: 0.0365 ::: bot acc: 0.0791
top acc: 0.0180 ::: bot acc: 0.0574
top acc: 0.0113 ::: bot acc: 0.0555
top acc: 0.0172 ::: bot acc: 0.0537
top acc: 0.0133 ::: bot acc: 0.0507
current epoch: 37
train loss is 0.046121
average val loss: 0.066540, accuracy: 0.0668
average test loss: 0.059028, accuracy: 0.0593
case acc: 0.076760545
case acc: 0.08350725
case acc: 0.04891607
case acc: 0.05982366
case acc: 0.04786028
case acc: 0.03918434
top acc: 0.0522 ::: bot acc: 0.1020
top acc: 0.0624 ::: bot acc: 0.1049
top acc: 0.0187 ::: bot acc: 0.0819
top acc: 0.0329 ::: bot acc: 0.0874
top acc: 0.0170 ::: bot acc: 0.0809
top acc: 0.0132 ::: bot acc: 0.0667
current epoch: 38
train loss is 0.048365
average val loss: 0.042990, accuracy: 0.0433
average test loss: 0.036648, accuracy: 0.0372
case acc: 0.04077788
case acc: 0.050444964
case acc: 0.03303962
case acc: 0.04287246
case acc: 0.033250004
case acc: 0.022763744
top acc: 0.0170 ::: bot acc: 0.0656
top acc: 0.0294 ::: bot acc: 0.0718
top acc: 0.0172 ::: bot acc: 0.0590
top acc: 0.0177 ::: bot acc: 0.0696
top acc: 0.0132 ::: bot acc: 0.0610
top acc: 0.0205 ::: bot acc: 0.0386
current epoch: 39
train loss is 0.042425
average val loss: 0.026736, accuracy: 0.0267
average test loss: 0.023747, accuracy: 0.0235
case acc: 0.019087166
case acc: 0.019293299
case acc: 0.026831137
case acc: 0.028326474
case acc: 0.025825944
case acc: 0.021767024
top acc: 0.0170 ::: bot acc: 0.0329
top acc: 0.0079 ::: bot acc: 0.0360
top acc: 0.0311 ::: bot acc: 0.0421
top acc: 0.0114 ::: bot acc: 0.0511
top acc: 0.0275 ::: bot acc: 0.0418
top acc: 0.0348 ::: bot acc: 0.0244
current epoch: 40
train loss is 0.034274
average val loss: 0.022458, accuracy: 0.0224
average test loss: 0.022802, accuracy: 0.0225
case acc: 0.020929083
case acc: 0.018540356
case acc: 0.026357744
case acc: 0.021660259
case acc: 0.02554169
case acc: 0.021979187
top acc: 0.0373 ::: bot acc: 0.0127
top acc: 0.0334 ::: bot acc: 0.0099
top acc: 0.0385 ::: bot acc: 0.0348
top acc: 0.0164 ::: bot acc: 0.0388
top acc: 0.0383 ::: bot acc: 0.0309
top acc: 0.0363 ::: bot acc: 0.0229
current epoch: 41
train loss is 0.032909
average val loss: 0.027265, accuracy: 0.0279
average test loss: 0.031776, accuracy: 0.0322
case acc: 0.03747806
case acc: 0.044936508
case acc: 0.03062708
case acc: 0.022734866
case acc: 0.031281266
case acc: 0.02603281
top acc: 0.0614 ::: bot acc: 0.0139
top acc: 0.0658 ::: bot acc: 0.0238
top acc: 0.0565 ::: bot acc: 0.0173
top acc: 0.0400 ::: bot acc: 0.0152
top acc: 0.0577 ::: bot acc: 0.0130
top acc: 0.0477 ::: bot acc: 0.0131
current epoch: 42
train loss is 0.036601
average val loss: 0.044129, accuracy: 0.0444
average test loss: 0.050489, accuracy: 0.0507
case acc: 0.056921028
case acc: 0.07481476
case acc: 0.04512068
case acc: 0.043580234
case acc: 0.04805327
case acc: 0.035736185
top acc: 0.0817 ::: bot acc: 0.0316
top acc: 0.0958 ::: bot acc: 0.0534
top acc: 0.0791 ::: bot acc: 0.0151
top acc: 0.0701 ::: bot acc: 0.0173
top acc: 0.0818 ::: bot acc: 0.0147
top acc: 0.0626 ::: bot acc: 0.0122
current epoch: 43
train loss is 0.042352
average val loss: 0.050307, accuracy: 0.0503
average test loss: 0.056856, accuracy: 0.0570
case acc: 0.05483731
case acc: 0.078538634
case acc: 0.053307652
case acc: 0.058444507
case acc: 0.058622487
case acc: 0.038274523
top acc: 0.0796 ::: bot acc: 0.0295
top acc: 0.0995 ::: bot acc: 0.0571
top acc: 0.0887 ::: bot acc: 0.0204
top acc: 0.0857 ::: bot acc: 0.0306
top acc: 0.0931 ::: bot acc: 0.0240
top acc: 0.0657 ::: bot acc: 0.0136
current epoch: 44
train loss is 0.042313
average val loss: 0.029485, accuracy: 0.0293
average test loss: 0.034683, accuracy: 0.0350
case acc: 0.023902155
case acc: 0.04375092
case acc: 0.036565717
case acc: 0.04133047
case acc: 0.040761884
case acc: 0.023478452
top acc: 0.0435 ::: bot acc: 0.0091
top acc: 0.0646 ::: bot acc: 0.0226
top acc: 0.0674 ::: bot acc: 0.0129
top acc: 0.0676 ::: bot acc: 0.0155
top acc: 0.0730 ::: bot acc: 0.0107
top acc: 0.0418 ::: bot acc: 0.0174
current epoch: 45
train loss is 0.037232
average val loss: 0.022231, accuracy: 0.0223
average test loss: 0.023314, accuracy: 0.0237
case acc: 0.02073052
case acc: 0.016636403
case acc: 0.028177332
case acc: 0.025970083
case acc: 0.029139847
case acc: 0.021332344
top acc: 0.0117 ::: bot acc: 0.0384
top acc: 0.0283 ::: bot acc: 0.0142
top acc: 0.0494 ::: bot acc: 0.0239
top acc: 0.0471 ::: bot acc: 0.0107
top acc: 0.0528 ::: bot acc: 0.0167
top acc: 0.0273 ::: bot acc: 0.0319
current epoch: 46
train loss is 0.035105
average val loss: 0.032005, accuracy: 0.0326
average test loss: 0.027341, accuracy: 0.0284
case acc: 0.04084695
case acc: 0.030362854
case acc: 0.027389029
case acc: 0.02042288
case acc: 0.025567787
case acc: 0.025575627
top acc: 0.0169 ::: bot acc: 0.0658
top acc: 0.0107 ::: bot acc: 0.0511
top acc: 0.0286 ::: bot acc: 0.0447
top acc: 0.0201 ::: bot acc: 0.0349
top acc: 0.0295 ::: bot acc: 0.0398
top acc: 0.0151 ::: bot acc: 0.0456
current epoch: 47
train loss is 0.036821
average val loss: 0.050006, accuracy: 0.0504
average test loss: 0.042869, accuracy: 0.0437
case acc: 0.059046637
case acc: 0.059903726
case acc: 0.036957737
case acc: 0.038260564
case acc: 0.035252154
case acc: 0.032510716
top acc: 0.0345 ::: bot acc: 0.0843
top acc: 0.0389 ::: bot acc: 0.0813
top acc: 0.0155 ::: bot acc: 0.0656
top acc: 0.0143 ::: bot acc: 0.0645
top acc: 0.0126 ::: bot acc: 0.0642
top acc: 0.0121 ::: bot acc: 0.0574
current epoch: 48
train loss is 0.039289
average val loss: 0.050567, accuracy: 0.0509
average test loss: 0.043376, accuracy: 0.0439
case acc: 0.050895132
case acc: 0.058084376
case acc: 0.038855728
case acc: 0.046769276
case acc: 0.039264426
case acc: 0.029777767
top acc: 0.0266 ::: bot acc: 0.0761
top acc: 0.0371 ::: bot acc: 0.0795
top acc: 0.0156 ::: bot acc: 0.0684
top acc: 0.0207 ::: bot acc: 0.0740
top acc: 0.0129 ::: bot acc: 0.0700
top acc: 0.0126 ::: bot acc: 0.0531
current epoch: 49
train loss is 0.039900
average val loss: 0.030166, accuracy: 0.0302
average test loss: 0.025868, accuracy: 0.0257
case acc: 0.0213459
case acc: 0.024466302
case acc: 0.02813719
case acc: 0.031025548
case acc: 0.027753461
case acc: 0.021344023
top acc: 0.0104 ::: bot acc: 0.0400
top acc: 0.0072 ::: bot acc: 0.0441
top acc: 0.0261 ::: bot acc: 0.0472
top acc: 0.0112 ::: bot acc: 0.0552
top acc: 0.0204 ::: bot acc: 0.0493
top acc: 0.0293 ::: bot acc: 0.0300
current epoch: 50
train loss is 0.033568
average val loss: 0.022243, accuracy: 0.0223
average test loss: 0.023067, accuracy: 0.0227
case acc: 0.021914018
case acc: 0.018071102
case acc: 0.026612671
case acc: 0.020944417
case acc: 0.025548732
case acc: 0.023197278
top acc: 0.0395 ::: bot acc: 0.0112
top acc: 0.0323 ::: bot acc: 0.0104
top acc: 0.0416 ::: bot acc: 0.0317
top acc: 0.0185 ::: bot acc: 0.0366
top acc: 0.0384 ::: bot acc: 0.0308
top acc: 0.0410 ::: bot acc: 0.0183
LME_Co_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6786 6786 6786
1.7082474 -0.6288155 0.12137239 -0.15229516
Validation: 756 756 756
Testing: 768 768 768
pre-processing time: 0.00022912025451660156
the split date is 2011-07-01
net initializing with time: 0.002589702606201172
preparing training and testing date with time: 2.384185791015625e-07
current epoch: 1
train loss is 0.278111
average val loss: 0.200242, accuracy: 0.2012
average test loss: 0.199808, accuracy: 0.2013
case acc: 0.37892386
case acc: 0.3123871
case acc: 0.03290242
case acc: 0.13088804
case acc: 0.32962975
case acc: 0.022898111
top acc: 0.4032 ::: bot acc: 0.3540
top acc: 0.3349 ::: bot acc: 0.2914
top acc: 0.0179 ::: bot acc: 0.0571
top acc: 0.1509 ::: bot acc: 0.1078
top acc: 0.3548 ::: bot acc: 0.3019
top acc: 0.0253 ::: bot acc: 0.0335
current epoch: 2
train loss is 0.269350
average val loss: 0.150615, accuracy: 0.1509
average test loss: 0.150545, accuracy: 0.1503
case acc: 0.2173462
case acc: 0.15706256
case acc: 0.16943017
case acc: 0.024254683
case acc: 0.17214328
case acc: 0.16126926
top acc: 0.2421 ::: bot acc: 0.1930
top acc: 0.1788 ::: bot acc: 0.1368
top acc: 0.1359 ::: bot acc: 0.2027
top acc: 0.0102 ::: bot acc: 0.0435
top acc: 0.1980 ::: bot acc: 0.1437
top acc: 0.1308 ::: bot acc: 0.1912
current epoch: 3
train loss is 0.156265
average val loss: 0.154923, accuracy: 0.1557
average test loss: 0.155181, accuracy: 0.1560
case acc: 0.27223438
case acc: 0.2184411
case acc: 0.08613959
case acc: 0.04987722
case acc: 0.23269744
case acc: 0.0763997
top acc: 0.2972 ::: bot acc: 0.2482
top acc: 0.2399 ::: bot acc: 0.1985
top acc: 0.0530 ::: bot acc: 0.1192
top acc: 0.0683 ::: bot acc: 0.0296
top acc: 0.2589 ::: bot acc: 0.2042
top acc: 0.0482 ::: bot acc: 0.1053
current epoch: 4
train loss is 0.161445
average val loss: 0.133441, accuracy: 0.1339
average test loss: 0.133325, accuracy: 0.1336
case acc: 0.22130427
case acc: 0.17429832
case acc: 0.10530275
case acc: 0.022109501
case acc: 0.18737194
case acc: 0.09144692
top acc: 0.2463 ::: bot acc: 0.1973
top acc: 0.1957 ::: bot acc: 0.1544
top acc: 0.0715 ::: bot acc: 0.1387
top acc: 0.0354 ::: bot acc: 0.0122
top acc: 0.2136 ::: bot acc: 0.1587
top acc: 0.0620 ::: bot acc: 0.1211
current epoch: 5
train loss is 0.138005
average val loss: 0.130539, accuracy: 0.1314
average test loss: 0.130832, accuracy: 0.1319
case acc: 0.23469868
case acc: 0.19506054
case acc: 0.05955431
case acc: 0.050865926
case acc: 0.20642586
case acc: 0.04453577
top acc: 0.2596 ::: bot acc: 0.2107
top acc: 0.2165 ::: bot acc: 0.1752
top acc: 0.0295 ::: bot acc: 0.0912
top acc: 0.0692 ::: bot acc: 0.0306
top acc: 0.2326 ::: bot acc: 0.1777
top acc: 0.0210 ::: bot acc: 0.0714
current epoch: 6
train loss is 0.131000
average val loss: 0.111572, accuracy: 0.1122
average test loss: 0.111768, accuracy: 0.1125
case acc: 0.19427183
case acc: 0.16175826
case acc: 0.0669364
case acc: 0.031241953
case acc: 0.17160186
case acc: 0.049242456
top acc: 0.2191 ::: bot acc: 0.1702
top acc: 0.1832 ::: bot acc: 0.1419
top acc: 0.0353 ::: bot acc: 0.0993
top acc: 0.0479 ::: bot acc: 0.0145
top acc: 0.1978 ::: bot acc: 0.1428
top acc: 0.0244 ::: bot acc: 0.0769
current epoch: 7
train loss is 0.117351
average val loss: 0.103265, accuracy: 0.1042
average test loss: 0.103207, accuracy: 0.1043
case acc: 0.1842396
case acc: 0.15903242
case acc: 0.04690926
case acc: 0.039451916
case acc: 0.16718033
case acc: 0.02918791
top acc: 0.2091 ::: bot acc: 0.1601
top acc: 0.1805 ::: bot acc: 0.1392
top acc: 0.0207 ::: bot acc: 0.0766
top acc: 0.0572 ::: bot acc: 0.0204
top acc: 0.1934 ::: bot acc: 0.1383
top acc: 0.0139 ::: bot acc: 0.0522
current epoch: 8
train loss is 0.103553
average val loss: 0.090911, accuracy: 0.0918
average test loss: 0.090554, accuracy: 0.0919
case acc: 0.16007286
case acc: 0.14212017
case acc: 0.040658638
case acc: 0.034667864
case acc: 0.14866903
case acc: 0.024964197
top acc: 0.1849 ::: bot acc: 0.1359
top acc: 0.1635 ::: bot acc: 0.1223
top acc: 0.0174 ::: bot acc: 0.0690
top acc: 0.0518 ::: bot acc: 0.0169
top acc: 0.1749 ::: bot acc: 0.1197
top acc: 0.0194 ::: bot acc: 0.0429
current epoch: 9
train loss is 0.093574
average val loss: 0.082485, accuracy: 0.0833
average test loss: 0.081680, accuracy: 0.0834
case acc: 0.14205119
case acc: 0.13149717
case acc: 0.03145487
case acc: 0.035219133
case acc: 0.13637537
case acc: 0.023541752
top acc: 0.1669 ::: bot acc: 0.1179
top acc: 0.1529 ::: bot acc: 0.1118
top acc: 0.0173 ::: bot acc: 0.0553
top acc: 0.0523 ::: bot acc: 0.0173
top acc: 0.1627 ::: bot acc: 0.1073
top acc: 0.0338 ::: bot acc: 0.0287
current epoch: 10
train loss is 0.082137
average val loss: 0.073356, accuracy: 0.0741
average test loss: 0.072271, accuracy: 0.0739
case acc: 0.12056002
case acc: 0.11749661
case acc: 0.02687319
case acc: 0.032478407
case acc: 0.12074585
case acc: 0.024977839
top acc: 0.1454 ::: bot acc: 0.0964
top acc: 0.1388 ::: bot acc: 0.0978
top acc: 0.0227 ::: bot acc: 0.0457
top acc: 0.0492 ::: bot acc: 0.0154
top acc: 0.1472 ::: bot acc: 0.0916
top acc: 0.0430 ::: bot acc: 0.0203
current epoch: 11
train loss is 0.072617
average val loss: 0.066741, accuracy: 0.0675
average test loss: 0.065512, accuracy: 0.0669
case acc: 0.10174307
case acc: 0.106243
case acc: 0.024614472
case acc: 0.031745527
case acc: 0.107843965
case acc: 0.029194698
top acc: 0.1267 ::: bot acc: 0.0777
top acc: 0.1274 ::: bot acc: 0.0866
top acc: 0.0336 ::: bot acc: 0.0341
top acc: 0.0483 ::: bot acc: 0.0149
top acc: 0.1344 ::: bot acc: 0.0787
top acc: 0.0529 ::: bot acc: 0.0140
current epoch: 12
train loss is 0.063508
average val loss: 0.058699, accuracy: 0.0594
average test loss: 0.057412, accuracy: 0.0586
case acc: 0.080480516
case acc: 0.09275676
case acc: 0.025460357
case acc: 0.02854304
case acc: 0.092671536
case acc: 0.03158656
top acc: 0.1054 ::: bot acc: 0.0566
top acc: 0.1138 ::: bot acc: 0.0732
top acc: 0.0419 ::: bot acc: 0.0262
top acc: 0.0444 ::: bot acc: 0.0129
top acc: 0.1193 ::: bot acc: 0.0634
top acc: 0.0570 ::: bot acc: 0.0130
current epoch: 13
train loss is 0.055500
average val loss: 0.052827, accuracy: 0.0534
average test loss: 0.051608, accuracy: 0.0525
case acc: 0.06247869
case acc: 0.08243346
case acc: 0.028632473
case acc: 0.027188655
case acc: 0.080647305
case acc: 0.03343703
top acc: 0.0875 ::: bot acc: 0.0388
top acc: 0.1033 ::: bot acc: 0.0631
top acc: 0.0518 ::: bot acc: 0.0178
top acc: 0.0428 ::: bot acc: 0.0121
top acc: 0.1075 ::: bot acc: 0.0512
top acc: 0.0598 ::: bot acc: 0.0131
current epoch: 14
train loss is 0.048167
average val loss: 0.048172, accuracy: 0.0485
average test loss: 0.047105, accuracy: 0.0475
case acc: 0.04715468
case acc: 0.074229926
case acc: 0.033548504
case acc: 0.026479552
case acc: 0.07059808
case acc: 0.03316103
top acc: 0.0723 ::: bot acc: 0.0237
top acc: 0.0949 ::: bot acc: 0.0550
top acc: 0.0616 ::: bot acc: 0.0131
top acc: 0.0420 ::: bot acc: 0.0117
top acc: 0.0975 ::: bot acc: 0.0413
top acc: 0.0595 ::: bot acc: 0.0129
current epoch: 15
train loss is 0.041786
average val loss: 0.043902, accuracy: 0.0440
average test loss: 0.042906, accuracy: 0.0429
case acc: 0.034637436
case acc: 0.06677893
case acc: 0.038397405
case acc: 0.025388196
case acc: 0.06150814
case acc: 0.03086391
top acc: 0.0592 ::: bot acc: 0.0131
top acc: 0.0874 ::: bot acc: 0.0476
top acc: 0.0697 ::: bot acc: 0.0114
top acc: 0.0406 ::: bot acc: 0.0111
top acc: 0.0883 ::: bot acc: 0.0328
top acc: 0.0560 ::: bot acc: 0.0129
current epoch: 16
train loss is 0.037138
average val loss: 0.042613, accuracy: 0.0426
average test loss: 0.041655, accuracy: 0.0414
case acc: 0.028150424
case acc: 0.0630095
case acc: 0.04510326
case acc: 0.02644093
case acc: 0.05618625
case acc: 0.02946327
top acc: 0.0515 ::: bot acc: 0.0094
top acc: 0.0835 ::: bot acc: 0.0439
top acc: 0.0790 ::: bot acc: 0.0130
top acc: 0.0419 ::: bot acc: 0.0115
top acc: 0.0829 ::: bot acc: 0.0279
top acc: 0.0538 ::: bot acc: 0.0132
current epoch: 17
train loss is 0.034480
average val loss: 0.050301, accuracy: 0.0503
average test loss: 0.049594, accuracy: 0.0494
case acc: 0.031584345
case acc: 0.06993252
case acc: 0.06154379
case acc: 0.03665633
case acc: 0.06176191
case acc: 0.035152733
top acc: 0.0559 ::: bot acc: 0.0111
top acc: 0.0904 ::: bot acc: 0.0508
top acc: 0.0965 ::: bot acc: 0.0274
top acc: 0.0535 ::: bot acc: 0.0189
top acc: 0.0888 ::: bot acc: 0.0329
top acc: 0.0621 ::: bot acc: 0.0135
current epoch: 18
train loss is 0.036746
average val loss: 0.065515, accuracy: 0.0655
average test loss: 0.065034, accuracy: 0.0651
case acc: 0.041929394
case acc: 0.084299356
case acc: 0.08380847
case acc: 0.055253938
case acc: 0.075977005
case acc: 0.04911922
top acc: 0.0673 ::: bot acc: 0.0194
top acc: 0.1048 ::: bot acc: 0.0651
top acc: 0.1189 ::: bot acc: 0.0494
top acc: 0.0729 ::: bot acc: 0.0361
top acc: 0.1035 ::: bot acc: 0.0463
top acc: 0.0784 ::: bot acc: 0.0225
current epoch: 19
train loss is 0.042768
average val loss: 0.075574, accuracy: 0.0755
average test loss: 0.075110, accuracy: 0.0751
case acc: 0.0453519
case acc: 0.092990495
case acc: 0.09841852
case acc: 0.069103464
case acc: 0.08621854
case acc: 0.05838567
top acc: 0.0710 ::: bot acc: 0.0225
top acc: 0.1134 ::: bot acc: 0.0738
top acc: 0.1335 ::: bot acc: 0.0640
top acc: 0.0870 ::: bot acc: 0.0493
top acc: 0.1138 ::: bot acc: 0.0565
top acc: 0.0888 ::: bot acc: 0.0296
current epoch: 20
train loss is 0.051904
average val loss: 0.063254, accuracy: 0.0631
average test loss: 0.062720, accuracy: 0.0626
case acc: 0.02732668
case acc: 0.07835695
case acc: 0.08534597
case acc: 0.060147494
case acc: 0.07521476
case acc: 0.04919228
top acc: 0.0509 ::: bot acc: 0.0089
top acc: 0.0987 ::: bot acc: 0.0593
top acc: 0.1205 ::: bot acc: 0.0509
top acc: 0.0779 ::: bot acc: 0.0407
top acc: 0.1028 ::: bot acc: 0.0455
top acc: 0.0785 ::: bot acc: 0.0226
current epoch: 21
train loss is 0.056309
average val loss: 0.031582, accuracy: 0.0318
average test loss: 0.030517, accuracy: 0.0304
case acc: 0.029304262
case acc: 0.031505823
case acc: 0.038621478
case acc: 0.021318972
case acc: 0.036671977
case acc: 0.024969079
top acc: 0.0144 ::: bot acc: 0.0467
top acc: 0.0517 ::: bot acc: 0.0128
top acc: 0.0702 ::: bot acc: 0.0115
top acc: 0.0353 ::: bot acc: 0.0095
top acc: 0.0615 ::: bot acc: 0.0127
top acc: 0.0440 ::: bot acc: 0.0192
current epoch: 22
train loss is 0.058433
average val loss: 0.040519, accuracy: 0.0412
average test loss: 0.040485, accuracy: 0.0406
case acc: 0.07670057
case acc: 0.029178848
case acc: 0.037182502
case acc: 0.040535454
case acc: 0.025824983
case acc: 0.03441027
top acc: 0.0517 ::: bot acc: 0.0989
top acc: 0.0126 ::: bot acc: 0.0464
top acc: 0.0146 ::: bot acc: 0.0655
top acc: 0.0234 ::: bot acc: 0.0599
top acc: 0.0117 ::: bot acc: 0.0490
top acc: 0.0145 ::: bot acc: 0.0601
current epoch: 23
train loss is 0.041581
average val loss: 0.034610, accuracy: 0.0352
average test loss: 0.034073, accuracy: 0.0346
case acc: 0.060900085
case acc: 0.025270537
case acc: 0.038520113
case acc: 0.03705826
case acc: 0.022022093
case acc: 0.023553655
top acc: 0.0370 ::: bot acc: 0.0826
top acc: 0.0108 ::: bot acc: 0.0415
top acc: 0.0149 ::: bot acc: 0.0674
top acc: 0.0203 ::: bot acc: 0.0562
top acc: 0.0170 ::: bot acc: 0.0404
top acc: 0.0255 ::: bot acc: 0.0375
current epoch: 24
train loss is 0.035330
average val loss: 0.044044, accuracy: 0.0444
average test loss: 0.044113, accuracy: 0.0444
case acc: 0.064546905
case acc: 0.037717257
case acc: 0.056789346
case acc: 0.054001227
case acc: 0.02874121
case acc: 0.024412429
top acc: 0.0404 ::: bot acc: 0.0863
top acc: 0.0182 ::: bot acc: 0.0564
top acc: 0.0262 ::: bot acc: 0.0891
top acc: 0.0362 ::: bot acc: 0.0736
top acc: 0.0112 ::: bot acc: 0.0535
top acc: 0.0212 ::: bot acc: 0.0418
current epoch: 25
train loss is 0.042348
average val loss: 0.057014, accuracy: 0.0572
average test loss: 0.057448, accuracy: 0.0575
case acc: 0.069706365
case acc: 0.05257125
case acc: 0.07658261
case acc: 0.07379986
case acc: 0.041529283
case acc: 0.031022673
top acc: 0.0452 ::: bot acc: 0.0916
top acc: 0.0323 ::: bot acc: 0.0716
top acc: 0.0424 ::: bot acc: 0.1106
top acc: 0.0560 ::: bot acc: 0.0934
top acc: 0.0176 ::: bot acc: 0.0694
top acc: 0.0140 ::: bot acc: 0.0553
current epoch: 26
train loss is 0.068055
average val loss: 0.027359, accuracy: 0.0272
average test loss: 0.025775, accuracy: 0.0253
case acc: 0.017867893
case acc: 0.02005814
case acc: 0.025650417
case acc: 0.014709802
case acc: 0.031162862
case acc: 0.04214219
top acc: 0.0341 ::: bot acc: 0.0141
top acc: 0.0381 ::: bot acc: 0.0056
top acc: 0.0298 ::: bot acc: 0.0397
top acc: 0.0101 ::: bot acc: 0.0279
top acc: 0.0537 ::: bot acc: 0.0119
top acc: 0.0704 ::: bot acc: 0.0177
current epoch: 27
train loss is 0.047838
average val loss: 0.029755, accuracy: 0.0297
average test loss: 0.028427, accuracy: 0.0281
case acc: 0.025703005
case acc: 0.030719794
case acc: 0.02605972
case acc: 0.01373335
case acc: 0.036153637
case acc: 0.03610155
top acc: 0.0489 ::: bot acc: 0.0082
top acc: 0.0508 ::: bot acc: 0.0120
top acc: 0.0443 ::: bot acc: 0.0251
top acc: 0.0186 ::: bot acc: 0.0191
top acc: 0.0607 ::: bot acc: 0.0127
top acc: 0.0630 ::: bot acc: 0.0143
current epoch: 28
train loss is 0.039957
average val loss: 0.031384, accuracy: 0.0314
average test loss: 0.030198, accuracy: 0.0300
case acc: 0.03052913
case acc: 0.038075168
case acc: 0.030799253
case acc: 0.0152496975
case acc: 0.037809283
case acc: 0.027251795
top acc: 0.0550 ::: bot acc: 0.0104
top acc: 0.0584 ::: bot acc: 0.0189
top acc: 0.0566 ::: bot acc: 0.0152
top acc: 0.0245 ::: bot acc: 0.0132
top acc: 0.0628 ::: bot acc: 0.0135
top acc: 0.0500 ::: bot acc: 0.0140
current epoch: 29
train loss is 0.033759
average val loss: 0.039377, accuracy: 0.0395
average test loss: 0.038602, accuracy: 0.0384
case acc: 0.039822098
case acc: 0.051797673
case acc: 0.043921284
case acc: 0.023483645
case acc: 0.04542488
case acc: 0.025836337
top acc: 0.0653 ::: bot acc: 0.0177
top acc: 0.0722 ::: bot acc: 0.0326
top acc: 0.0774 ::: bot acc: 0.0126
top acc: 0.0385 ::: bot acc: 0.0097
top acc: 0.0716 ::: bot acc: 0.0186
top acc: 0.0468 ::: bot acc: 0.0161
current epoch: 30
train loss is 0.031003
average val loss: 0.056803, accuracy: 0.0569
average test loss: 0.056443, accuracy: 0.0566
case acc: 0.054184422
case acc: 0.07245377
case acc: 0.07368639
case acc: 0.044928797
case acc: 0.06167813
case acc: 0.03281281
top acc: 0.0799 ::: bot acc: 0.0316
top acc: 0.0929 ::: bot acc: 0.0532
top acc: 0.1086 ::: bot acc: 0.0393
top acc: 0.0623 ::: bot acc: 0.0265
top acc: 0.0888 ::: bot acc: 0.0331
top acc: 0.0587 ::: bot acc: 0.0130
current epoch: 31
train loss is 0.038864
average val loss: 0.079639, accuracy: 0.0797
average test loss: 0.079357, accuracy: 0.0796
case acc: 0.068406925
case acc: 0.09474569
case acc: 0.107148275
case acc: 0.07240802
case acc: 0.08277667
case acc: 0.05182372
top acc: 0.0942 ::: bot acc: 0.0458
top acc: 0.1152 ::: bot acc: 0.0755
top acc: 0.1421 ::: bot acc: 0.0728
top acc: 0.0904 ::: bot acc: 0.0526
top acc: 0.1103 ::: bot acc: 0.0533
top acc: 0.0811 ::: bot acc: 0.0250
current epoch: 32
train loss is 0.060954
average val loss: 0.037047, accuracy: 0.0371
average test loss: 0.035970, accuracy: 0.0356
case acc: 0.01874556
case acc: 0.044692323
case acc: 0.05818887
case acc: 0.029789198
case acc: 0.039079808
case acc: 0.023391629
top acc: 0.0370 ::: bot acc: 0.0114
top acc: 0.0652 ::: bot acc: 0.0254
top acc: 0.0930 ::: bot acc: 0.0241
top acc: 0.0460 ::: bot acc: 0.0136
top acc: 0.0643 ::: bot acc: 0.0143
top acc: 0.0381 ::: bot acc: 0.0244
current epoch: 33
train loss is 0.050539
average val loss: 0.024964, accuracy: 0.0251
average test loss: 0.023189, accuracy: 0.0228
case acc: 0.026629316
case acc: 0.017844766
case acc: 0.03204694
case acc: 0.013788935
case acc: 0.023387674
case acc: 0.023337603
top acc: 0.0137 ::: bot acc: 0.0430
top acc: 0.0343 ::: bot acc: 0.0069
top acc: 0.0589 ::: bot acc: 0.0144
top acc: 0.0190 ::: bot acc: 0.0187
top acc: 0.0392 ::: bot acc: 0.0179
top acc: 0.0261 ::: bot acc: 0.0365
current epoch: 34
train loss is 0.040443
average val loss: 0.023636, accuracy: 0.0238
average test loss: 0.021686, accuracy: 0.0217
case acc: 0.03056167
case acc: 0.014223218
case acc: 0.025393229
case acc: 0.015581004
case acc: 0.021549879
case acc: 0.023016278
top acc: 0.0146 ::: bot acc: 0.0484
top acc: 0.0225 ::: bot acc: 0.0173
top acc: 0.0403 ::: bot acc: 0.0291
top acc: 0.0090 ::: bot acc: 0.0298
top acc: 0.0323 ::: bot acc: 0.0247
top acc: 0.0332 ::: bot acc: 0.0293
current epoch: 35
train loss is 0.031954
average val loss: 0.024462, accuracy: 0.0246
average test loss: 0.022777, accuracy: 0.0231
case acc: 0.030444456
case acc: 0.01563819
case acc: 0.026829766
case acc: 0.02148417
case acc: 0.0207899
case acc: 0.023547046
top acc: 0.0145 ::: bot acc: 0.0482
top acc: 0.0142 ::: bot acc: 0.0256
top acc: 0.0241 ::: bot acc: 0.0454
top acc: 0.0080 ::: bot acc: 0.0390
top acc: 0.0278 ::: bot acc: 0.0293
top acc: 0.0390 ::: bot acc: 0.0235
current epoch: 36
train loss is 0.026761
average val loss: 0.029654, accuracy: 0.0297
average test loss: 0.028820, accuracy: 0.0293
case acc: 0.034537364
case acc: 0.023370586
case acc: 0.037677363
case acc: 0.035353277
case acc: 0.021998836
case acc: 0.023004506
top acc: 0.0166 ::: bot acc: 0.0533
top acc: 0.0106 ::: bot acc: 0.0389
top acc: 0.0145 ::: bot acc: 0.0663
top acc: 0.0188 ::: bot acc: 0.0544
top acc: 0.0165 ::: bot acc: 0.0406
top acc: 0.0313 ::: bot acc: 0.0313
current epoch: 37
train loss is 0.030824
average val loss: 0.037420, accuracy: 0.0374
average test loss: 0.037268, accuracy: 0.0375
case acc: 0.03716116
case acc: 0.032096557
case acc: 0.052338924
case acc: 0.04990635
case acc: 0.028021667
case acc: 0.02549146
top acc: 0.0181 ::: bot acc: 0.0564
top acc: 0.0143 ::: bot acc: 0.0500
top acc: 0.0231 ::: bot acc: 0.0840
top acc: 0.0320 ::: bot acc: 0.0696
top acc: 0.0109 ::: bot acc: 0.0524
top acc: 0.0180 ::: bot acc: 0.0450
current epoch: 38
train loss is 0.043413
average val loss: 0.025495, accuracy: 0.0253
average test loss: 0.023941, accuracy: 0.0241
case acc: 0.018039305
case acc: 0.015921019
case acc: 0.03490059
case acc: 0.03194172
case acc: 0.020695463
case acc: 0.023069903
top acc: 0.0228 ::: bot acc: 0.0255
top acc: 0.0134 ::: bot acc: 0.0264
top acc: 0.0143 ::: bot acc: 0.0623
top acc: 0.0159 ::: bot acc: 0.0508
top acc: 0.0248 ::: bot acc: 0.0323
top acc: 0.0336 ::: bot acc: 0.0290
current epoch: 39
train loss is 0.045967
average val loss: 0.035920, accuracy: 0.0361
average test loss: 0.035137, accuracy: 0.0352
case acc: 0.047022972
case acc: 0.039386675
case acc: 0.030546747
case acc: 0.017693602
case acc: 0.04028807
case acc: 0.03628446
top acc: 0.0728 ::: bot acc: 0.0245
top acc: 0.0598 ::: bot acc: 0.0202
top acc: 0.0561 ::: bot acc: 0.0155
top acc: 0.0297 ::: bot acc: 0.0101
top acc: 0.0658 ::: bot acc: 0.0149
top acc: 0.0631 ::: bot acc: 0.0146
current epoch: 40
train loss is 0.040946
average val loss: 0.047351, accuracy: 0.0475
average test loss: 0.047042, accuracy: 0.0470
case acc: 0.059145935
case acc: 0.057031512
case acc: 0.04703366
case acc: 0.031627495
case acc: 0.052012064
case acc: 0.035329774
top acc: 0.0849 ::: bot acc: 0.0366
top acc: 0.0775 ::: bot acc: 0.0378
top acc: 0.0813 ::: bot acc: 0.0141
top acc: 0.0480 ::: bot acc: 0.0150
top acc: 0.0786 ::: bot acc: 0.0244
top acc: 0.0618 ::: bot acc: 0.0142
current epoch: 41
train loss is 0.034135
average val loss: 0.059877, accuracy: 0.0600
average test loss: 0.059658, accuracy: 0.0599
case acc: 0.06454948
case acc: 0.07184422
case acc: 0.07219669
case acc: 0.049723953
case acc: 0.063349105
case acc: 0.037745267
top acc: 0.0903 ::: bot acc: 0.0420
top acc: 0.0923 ::: bot acc: 0.0526
top acc: 0.1072 ::: bot acc: 0.0377
top acc: 0.0671 ::: bot acc: 0.0310
top acc: 0.0905 ::: bot acc: 0.0346
top acc: 0.0649 ::: bot acc: 0.0153
current epoch: 42
train loss is 0.042537
average val loss: 0.065220, accuracy: 0.0653
average test loss: 0.065042, accuracy: 0.0653
case acc: 0.059605286
case acc: 0.076195285
case acc: 0.08622067
case acc: 0.06015563
case acc: 0.06790649
case acc: 0.04146232
top acc: 0.0854 ::: bot acc: 0.0370
top acc: 0.0967 ::: bot acc: 0.0569
top acc: 0.1212 ::: bot acc: 0.0518
top acc: 0.0779 ::: bot acc: 0.0408
top acc: 0.0953 ::: bot acc: 0.0388
top acc: 0.0694 ::: bot acc: 0.0175
current epoch: 43
train loss is 0.053542
average val loss: 0.027729, accuracy: 0.0279
average test loss: 0.026161, accuracy: 0.0257
case acc: 0.017245648
case acc: 0.026464071
case acc: 0.039354734
case acc: 0.019574687
case acc: 0.028510524
case acc: 0.02294047
top acc: 0.0286 ::: bot acc: 0.0198
top acc: 0.0462 ::: bot acc: 0.0087
top acc: 0.0711 ::: bot acc: 0.0115
top acc: 0.0330 ::: bot acc: 0.0091
top acc: 0.0495 ::: bot acc: 0.0124
top acc: 0.0306 ::: bot acc: 0.0318
current epoch: 44
train loss is 0.037606
average val loss: 0.024302, accuracy: 0.0244
average test loss: 0.022337, accuracy: 0.0221
case acc: 0.019721668
case acc: 0.018311284
case acc: 0.030770015
case acc: 0.015433487
case acc: 0.025189342
case acc: 0.023332596
top acc: 0.0182 ::: bot acc: 0.0304
top acc: 0.0352 ::: bot acc: 0.0065
top acc: 0.0565 ::: bot acc: 0.0153
top acc: 0.0251 ::: bot acc: 0.0127
top acc: 0.0437 ::: bot acc: 0.0143
top acc: 0.0379 ::: bot acc: 0.0244
current epoch: 45
train loss is 0.031005
average val loss: 0.022821, accuracy: 0.0228
average test loss: 0.020657, accuracy: 0.0206
case acc: 0.022644695
case acc: 0.014570328
case acc: 0.025370128
case acc: 0.013474282
case acc: 0.0229615
case acc: 0.024525138
top acc: 0.0149 ::: bot acc: 0.0364
top acc: 0.0251 ::: bot acc: 0.0146
top acc: 0.0403 ::: bot acc: 0.0291
top acc: 0.0161 ::: bot acc: 0.0216
top acc: 0.0381 ::: bot acc: 0.0189
top acc: 0.0433 ::: bot acc: 0.0191
current epoch: 46
train loss is 0.026213
average val loss: 0.023940, accuracy: 0.0240
average test loss: 0.022203, accuracy: 0.0225
case acc: 0.027055357
case acc: 0.016459065
case acc: 0.028165735
case acc: 0.018837105
case acc: 0.020764954
case acc: 0.02350299
top acc: 0.0137 ::: bot acc: 0.0435
top acc: 0.0126 ::: bot acc: 0.0276
top acc: 0.0198 ::: bot acc: 0.0496
top acc: 0.0075 ::: bot acc: 0.0354
top acc: 0.0282 ::: bot acc: 0.0288
top acc: 0.0392 ::: bot acc: 0.0232
current epoch: 47
train loss is 0.024808
average val loss: 0.030608, accuracy: 0.0306
average test loss: 0.029889, accuracy: 0.0303
case acc: 0.03315539
case acc: 0.02613916
case acc: 0.04220283
case acc: 0.034162927
case acc: 0.022748388
case acc: 0.023232779
top acc: 0.0159 ::: bot acc: 0.0515
top acc: 0.0112 ::: bot acc: 0.0427
top acc: 0.0164 ::: bot acc: 0.0721
top acc: 0.0178 ::: bot acc: 0.0531
top acc: 0.0144 ::: bot acc: 0.0428
top acc: 0.0261 ::: bot acc: 0.0363
current epoch: 48
train loss is 0.031571
average val loss: 0.034477, accuracy: 0.0343
average test loss: 0.034068, accuracy: 0.0343
case acc: 0.03089293
case acc: 0.03009562
case acc: 0.050832324
case acc: 0.04296103
case acc: 0.02595589
case acc: 0.024987709
top acc: 0.0148 ::: bot acc: 0.0486
top acc: 0.0132 ::: bot acc: 0.0476
top acc: 0.0220 ::: bot acc: 0.0823
top acc: 0.0254 ::: bot acc: 0.0625
top acc: 0.0112 ::: bot acc: 0.0492
top acc: 0.0189 ::: bot acc: 0.0438
current epoch: 49
train loss is 0.043006
average val loss: 0.023471, accuracy: 0.0233
average test loss: 0.021468, accuracy: 0.0212
case acc: 0.019489767
case acc: 0.014529
case acc: 0.028066095
case acc: 0.018101165
case acc: 0.0225118
case acc: 0.024391737
top acc: 0.0391 ::: bot acc: 0.0096
top acc: 0.0250 ::: bot acc: 0.0146
top acc: 0.0202 ::: bot acc: 0.0493
top acc: 0.0076 ::: bot acc: 0.0342
top acc: 0.0366 ::: bot acc: 0.0205
top acc: 0.0427 ::: bot acc: 0.0198
current epoch: 50
train loss is 0.040160
average val loss: 0.035184, accuracy: 0.0354
average test loss: 0.034427, accuracy: 0.0346
case acc: 0.047277153
case acc: 0.037523072
case acc: 0.03124131
case acc: 0.020216238
case acc: 0.038854636
case acc: 0.03228324
top acc: 0.0731 ::: bot acc: 0.0248
top acc: 0.0579 ::: bot acc: 0.0183
top acc: 0.0574 ::: bot acc: 0.0149
top acc: 0.0339 ::: bot acc: 0.0091
top acc: 0.0641 ::: bot acc: 0.0141
top acc: 0.0579 ::: bot acc: 0.0130

		{"drop_out": 0.4, "drop_out_mc": 0.15, "repeat_mc": 50, "hidden": 20, "embedding_size": 5, "batch": 512, "lag": 4}
{'generate_norm_params': 'v1', 'generate_tech_params': 'v3', 'generate_strat_params': None, 'generate_SD_params': 'v1', 'deal_with_abnormal_value': 'v2', 'labelling': 'v3', 'process_missing_value': 'v1', 'strategy_signal': None, 'normalize_without_1d_return': 'v1', 'technical_indication': 'v4', 'supply_and_demand': None, 'remove_unused_columns': 'v6', 'price_normalization': 'v3', 'scaling': None, 'construct': 'v4'}
LME_Co_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2009-01-01', '2009-07-01', '2014-07-01', '2015-01-01', '2015-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6780 6780 6780
1.8562728 -0.6288155 0.15869391 -0.16256663
Validation: 756 756 756
Testing: 774 774 774
pre-processing time: 0.00025773048400878906
the split date is 2009-07-01
net initializing with time: 0.0039865970611572266
preparing training and testing date with time: 2.384185791015625e-07
current epoch: 1
train loss is 0.433662
average val loss: 0.288573, accuracy: 0.2886
average test loss: 0.284902, accuracy: 0.2849
case acc: 0.22398554
case acc: 0.3678977
case acc: 0.260163
case acc: 0.118679725
case acc: 0.4391105
case acc: 0.29957658
top acc: 0.2368 ::: bot acc: 0.2096
top acc: 0.3865 ::: bot acc: 0.3495
top acc: 0.2876 ::: bot acc: 0.2344
top acc: 0.1386 ::: bot acc: 0.0976
top acc: 0.4594 ::: bot acc: 0.4177
top acc: 0.3149 ::: bot acc: 0.2826
current epoch: 2
train loss is 0.163374
average val loss: 0.087235, accuracy: 0.0886
average test loss: 0.086242, accuracy: 0.0871
case acc: 0.029100887
case acc: 0.113601044
case acc: 0.021558957
case acc: 0.13077462
case acc: 0.18099186
case acc: 0.046377756
top acc: 0.0168 ::: bot acc: 0.0432
top acc: 0.1324 ::: bot acc: 0.0951
top acc: 0.0390 ::: bot acc: 0.0151
top acc: 0.1110 ::: bot acc: 0.1515
top acc: 0.2011 ::: bot acc: 0.1598
top acc: 0.0618 ::: bot acc: 0.0295
current epoch: 3
train loss is 0.130990
average val loss: 0.082934, accuracy: 0.0828
average test loss: 0.083784, accuracy: 0.0848
case acc: 0.09287211
case acc: 0.039604202
case acc: 0.052277286
case acc: 0.18655504
case acc: 0.12102815
case acc: 0.01646203
top acc: 0.0801 ::: bot acc: 0.1071
top acc: 0.0587 ::: bot acc: 0.0210
top acc: 0.0265 ::: bot acc: 0.0773
top acc: 0.1672 ::: bot acc: 0.2069
top acc: 0.1409 ::: bot acc: 0.1001
top acc: 0.0068 ::: bot acc: 0.0300
current epoch: 4
train loss is 0.130900
average val loss: 0.126823, accuracy: 0.1272
average test loss: 0.124204, accuracy: 0.1244
case acc: 0.052007925
case acc: 0.1852177
case acc: 0.092064366
case acc: 0.042531073
case acc: 0.24778865
case acc: 0.1266113
top acc: 0.0648 ::: bot acc: 0.0379
top acc: 0.2045 ::: bot acc: 0.1663
top acc: 0.1199 ::: bot acc: 0.0659
top acc: 0.0243 ::: bot acc: 0.0622
top acc: 0.2675 ::: bot acc: 0.2270
top acc: 0.1422 ::: bot acc: 0.1097
current epoch: 5
train loss is 0.097026
average val loss: 0.071769, accuracy: 0.0730
average test loss: 0.071555, accuracy: 0.0731
case acc: 0.059582837
case acc: 0.06806695
case acc: 0.024209255
case acc: 0.14758255
case acc: 0.12128002
case acc: 0.01797407
top acc: 0.0467 ::: bot acc: 0.0737
top acc: 0.0874 ::: bot acc: 0.0491
top acc: 0.0134 ::: bot acc: 0.0419
top acc: 0.1285 ::: bot acc: 0.1676
top acc: 0.1409 ::: bot acc: 0.1005
top acc: 0.0292 ::: bot acc: 0.0098
current epoch: 6
train loss is 0.093419
average val loss: 0.066903, accuracy: 0.0678
average test loss: 0.066995, accuracy: 0.0684
case acc: 0.067825094
case acc: 0.048787665
case acc: 0.028827934
case acc: 0.15005565
case acc: 0.10089951
case acc: 0.013803174
top acc: 0.0549 ::: bot acc: 0.0818
top acc: 0.0682 ::: bot acc: 0.0298
top acc: 0.0121 ::: bot acc: 0.0495
top acc: 0.1311 ::: bot acc: 0.1700
top acc: 0.1205 ::: bot acc: 0.0802
top acc: 0.0216 ::: bot acc: 0.0120
current epoch: 7
train loss is 0.099329
average val loss: 0.079041, accuracy: 0.0795
average test loss: 0.076987, accuracy: 0.0767
case acc: 0.010419249
case acc: 0.10938845
case acc: 0.042476863
case acc: 0.08351437
case acc: 0.1473087
case acc: 0.06684117
top acc: 0.0101 ::: bot acc: 0.0170
top acc: 0.1288 ::: bot acc: 0.0904
top acc: 0.0691 ::: bot acc: 0.0187
top acc: 0.0646 ::: bot acc: 0.1034
top acc: 0.1669 ::: bot acc: 0.1266
top acc: 0.0824 ::: bot acc: 0.0499
current epoch: 8
train loss is 0.079920
average val loss: 0.059880, accuracy: 0.0614
average test loss: 0.058971, accuracy: 0.0603
case acc: 0.043486886
case acc: 0.06413789
case acc: 0.019676475
case acc: 0.121097356
case acc: 0.088646024
case acc: 0.024869317
top acc: 0.0305 ::: bot acc: 0.0575
top acc: 0.0836 ::: bot acc: 0.0451
top acc: 0.0306 ::: bot acc: 0.0236
top acc: 0.1022 ::: bot acc: 0.1410
top acc: 0.1082 ::: bot acc: 0.0680
top acc: 0.0382 ::: bot acc: 0.0125
current epoch: 9
train loss is 0.075021
average val loss: 0.053608, accuracy: 0.0553
average test loss: 0.052985, accuracy: 0.0544
case acc: 0.052083705
case acc: 0.04718679
case acc: 0.020284798
case acc: 0.12598185
case acc: 0.0643823
case acc: 0.016729735
top acc: 0.0390 ::: bot acc: 0.0660
top acc: 0.0667 ::: bot acc: 0.0281
top acc: 0.0234 ::: bot acc: 0.0308
top acc: 0.1072 ::: bot acc: 0.1457
top acc: 0.0838 ::: bot acc: 0.0438
top acc: 0.0277 ::: bot acc: 0.0093
current epoch: 10
train loss is 0.074824
average val loss: 0.052254, accuracy: 0.0536
average test loss: 0.051037, accuracy: 0.0520
case acc: 0.036964778
case acc: 0.0566772
case acc: 0.021810967
case acc: 0.108637154
case acc: 0.062351383
case acc: 0.025783336
top acc: 0.0238 ::: bot acc: 0.0508
top acc: 0.0762 ::: bot acc: 0.0375
top acc: 0.0393 ::: bot acc: 0.0159
top acc: 0.0900 ::: bot acc: 0.1282
top acc: 0.0817 ::: bot acc: 0.0418
top acc: 0.0395 ::: bot acc: 0.0130
current epoch: 11
train loss is 0.070176
average val loss: 0.049121, accuracy: 0.0503
average test loss: 0.047800, accuracy: 0.0486
case acc: 0.032691933
case acc: 0.057200618
case acc: 0.024116747
case acc: 0.10285756
case acc: 0.04877373
case acc: 0.02572212
top acc: 0.0196 ::: bot acc: 0.0465
top acc: 0.0768 ::: bot acc: 0.0380
top acc: 0.0444 ::: bot acc: 0.0130
top acc: 0.0843 ::: bot acc: 0.1224
top acc: 0.0679 ::: bot acc: 0.0286
top acc: 0.0395 ::: bot acc: 0.0129
current epoch: 12
train loss is 0.065450
average val loss: 0.046858, accuracy: 0.0478
average test loss: 0.045454, accuracy: 0.0459
case acc: 0.027077269
case acc: 0.0597212
case acc: 0.028091306
case acc: 0.09539858
case acc: 0.03826572
case acc: 0.026971167
top acc: 0.0142 ::: bot acc: 0.0408
top acc: 0.0794 ::: bot acc: 0.0405
top acc: 0.0511 ::: bot acc: 0.0114
top acc: 0.0769 ::: bot acc: 0.1149
top acc: 0.0567 ::: bot acc: 0.0194
top acc: 0.0410 ::: bot acc: 0.0136
current epoch: 13
train loss is 0.060448
average val loss: 0.043884, accuracy: 0.0448
average test loss: 0.042482, accuracy: 0.0428
case acc: 0.025519071
case acc: 0.056586035
case acc: 0.03002682
case acc: 0.09029621
case acc: 0.028570112
case acc: 0.026088083
top acc: 0.0127 ::: bot acc: 0.0392
top acc: 0.0763 ::: bot acc: 0.0373
top acc: 0.0540 ::: bot acc: 0.0115
top acc: 0.0717 ::: bot acc: 0.1098
top acc: 0.0455 ::: bot acc: 0.0127
top acc: 0.0400 ::: bot acc: 0.0131
current epoch: 14
train loss is 0.057508
average val loss: 0.043057, accuracy: 0.0437
average test loss: 0.041467, accuracy: 0.0415
case acc: 0.01953102
case acc: 0.057221953
case acc: 0.036002208
case acc: 0.07869517
case acc: 0.027165065
case acc: 0.030482538
top acc: 0.0078 ::: bot acc: 0.0326
top acc: 0.0769 ::: bot acc: 0.0379
top acc: 0.0617 ::: bot acc: 0.0139
top acc: 0.0601 ::: bot acc: 0.0983
top acc: 0.0438 ::: bot acc: 0.0118
top acc: 0.0452 ::: bot acc: 0.0161
current epoch: 15
train loss is 0.055827
average val loss: 0.042617, accuracy: 0.0431
average test loss: 0.040806, accuracy: 0.0407
case acc: 0.01526315
case acc: 0.055956785
case acc: 0.042033877
case acc: 0.066406764
case acc: 0.028968297
case acc: 0.035316143
top acc: 0.0058 ::: bot acc: 0.0272
top acc: 0.0757 ::: bot acc: 0.0366
top acc: 0.0687 ::: bot acc: 0.0181
top acc: 0.0477 ::: bot acc: 0.0860
top acc: 0.0461 ::: bot acc: 0.0127
top acc: 0.0505 ::: bot acc: 0.0201
current epoch: 16
train loss is 0.052986
average val loss: 0.040463, accuracy: 0.0409
average test loss: 0.038642, accuracy: 0.0385
case acc: 0.01566114
case acc: 0.048379097
case acc: 0.043136578
case acc: 0.05860743
case acc: 0.029426068
case acc: 0.035556592
top acc: 0.0059 ::: bot acc: 0.0277
top acc: 0.0681 ::: bot acc: 0.0290
top acc: 0.0700 ::: bot acc: 0.0189
top acc: 0.0400 ::: bot acc: 0.0782
top acc: 0.0467 ::: bot acc: 0.0129
top acc: 0.0507 ::: bot acc: 0.0202
current epoch: 17
train loss is 0.049158
average val loss: 0.035946, accuracy: 0.0365
average test loss: 0.034414, accuracy: 0.0344
case acc: 0.021934675
case acc: 0.034112938
case acc: 0.037802108
case acc: 0.05763316
case acc: 0.025315115
case acc: 0.029409302
top acc: 0.0094 ::: bot acc: 0.0354
top acc: 0.0537 ::: bot acc: 0.0152
top acc: 0.0639 ::: bot acc: 0.0149
top acc: 0.0390 ::: bot acc: 0.0772
top acc: 0.0414 ::: bot acc: 0.0110
top acc: 0.0440 ::: bot acc: 0.0153
current epoch: 18
train loss is 0.046152
average val loss: 0.031416, accuracy: 0.0324
average test loss: 0.030394, accuracy: 0.0305
case acc: 0.031970587
case acc: 0.020200133
case acc: 0.030280646
case acc: 0.06011308
case acc: 0.019406807
case acc: 0.021202099
top acc: 0.0189 ::: bot acc: 0.0456
top acc: 0.0374 ::: bot acc: 0.0061
top acc: 0.0545 ::: bot acc: 0.0114
top acc: 0.0414 ::: bot acc: 0.0797
top acc: 0.0327 ::: bot acc: 0.0107
top acc: 0.0342 ::: bot acc: 0.0105
current epoch: 19
train loss is 0.043654
average val loss: 0.028787, accuracy: 0.0301
average test loss: 0.028555, accuracy: 0.0288
case acc: 0.04027748
case acc: 0.014990251
case acc: 0.02484645
case acc: 0.062516935
case acc: 0.015067611
case acc: 0.014958186
top acc: 0.0273 ::: bot acc: 0.0539
top acc: 0.0249 ::: bot acc: 0.0144
top acc: 0.0458 ::: bot acc: 0.0123
top acc: 0.0437 ::: bot acc: 0.0822
top acc: 0.0231 ::: bot acc: 0.0169
top acc: 0.0251 ::: bot acc: 0.0100
current epoch: 20
train loss is 0.042868
average val loss: 0.027967, accuracy: 0.0294
average test loss: 0.028330, accuracy: 0.0284
case acc: 0.043941256
case acc: 0.0145001095
case acc: 0.022354478
case acc: 0.062352993
case acc: 0.014700653
case acc: 0.012664992
top acc: 0.0309 ::: bot acc: 0.0576
top acc: 0.0191 ::: bot acc: 0.0201
top acc: 0.0407 ::: bot acc: 0.0150
top acc: 0.0435 ::: bot acc: 0.0820
top acc: 0.0145 ::: bot acc: 0.0254
top acc: 0.0193 ::: bot acc: 0.0141
current epoch: 21
train loss is 0.042059
average val loss: 0.026921, accuracy: 0.0282
average test loss: 0.027255, accuracy: 0.0272
case acc: 0.040485352
case acc: 0.014618035
case acc: 0.023005994
case acc: 0.056615166
case acc: 0.015574575
case acc: 0.012804852
top acc: 0.0274 ::: bot acc: 0.0542
top acc: 0.0227 ::: bot acc: 0.0166
top acc: 0.0421 ::: bot acc: 0.0141
top acc: 0.0379 ::: bot acc: 0.0763
top acc: 0.0110 ::: bot acc: 0.0289
top acc: 0.0198 ::: bot acc: 0.0137
current epoch: 22
train loss is 0.041310
average val loss: 0.025791, accuracy: 0.0268
average test loss: 0.025624, accuracy: 0.0253
case acc: 0.03250609
case acc: 0.016725723
case acc: 0.026153708
case acc: 0.046587974
case acc: 0.015139544
case acc: 0.01487765
top acc: 0.0194 ::: bot acc: 0.0462
top acc: 0.0310 ::: bot acc: 0.0085
top acc: 0.0482 ::: bot acc: 0.0114
top acc: 0.0284 ::: bot acc: 0.0659
top acc: 0.0126 ::: bot acc: 0.0273
top acc: 0.0248 ::: bot acc: 0.0103
current epoch: 23
train loss is 0.040120
average val loss: 0.025608, accuracy: 0.0261
average test loss: 0.024798, accuracy: 0.0243
case acc: 0.023792047
case acc: 0.022506475
case acc: 0.031044165
case acc: 0.03553412
case acc: 0.014420973
case acc: 0.018660586
top acc: 0.0110 ::: bot acc: 0.0374
top acc: 0.0408 ::: bot acc: 0.0062
top acc: 0.0556 ::: bot acc: 0.0113
top acc: 0.0185 ::: bot acc: 0.0542
top acc: 0.0166 ::: bot acc: 0.0233
top acc: 0.0308 ::: bot acc: 0.0098
current epoch: 24
train loss is 0.039323
average val loss: 0.026818, accuracy: 0.0267
average test loss: 0.025269, accuracy: 0.0248
case acc: 0.015472071
case acc: 0.031282324
case acc: 0.038496517
case acc: 0.023549916
case acc: 0.015473268
case acc: 0.024580386
top acc: 0.0056 ::: bot acc: 0.0276
top acc: 0.0508 ::: bot acc: 0.0127
top acc: 0.0648 ::: bot acc: 0.0153
top acc: 0.0104 ::: bot acc: 0.0403
top acc: 0.0242 ::: bot acc: 0.0158
top acc: 0.0384 ::: bot acc: 0.0123
current epoch: 25
train loss is 0.038824
average val loss: 0.029828, accuracy: 0.0292
average test loss: 0.027339, accuracy: 0.0267
case acc: 0.010767942
case acc: 0.038036227
case acc: 0.045996446
case acc: 0.014813818
case acc: 0.020136056
case acc: 0.030572819
top acc: 0.0076 ::: bot acc: 0.0195
top acc: 0.0578 ::: bot acc: 0.0189
top acc: 0.0732 ::: bot acc: 0.0209
top acc: 0.0123 ::: bot acc: 0.0262
top acc: 0.0341 ::: bot acc: 0.0102
top acc: 0.0454 ::: bot acc: 0.0163
current epoch: 26
train loss is 0.037281
average val loss: 0.028760, accuracy: 0.0281
average test loss: 0.026217, accuracy: 0.0256
case acc: 0.012007067
case acc: 0.03327124
case acc: 0.044787508
case acc: 0.013859928
case acc: 0.021606637
case acc: 0.028246433
top acc: 0.0063 ::: bot acc: 0.0221
top acc: 0.0529 ::: bot acc: 0.0144
top acc: 0.0719 ::: bot acc: 0.0199
top acc: 0.0172 ::: bot acc: 0.0211
top acc: 0.0363 ::: bot acc: 0.0101
top acc: 0.0428 ::: bot acc: 0.0145
current epoch: 27
train loss is 0.035097
average val loss: 0.026417, accuracy: 0.0260
average test loss: 0.024061, accuracy: 0.0236
case acc: 0.015693476
case acc: 0.025108116
case acc: 0.04078808
case acc: 0.013956725
case acc: 0.022083627
case acc: 0.023781028
top acc: 0.0056 ::: bot acc: 0.0280
top acc: 0.0439 ::: bot acc: 0.0078
top acc: 0.0674 ::: bot acc: 0.0169
top acc: 0.0195 ::: bot acc: 0.0188
top acc: 0.0371 ::: bot acc: 0.0101
top acc: 0.0375 ::: bot acc: 0.0119
current epoch: 28
train loss is 0.033209
average val loss: 0.024367, accuracy: 0.0243
average test loss: 0.022324, accuracy: 0.0220
case acc: 0.021187047
case acc: 0.017557103
case acc: 0.035830896
case acc: 0.014249615
case acc: 0.023701856
case acc: 0.01951054
top acc: 0.0086 ::: bot acc: 0.0347
top acc: 0.0328 ::: bot acc: 0.0075
top acc: 0.0617 ::: bot acc: 0.0135
top acc: 0.0214 ::: bot acc: 0.0169
top acc: 0.0394 ::: bot acc: 0.0103
top acc: 0.0320 ::: bot acc: 0.0100
current epoch: 29
train loss is 0.032921
average val loss: 0.024916, accuracy: 0.0251
average test loss: 0.023076, accuracy: 0.0229
case acc: 0.02533166
case acc: 0.014504214
case acc: 0.03281702
case acc: 0.015751915
case acc: 0.030734643
case acc: 0.01846276
top acc: 0.0124 ::: bot acc: 0.0390
top acc: 0.0213 ::: bot acc: 0.0178
top acc: 0.0580 ::: bot acc: 0.0119
top acc: 0.0266 ::: bot acc: 0.0121
top acc: 0.0484 ::: bot acc: 0.0134
top acc: 0.0306 ::: bot acc: 0.0097
current epoch: 30
train loss is 0.035382
average val loss: 0.027783, accuracy: 0.0282
average test loss: 0.026460, accuracy: 0.0263
case acc: 0.032490972
case acc: 0.020980459
case acc: 0.027967233
case acc: 0.017421803
case acc: 0.04140629
case acc: 0.01740162
top acc: 0.0194 ::: bot acc: 0.0463
top acc: 0.0083 ::: bot acc: 0.0368
top acc: 0.0513 ::: bot acc: 0.0107
top acc: 0.0304 ::: bot acc: 0.0097
top acc: 0.0604 ::: bot acc: 0.0215
top acc: 0.0292 ::: bot acc: 0.0095
current epoch: 31
train loss is 0.046619
average val loss: 0.044767, accuracy: 0.0455
average test loss: 0.047347, accuracy: 0.0484
case acc: 0.08611042
case acc: 0.087271295
case acc: 0.03410219
case acc: 0.03334798
case acc: 0.016556371
case acc: 0.032824703
top acc: 0.0729 ::: bot acc: 0.1000
top acc: 0.0675 ::: bot acc: 0.1066
top acc: 0.0142 ::: bot acc: 0.0570
top acc: 0.0168 ::: bot acc: 0.0516
top acc: 0.0272 ::: bot acc: 0.0132
top acc: 0.0169 ::: bot acc: 0.0499
current epoch: 32
train loss is 0.080669
average val loss: 0.110481, accuracy: 0.1105
average test loss: 0.114546, accuracy: 0.1145
case acc: 0.15446214
case acc: 0.16588007
case acc: 0.10091959
case acc: 0.10470251
case acc: 0.06336389
case acc: 0.097937934
top acc: 0.1411 ::: bot acc: 0.1683
top acc: 0.1461 ::: bot acc: 0.1853
top acc: 0.0728 ::: bot acc: 0.1279
top acc: 0.0861 ::: bot acc: 0.1240
top acc: 0.0441 ::: bot acc: 0.0839
top acc: 0.0817 ::: bot acc: 0.1152
current epoch: 33
train loss is 0.079939
average val loss: 0.053094, accuracy: 0.0535
average test loss: 0.056748, accuracy: 0.0568
case acc: 0.086090505
case acc: 0.084205754
case acc: 0.042337224
case acc: 0.058475338
case acc: 0.030389372
case acc: 0.039525174
top acc: 0.0728 ::: bot acc: 0.0999
top acc: 0.0645 ::: bot acc: 0.1036
top acc: 0.0186 ::: bot acc: 0.0672
top acc: 0.0399 ::: bot acc: 0.0777
top acc: 0.0118 ::: bot acc: 0.0505
top acc: 0.0235 ::: bot acc: 0.0566
current epoch: 34
train loss is 0.048896
average val loss: 0.042339, accuracy: 0.0433
average test loss: 0.045778, accuracy: 0.0460
case acc: 0.06446925
case acc: 0.044447314
case acc: 0.0313652
case acc: 0.05994005
case acc: 0.04547073
case acc: 0.03058523
top acc: 0.0513 ::: bot acc: 0.0782
top acc: 0.0249 ::: bot acc: 0.0637
top acc: 0.0130 ::: bot acc: 0.0535
top acc: 0.0413 ::: bot acc: 0.0792
top acc: 0.0263 ::: bot acc: 0.0659
top acc: 0.0149 ::: bot acc: 0.0475
current epoch: 35
train loss is 0.037221
average val loss: 0.022651, accuracy: 0.0239
average test loss: 0.023706, accuracy: 0.0236
case acc: 0.030127898
case acc: 0.014486939
case acc: 0.02001518
case acc: 0.037558794
case acc: 0.02752989
case acc: 0.0120846275
top acc: 0.0170 ::: bot acc: 0.0438
top acc: 0.0178 ::: bot acc: 0.0214
top acc: 0.0309 ::: bot acc: 0.0245
top acc: 0.0204 ::: bot acc: 0.0560
top acc: 0.0095 ::: bot acc: 0.0474
top acc: 0.0147 ::: bot acc: 0.0188
current epoch: 36
train loss is 0.033752
average val loss: 0.022135, accuracy: 0.0217
average test loss: 0.020536, accuracy: 0.0198
case acc: 0.011390936
case acc: 0.023681656
case acc: 0.028315801
case acc: 0.01834584
case acc: 0.014290026
case acc: 0.022778744
top acc: 0.0065 ::: bot acc: 0.0210
top acc: 0.0422 ::: bot acc: 0.0068
top acc: 0.0518 ::: bot acc: 0.0108
top acc: 0.0095 ::: bot acc: 0.0327
top acc: 0.0166 ::: bot acc: 0.0230
top acc: 0.0364 ::: bot acc: 0.0110
current epoch: 37
train loss is 0.032641
average val loss: 0.022633, accuracy: 0.0220
average test loss: 0.020646, accuracy: 0.0199
case acc: 0.010635938
case acc: 0.02670137
case acc: 0.029485004
case acc: 0.015091427
case acc: 0.014320652
case acc: 0.023129016
top acc: 0.0076 ::: bot acc: 0.0192
top acc: 0.0457 ::: bot acc: 0.0089
top acc: 0.0535 ::: bot acc: 0.0109
top acc: 0.0112 ::: bot acc: 0.0270
top acc: 0.0208 ::: bot acc: 0.0189
top acc: 0.0368 ::: bot acc: 0.0112
current epoch: 38
train loss is 0.032232
average val loss: 0.023206, accuracy: 0.0225
average test loss: 0.021027, accuracy: 0.0202
case acc: 0.010312361
case acc: 0.029979896
case acc: 0.030625857
case acc: 0.013743724
case acc: 0.014357565
case acc: 0.022259593
top acc: 0.0087 ::: bot acc: 0.0182
top acc: 0.0493 ::: bot acc: 0.0115
top acc: 0.0550 ::: bot acc: 0.0112
top acc: 0.0157 ::: bot acc: 0.0222
top acc: 0.0210 ::: bot acc: 0.0187
top acc: 0.0357 ::: bot acc: 0.0108
current epoch: 39
train loss is 0.032192
average val loss: 0.027293, accuracy: 0.0267
average test loss: 0.024447, accuracy: 0.0237
case acc: 0.010019395
case acc: 0.0380668
case acc: 0.036405757
case acc: 0.015507486
case acc: 0.01646569
case acc: 0.025922505
top acc: 0.0152 ::: bot acc: 0.0117
top acc: 0.0578 ::: bot acc: 0.0188
top acc: 0.0624 ::: bot acc: 0.0139
top acc: 0.0262 ::: bot acc: 0.0120
top acc: 0.0270 ::: bot acc: 0.0133
top acc: 0.0402 ::: bot acc: 0.0128
current epoch: 40
train loss is 0.032532
average val loss: 0.032645, accuracy: 0.0323
average test loss: 0.029171, accuracy: 0.0285
case acc: 0.011829818
case acc: 0.043670826
case acc: 0.042699695
case acc: 0.021919066
case acc: 0.021217009
case acc: 0.029939651
top acc: 0.0206 ::: bot acc: 0.0068
top acc: 0.0635 ::: bot acc: 0.0243
top acc: 0.0696 ::: bot acc: 0.0184
top acc: 0.0378 ::: bot acc: 0.0081
top acc: 0.0358 ::: bot acc: 0.0101
top acc: 0.0448 ::: bot acc: 0.0156
current epoch: 41
train loss is 0.031849
average val loss: 0.033398, accuracy: 0.0330
average test loss: 0.029874, accuracy: 0.0292
case acc: 0.011067455
case acc: 0.04029251
case acc: 0.043267436
case acc: 0.02710671
case acc: 0.025165576
case acc: 0.028598456
top acc: 0.0187 ::: bot acc: 0.0083
top acc: 0.0600 ::: bot acc: 0.0210
top acc: 0.0702 ::: bot acc: 0.0188
top acc: 0.0440 ::: bot acc: 0.0112
top acc: 0.0414 ::: bot acc: 0.0107
top acc: 0.0433 ::: bot acc: 0.0146
current epoch: 42
train loss is 0.029650
average val loss: 0.030290, accuracy: 0.0299
average test loss: 0.027036, accuracy: 0.0264
case acc: 0.009997826
case acc: 0.029534247
case acc: 0.038809024
case acc: 0.028602514
case acc: 0.027816843
case acc: 0.023373678
top acc: 0.0109 ::: bot acc: 0.0160
top acc: 0.0488 ::: bot acc: 0.0112
top acc: 0.0652 ::: bot acc: 0.0155
top acc: 0.0457 ::: bot acc: 0.0123
top acc: 0.0449 ::: bot acc: 0.0117
top acc: 0.0371 ::: bot acc: 0.0114
current epoch: 43
train loss is 0.028236
average val loss: 0.028067, accuracy: 0.0280
average test loss: 0.025331, accuracy: 0.0248
case acc: 0.01354672
case acc: 0.018292338
case acc: 0.033624537
case acc: 0.030167
case acc: 0.033894297
case acc: 0.019095983
top acc: 0.0054 ::: bot acc: 0.0248
top acc: 0.0341 ::: bot acc: 0.0069
top acc: 0.0589 ::: bot acc: 0.0124
top acc: 0.0474 ::: bot acc: 0.0135
top acc: 0.0519 ::: bot acc: 0.0158
top acc: 0.0316 ::: bot acc: 0.0095
current epoch: 44
train loss is 0.031752
average val loss: 0.027262, accuracy: 0.0278
average test loss: 0.025646, accuracy: 0.0255
case acc: 0.024618948
case acc: 0.01684004
case acc: 0.025750412
case acc: 0.028877862
case acc: 0.042032026
case acc: 0.014635783
top acc: 0.0117 ::: bot acc: 0.0382
top acc: 0.0108 ::: bot acc: 0.0294
top acc: 0.0476 ::: bot acc: 0.0114
top acc: 0.0460 ::: bot acc: 0.0125
top acc: 0.0610 ::: bot acc: 0.0222
top acc: 0.0246 ::: bot acc: 0.0102
current epoch: 45
train loss is 0.048495
average val loss: 0.063418, accuracy: 0.0633
average test loss: 0.067014, accuracy: 0.0671
case acc: 0.10590946
case acc: 0.108674265
case acc: 0.060545035
case acc: 0.04428796
case acc: 0.019563045
case acc: 0.063677296
top acc: 0.0927 ::: bot acc: 0.1196
top acc: 0.0889 ::: bot acc: 0.1281
top acc: 0.0331 ::: bot acc: 0.0872
top acc: 0.0266 ::: bot acc: 0.0631
top acc: 0.0070 ::: bot acc: 0.0367
top acc: 0.0474 ::: bot acc: 0.0809
current epoch: 46
train loss is 0.087239
average val loss: 0.060438, accuracy: 0.0603
average test loss: 0.064037, accuracy: 0.0641
case acc: 0.09941453
case acc: 0.10151204
case acc: 0.058731936
case acc: 0.047107555
case acc: 0.020071909
case acc: 0.057895113
top acc: 0.0862 ::: bot acc: 0.1132
top acc: 0.0818 ::: bot acc: 0.1209
top acc: 0.0315 ::: bot acc: 0.0853
top acc: 0.0292 ::: bot acc: 0.0659
top acc: 0.0069 ::: bot acc: 0.0375
top acc: 0.0416 ::: bot acc: 0.0750
current epoch: 47
train loss is 0.059290
average val loss: 0.041235, accuracy: 0.0416
average test loss: 0.044718, accuracy: 0.0449
case acc: 0.069317885
case acc: 0.054965913
case acc: 0.03865695
case acc: 0.04124705
case acc: 0.025889752
case acc: 0.03928583
top acc: 0.0561 ::: bot acc: 0.0830
top acc: 0.0352 ::: bot acc: 0.0743
top acc: 0.0164 ::: bot acc: 0.0628
top acc: 0.0238 ::: bot acc: 0.0598
top acc: 0.0083 ::: bot acc: 0.0455
top acc: 0.0233 ::: bot acc: 0.0563
current epoch: 48
train loss is 0.039795
average val loss: 0.026778, accuracy: 0.0279
average test loss: 0.029484, accuracy: 0.0298
case acc: 0.044265766
case acc: 0.021351626
case acc: 0.025276938
case acc: 0.035675995
case acc: 0.028800055
case acc: 0.023260491
top acc: 0.0311 ::: bot acc: 0.0580
top acc: 0.0081 ::: bot acc: 0.0374
top acc: 0.0132 ::: bot acc: 0.0443
top acc: 0.0190 ::: bot acc: 0.0539
top acc: 0.0106 ::: bot acc: 0.0487
top acc: 0.0089 ::: bot acc: 0.0395
current epoch: 49
train loss is 0.032396
average val loss: 0.016973, accuracy: 0.0171
average test loss: 0.016384, accuracy: 0.0163
case acc: 0.018457532
case acc: 0.014893813
case acc: 0.020751972
case acc: 0.01630901
case acc: 0.0141312
case acc: 0.013456007
top acc: 0.0067 ::: bot acc: 0.0315
top acc: 0.0242 ::: bot acc: 0.0149
top acc: 0.0356 ::: bot acc: 0.0198
top acc: 0.0098 ::: bot acc: 0.0295
top acc: 0.0188 ::: bot acc: 0.0208
top acc: 0.0220 ::: bot acc: 0.0118
current epoch: 50
train loss is 0.027814
average val loss: 0.017179, accuracy: 0.0177
average test loss: 0.017044, accuracy: 0.0174
case acc: 0.02361006
case acc: 0.016008168
case acc: 0.019958604
case acc: 0.015938794
case acc: 0.0159517
case acc: 0.012796594
top acc: 0.0107 ::: bot acc: 0.0372
top acc: 0.0120 ::: bot acc: 0.0275
top acc: 0.0304 ::: bot acc: 0.0250
top acc: 0.0100 ::: bot acc: 0.0288
top acc: 0.0258 ::: bot acc: 0.0142
top acc: 0.0202 ::: bot acc: 0.0133
LME_Co_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2009-07-01', '2010-01-01', '2015-01-01', '2015-07-01', '2016-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6804 6804 6804
1.8562728 -0.6288155 0.12137239 -0.16228472
Validation: 762 762 762
Testing: 744 744 744
pre-processing time: 0.0002498626708984375
the split date is 2010-01-01
net initializing with time: 0.11371111869812012
preparing training and testing date with time: 2.384185791015625e-07
current epoch: 1
train loss is 0.166971
average val loss: 0.038839, accuracy: 0.0386
average test loss: 0.040810, accuracy: 0.0409
case acc: 0.030177195
case acc: 0.01634293
case acc: 0.03792255
case acc: 0.025446553
case acc: 0.028854415
case acc: 0.10642692
top acc: 0.0141 ::: bot acc: 0.0479
top acc: 0.0280 ::: bot acc: 0.0137
top acc: 0.0688 ::: bot acc: 0.0122
top acc: 0.0169 ::: bot acc: 0.0427
top acc: 0.0493 ::: bot acc: 0.0111
top acc: 0.1387 ::: bot acc: 0.0762
current epoch: 2
train loss is 0.061546
average val loss: 0.095496, accuracy: 0.0951
average test loss: 0.097017, accuracy: 0.0977
case acc: 0.14208694
case acc: 0.107882306
case acc: 0.086174436
case acc: 0.1277433
case acc: 0.09269694
case acc: 0.029339481
top acc: 0.1184 ::: bot acc: 0.1638
top acc: 0.0877 ::: bot acc: 0.1269
top acc: 0.0498 ::: bot acc: 0.1233
top acc: 0.0991 ::: bot acc: 0.1550
top acc: 0.0694 ::: bot acc: 0.1166
top acc: 0.0174 ::: bot acc: 0.0488
current epoch: 3
train loss is 0.077552
average val loss: 0.134437, accuracy: 0.1344
average test loss: 0.135427, accuracy: 0.1355
case acc: 0.17649932
case acc: 0.14380704
case acc: 0.12698923
case acc: 0.16591151
case acc: 0.130807
case acc: 0.06925476
top acc: 0.1524 ::: bot acc: 0.1985
top acc: 0.1236 ::: bot acc: 0.1632
top acc: 0.0912 ::: bot acc: 0.1637
top acc: 0.1383 ::: bot acc: 0.1926
top acc: 0.1082 ::: bot acc: 0.1538
top acc: 0.0403 ::: bot acc: 0.0969
current epoch: 4
train loss is 0.091977
average val loss: 0.116841, accuracy: 0.1168
average test loss: 0.117738, accuracy: 0.1179
case acc: 0.15370001
case acc: 0.12277572
case acc: 0.11015317
case acc: 0.14986883
case acc: 0.111526765
case acc: 0.059400238
top acc: 0.1294 ::: bot acc: 0.1759
top acc: 0.1026 ::: bot acc: 0.1423
top acc: 0.0745 ::: bot acc: 0.1467
top acc: 0.1228 ::: bot acc: 0.1763
top acc: 0.0892 ::: bot acc: 0.1342
top acc: 0.0317 ::: bot acc: 0.0863
current epoch: 5
train loss is 0.098184
average val loss: 0.059022, accuracy: 0.0586
average test loss: 0.060682, accuracy: 0.0613
case acc: 0.089276485
case acc: 0.060280398
case acc: 0.052755628
case acc: 0.09203967
case acc: 0.050790027
case acc: 0.02242685
top acc: 0.0649 ::: bot acc: 0.1115
top acc: 0.0399 ::: bot acc: 0.0798
top acc: 0.0197 ::: bot acc: 0.0880
top acc: 0.0648 ::: bot acc: 0.1185
top acc: 0.0285 ::: bot acc: 0.0737
top acc: 0.0238 ::: bot acc: 0.0348
current epoch: 6
train loss is 0.067649
average val loss: 0.075386, accuracy: 0.0753
average test loss: 0.076510, accuracy: 0.0768
case acc: 0.10158617
case acc: 0.07433598
case acc: 0.07010326
case acc: 0.11011667
case acc: 0.06671491
case acc: 0.038045604
top acc: 0.0772 ::: bot acc: 0.1238
top acc: 0.0540 ::: bot acc: 0.0939
top acc: 0.0346 ::: bot acc: 0.1067
top acc: 0.0831 ::: bot acc: 0.1364
top acc: 0.0443 ::: bot acc: 0.0895
top acc: 0.0168 ::: bot acc: 0.0617
current epoch: 7
train loss is 0.067607
average val loss: 0.072252, accuracy: 0.0722
average test loss: 0.073298, accuracy: 0.0735
case acc: 0.09342458
case acc: 0.06789481
case acc: 0.068153195
case acc: 0.10725337
case acc: 0.06188153
case acc: 0.04250477
top acc: 0.0691 ::: bot acc: 0.1157
top acc: 0.0475 ::: bot acc: 0.0875
top acc: 0.0329 ::: bot acc: 0.1046
top acc: 0.0805 ::: bot acc: 0.1333
top acc: 0.0396 ::: bot acc: 0.0845
top acc: 0.0191 ::: bot acc: 0.0672
current epoch: 8
train loss is 0.062985
average val loss: 0.068281, accuracy: 0.0682
average test loss: 0.069280, accuracy: 0.0694
case acc: 0.084657185
case acc: 0.06078493
case acc: 0.06535284
case acc: 0.10386333
case acc: 0.056141343
case acc: 0.045684196
top acc: 0.0602 ::: bot acc: 0.1070
top acc: 0.0404 ::: bot acc: 0.0805
top acc: 0.0305 ::: bot acc: 0.1017
top acc: 0.0772 ::: bot acc: 0.1299
top acc: 0.0339 ::: bot acc: 0.0787
top acc: 0.0209 ::: bot acc: 0.0710
current epoch: 9
train loss is 0.055743
average val loss: 0.065543, accuracy: 0.0655
average test loss: 0.066498, accuracy: 0.0666
case acc: 0.077603996
case acc: 0.055166546
case acc: 0.06368774
case acc: 0.10202015
case acc: 0.05167769
case acc: 0.049188975
top acc: 0.0532 ::: bot acc: 0.1000
top acc: 0.0348 ::: bot acc: 0.0749
top acc: 0.0291 ::: bot acc: 0.0999
top acc: 0.0754 ::: bot acc: 0.1280
top acc: 0.0295 ::: bot acc: 0.0742
top acc: 0.0231 ::: bot acc: 0.0750
current epoch: 10
train loss is 0.048722
average val loss: 0.062763, accuracy: 0.0627
average test loss: 0.063723, accuracy: 0.0637
case acc: 0.07120245
case acc: 0.050122418
case acc: 0.06196039
case acc: 0.09979078
case acc: 0.0476079
case acc: 0.051615667
top acc: 0.0470 ::: bot acc: 0.0936
top acc: 0.0297 ::: bot acc: 0.0699
top acc: 0.0276 ::: bot acc: 0.0981
top acc: 0.0733 ::: bot acc: 0.1257
top acc: 0.0256 ::: bot acc: 0.0700
top acc: 0.0250 ::: bot acc: 0.0777
current epoch: 11
train loss is 0.043201
average val loss: 0.053135, accuracy: 0.0531
average test loss: 0.054381, accuracy: 0.0543
case acc: 0.058688752
case acc: 0.03921923
case acc: 0.053767342
case acc: 0.08995988
case acc: 0.03739934
case acc: 0.046545416
top acc: 0.0349 ::: bot acc: 0.0810
top acc: 0.0195 ::: bot acc: 0.0587
top acc: 0.0209 ::: bot acc: 0.0892
top acc: 0.0637 ::: bot acc: 0.1158
top acc: 0.0162 ::: bot acc: 0.0593
top acc: 0.0213 ::: bot acc: 0.0719
current epoch: 12
train loss is 0.037449
average val loss: 0.046594, accuracy: 0.0466
average test loss: 0.048118, accuracy: 0.0480
case acc: 0.050816253
case acc: 0.033195242
case acc: 0.048567176
case acc: 0.08101961
case acc: 0.031847563
case acc: 0.04233957
top acc: 0.0275 ::: bot acc: 0.0729
top acc: 0.0146 ::: bot acc: 0.0522
top acc: 0.0173 ::: bot acc: 0.0832
top acc: 0.0549 ::: bot acc: 0.1068
top acc: 0.0121 ::: bot acc: 0.0529
top acc: 0.0187 ::: bot acc: 0.0668
current epoch: 13
train loss is 0.035318
average val loss: 0.041998, accuracy: 0.0420
average test loss: 0.043786, accuracy: 0.0436
case acc: 0.04573345
case acc: 0.029805241
case acc: 0.04532662
case acc: 0.072570354
case acc: 0.028785532
case acc: 0.039556157
top acc: 0.0235 ::: bot acc: 0.0673
top acc: 0.0123 ::: bot acc: 0.0483
top acc: 0.0152 ::: bot acc: 0.0793
top acc: 0.0464 ::: bot acc: 0.0984
top acc: 0.0104 ::: bot acc: 0.0493
top acc: 0.0171 ::: bot acc: 0.0634
current epoch: 14
train loss is 0.033590
average val loss: 0.037451, accuracy: 0.0375
average test loss: 0.039557, accuracy: 0.0395
case acc: 0.041411385
case acc: 0.027186261
case acc: 0.0420815
case acc: 0.06335242
case acc: 0.026442792
case acc: 0.0363036
top acc: 0.0204 ::: bot acc: 0.0622
top acc: 0.0109 ::: bot acc: 0.0450
top acc: 0.0134 ::: bot acc: 0.0754
top acc: 0.0372 ::: bot acc: 0.0892
top acc: 0.0096 ::: bot acc: 0.0463
top acc: 0.0156 ::: bot acc: 0.0593
current epoch: 15
train loss is 0.031808
average val loss: 0.033183, accuracy: 0.0333
average test loss: 0.035645, accuracy: 0.0356
case acc: 0.037509345
case acc: 0.024776356
case acc: 0.03904539
case acc: 0.05461172
case acc: 0.024374496
case acc: 0.03339372
top acc: 0.0178 ::: bot acc: 0.0576
top acc: 0.0098 ::: bot acc: 0.0419
top acc: 0.0122 ::: bot acc: 0.0715
top acc: 0.0289 ::: bot acc: 0.0803
top acc: 0.0093 ::: bot acc: 0.0434
top acc: 0.0150 ::: bot acc: 0.0552
current epoch: 16
train loss is 0.030544
average val loss: 0.029625, accuracy: 0.0297
average test loss: 0.032454, accuracy: 0.0325
case acc: 0.03464516
case acc: 0.023135874
case acc: 0.036517154
case acc: 0.046963744
case acc: 0.023029935
case acc: 0.030576473
top acc: 0.0161 ::: bot acc: 0.0542
top acc: 0.0092 ::: bot acc: 0.0398
top acc: 0.0117 ::: bot acc: 0.0679
top acc: 0.0225 ::: bot acc: 0.0720
top acc: 0.0095 ::: bot acc: 0.0413
top acc: 0.0150 ::: bot acc: 0.0509
current epoch: 17
train loss is 0.029286
average val loss: 0.026359, accuracy: 0.0265
average test loss: 0.029573, accuracy: 0.0297
case acc: 0.03206356
case acc: 0.021579705
case acc: 0.034333587
case acc: 0.04035612
case acc: 0.021748077
case acc: 0.027935503
top acc: 0.0148 ::: bot acc: 0.0510
top acc: 0.0087 ::: bot acc: 0.0377
top acc: 0.0122 ::: bot acc: 0.0644
top acc: 0.0181 ::: bot acc: 0.0644
top acc: 0.0098 ::: bot acc: 0.0393
top acc: 0.0157 ::: bot acc: 0.0467
current epoch: 18
train loss is 0.028370
average val loss: 0.025917, accuracy: 0.0260
average test loss: 0.029171, accuracy: 0.0293
case acc: 0.03207074
case acc: 0.02228199
case acc: 0.034238245
case acc: 0.037086193
case acc: 0.022365933
case acc: 0.027579198
top acc: 0.0148 ::: bot acc: 0.0510
top acc: 0.0089 ::: bot acc: 0.0386
top acc: 0.0123 ::: bot acc: 0.0643
top acc: 0.0161 ::: bot acc: 0.0605
top acc: 0.0097 ::: bot acc: 0.0403
top acc: 0.0158 ::: bot acc: 0.0461
current epoch: 19
train loss is 0.027870
average val loss: 0.021335, accuracy: 0.0215
average test loss: 0.025265, accuracy: 0.0253
case acc: 0.027429793
case acc: 0.018981194
case acc: 0.03132394
case acc: 0.029904576
case acc: 0.019438628
case acc: 0.024849407
top acc: 0.0129 ::: bot acc: 0.0450
top acc: 0.0094 ::: bot acc: 0.0335
top acc: 0.0147 ::: bot acc: 0.0588
top acc: 0.0124 ::: bot acc: 0.0516
top acc: 0.0110 ::: bot acc: 0.0352
top acc: 0.0185 ::: bot acc: 0.0407
current epoch: 20
train loss is 0.027001
average val loss: 0.021691, accuracy: 0.0218
average test loss: 0.025550, accuracy: 0.0255
case acc: 0.027837368
case acc: 0.019575182
case acc: 0.031728644
case acc: 0.02861922
case acc: 0.020117423
case acc: 0.025336284
top acc: 0.0130 ::: bot acc: 0.0456
top acc: 0.0088 ::: bot acc: 0.0346
top acc: 0.0142 ::: bot acc: 0.0596
top acc: 0.0120 ::: bot acc: 0.0500
top acc: 0.0105 ::: bot acc: 0.0365
top acc: 0.0179 ::: bot acc: 0.0417
current epoch: 21
train loss is 0.026717
average val loss: 0.020134, accuracy: 0.0202
average test loss: 0.024221, accuracy: 0.0242
case acc: 0.0261057
case acc: 0.01855526
case acc: 0.030815743
case acc: 0.025695106
case acc: 0.019165706
case acc: 0.02461473
top acc: 0.0127 ::: bot acc: 0.0431
top acc: 0.0096 ::: bot acc: 0.0327
top acc: 0.0153 ::: bot acc: 0.0577
top acc: 0.0115 ::: bot acc: 0.0458
top acc: 0.0112 ::: bot acc: 0.0347
top acc: 0.0188 ::: bot acc: 0.0402
current epoch: 22
train loss is 0.026380
average val loss: 0.017362, accuracy: 0.0174
average test loss: 0.021922, accuracy: 0.0219
case acc: 0.022828523
case acc: 0.016288664
case acc: 0.029100182
case acc: 0.022471515
case acc: 0.0173993
case acc: 0.023148086
top acc: 0.0133 ::: bot acc: 0.0379
top acc: 0.0124 ::: bot acc: 0.0279
top acc: 0.0187 ::: bot acc: 0.0535
top acc: 0.0135 ::: bot acc: 0.0401
top acc: 0.0149 ::: bot acc: 0.0301
top acc: 0.0214 ::: bot acc: 0.0367
current epoch: 23
train loss is 0.025898
average val loss: 0.016581, accuracy: 0.0167
average test loss: 0.021287, accuracy: 0.0212
case acc: 0.021704772
case acc: 0.015592639
case acc: 0.028601103
case acc: 0.02172842
case acc: 0.017030673
case acc: 0.022833792
top acc: 0.0140 ::: bot acc: 0.0359
top acc: 0.0140 ::: bot acc: 0.0261
top acc: 0.0201 ::: bot acc: 0.0520
top acc: 0.0146 ::: bot acc: 0.0384
top acc: 0.0167 ::: bot acc: 0.0284
top acc: 0.0221 ::: bot acc: 0.0359
current epoch: 24
train loss is 0.025578
average val loss: 0.018138, accuracy: 0.0182
average test loss: 0.022533, accuracy: 0.0225
case acc: 0.023537569
case acc: 0.016909584
case acc: 0.0295629
case acc: 0.023174958
case acc: 0.017851636
case acc: 0.023708485
top acc: 0.0129 ::: bot acc: 0.0392
top acc: 0.0112 ::: bot acc: 0.0294
top acc: 0.0177 ::: bot acc: 0.0547
top acc: 0.0126 ::: bot acc: 0.0416
top acc: 0.0134 ::: bot acc: 0.0317
top acc: 0.0203 ::: bot acc: 0.0381
current epoch: 25
train loss is 0.025429
average val loss: 0.018271, accuracy: 0.0183
average test loss: 0.022641, accuracy: 0.0226
case acc: 0.023853505
case acc: 0.017271843
case acc: 0.029553402
case acc: 0.023126397
case acc: 0.018135035
case acc: 0.023538345
top acc: 0.0127 ::: bot acc: 0.0397
top acc: 0.0107 ::: bot acc: 0.0302
top acc: 0.0177 ::: bot acc: 0.0547
top acc: 0.0127 ::: bot acc: 0.0415
top acc: 0.0127 ::: bot acc: 0.0325
top acc: 0.0208 ::: bot acc: 0.0376
current epoch: 26
train loss is 0.025259
average val loss: 0.017600, accuracy: 0.0176
average test loss: 0.022093, accuracy: 0.0220
case acc: 0.023045678
case acc: 0.016767155
case acc: 0.029090526
case acc: 0.022288952
case acc: 0.0177898
case acc: 0.023189666
top acc: 0.0130 ::: bot acc: 0.0383
top acc: 0.0114 ::: bot acc: 0.0291
top acc: 0.0187 ::: bot acc: 0.0535
top acc: 0.0137 ::: bot acc: 0.0397
top acc: 0.0137 ::: bot acc: 0.0315
top acc: 0.0215 ::: bot acc: 0.0367
current epoch: 27
train loss is 0.025099
average val loss: 0.016935, accuracy: 0.0170
average test loss: 0.021554, accuracy: 0.0215
case acc: 0.022049118
case acc: 0.016099697
case acc: 0.028683452
case acc: 0.02162769
case acc: 0.017386403
case acc: 0.023037752
top acc: 0.0136 ::: bot acc: 0.0366
top acc: 0.0125 ::: bot acc: 0.0275
top acc: 0.0197 ::: bot acc: 0.0524
top acc: 0.0148 ::: bot acc: 0.0382
top acc: 0.0151 ::: bot acc: 0.0301
top acc: 0.0219 ::: bot acc: 0.0364
current epoch: 28
train loss is 0.024892
average val loss: 0.014939, accuracy: 0.0151
average test loss: 0.019955, accuracy: 0.0199
case acc: 0.019230122
case acc: 0.014599439
case acc: 0.027388737
case acc: 0.01998826
case acc: 0.016584938
case acc: 0.021717947
top acc: 0.0166 ::: bot acc: 0.0309
top acc: 0.0179 ::: bot acc: 0.0220
top acc: 0.0246 ::: bot acc: 0.0474
top acc: 0.0193 ::: bot acc: 0.0334
top acc: 0.0205 ::: bot acc: 0.0246
top acc: 0.0258 ::: bot acc: 0.0322
current epoch: 29
train loss is 0.024691
average val loss: 0.015726, accuracy: 0.0158
average test loss: 0.020592, accuracy: 0.0206
case acc: 0.020400504
case acc: 0.015055451
case acc: 0.027823651
case acc: 0.021073954
case acc: 0.016813733
case acc: 0.022167157
top acc: 0.0149 ::: bot acc: 0.0334
top acc: 0.0155 ::: bot acc: 0.0244
top acc: 0.0225 ::: bot acc: 0.0495
top acc: 0.0158 ::: bot acc: 0.0369
top acc: 0.0181 ::: bot acc: 0.0270
top acc: 0.0240 ::: bot acc: 0.0340
current epoch: 30
train loss is 0.024614
average val loss: 0.016476, accuracy: 0.0166
average test loss: 0.021180, accuracy: 0.0212
case acc: 0.021493608
case acc: 0.015704343
case acc: 0.028074164
case acc: 0.022170447
case acc: 0.01715103
case acc: 0.022325424
top acc: 0.0139 ::: bot acc: 0.0355
top acc: 0.0134 ::: bot acc: 0.0265
top acc: 0.0213 ::: bot acc: 0.0506
top acc: 0.0137 ::: bot acc: 0.0396
top acc: 0.0161 ::: bot acc: 0.0290
top acc: 0.0236 ::: bot acc: 0.0344
current epoch: 31
train loss is 0.024506
average val loss: 0.019864, accuracy: 0.0199
average test loss: 0.023944, accuracy: 0.0239
case acc: 0.025514854
case acc: 0.018793957
case acc: 0.02998852
case acc: 0.025613744
case acc: 0.019637926
case acc: 0.023999805
top acc: 0.0126 ::: bot acc: 0.0422
top acc: 0.0090 ::: bot acc: 0.0333
top acc: 0.0166 ::: bot acc: 0.0559
top acc: 0.0116 ::: bot acc: 0.0457
top acc: 0.0108 ::: bot acc: 0.0357
top acc: 0.0200 ::: bot acc: 0.0387
current epoch: 32
train loss is 0.024897
average val loss: 0.021763, accuracy: 0.0218
average test loss: 0.025542, accuracy: 0.0255
case acc: 0.02756635
case acc: 0.02095956
case acc: 0.031222409
case acc: 0.026310816
case acc: 0.021738177
case acc: 0.025287833
top acc: 0.0128 ::: bot acc: 0.0451
top acc: 0.0086 ::: bot acc: 0.0367
top acc: 0.0146 ::: bot acc: 0.0587
top acc: 0.0116 ::: bot acc: 0.0468
top acc: 0.0099 ::: bot acc: 0.0392
top acc: 0.0181 ::: bot acc: 0.0416
current epoch: 33
train loss is 0.025098
average val loss: 0.020947, accuracy: 0.0209
average test loss: 0.024852, accuracy: 0.0247
case acc: 0.026329473
case acc: 0.020278083
case acc: 0.030989908
case acc: 0.023588933
case acc: 0.021328561
case acc: 0.025667904
top acc: 0.0126 ::: bot acc: 0.0434
top acc: 0.0085 ::: bot acc: 0.0358
top acc: 0.0149 ::: bot acc: 0.0582
top acc: 0.0122 ::: bot acc: 0.0424
top acc: 0.0100 ::: bot acc: 0.0386
top acc: 0.0176 ::: bot acc: 0.0424
current epoch: 34
train loss is 0.025502
average val loss: 0.015344, accuracy: 0.0154
average test loss: 0.020225, accuracy: 0.0200
case acc: 0.018976627
case acc: 0.014768273
case acc: 0.027554132
case acc: 0.01915472
case acc: 0.01673265
case acc: 0.022755623
top acc: 0.0171 ::: bot acc: 0.0302
top acc: 0.0166 ::: bot acc: 0.0233
top acc: 0.0235 ::: bot acc: 0.0484
top acc: 0.0239 ::: bot acc: 0.0287
top acc: 0.0186 ::: bot acc: 0.0265
top acc: 0.0223 ::: bot acc: 0.0356
current epoch: 35
train loss is 0.025928
average val loss: 0.023333, accuracy: 0.0235
average test loss: 0.025986, accuracy: 0.0263
case acc: 0.02503377
case acc: 0.02669757
case acc: 0.028520275
case acc: 0.027791448
case acc: 0.026957605
case acc: 0.022528736
top acc: 0.0459 ::: bot acc: 0.0103
top acc: 0.0454 ::: bot acc: 0.0100
top acc: 0.0478 ::: bot acc: 0.0240
top acc: 0.0487 ::: bot acc: 0.0126
top acc: 0.0470 ::: bot acc: 0.0091
top acc: 0.0428 ::: bot acc: 0.0152
current epoch: 36
train loss is 0.031056
average val loss: 0.021339, accuracy: 0.0214
average test loss: 0.024356, accuracy: 0.0248
case acc: 0.023645114
case acc: 0.026180264
case acc: 0.027955677
case acc: 0.022430595
case acc: 0.026577728
case acc: 0.021770673
top acc: 0.0440 ::: bot acc: 0.0100
top acc: 0.0448 ::: bot acc: 0.0097
top acc: 0.0458 ::: bot acc: 0.0260
top acc: 0.0395 ::: bot acc: 0.0150
top acc: 0.0465 ::: bot acc: 0.0089
top acc: 0.0403 ::: bot acc: 0.0176
current epoch: 37
train loss is 0.032168
average val loss: 0.026747, accuracy: 0.0269
average test loss: 0.029764, accuracy: 0.0298
case acc: 0.031261574
case acc: 0.023943637
case acc: 0.034341026
case acc: 0.034748774
case acc: 0.024436517
case acc: 0.02995207
top acc: 0.0143 ::: bot acc: 0.0499
top acc: 0.0095 ::: bot acc: 0.0407
top acc: 0.0120 ::: bot acc: 0.0646
top acc: 0.0147 ::: bot acc: 0.0579
top acc: 0.0094 ::: bot acc: 0.0435
top acc: 0.0153 ::: bot acc: 0.0499
current epoch: 38
train loss is 0.026520
average val loss: 0.028258, accuracy: 0.0283
average test loss: 0.031047, accuracy: 0.0311
case acc: 0.034916684
case acc: 0.028153257
case acc: 0.034540888
case acc: 0.033237826
case acc: 0.027953312
case acc: 0.028054083
top acc: 0.0162 ::: bot acc: 0.0544
top acc: 0.0115 ::: bot acc: 0.0460
top acc: 0.0118 ::: bot acc: 0.0650
top acc: 0.0138 ::: bot acc: 0.0561
top acc: 0.0098 ::: bot acc: 0.0486
top acc: 0.0159 ::: bot acc: 0.0467
current epoch: 39
train loss is 0.028212
average val loss: 0.014283, accuracy: 0.0143
average test loss: 0.019318, accuracy: 0.0192
case acc: 0.017983768
case acc: 0.014432257
case acc: 0.026525812
case acc: 0.019104382
case acc: 0.01650324
case acc: 0.020864364
top acc: 0.0203 ::: bot acc: 0.0270
top acc: 0.0201 ::: bot acc: 0.0198
top acc: 0.0305 ::: bot acc: 0.0413
top acc: 0.0259 ::: bot acc: 0.0269
top acc: 0.0223 ::: bot acc: 0.0228
top acc: 0.0318 ::: bot acc: 0.0260
current epoch: 40
train loss is 0.024997
average val loss: 0.017666, accuracy: 0.0177
average test loss: 0.021402, accuracy: 0.0215
case acc: 0.018838631
case acc: 0.019512456
case acc: 0.026863595
case acc: 0.021719221
case acc: 0.020652888
case acc: 0.021209968
top acc: 0.0360 ::: bot acc: 0.0117
top acc: 0.0357 ::: bot acc: 0.0080
top acc: 0.0412 ::: bot acc: 0.0306
top acc: 0.0379 ::: bot acc: 0.0161
top acc: 0.0374 ::: bot acc: 0.0093
top acc: 0.0381 ::: bot acc: 0.0198
current epoch: 41
train loss is 0.026220
average val loss: 0.015315, accuracy: 0.0154
average test loss: 0.019724, accuracy: 0.0199
case acc: 0.01725601
case acc: 0.017011533
case acc: 0.026450781
case acc: 0.019062797
case acc: 0.01863682
case acc: 0.020834144
top acc: 0.0306 ::: bot acc: 0.0167
top acc: 0.0312 ::: bot acc: 0.0095
top acc: 0.0361 ::: bot acc: 0.0356
top acc: 0.0283 ::: bot acc: 0.0244
top acc: 0.0330 ::: bot acc: 0.0122
top acc: 0.0331 ::: bot acc: 0.0247
current epoch: 42
train loss is 0.026405
average val loss: 0.019609, accuracy: 0.0197
average test loss: 0.023701, accuracy: 0.0237
case acc: 0.024671376
case acc: 0.018177105
case acc: 0.029311128
case acc: 0.026872259
case acc: 0.019206269
case acc: 0.024090838
top acc: 0.0127 ::: bot acc: 0.0408
top acc: 0.0095 ::: bot acc: 0.0321
top acc: 0.0177 ::: bot acc: 0.0543
top acc: 0.0116 ::: bot acc: 0.0478
top acc: 0.0109 ::: bot acc: 0.0349
top acc: 0.0197 ::: bot acc: 0.0389
current epoch: 43
train loss is 0.025508
average val loss: 0.028682, accuracy: 0.0287
average test loss: 0.031384, accuracy: 0.0315
case acc: 0.03544674
case acc: 0.028794238
case acc: 0.03449105
case acc: 0.033897735
case acc: 0.028592817
case acc: 0.027837796
top acc: 0.0165 ::: bot acc: 0.0550
top acc: 0.0118 ::: bot acc: 0.0468
top acc: 0.0119 ::: bot acc: 0.0649
top acc: 0.0141 ::: bot acc: 0.0570
top acc: 0.0100 ::: bot acc: 0.0494
top acc: 0.0159 ::: bot acc: 0.0464
current epoch: 44
train loss is 0.028443
average val loss: 0.014247, accuracy: 0.0143
average test loss: 0.019243, accuracy: 0.0192
case acc: 0.017714944
case acc: 0.014403434
case acc: 0.026432464
case acc: 0.019106215
case acc: 0.016513214
case acc: 0.020839468
top acc: 0.0214 ::: bot acc: 0.0259
top acc: 0.0210 ::: bot acc: 0.0188
top acc: 0.0321 ::: bot acc: 0.0396
top acc: 0.0262 ::: bot acc: 0.0266
top acc: 0.0232 ::: bot acc: 0.0218
top acc: 0.0338 ::: bot acc: 0.0241
current epoch: 45
train loss is 0.024558
average val loss: 0.017118, accuracy: 0.0172
average test loss: 0.020972, accuracy: 0.0210
case acc: 0.01841053
case acc: 0.018725965
case acc: 0.026809402
case acc: 0.020983042
case acc: 0.019978892
case acc: 0.0211918
top acc: 0.0350 ::: bot acc: 0.0125
top acc: 0.0344 ::: bot acc: 0.0082
top acc: 0.0407 ::: bot acc: 0.0311
top acc: 0.0362 ::: bot acc: 0.0173
top acc: 0.0362 ::: bot acc: 0.0098
top acc: 0.0379 ::: bot acc: 0.0200
current epoch: 46
train loss is 0.025566
average val loss: 0.014501, accuracy: 0.0147
average test loss: 0.019282, accuracy: 0.0194
case acc: 0.017017178
case acc: 0.015398399
case acc: 0.02640639
case acc: 0.019176118
case acc: 0.017360458
case acc: 0.02091926
top acc: 0.0271 ::: bot acc: 0.0202
top acc: 0.0274 ::: bot acc: 0.0124
top acc: 0.0335 ::: bot acc: 0.0384
top acc: 0.0250 ::: bot acc: 0.0279
top acc: 0.0292 ::: bot acc: 0.0158
top acc: 0.0309 ::: bot acc: 0.0271
current epoch: 47
train loss is 0.024971
average val loss: 0.018706, accuracy: 0.0188
average test loss: 0.022943, accuracy: 0.0230
case acc: 0.023636991
case acc: 0.01755413
case acc: 0.028737688
case acc: 0.025799766
case acc: 0.018650606
case acc: 0.023525842
top acc: 0.0129 ::: bot acc: 0.0392
top acc: 0.0102 ::: bot acc: 0.0308
top acc: 0.0191 ::: bot acc: 0.0527
top acc: 0.0115 ::: bot acc: 0.0462
top acc: 0.0116 ::: bot acc: 0.0337
top acc: 0.0208 ::: bot acc: 0.0375
current epoch: 48
train loss is 0.024689
average val loss: 0.024926, accuracy: 0.0250
average test loss: 0.028188, accuracy: 0.0283
case acc: 0.031042274
case acc: 0.024759123
case acc: 0.03221197
case acc: 0.030517481
case acc: 0.025077526
case acc: 0.026250327
top acc: 0.0143 ::: bot acc: 0.0496
top acc: 0.0099 ::: bot acc: 0.0417
top acc: 0.0134 ::: bot acc: 0.0608
top acc: 0.0126 ::: bot acc: 0.0527
top acc: 0.0093 ::: bot acc: 0.0445
top acc: 0.0170 ::: bot acc: 0.0434
current epoch: 49
train loss is 0.026722
average val loss: 0.014185, accuracy: 0.0142
average test loss: 0.019245, accuracy: 0.0192
case acc: 0.017695077
case acc: 0.014384867
case acc: 0.02648818
case acc: 0.019170184
case acc: 0.016507164
case acc: 0.020895237
top acc: 0.0214 ::: bot acc: 0.0259
top acc: 0.0207 ::: bot acc: 0.0190
top acc: 0.0311 ::: bot acc: 0.0407
top acc: 0.0251 ::: bot acc: 0.0278
top acc: 0.0228 ::: bot acc: 0.0222
top acc: 0.0316 ::: bot acc: 0.0264
current epoch: 50
train loss is 0.024518
average val loss: 0.018168, accuracy: 0.0182
average test loss: 0.021798, accuracy: 0.0219
case acc: 0.019663021
case acc: 0.020212956
case acc: 0.027178288
case acc: 0.02169318
case acc: 0.021221275
case acc: 0.021431493
top acc: 0.0377 ::: bot acc: 0.0108
top acc: 0.0368 ::: bot acc: 0.0078
top acc: 0.0427 ::: bot acc: 0.0291
top acc: 0.0378 ::: bot acc: 0.0162
top acc: 0.0385 ::: bot acc: 0.0089
top acc: 0.0391 ::: bot acc: 0.0189
LME_Co_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2010-01-01', '2010-07-01', '2015-07-01', '2016-01-01', '2016-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6780 6780 6780
1.7082474 -0.6288155 0.12137239 -0.1537469
Validation: 756 756 756
Testing: 774 774 774
pre-processing time: 0.0002846717834472656
the split date is 2010-07-01
net initializing with time: 0.13027548789978027
preparing training and testing date with time: 4.76837158203125e-07
current epoch: 1
train loss is 0.321543
average val loss: 0.154027, accuracy: 0.1542
average test loss: 0.155215, accuracy: 0.1553
case acc: 0.21192421
case acc: 0.357798
case acc: 0.07055182
case acc: 0.14108516
case acc: 0.10513931
case acc: 0.045440245
top acc: 0.1892 ::: bot acc: 0.2342
top acc: 0.3361 ::: bot acc: 0.3782
top acc: 0.0411 ::: bot acc: 0.1006
top acc: 0.1070 ::: bot acc: 0.1729
top acc: 0.0723 ::: bot acc: 0.1343
top acc: 0.0204 ::: bot acc: 0.0710
current epoch: 2
train loss is 0.204999
average val loss: 0.106107, accuracy: 0.1054
average test loss: 0.106068, accuracy: 0.1054
case acc: 0.018787872
case acc: 0.12908457
case acc: 0.14499018
case acc: 0.072884396
case acc: 0.103021376
case acc: 0.16371696
top acc: 0.0317 ::: bot acc: 0.0136
top acc: 0.1073 ::: bot acc: 0.1495
top acc: 0.1770 ::: bot acc: 0.1134
top acc: 0.1065 ::: bot acc: 0.0415
top acc: 0.1364 ::: bot acc: 0.0738
top acc: 0.1935 ::: bot acc: 0.1358
current epoch: 3
train loss is 0.083822
average val loss: 0.139785, accuracy: 0.1401
average test loss: 0.140981, accuracy: 0.1411
case acc: 0.19193779
case acc: 0.31815237
case acc: 0.060512234
case acc: 0.1284218
case acc: 0.10255779
case acc: 0.04524656
top acc: 0.1689 ::: bot acc: 0.2143
top acc: 0.2964 ::: bot acc: 0.3387
top acc: 0.0326 ::: bot acc: 0.0901
top acc: 0.0945 ::: bot acc: 0.1602
top acc: 0.0698 ::: bot acc: 0.1314
top acc: 0.0201 ::: bot acc: 0.0708
current epoch: 4
train loss is 0.118392
average val loss: 0.114002, accuracy: 0.1149
average test loss: 0.115411, accuracy: 0.1158
case acc: 0.15996064
case acc: 0.28156298
case acc: 0.040176153
case acc: 0.10323109
case acc: 0.08103777
case acc: 0.029025577
top acc: 0.1367 ::: bot acc: 0.1825
top acc: 0.2601 ::: bot acc: 0.3021
top acc: 0.0189 ::: bot acc: 0.0663
top acc: 0.0693 ::: bot acc: 0.1349
top acc: 0.0499 ::: bot acc: 0.1091
top acc: 0.0134 ::: bot acc: 0.0499
current epoch: 5
train loss is 0.110585
average val loss: 0.091863, accuracy: 0.0934
average test loss: 0.093398, accuracy: 0.0939
case acc: 0.12852667
case acc: 0.2455804
case acc: 0.025798779
case acc: 0.07956858
case acc: 0.062156115
case acc: 0.021963615
top acc: 0.1052 ::: bot acc: 0.1510
top acc: 0.2242 ::: bot acc: 0.2661
top acc: 0.0208 ::: bot acc: 0.0435
top acc: 0.0462 ::: bot acc: 0.1109
top acc: 0.0331 ::: bot acc: 0.0891
top acc: 0.0268 ::: bot acc: 0.0312
current epoch: 6
train loss is 0.098586
average val loss: 0.088881, accuracy: 0.0904
average test loss: 0.090408, accuracy: 0.0908
case acc: 0.12052505
case acc: 0.23203178
case acc: 0.0259203
case acc: 0.07843234
case acc: 0.0653257
case acc: 0.022836564
top acc: 0.0971 ::: bot acc: 0.1430
top acc: 0.2107 ::: bot acc: 0.2526
top acc: 0.0205 ::: bot acc: 0.0439
top acc: 0.0451 ::: bot acc: 0.1096
top acc: 0.0357 ::: bot acc: 0.0926
top acc: 0.0220 ::: bot acc: 0.0362
current epoch: 7
train loss is 0.091131
average val loss: 0.084814, accuracy: 0.0863
average test loss: 0.086344, accuracy: 0.0867
case acc: 0.111272134
case acc: 0.21700786
case acc: 0.025570327
case acc: 0.07571856
case acc: 0.06687197
case acc: 0.023817033
top acc: 0.0879 ::: bot acc: 0.1337
top acc: 0.1956 ::: bot acc: 0.2376
top acc: 0.0215 ::: bot acc: 0.0428
top acc: 0.0425 ::: bot acc: 0.1069
top acc: 0.0369 ::: bot acc: 0.0942
top acc: 0.0187 ::: bot acc: 0.0395
current epoch: 8
train loss is 0.085128
average val loss: 0.081021, accuracy: 0.0825
average test loss: 0.082537, accuracy: 0.0829
case acc: 0.102403715
case acc: 0.2027524
case acc: 0.025392942
case acc: 0.073310055
case acc: 0.068185024
case acc: 0.025152551
top acc: 0.0791 ::: bot acc: 0.1248
top acc: 0.1814 ::: bot acc: 0.2233
top acc: 0.0221 ::: bot acc: 0.0422
top acc: 0.0403 ::: bot acc: 0.1043
top acc: 0.0381 ::: bot acc: 0.0955
top acc: 0.0164 ::: bot acc: 0.0426
current epoch: 9
train loss is 0.081417
average val loss: 0.082040, accuracy: 0.0833
average test loss: 0.083545, accuracy: 0.0838
case acc: 0.099226765
case acc: 0.19560058
case acc: 0.027559333
case acc: 0.07668991
case acc: 0.07406023
case acc: 0.029470092
top acc: 0.0760 ::: bot acc: 0.1217
top acc: 0.1743 ::: bot acc: 0.2161
top acc: 0.0180 ::: bot acc: 0.0476
top acc: 0.0434 ::: bot acc: 0.1079
top acc: 0.0431 ::: bot acc: 0.1017
top acc: 0.0130 ::: bot acc: 0.0508
current epoch: 10
train loss is 0.081443
average val loss: 0.089079, accuracy: 0.0899
average test loss: 0.090494, accuracy: 0.0907
case acc: 0.10200712
case acc: 0.19628912
case acc: 0.034696944
case acc: 0.086454034
case acc: 0.085206814
case acc: 0.039666515
top acc: 0.0787 ::: bot acc: 0.1245
top acc: 0.1750 ::: bot acc: 0.2168
top acc: 0.0164 ::: bot acc: 0.0592
top acc: 0.0525 ::: bot acc: 0.1180
top acc: 0.0529 ::: bot acc: 0.1135
top acc: 0.0164 ::: bot acc: 0.0643
current epoch: 11
train loss is 0.079062
average val loss: 0.081993, accuracy: 0.0829
average test loss: 0.083470, accuracy: 0.0836
case acc: 0.0888202
case acc: 0.18184035
case acc: 0.031514738
case acc: 0.0809548
case acc: 0.08115684
case acc: 0.037573855
top acc: 0.0655 ::: bot acc: 0.1113
top acc: 0.1605 ::: bot acc: 0.2024
top acc: 0.0157 ::: bot acc: 0.0548
top acc: 0.0474 ::: bot acc: 0.1124
top acc: 0.0493 ::: bot acc: 0.1092
top acc: 0.0154 ::: bot acc: 0.0617
current epoch: 12
train loss is 0.074369
average val loss: 0.077784, accuracy: 0.0787
average test loss: 0.079293, accuracy: 0.0794
case acc: 0.07886388
case acc: 0.17077862
case acc: 0.03055931
case acc: 0.07840615
case acc: 0.0800282
case acc: 0.03787554
top acc: 0.0556 ::: bot acc: 0.1014
top acc: 0.1494 ::: bot acc: 0.1914
top acc: 0.0157 ::: bot acc: 0.0534
top acc: 0.0450 ::: bot acc: 0.1098
top acc: 0.0484 ::: bot acc: 0.1079
top acc: 0.0154 ::: bot acc: 0.0621
current epoch: 13
train loss is 0.069846
average val loss: 0.069246, accuracy: 0.0704
average test loss: 0.070882, accuracy: 0.0710
case acc: 0.06405662
case acc: 0.1548552
case acc: 0.027217304
case acc: 0.07116043
case acc: 0.07419682
case acc: 0.034300417
top acc: 0.0409 ::: bot acc: 0.0866
top acc: 0.1334 ::: bot acc: 0.1755
top acc: 0.0186 ::: bot acc: 0.0469
top acc: 0.0385 ::: bot acc: 0.1022
top acc: 0.0434 ::: bot acc: 0.1017
top acc: 0.0139 ::: bot acc: 0.0574
current epoch: 14
train loss is 0.066435
average val loss: 0.068225, accuracy: 0.0692
average test loss: 0.069900, accuracy: 0.0699
case acc: 0.058097906
case acc: 0.14780168
case acc: 0.028189844
case acc: 0.07201393
case acc: 0.076153524
case acc: 0.037189085
top acc: 0.0350 ::: bot acc: 0.0806
top acc: 0.1263 ::: bot acc: 0.1685
top acc: 0.0173 ::: bot acc: 0.0491
top acc: 0.0393 ::: bot acc: 0.1032
top acc: 0.0452 ::: bot acc: 0.1037
top acc: 0.0150 ::: bot acc: 0.0611
current epoch: 15
train loss is 0.061451
average val loss: 0.058185, accuracy: 0.0595
average test loss: 0.059959, accuracy: 0.0599
case acc: 0.042161446
case acc: 0.12981811
case acc: 0.02493068
case acc: 0.062825486
case acc: 0.0678847
case acc: 0.031782936
top acc: 0.0204 ::: bot acc: 0.0640
top acc: 0.1083 ::: bot acc: 0.1505
top acc: 0.0246 ::: bot acc: 0.0403
top acc: 0.0319 ::: bot acc: 0.0931
top acc: 0.0380 ::: bot acc: 0.0949
top acc: 0.0130 ::: bot acc: 0.0540
current epoch: 16
train loss is 0.056669
average val loss: 0.052113, accuracy: 0.0535
average test loss: 0.053923, accuracy: 0.0537
case acc: 0.03165154
case acc: 0.1159627
case acc: 0.024174232
case acc: 0.057595357
case acc: 0.0633788
case acc: 0.02965167
top acc: 0.0119 ::: bot acc: 0.0525
top acc: 0.0944 ::: bot acc: 0.1367
top acc: 0.0292 ::: bot acc: 0.0357
top acc: 0.0281 ::: bot acc: 0.0872
top acc: 0.0340 ::: bot acc: 0.0901
top acc: 0.0127 ::: bot acc: 0.0510
current epoch: 17
train loss is 0.051578
average val loss: 0.045834, accuracy: 0.0471
average test loss: 0.047647, accuracy: 0.0474
case acc: 0.02332384
case acc: 0.10094329
case acc: 0.023859663
case acc: 0.051281065
case acc: 0.05776619
case acc: 0.027170677
top acc: 0.0101 ::: bot acc: 0.0409
top acc: 0.0794 ::: bot acc: 0.1216
top acc: 0.0348 ::: bot acc: 0.0302
top acc: 0.0239 ::: bot acc: 0.0798
top acc: 0.0293 ::: bot acc: 0.0840
top acc: 0.0138 ::: bot acc: 0.0467
current epoch: 18
train loss is 0.046088
average val loss: 0.037756, accuracy: 0.0386
average test loss: 0.039431, accuracy: 0.0391
case acc: 0.016982574
case acc: 0.08015061
case acc: 0.025633598
case acc: 0.04081941
case acc: 0.047705945
case acc: 0.023257421
top acc: 0.0198 ::: bot acc: 0.0258
top acc: 0.0586 ::: bot acc: 0.1008
top acc: 0.0453 ::: bot acc: 0.0200
top acc: 0.0184 ::: bot acc: 0.0668
top acc: 0.0221 ::: bot acc: 0.0726
top acc: 0.0207 ::: bot acc: 0.0373
current epoch: 19
train loss is 0.041047
average val loss: 0.031167, accuracy: 0.0312
average test loss: 0.032518, accuracy: 0.0325
case acc: 0.019418135
case acc: 0.054938458
case acc: 0.032417644
case acc: 0.030361498
case acc: 0.03647517
case acc: 0.02116527
top acc: 0.0353 ::: bot acc: 0.0113
top acc: 0.0335 ::: bot acc: 0.0756
top acc: 0.0584 ::: bot acc: 0.0143
top acc: 0.0205 ::: bot acc: 0.0501
top acc: 0.0176 ::: bot acc: 0.0580
top acc: 0.0330 ::: bot acc: 0.0250
current epoch: 20
train loss is 0.038408
average val loss: 0.028023, accuracy: 0.0274
average test loss: 0.029083, accuracy: 0.0289
case acc: 0.026636
case acc: 0.029247006
case acc: 0.04194375
case acc: 0.02411851
case acc: 0.028091682
case acc: 0.023519007
top acc: 0.0469 ::: bot acc: 0.0098
top acc: 0.0103 ::: bot acc: 0.0486
top acc: 0.0709 ::: bot acc: 0.0178
top acc: 0.0339 ::: bot acc: 0.0327
top acc: 0.0206 ::: bot acc: 0.0439
top acc: 0.0444 ::: bot acc: 0.0142
current epoch: 21
train loss is 0.037287
average val loss: 0.026663, accuracy: 0.0255
average test loss: 0.027632, accuracy: 0.0274
case acc: 0.027216101
case acc: 0.017124826
case acc: 0.04518273
case acc: 0.02450586
case acc: 0.026248202
case acc: 0.024121143
top acc: 0.0477 ::: bot acc: 0.0100
top acc: 0.0134 ::: bot acc: 0.0287
top acc: 0.0746 ::: bot acc: 0.0201
top acc: 0.0427 ::: bot acc: 0.0240
top acc: 0.0234 ::: bot acc: 0.0397
top acc: 0.0458 ::: bot acc: 0.0132
current epoch: 22
train loss is 0.035133
average val loss: 0.027500, accuracy: 0.0263
average test loss: 0.028134, accuracy: 0.0281
case acc: 0.026948623
case acc: 0.01770688
case acc: 0.047994487
case acc: 0.026759189
case acc: 0.025272306
case acc: 0.024015825
top acc: 0.0473 ::: bot acc: 0.0098
top acc: 0.0330 ::: bot acc: 0.0096
top acc: 0.0777 ::: bot acc: 0.0223
top acc: 0.0502 ::: bot acc: 0.0170
top acc: 0.0255 ::: bot acc: 0.0372
top acc: 0.0456 ::: bot acc: 0.0132
current epoch: 23
train loss is 0.032424
average val loss: 0.034598, accuracy: 0.0339
average test loss: 0.034649, accuracy: 0.0351
case acc: 0.03192515
case acc: 0.036852736
case acc: 0.05671589
case acc: 0.03432313
case acc: 0.023269285
case acc: 0.027357528
top acc: 0.0534 ::: bot acc: 0.0126
top acc: 0.0583 ::: bot acc: 0.0166
top acc: 0.0874 ::: bot acc: 0.0289
top acc: 0.0640 ::: bot acc: 0.0122
top acc: 0.0341 ::: bot acc: 0.0285
top acc: 0.0519 ::: bot acc: 0.0107
current epoch: 24
train loss is 0.032939
average val loss: 0.048130, accuracy: 0.0477
average test loss: 0.047759, accuracy: 0.0480
case acc: 0.0412513
case acc: 0.065359324
case acc: 0.071050264
case acc: 0.049815115
case acc: 0.02417742
case acc: 0.03615344
top acc: 0.0636 ::: bot acc: 0.0203
top acc: 0.0870 ::: bot acc: 0.0447
top acc: 0.1029 ::: bot acc: 0.0410
top acc: 0.0829 ::: bot acc: 0.0209
top acc: 0.0482 ::: bot acc: 0.0144
top acc: 0.0640 ::: bot acc: 0.0127
current epoch: 25
train loss is 0.040213
average val loss: 0.074585, accuracy: 0.0744
average test loss: 0.074053, accuracy: 0.0739
case acc: 0.06126889
case acc: 0.10314965
case acc: 0.098534696
case acc: 0.079263106
case acc: 0.041511387
case acc: 0.059423026
top acc: 0.0843 ::: bot acc: 0.0390
top acc: 0.1247 ::: bot acc: 0.0826
top acc: 0.1310 ::: bot acc: 0.0672
top acc: 0.1138 ::: bot acc: 0.0476
top acc: 0.0746 ::: bot acc: 0.0136
top acc: 0.0893 ::: bot acc: 0.0323
current epoch: 26
train loss is 0.058005
average val loss: 0.078092, accuracy: 0.0780
average test loss: 0.077579, accuracy: 0.0774
case acc: 0.056465194
case acc: 0.109684855
case acc: 0.10319099
case acc: 0.08572922
case acc: 0.045645382
case acc: 0.06347228
top acc: 0.0795 ::: bot acc: 0.0343
top acc: 0.1312 ::: bot acc: 0.0892
top acc: 0.1358 ::: bot acc: 0.0716
top acc: 0.1204 ::: bot acc: 0.0539
top acc: 0.0790 ::: bot acc: 0.0172
top acc: 0.0935 ::: bot acc: 0.0362
current epoch: 27
train loss is 0.070055
average val loss: 0.044869, accuracy: 0.0441
average test loss: 0.044820, accuracy: 0.0447
case acc: 0.019193143
case acc: 0.068676785
case acc: 0.068304196
case acc: 0.05389649
case acc: 0.023753887
case acc: 0.03456429
top acc: 0.0352 ::: bot acc: 0.0113
top acc: 0.0901 ::: bot acc: 0.0482
top acc: 0.1001 ::: bot acc: 0.0385
top acc: 0.0875 ::: bot acc: 0.0242
top acc: 0.0469 ::: bot acc: 0.0155
top acc: 0.0623 ::: bot acc: 0.0119
current epoch: 28
train loss is 0.068635
average val loss: 0.026276, accuracy: 0.0257
average test loss: 0.027658, accuracy: 0.0280
case acc: 0.03944453
case acc: 0.017863961
case acc: 0.029917428
case acc: 0.024804352
case acc: 0.03367289
case acc: 0.022276517
top acc: 0.0178 ::: bot acc: 0.0612
top acc: 0.0335 ::: bot acc: 0.0091
top acc: 0.0544 ::: bot acc: 0.0149
top acc: 0.0443 ::: bot acc: 0.0224
top acc: 0.0173 ::: bot acc: 0.0540
top acc: 0.0252 ::: bot acc: 0.0327
current epoch: 29
train loss is 0.061084
average val loss: 0.031133, accuracy: 0.0315
average test loss: 0.032980, accuracy: 0.0333
case acc: 0.053907905
case acc: 0.025753586
case acc: 0.02371275
case acc: 0.027115185
case acc: 0.043052502
case acc: 0.025993811
top acc: 0.0306 ::: bot acc: 0.0765
top acc: 0.0084 ::: bot acc: 0.0442
top acc: 0.0343 ::: bot acc: 0.0308
top acc: 0.0247 ::: bot acc: 0.0429
top acc: 0.0196 ::: bot acc: 0.0669
top acc: 0.0151 ::: bot acc: 0.0440
current epoch: 30
train loss is 0.047568
average val loss: 0.028439, accuracy: 0.0289
average test loss: 0.030283, accuracy: 0.0309
case acc: 0.040824432
case acc: 0.036457766
case acc: 0.024006326
case acc: 0.026268186
case acc: 0.03571369
case acc: 0.022211729
top acc: 0.0190 ::: bot acc: 0.0627
top acc: 0.0161 ::: bot acc: 0.0564
top acc: 0.0384 ::: bot acc: 0.0267
top acc: 0.0263 ::: bot acc: 0.0408
top acc: 0.0175 ::: bot acc: 0.0569
top acc: 0.0255 ::: bot acc: 0.0325
current epoch: 31
train loss is 0.041663
average val loss: 0.032584, accuracy: 0.0335
average test loss: 0.034445, accuracy: 0.0353
case acc: 0.039793316
case acc: 0.056810565
case acc: 0.02391118
case acc: 0.030682597
case acc: 0.037830736
case acc: 0.022625228
top acc: 0.0181 ::: bot acc: 0.0616
top acc: 0.0353 ::: bot acc: 0.0773
top acc: 0.0304 ::: bot acc: 0.0347
top acc: 0.0204 ::: bot acc: 0.0504
top acc: 0.0179 ::: bot acc: 0.0599
top acc: 0.0235 ::: bot acc: 0.0344
current epoch: 32
train loss is 0.044810
average val loss: 0.051932, accuracy: 0.0525
average test loss: 0.053504, accuracy: 0.0539
case acc: 0.056897216
case acc: 0.090479665
case acc: 0.03510451
case acc: 0.049683113
case acc: 0.056852415
case acc: 0.034149755
top acc: 0.0336 ::: bot acc: 0.0795
top acc: 0.0690 ::: bot acc: 0.1110
top acc: 0.0145 ::: bot acc: 0.0611
top acc: 0.0227 ::: bot acc: 0.0778
top acc: 0.0290 ::: bot acc: 0.0829
top acc: 0.0135 ::: bot acc: 0.0571
current epoch: 33
train loss is 0.050297
average val loss: 0.055477, accuracy: 0.0559
average test loss: 0.057002, accuracy: 0.0572
case acc: 0.05351023
case acc: 0.09499071
case acc: 0.03978512
case acc: 0.0548419
case acc: 0.061660483
case acc: 0.038679644
top acc: 0.0303 ::: bot acc: 0.0761
top acc: 0.0734 ::: bot acc: 0.1155
top acc: 0.0167 ::: bot acc: 0.0671
top acc: 0.0262 ::: bot acc: 0.0838
top acc: 0.0330 ::: bot acc: 0.0881
top acc: 0.0153 ::: bot acc: 0.0630
current epoch: 34
train loss is 0.042464
average val loss: 0.034805, accuracy: 0.0357
average test loss: 0.036699, accuracy: 0.0370
case acc: 0.02548342
case acc: 0.06567868
case acc: 0.026054554
case acc: 0.036653176
case acc: 0.04269382
case acc: 0.025342772
top acc: 0.0098 ::: bot acc: 0.0443
top acc: 0.0441 ::: bot acc: 0.0862
top acc: 0.0207 ::: bot acc: 0.0445
top acc: 0.0179 ::: bot acc: 0.0607
top acc: 0.0194 ::: bot acc: 0.0665
top acc: 0.0159 ::: bot acc: 0.0427
current epoch: 35
train loss is 0.034465
average val loss: 0.028766, accuracy: 0.0295
average test loss: 0.030747, accuracy: 0.0310
case acc: 0.018206434
case acc: 0.050645724
case acc: 0.02421809
case acc: 0.031623382
case acc: 0.037755147
case acc: 0.023436107
top acc: 0.0151 ::: bot acc: 0.0307
top acc: 0.0291 ::: bot acc: 0.0712
top acc: 0.0276 ::: bot acc: 0.0375
top acc: 0.0197 ::: bot acc: 0.0523
top acc: 0.0179 ::: bot acc: 0.0598
top acc: 0.0202 ::: bot acc: 0.0376
current epoch: 36
train loss is 0.030225
average val loss: 0.023759, accuracy: 0.0240
average test loss: 0.025611, accuracy: 0.0257
case acc: 0.0167523
case acc: 0.034392487
case acc: 0.023819132
case acc: 0.026334519
case acc: 0.03120728
case acc: 0.02167798
top acc: 0.0271 ::: bot acc: 0.0187
top acc: 0.0142 ::: bot acc: 0.0543
top acc: 0.0364 ::: bot acc: 0.0287
top acc: 0.0261 ::: bot acc: 0.0411
top acc: 0.0173 ::: bot acc: 0.0502
top acc: 0.0281 ::: bot acc: 0.0298
current epoch: 37
train loss is 0.026995
average val loss: 0.021440, accuracy: 0.0212
average test loss: 0.023031, accuracy: 0.0229
case acc: 0.018571965
case acc: 0.021578748
case acc: 0.025068143
case acc: 0.024059016
case acc: 0.026892811
case acc: 0.021182619
top acc: 0.0335 ::: bot acc: 0.0124
top acc: 0.0079 ::: bot acc: 0.0382
top acc: 0.0435 ::: bot acc: 0.0216
top acc: 0.0359 ::: bot acc: 0.0308
top acc: 0.0214 ::: bot acc: 0.0417
top acc: 0.0348 ::: bot acc: 0.0231
current epoch: 38
train loss is 0.025429
average val loss: 0.021205, accuracy: 0.0206
average test loss: 0.022465, accuracy: 0.0223
case acc: 0.019678563
case acc: 0.015882064
case acc: 0.0272324
case acc: 0.025026126
case acc: 0.024390131
case acc: 0.021833641
top acc: 0.0362 ::: bot acc: 0.0103
top acc: 0.0191 ::: bot acc: 0.0231
top acc: 0.0490 ::: bot acc: 0.0172
top acc: 0.0450 ::: bot acc: 0.0217
top acc: 0.0274 ::: bot acc: 0.0348
top acc: 0.0398 ::: bot acc: 0.0180
current epoch: 39
train loss is 0.024390
average val loss: 0.022944, accuracy: 0.0223
average test loss: 0.023707, accuracy: 0.0237
case acc: 0.020139048
case acc: 0.017723134
case acc: 0.029679332
case acc: 0.028030133
case acc: 0.02322231
case acc: 0.023267625
top acc: 0.0372 ::: bot acc: 0.0097
top acc: 0.0332 ::: bot acc: 0.0094
top acc: 0.0539 ::: bot acc: 0.0147
top acc: 0.0534 ::: bot acc: 0.0146
top acc: 0.0334 ::: bot acc: 0.0289
top acc: 0.0441 ::: bot acc: 0.0141
current epoch: 40
train loss is 0.023961
average val loss: 0.026105, accuracy: 0.0256
average test loss: 0.026433, accuracy: 0.0266
case acc: 0.020574858
case acc: 0.025705528
case acc: 0.032831606
case acc: 0.03232834
case acc: 0.022677688
case acc: 0.025372744
top acc: 0.0381 ::: bot acc: 0.0093
top acc: 0.0455 ::: bot acc: 0.0088
top acc: 0.0588 ::: bot acc: 0.0144
top acc: 0.0610 ::: bot acc: 0.0122
top acc: 0.0390 ::: bot acc: 0.0233
top acc: 0.0484 ::: bot acc: 0.0118
current epoch: 41
train loss is 0.024712
average val loss: 0.029430, accuracy: 0.0289
average test loss: 0.029517, accuracy: 0.0296
case acc: 0.02069147
case acc: 0.03394847
case acc: 0.036007777
case acc: 0.036767244
case acc: 0.022968866
case acc: 0.027469624
top acc: 0.0383 ::: bot acc: 0.0092
top acc: 0.0552 ::: bot acc: 0.0141
top acc: 0.0632 ::: bot acc: 0.0152
top acc: 0.0674 ::: bot acc: 0.0127
top acc: 0.0437 ::: bot acc: 0.0186
top acc: 0.0522 ::: bot acc: 0.0105
current epoch: 42
train loss is 0.026009
average val loss: 0.033874, accuracy: 0.0333
average test loss: 0.033764, accuracy: 0.0338
case acc: 0.021620832
case acc: 0.042881466
case acc: 0.040441725
case acc: 0.042533882
case acc: 0.024555484
case acc: 0.03087523
top acc: 0.0399 ::: bot acc: 0.0089
top acc: 0.0645 ::: bot acc: 0.0222
top acc: 0.0690 ::: bot acc: 0.0169
top acc: 0.0745 ::: bot acc: 0.0157
top acc: 0.0494 ::: bot acc: 0.0130
top acc: 0.0574 ::: bot acc: 0.0104
current epoch: 43
train loss is 0.028080
average val loss: 0.039260, accuracy: 0.0388
average test loss: 0.039051, accuracy: 0.0390
case acc: 0.023199847
case acc: 0.051181156
case acc: 0.04633488
case acc: 0.049328074
case acc: 0.027964817
case acc: 0.036074806
top acc: 0.0423 ::: bot acc: 0.0088
top acc: 0.0728 ::: bot acc: 0.0305
top acc: 0.0758 ::: bot acc: 0.0209
top acc: 0.0823 ::: bot acc: 0.0205
top acc: 0.0563 ::: bot acc: 0.0095
top acc: 0.0641 ::: bot acc: 0.0127
current epoch: 44
train loss is 0.030805
average val loss: 0.041601, accuracy: 0.0411
average test loss: 0.041389, accuracy: 0.0412
case acc: 0.021951934
case acc: 0.05332416
case acc: 0.049244706
case acc: 0.052917738
case acc: 0.030275263
case acc: 0.03948539
top acc: 0.0405 ::: bot acc: 0.0088
top acc: 0.0750 ::: bot acc: 0.0327
top acc: 0.0791 ::: bot acc: 0.0231
top acc: 0.0863 ::: bot acc: 0.0234
top acc: 0.0602 ::: bot acc: 0.0085
top acc: 0.0681 ::: bot acc: 0.0147
current epoch: 45
train loss is 0.032331
average val loss: 0.037240, accuracy: 0.0366
average test loss: 0.037199, accuracy: 0.0370
case acc: 0.017543763
case acc: 0.044500243
case acc: 0.044912685
case acc: 0.049117073
case acc: 0.02851069
case acc: 0.037345972
top acc: 0.0306 ::: bot acc: 0.0153
top acc: 0.0661 ::: bot acc: 0.0238
top acc: 0.0742 ::: bot acc: 0.0198
top acc: 0.0821 ::: bot acc: 0.0204
top acc: 0.0572 ::: bot acc: 0.0092
top acc: 0.0656 ::: bot acc: 0.0134
current epoch: 46
train loss is 0.031942
average val loss: 0.029495, accuracy: 0.0288
average test loss: 0.029804, accuracy: 0.0297
case acc: 0.017991528
case acc: 0.02802871
case acc: 0.035916824
case acc: 0.040001687
case acc: 0.024533838
case acc: 0.031539984
top acc: 0.0161 ::: bot acc: 0.0298
top acc: 0.0484 ::: bot acc: 0.0100
top acc: 0.0630 ::: bot acc: 0.0152
top acc: 0.0715 ::: bot acc: 0.0142
top acc: 0.0493 ::: bot acc: 0.0131
top acc: 0.0583 ::: bot acc: 0.0106
current epoch: 47
train loss is 0.032416
average val loss: 0.023191, accuracy: 0.0227
average test loss: 0.024231, accuracy: 0.0243
case acc: 0.025468446
case acc: 0.015737318
case acc: 0.026818201
case acc: 0.02981269
case acc: 0.022686541
case acc: 0.025505576
top acc: 0.0099 ::: bot acc: 0.0442
top acc: 0.0239 ::: bot acc: 0.0184
top acc: 0.0480 ::: bot acc: 0.0180
top acc: 0.0569 ::: bot acc: 0.0130
top acc: 0.0391 ::: bot acc: 0.0232
top acc: 0.0487 ::: bot acc: 0.0116
current epoch: 48
train loss is 0.035410
average val loss: 0.027083, accuracy: 0.0275
average test loss: 0.029125, accuracy: 0.0300
case acc: 0.043470014
case acc: 0.03722392
case acc: 0.025611544
case acc: 0.024582073
case acc: 0.027495414
case acc: 0.02149909
top acc: 0.0213 ::: bot acc: 0.0655
top acc: 0.0166 ::: bot acc: 0.0574
top acc: 0.0220 ::: bot acc: 0.0433
top acc: 0.0302 ::: bot acc: 0.0363
top acc: 0.0203 ::: bot acc: 0.0432
top acc: 0.0296 ::: bot acc: 0.0282
current epoch: 49
train loss is 0.039993
average val loss: 0.054733, accuracy: 0.0550
average test loss: 0.056245, accuracy: 0.0568
case acc: 0.070053436
case acc: 0.087217316
case acc: 0.05072837
case acc: 0.04752744
case acc: 0.049635004
case acc: 0.03558604
top acc: 0.0468 ::: bot acc: 0.0926
top acc: 0.0656 ::: bot acc: 0.1079
top acc: 0.0239 ::: bot acc: 0.0800
top acc: 0.0214 ::: bot acc: 0.0752
top acc: 0.0234 ::: bot acc: 0.0748
top acc: 0.0139 ::: bot acc: 0.0590
current epoch: 50
train loss is 0.050346
average val loss: 0.050701, accuracy: 0.0510
average test loss: 0.052313, accuracy: 0.0528
case acc: 0.056465518
case acc: 0.085064985
case acc: 0.048696302
case acc: 0.046089154
case acc: 0.04689034
case acc: 0.033626836
top acc: 0.0332 ::: bot acc: 0.0790
top acc: 0.0634 ::: bot acc: 0.1058
top acc: 0.0226 ::: bot acc: 0.0776
top acc: 0.0206 ::: bot acc: 0.0735
top acc: 0.0215 ::: bot acc: 0.0717
top acc: 0.0134 ::: bot acc: 0.0564
LME_Co_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2010-07-01', '2011-01-01', '2016-01-01', '2016-07-01', '2017-01-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6804 6804 6804
1.7082474 -0.6288155 0.12137239 -0.15229516
Validation: 762 762 762
Testing: 750 750 750
pre-processing time: 0.0002300739288330078
the split date is 2011-01-01
net initializing with time: 0.37069082260131836
preparing training and testing date with time: 2.384185791015625e-07
current epoch: 1
train loss is 0.297792
average val loss: 0.085393, accuracy: 0.0862
average test loss: 0.078548, accuracy: 0.0794
case acc: 0.1602088
case acc: 0.13499391
case acc: 0.04341605
case acc: 0.033284005
case acc: 0.034337964
case acc: 0.07043736
top acc: 0.1359 ::: bot acc: 0.1843
top acc: 0.1141 ::: bot acc: 0.1550
top acc: 0.0166 ::: bot acc: 0.0746
top acc: 0.0120 ::: bot acc: 0.0586
top acc: 0.0142 ::: bot acc: 0.0612
top acc: 0.0411 ::: bot acc: 0.0994
current epoch: 2
train loss is 0.104875
average val loss: 0.055993, accuracy: 0.0573
average test loss: 0.051346, accuracy: 0.0533
case acc: 0.11576809
case acc: 0.09347393
case acc: 0.027830705
case acc: 0.020488147
case acc: 0.025056835
case acc: 0.037348054
top acc: 0.0913 ::: bot acc: 0.1401
top acc: 0.0727 ::: bot acc: 0.1135
top acc: 0.0291 ::: bot acc: 0.0446
top acc: 0.0230 ::: bot acc: 0.0328
top acc: 0.0342 ::: bot acc: 0.0332
top acc: 0.0120 ::: bot acc: 0.0645
current epoch: 3
train loss is 0.093411
average val loss: 0.081823, accuracy: 0.0824
average test loss: 0.074642, accuracy: 0.0753
case acc: 0.13716187
case acc: 0.11954217
case acc: 0.04664488
case acc: 0.045102548
case acc: 0.040933426
case acc: 0.062176775
top acc: 0.1126 ::: bot acc: 0.1615
top acc: 0.0988 ::: bot acc: 0.1397
top acc: 0.0179 ::: bot acc: 0.0787
top acc: 0.0195 ::: bot acc: 0.0725
top acc: 0.0148 ::: bot acc: 0.0707
top acc: 0.0328 ::: bot acc: 0.0913
current epoch: 4
train loss is 0.091244
average val loss: 0.079427, accuracy: 0.0799
average test loss: 0.072159, accuracy: 0.0727
case acc: 0.12500522
case acc: 0.11300763
case acc: 0.04692858
case acc: 0.052371174
case acc: 0.045076035
case acc: 0.053581674
top acc: 0.1005 ::: bot acc: 0.1494
top acc: 0.0922 ::: bot acc: 0.1332
top acc: 0.0180 ::: bot acc: 0.0791
top acc: 0.0259 ::: bot acc: 0.0801
top acc: 0.0167 ::: bot acc: 0.0761
top acc: 0.0244 ::: bot acc: 0.0826
current epoch: 5
train loss is 0.080019
average val loss: 0.073837, accuracy: 0.0743
average test loss: 0.066523, accuracy: 0.0670
case acc: 0.10914669
case acc: 0.10153086
case acc: 0.045072693
case acc: 0.0559471
case acc: 0.046228543
case acc: 0.044274718
top acc: 0.0846 ::: bot acc: 0.1337
top acc: 0.0807 ::: bot acc: 0.1218
top acc: 0.0174 ::: bot acc: 0.0766
top acc: 0.0291 ::: bot acc: 0.0837
top acc: 0.0173 ::: bot acc: 0.0776
top acc: 0.0166 ::: bot acc: 0.0726
current epoch: 6
train loss is 0.069407
average val loss: 0.069673, accuracy: 0.0700
average test loss: 0.062329, accuracy: 0.0628
case acc: 0.09461352
case acc: 0.09048484
case acc: 0.0448942
case acc: 0.060153574
case acc: 0.047737747
case acc: 0.03881034
top acc: 0.0700 ::: bot acc: 0.1193
top acc: 0.0696 ::: bot acc: 0.1109
top acc: 0.0174 ::: bot acc: 0.0763
top acc: 0.0330 ::: bot acc: 0.0880
top acc: 0.0181 ::: bot acc: 0.0796
top acc: 0.0127 ::: bot acc: 0.0664
current epoch: 7
train loss is 0.060522
average val loss: 0.071933, accuracy: 0.0722
average test loss: 0.064526, accuracy: 0.0648
case acc: 0.087047845
case acc: 0.08616498
case acc: 0.050185833
case acc: 0.070585184
case acc: 0.054355107
case acc: 0.040226474
top acc: 0.0625 ::: bot acc: 0.1117
top acc: 0.0653 ::: bot acc: 0.1067
top acc: 0.0197 ::: bot acc: 0.0831
top acc: 0.0432 ::: bot acc: 0.0985
top acc: 0.0224 ::: bot acc: 0.0874
top acc: 0.0135 ::: bot acc: 0.0681
current epoch: 8
train loss is 0.056405
average val loss: 0.066910, accuracy: 0.0671
average test loss: 0.059479, accuracy: 0.0597
case acc: 0.071704715
case acc: 0.073421374
case acc: 0.049798734
case acc: 0.07291099
case acc: 0.05363711
case acc: 0.036743607
top acc: 0.0473 ::: bot acc: 0.0963
top acc: 0.0524 ::: bot acc: 0.0940
top acc: 0.0194 ::: bot acc: 0.0827
top acc: 0.0456 ::: bot acc: 0.1006
top acc: 0.0217 ::: bot acc: 0.0867
top acc: 0.0118 ::: bot acc: 0.0637
current epoch: 9
train loss is 0.049151
average val loss: 0.063122, accuracy: 0.0631
average test loss: 0.055676, accuracy: 0.0558
case acc: 0.058147542
case acc: 0.061342087
case acc: 0.050732933
case acc: 0.07550982
case acc: 0.053507507
case acc: 0.03559724
top acc: 0.0341 ::: bot acc: 0.0826
top acc: 0.0404 ::: bot acc: 0.0820
top acc: 0.0201 ::: bot acc: 0.0838
top acc: 0.0483 ::: bot acc: 0.1032
top acc: 0.0216 ::: bot acc: 0.0867
top acc: 0.0115 ::: bot acc: 0.0622
current epoch: 10
train loss is 0.043881
average val loss: 0.056696, accuracy: 0.0565
average test loss: 0.049338, accuracy: 0.0492
case acc: 0.042332135
case acc: 0.045696035
case acc: 0.049293276
case acc: 0.07387515
case acc: 0.050214075
case acc: 0.033854783
top acc: 0.0188 ::: bot acc: 0.0665
top acc: 0.0247 ::: bot acc: 0.0664
top acc: 0.0192 ::: bot acc: 0.0821
top acc: 0.0467 ::: bot acc: 0.1015
top acc: 0.0191 ::: bot acc: 0.0830
top acc: 0.0115 ::: bot acc: 0.0596
current epoch: 11
train loss is 0.040325
average val loss: 0.052373, accuracy: 0.0518
average test loss: 0.045308, accuracy: 0.0446
case acc: 0.030221984
case acc: 0.032289993
case acc: 0.04908909
case acc: 0.07296488
case acc: 0.0489734
case acc: 0.03393946
top acc: 0.0085 ::: bot acc: 0.0535
top acc: 0.0122 ::: bot acc: 0.0527
top acc: 0.0191 ::: bot acc: 0.0819
top acc: 0.0458 ::: bot acc: 0.1005
top acc: 0.0183 ::: bot acc: 0.0816
top acc: 0.0116 ::: bot acc: 0.0597
current epoch: 12
train loss is 0.039845
average val loss: 0.045867, accuracy: 0.0449
average test loss: 0.039751, accuracy: 0.0385
case acc: 0.020960473
case acc: 0.019523732
case acc: 0.04563728
case acc: 0.06759734
case acc: 0.04559236
case acc: 0.031842396
top acc: 0.0108 ::: bot acc: 0.0386
top acc: 0.0079 ::: bot acc: 0.0358
top acc: 0.0176 ::: bot acc: 0.0775
top acc: 0.0405 ::: bot acc: 0.0952
top acc: 0.0162 ::: bot acc: 0.0776
top acc: 0.0120 ::: bot acc: 0.0564
current epoch: 13
train loss is 0.048132
average val loss: 0.031547, accuracy: 0.0312
average test loss: 0.029651, accuracy: 0.0289
case acc: 0.02414169
case acc: 0.025460962
case acc: 0.030293586
case acc: 0.04169478
case acc: 0.029821433
case acc: 0.022055164
top acc: 0.0439 ::: bot acc: 0.0090
top acc: 0.0442 ::: bot acc: 0.0091
top acc: 0.0207 ::: bot acc: 0.0532
top acc: 0.0168 ::: bot acc: 0.0681
top acc: 0.0167 ::: bot acc: 0.0539
top acc: 0.0235 ::: bot acc: 0.0358
current epoch: 14
train loss is 0.062275
average val loss: 0.058418, accuracy: 0.0587
average test loss: 0.064894, accuracy: 0.0649
case acc: 0.092562996
case acc: 0.10602144
case acc: 0.051992457
case acc: 0.03575163
case acc: 0.04914059
case acc: 0.053926058
top acc: 0.1170 ::: bot acc: 0.0679
top acc: 0.1270 ::: bot acc: 0.0851
top acc: 0.0871 ::: bot acc: 0.0192
top acc: 0.0610 ::: bot acc: 0.0122
top acc: 0.0829 ::: bot acc: 0.0159
top acc: 0.0833 ::: bot acc: 0.0255
current epoch: 15
train loss is 0.080905
average val loss: 0.084011, accuracy: 0.0841
average test loss: 0.090917, accuracy: 0.0909
case acc: 0.11324748
case acc: 0.13745461
case acc: 0.07711203
case acc: 0.0698822
case acc: 0.0780144
case acc: 0.0697516
top acc: 0.1377 ::: bot acc: 0.0885
top acc: 0.1584 ::: bot acc: 0.1165
top acc: 0.1135 ::: bot acc: 0.0415
top acc: 0.0970 ::: bot acc: 0.0422
top acc: 0.1124 ::: bot acc: 0.0434
top acc: 0.0996 ::: bot acc: 0.0404
current epoch: 16
train loss is 0.065484
average val loss: 0.058027, accuracy: 0.0581
average test loss: 0.064549, accuracy: 0.0647
case acc: 0.076375425
case acc: 0.10559007
case acc: 0.05395822
case acc: 0.0534832
case acc: 0.059275113
case acc: 0.039490122
top acc: 0.1009 ::: bot acc: 0.0516
top acc: 0.1266 ::: bot acc: 0.0845
top acc: 0.0892 ::: bot acc: 0.0208
top acc: 0.0804 ::: bot acc: 0.0261
top acc: 0.0937 ::: bot acc: 0.0247
top acc: 0.0674 ::: bot acc: 0.0141
current epoch: 17
train loss is 0.051570
average val loss: 0.055793, accuracy: 0.0558
average test loss: 0.062297, accuracy: 0.0624
case acc: 0.063032895
case acc: 0.09349445
case acc: 0.056686774
case acc: 0.059477564
case acc: 0.062957056
case acc: 0.03890663
top acc: 0.0875 ::: bot acc: 0.0383
top acc: 0.1146 ::: bot acc: 0.0723
top acc: 0.0921 ::: bot acc: 0.0231
top acc: 0.0865 ::: bot acc: 0.0319
top acc: 0.0975 ::: bot acc: 0.0282
top acc: 0.0667 ::: bot acc: 0.0139
current epoch: 18
train loss is 0.046091
average val loss: 0.054075, accuracy: 0.0540
average test loss: 0.060605, accuracy: 0.0607
case acc: 0.05027784
case acc: 0.081862725
case acc: 0.06039086
case acc: 0.065900154
case acc: 0.06630792
case acc: 0.03948805
top acc: 0.0746 ::: bot acc: 0.0258
top acc: 0.1031 ::: bot acc: 0.0605
top acc: 0.0959 ::: bot acc: 0.0264
top acc: 0.0928 ::: bot acc: 0.0384
top acc: 0.1009 ::: bot acc: 0.0315
top acc: 0.0673 ::: bot acc: 0.0144
current epoch: 19
train loss is 0.041307
average val loss: 0.048746, accuracy: 0.0485
average test loss: 0.055145, accuracy: 0.0552
case acc: 0.03491377
case acc: 0.06624416
case acc: 0.060072783
case acc: 0.06753455
case acc: 0.065241784
case acc: 0.03696264
top acc: 0.0582 ::: bot acc: 0.0126
top acc: 0.0875 ::: bot acc: 0.0449
top acc: 0.0955 ::: bot acc: 0.0261
top acc: 0.0945 ::: bot acc: 0.0400
top acc: 0.0999 ::: bot acc: 0.0303
top acc: 0.0643 ::: bot acc: 0.0130
current epoch: 20
train loss is 0.039097
average val loss: 0.042540, accuracy: 0.0420
average test loss: 0.048525, accuracy: 0.0484
case acc: 0.022520484
case acc: 0.048491184
case acc: 0.057401996
case acc: 0.06582279
case acc: 0.062408734
case acc: 0.03374564
top acc: 0.0410 ::: bot acc: 0.0099
top acc: 0.0696 ::: bot acc: 0.0272
top acc: 0.0927 ::: bot acc: 0.0238
top acc: 0.0928 ::: bot acc: 0.0382
top acc: 0.0971 ::: bot acc: 0.0275
top acc: 0.0601 ::: bot acc: 0.0116
current epoch: 21
train loss is 0.045144
average val loss: 0.027943, accuracy: 0.0272
average test loss: 0.030779, accuracy: 0.0307
case acc: 0.023491614
case acc: 0.017259978
case acc: 0.037700158
case acc: 0.042283606
case acc: 0.041259926
case acc: 0.022296436
top acc: 0.0076 ::: bot acc: 0.0443
top acc: 0.0304 ::: bot acc: 0.0122
top acc: 0.0690 ::: bot acc: 0.0124
top acc: 0.0684 ::: bot acc: 0.0165
top acc: 0.0738 ::: bot acc: 0.0108
top acc: 0.0380 ::: bot acc: 0.0213
current epoch: 22
train loss is 0.057085
average val loss: 0.060116, accuracy: 0.0608
average test loss: 0.052919, accuracy: 0.0538
case acc: 0.09217335
case acc: 0.07299284
case acc: 0.03942122
case acc: 0.033151884
case acc: 0.03463797
case acc: 0.050174963
top acc: 0.0676 ::: bot acc: 0.1174
top acc: 0.0519 ::: bot acc: 0.0944
top acc: 0.0157 ::: bot acc: 0.0692
top acc: 0.0119 ::: bot acc: 0.0579
top acc: 0.0127 ::: bot acc: 0.0634
top acc: 0.0211 ::: bot acc: 0.0793
current epoch: 23
train loss is 0.061571
average val loss: 0.076837, accuracy: 0.0771
average test loss: 0.069329, accuracy: 0.0696
case acc: 0.10405696
case acc: 0.097054295
case acc: 0.052474156
case acc: 0.057461143
case acc: 0.051357035
case acc: 0.05504993
top acc: 0.0796 ::: bot acc: 0.1292
top acc: 0.0759 ::: bot acc: 0.1185
top acc: 0.0210 ::: bot acc: 0.0859
top acc: 0.0307 ::: bot acc: 0.0850
top acc: 0.0195 ::: bot acc: 0.0850
top acc: 0.0255 ::: bot acc: 0.0843
current epoch: 24
train loss is 0.053926
average val loss: 0.061137, accuracy: 0.0615
average test loss: 0.053772, accuracy: 0.0544
case acc: 0.07758433
case acc: 0.07691156
case acc: 0.041217115
case acc: 0.05155465
case acc: 0.04411102
case acc: 0.034750927
top acc: 0.0531 ::: bot acc: 0.1028
top acc: 0.0558 ::: bot acc: 0.0983
top acc: 0.0161 ::: bot acc: 0.0716
top acc: 0.0252 ::: bot acc: 0.0789
top acc: 0.0149 ::: bot acc: 0.0764
top acc: 0.0122 ::: bot acc: 0.0606
current epoch: 25
train loss is 0.045143
average val loss: 0.055801, accuracy: 0.0561
average test loss: 0.048507, accuracy: 0.0490
case acc: 0.06118129
case acc: 0.062282406
case acc: 0.040648434
case acc: 0.053999335
case acc: 0.044575017
case acc: 0.03142891
top acc: 0.0368 ::: bot acc: 0.0864
top acc: 0.0412 ::: bot acc: 0.0837
top acc: 0.0159 ::: bot acc: 0.0708
top acc: 0.0274 ::: bot acc: 0.0815
top acc: 0.0152 ::: bot acc: 0.0769
top acc: 0.0123 ::: bot acc: 0.0556
current epoch: 26
train loss is 0.039404
average val loss: 0.049296, accuracy: 0.0493
average test loss: 0.042139, accuracy: 0.0424
case acc: 0.0438107
case acc: 0.04465859
case acc: 0.039707802
case acc: 0.05358831
case acc: 0.042638596
case acc: 0.029718025
top acc: 0.0200 ::: bot acc: 0.0687
top acc: 0.0236 ::: bot acc: 0.0660
top acc: 0.0157 ::: bot acc: 0.0695
top acc: 0.0270 ::: bot acc: 0.0810
top acc: 0.0143 ::: bot acc: 0.0745
top acc: 0.0128 ::: bot acc: 0.0528
current epoch: 27
train loss is 0.036045
average val loss: 0.037568, accuracy: 0.0370
average test loss: 0.031681, accuracy: 0.0310
case acc: 0.023694454
case acc: 0.022176579
case acc: 0.03432859
case acc: 0.045143828
case acc: 0.03516425
case acc: 0.02542765
top acc: 0.0075 ::: bot acc: 0.0449
top acc: 0.0067 ::: bot acc: 0.0408
top acc: 0.0162 ::: bot acc: 0.0613
top acc: 0.0196 ::: bot acc: 0.0720
top acc: 0.0125 ::: bot acc: 0.0642
top acc: 0.0154 ::: bot acc: 0.0452
current epoch: 28
train loss is 0.032946
average val loss: 0.028051, accuracy: 0.0275
average test loss: 0.025393, accuracy: 0.0246
case acc: 0.018697707
case acc: 0.016768148
case acc: 0.028670162
case acc: 0.03321461
case acc: 0.028320635
case acc: 0.021905774
top acc: 0.0292 ::: bot acc: 0.0205
top acc: 0.0289 ::: bot acc: 0.0136
top acc: 0.0239 ::: bot acc: 0.0491
top acc: 0.0118 ::: bot acc: 0.0581
top acc: 0.0189 ::: bot acc: 0.0509
top acc: 0.0239 ::: bot acc: 0.0352
current epoch: 29
train loss is 0.037814
average val loss: 0.028796, accuracy: 0.0297
average test loss: 0.032483, accuracy: 0.0328
case acc: 0.04222289
case acc: 0.051135458
case acc: 0.029518906
case acc: 0.019909319
case acc: 0.027730264
case acc: 0.026573332
top acc: 0.0664 ::: bot acc: 0.0178
top acc: 0.0722 ::: bot acc: 0.0298
top acc: 0.0537 ::: bot acc: 0.0193
top acc: 0.0306 ::: bot acc: 0.0241
top acc: 0.0486 ::: bot acc: 0.0207
top acc: 0.0488 ::: bot acc: 0.0126
current epoch: 30
train loss is 0.047504
average val loss: 0.058913, accuracy: 0.0591
average test loss: 0.065597, accuracy: 0.0657
case acc: 0.08038445
case acc: 0.10029981
case acc: 0.056835752
case acc: 0.05104399
case acc: 0.056008138
case acc: 0.04955736
top acc: 0.1050 ::: bot acc: 0.0551
top acc: 0.1214 ::: bot acc: 0.0789
top acc: 0.0925 ::: bot acc: 0.0233
top acc: 0.0780 ::: bot acc: 0.0238
top acc: 0.0904 ::: bot acc: 0.0215
top acc: 0.0785 ::: bot acc: 0.0219
current epoch: 31
train loss is 0.056898
average val loss: 0.059015, accuracy: 0.0591
average test loss: 0.065698, accuracy: 0.0658
case acc: 0.07130268
case acc: 0.097876206
case acc: 0.058943845
case acc: 0.060810596
case acc: 0.06193477
case acc: 0.044037763
top acc: 0.0959 ::: bot acc: 0.0461
top acc: 0.1190 ::: bot acc: 0.0765
top acc: 0.0947 ::: bot acc: 0.0250
top acc: 0.0880 ::: bot acc: 0.0330
top acc: 0.0964 ::: bot acc: 0.0271
top acc: 0.0724 ::: bot acc: 0.0175
current epoch: 32
train loss is 0.051598
average val loss: 0.035081, accuracy: 0.0352
average test loss: 0.040809, accuracy: 0.0411
case acc: 0.03495619
case acc: 0.06155067
case acc: 0.039508935
case acc: 0.04246395
case acc: 0.04309423
case acc: 0.025276372
top acc: 0.0583 ::: bot acc: 0.0123
top acc: 0.0827 ::: bot acc: 0.0401
top acc: 0.0717 ::: bot acc: 0.0129
top acc: 0.0687 ::: bot acc: 0.0165
top acc: 0.0760 ::: bot acc: 0.0117
top acc: 0.0461 ::: bot acc: 0.0142
current epoch: 33
train loss is 0.040472
average val loss: 0.029346, accuracy: 0.0292
average test loss: 0.034664, accuracy: 0.0348
case acc: 0.022902697
case acc: 0.041603416
case acc: 0.03846043
case acc: 0.03971413
case acc: 0.04053011
case acc: 0.02573684
top acc: 0.0415 ::: bot acc: 0.0099
top acc: 0.0624 ::: bot acc: 0.0207
top acc: 0.0702 ::: bot acc: 0.0128
top acc: 0.0656 ::: bot acc: 0.0144
top acc: 0.0727 ::: bot acc: 0.0107
top acc: 0.0471 ::: bot acc: 0.0135
current epoch: 34
train loss is 0.035598
average val loss: 0.023964, accuracy: 0.0236
average test loss: 0.027652, accuracy: 0.0276
case acc: 0.018200293
case acc: 0.021231903
case acc: 0.034408942
case acc: 0.032398205
case acc: 0.035033602
case acc: 0.024590664
top acc: 0.0221 ::: bot acc: 0.0277
top acc: 0.0381 ::: bot acc: 0.0085
top acc: 0.0639 ::: bot acc: 0.0133
top acc: 0.0567 ::: bot acc: 0.0104
top acc: 0.0646 ::: bot acc: 0.0104
top acc: 0.0446 ::: bot acc: 0.0152
current epoch: 35
train loss is 0.034017
average val loss: 0.024428, accuracy: 0.0247
average test loss: 0.023828, accuracy: 0.0243
case acc: 0.028291127
case acc: 0.019005613
case acc: 0.027737722
case acc: 0.021741308
case acc: 0.027691117
case acc: 0.02157119
top acc: 0.0073 ::: bot acc: 0.0518
top acc: 0.0083 ::: bot acc: 0.0354
top acc: 0.0479 ::: bot acc: 0.0253
top acc: 0.0374 ::: bot acc: 0.0174
top acc: 0.0485 ::: bot acc: 0.0209
top acc: 0.0333 ::: bot acc: 0.0258
current epoch: 36
train loss is 0.037482
average val loss: 0.045095, accuracy: 0.0457
average test loss: 0.038646, accuracy: 0.0399
case acc: 0.06001466
case acc: 0.05761346
case acc: 0.032255977
case acc: 0.031289008
case acc: 0.029647077
case acc: 0.028491667
top acc: 0.0356 ::: bot acc: 0.0852
top acc: 0.0365 ::: bot acc: 0.0791
top acc: 0.0180 ::: bot acc: 0.0574
top acc: 0.0113 ::: bot acc: 0.0555
top acc: 0.0172 ::: bot acc: 0.0537
top acc: 0.0133 ::: bot acc: 0.0507
current epoch: 37
train loss is 0.046121
average val loss: 0.066540, accuracy: 0.0668
average test loss: 0.059028, accuracy: 0.0593
case acc: 0.076760545
case acc: 0.08350725
case acc: 0.04891607
case acc: 0.05982366
case acc: 0.04786028
case acc: 0.03918434
top acc: 0.0522 ::: bot acc: 0.1020
top acc: 0.0624 ::: bot acc: 0.1049
top acc: 0.0187 ::: bot acc: 0.0819
top acc: 0.0329 ::: bot acc: 0.0874
top acc: 0.0170 ::: bot acc: 0.0809
top acc: 0.0132 ::: bot acc: 0.0667
current epoch: 38
train loss is 0.048365
average val loss: 0.042990, accuracy: 0.0433
average test loss: 0.036648, accuracy: 0.0372
case acc: 0.04077788
case acc: 0.050444964
case acc: 0.03303962
case acc: 0.04287246
case acc: 0.033250004
case acc: 0.022763744
top acc: 0.0170 ::: bot acc: 0.0656
top acc: 0.0294 ::: bot acc: 0.0718
top acc: 0.0172 ::: bot acc: 0.0590
top acc: 0.0177 ::: bot acc: 0.0696
top acc: 0.0132 ::: bot acc: 0.0610
top acc: 0.0205 ::: bot acc: 0.0386
current epoch: 39
train loss is 0.042425
average val loss: 0.026736, accuracy: 0.0267
average test loss: 0.023747, accuracy: 0.0235
case acc: 0.019087166
case acc: 0.019293299
case acc: 0.026831137
case acc: 0.028326474
case acc: 0.025825944
case acc: 0.021767024
top acc: 0.0170 ::: bot acc: 0.0329
top acc: 0.0079 ::: bot acc: 0.0360
top acc: 0.0311 ::: bot acc: 0.0421
top acc: 0.0114 ::: bot acc: 0.0511
top acc: 0.0275 ::: bot acc: 0.0418
top acc: 0.0348 ::: bot acc: 0.0244
current epoch: 40
train loss is 0.034274
average val loss: 0.022458, accuracy: 0.0224
average test loss: 0.022802, accuracy: 0.0225
case acc: 0.020929083
case acc: 0.018540356
case acc: 0.026357744
case acc: 0.021660259
case acc: 0.02554169
case acc: 0.021979187
top acc: 0.0373 ::: bot acc: 0.0127
top acc: 0.0334 ::: bot acc: 0.0099
top acc: 0.0385 ::: bot acc: 0.0348
top acc: 0.0164 ::: bot acc: 0.0388
top acc: 0.0383 ::: bot acc: 0.0309
top acc: 0.0363 ::: bot acc: 0.0229
current epoch: 41
train loss is 0.032909
average val loss: 0.027265, accuracy: 0.0279
average test loss: 0.031776, accuracy: 0.0322
case acc: 0.03747806
case acc: 0.044936508
case acc: 0.03062708
case acc: 0.022734866
case acc: 0.031281266
case acc: 0.02603281
top acc: 0.0614 ::: bot acc: 0.0139
top acc: 0.0658 ::: bot acc: 0.0238
top acc: 0.0565 ::: bot acc: 0.0173
top acc: 0.0400 ::: bot acc: 0.0152
top acc: 0.0577 ::: bot acc: 0.0130
top acc: 0.0477 ::: bot acc: 0.0131
current epoch: 42
train loss is 0.036601
average val loss: 0.044129, accuracy: 0.0444
average test loss: 0.050489, accuracy: 0.0507
case acc: 0.056921028
case acc: 0.07481476
case acc: 0.04512068
case acc: 0.043580234
case acc: 0.04805327
case acc: 0.035736185
top acc: 0.0817 ::: bot acc: 0.0316
top acc: 0.0958 ::: bot acc: 0.0534
top acc: 0.0791 ::: bot acc: 0.0151
top acc: 0.0701 ::: bot acc: 0.0173
top acc: 0.0818 ::: bot acc: 0.0147
top acc: 0.0626 ::: bot acc: 0.0122
current epoch: 43
train loss is 0.042352
average val loss: 0.050307, accuracy: 0.0503
average test loss: 0.056856, accuracy: 0.0570
case acc: 0.05483731
case acc: 0.078538634
case acc: 0.053307652
case acc: 0.058444507
case acc: 0.058622487
case acc: 0.038274523
top acc: 0.0796 ::: bot acc: 0.0295
top acc: 0.0995 ::: bot acc: 0.0571
top acc: 0.0887 ::: bot acc: 0.0204
top acc: 0.0857 ::: bot acc: 0.0306
top acc: 0.0931 ::: bot acc: 0.0240
top acc: 0.0657 ::: bot acc: 0.0136
current epoch: 44
train loss is 0.042313
average val loss: 0.029485, accuracy: 0.0293
average test loss: 0.034683, accuracy: 0.0350
case acc: 0.023902155
case acc: 0.04375092
case acc: 0.036565717
case acc: 0.04133047
case acc: 0.040761884
case acc: 0.023478452
top acc: 0.0435 ::: bot acc: 0.0091
top acc: 0.0646 ::: bot acc: 0.0226
top acc: 0.0674 ::: bot acc: 0.0129
top acc: 0.0676 ::: bot acc: 0.0155
top acc: 0.0730 ::: bot acc: 0.0107
top acc: 0.0418 ::: bot acc: 0.0174
current epoch: 45
train loss is 0.037232
average val loss: 0.022231, accuracy: 0.0223
average test loss: 0.023314, accuracy: 0.0237
case acc: 0.02073052
case acc: 0.016636403
case acc: 0.028177332
case acc: 0.025970083
case acc: 0.029139847
case acc: 0.021332344
top acc: 0.0117 ::: bot acc: 0.0384
top acc: 0.0283 ::: bot acc: 0.0142
top acc: 0.0494 ::: bot acc: 0.0239
top acc: 0.0471 ::: bot acc: 0.0107
top acc: 0.0528 ::: bot acc: 0.0167
top acc: 0.0273 ::: bot acc: 0.0319
current epoch: 46
train loss is 0.035105
average val loss: 0.032005, accuracy: 0.0326
average test loss: 0.027341, accuracy: 0.0284
case acc: 0.04084695
case acc: 0.030362854
case acc: 0.027389029
case acc: 0.02042288
case acc: 0.025567787
case acc: 0.025575627
top acc: 0.0169 ::: bot acc: 0.0658
top acc: 0.0107 ::: bot acc: 0.0511
top acc: 0.0286 ::: bot acc: 0.0447
top acc: 0.0201 ::: bot acc: 0.0349
top acc: 0.0295 ::: bot acc: 0.0398
top acc: 0.0151 ::: bot acc: 0.0456
current epoch: 47
train loss is 0.036821
average val loss: 0.050006, accuracy: 0.0504
average test loss: 0.042869, accuracy: 0.0437
case acc: 0.059046637
case acc: 0.059903726
case acc: 0.036957737
case acc: 0.038260564
case acc: 0.035252154
case acc: 0.032510716
top acc: 0.0345 ::: bot acc: 0.0843
top acc: 0.0389 ::: bot acc: 0.0813
top acc: 0.0155 ::: bot acc: 0.0656
top acc: 0.0143 ::: bot acc: 0.0645
top acc: 0.0126 ::: bot acc: 0.0642
top acc: 0.0121 ::: bot acc: 0.0574
current epoch: 48
train loss is 0.039289
average val loss: 0.050567, accuracy: 0.0509
average test loss: 0.043376, accuracy: 0.0439
case acc: 0.050895132
case acc: 0.058084376
case acc: 0.038855728
case acc: 0.046769276
case acc: 0.039264426
case acc: 0.029777767
top acc: 0.0266 ::: bot acc: 0.0761
top acc: 0.0371 ::: bot acc: 0.0795
top acc: 0.0156 ::: bot acc: 0.0684
top acc: 0.0207 ::: bot acc: 0.0740
top acc: 0.0129 ::: bot acc: 0.0700
top acc: 0.0126 ::: bot acc: 0.0531
current epoch: 49
train loss is 0.039900
average val loss: 0.030166, accuracy: 0.0302
average test loss: 0.025868, accuracy: 0.0257
case acc: 0.0213459
case acc: 0.024466302
case acc: 0.02813719
case acc: 0.031025548
case acc: 0.027753461
case acc: 0.021344023
top acc: 0.0104 ::: bot acc: 0.0400
top acc: 0.0072 ::: bot acc: 0.0441
top acc: 0.0261 ::: bot acc: 0.0472
top acc: 0.0112 ::: bot acc: 0.0552
top acc: 0.0204 ::: bot acc: 0.0493
top acc: 0.0293 ::: bot acc: 0.0300
current epoch: 50
train loss is 0.033568
average val loss: 0.022243, accuracy: 0.0223
average test loss: 0.023067, accuracy: 0.0227
case acc: 0.021914018
case acc: 0.018071102
case acc: 0.026612671
case acc: 0.020944417
case acc: 0.025548732
case acc: 0.023197278
top acc: 0.0395 ::: bot acc: 0.0112
top acc: 0.0323 ::: bot acc: 0.0104
top acc: 0.0416 ::: bot acc: 0.0317
top acc: 0.0185 ::: bot acc: 0.0366
top acc: 0.0384 ::: bot acc: 0.0308
top acc: 0.0410 ::: bot acc: 0.0183
LME_Co_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_EMA125', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_Close_bollinger125']
features ['LME_Co_Close', 'LME_Co_Close_EMA12', 'LME_Co_Close_EMA125', 'LME_Co_Close_EMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_EMA65', 'LME_Co_Close_bollinger12', 'LME_Co_Close_bollinger125', 'LME_Co_Close_bollinger26', 'LME_Co_Close_bollinger40', 'LME_Co_Close_bollinger65', 'LME_Co_High', 'LME_Co_Low']
LME_Al_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_EMA125', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_Close_bollinger125']
features ['LME_Al_Close', 'LME_Al_Close_EMA12', 'LME_Al_Close_EMA125', 'LME_Al_Close_EMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_EMA65', 'LME_Al_Close_bollinger12', 'LME_Al_Close_bollinger125', 'LME_Al_Close_bollinger26', 'LME_Al_Close_bollinger40', 'LME_Al_Close_bollinger65', 'LME_Al_High', 'LME_Al_Low']
LME_Ni_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_Close_bollinger125']
features ['LME_Ni_Close', 'LME_Ni_Close_EMA12', 'LME_Ni_Close_EMA125', 'LME_Ni_Close_EMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_EMA65', 'LME_Ni_Close_bollinger12', 'LME_Ni_Close_bollinger125', 'LME_Ni_Close_bollinger26', 'LME_Ni_Close_bollinger40', 'LME_Ni_Close_bollinger65', 'LME_Ni_High', 'LME_Ni_Low']
LME_Ti_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_Close_bollinger125']
features ['LME_Ti_Close', 'LME_Ti_Close_EMA12', 'LME_Ti_Close_EMA125', 'LME_Ti_Close_EMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_EMA65', 'LME_Ti_Close_bollinger12', 'LME_Ti_Close_bollinger125', 'LME_Ti_Close_bollinger26', 'LME_Ti_Close_bollinger40', 'LME_Ti_Close_bollinger65', 'LME_Ti_High', 'LME_Ti_Low']
LME_Zi_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_Close_bollinger125']
features ['LME_Zi_Close', 'LME_Zi_Close_EMA12', 'LME_Zi_Close_EMA125', 'LME_Zi_Close_EMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_EMA65', 'LME_Zi_Close_bollinger12', 'LME_Zi_Close_bollinger125', 'LME_Zi_Close_bollinger26', 'LME_Zi_Close_bollinger40', 'LME_Zi_Close_bollinger65', 'LME_Zi_High', 'LME_Zi_Low']
LME_Le_Spot
Before Load Data
['2011-01-01', '2011-07-01', '2016-07-01', '2017-01-01', '2017-07-01']
Normalizing Spread:LME_Al_Close=>LME_Al_Spot
Normalizing Spread:LME_Co_Close=>LME_Co_Spot
Normalizing Spread:LME_Ti_Close=>LME_Ti_Spot
Normalizing Spread:LME_Le_Close=>LME_Le_Spot
Normalizing Spread:LME_Ni_Close=>LME_Ni_Spot
Normalizing Spread:LME_Zi_Close=>LME_Zi_Spot
====================================technical indicator========================================
origin features ['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'LME_Al_n3MSpread', 'LME_Co_n3MSpread', 'LME_Ti_n3MSpread', 'LME_Le_n3MSpread', 'LME_Ni_n3MSpread', 'LME_Zi_n3MSpread', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_EMA125', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_Close_bollinger125']
features ['LME_Le_Close', 'LME_Le_Close_EMA12', 'LME_Le_Close_EMA125', 'LME_Le_Close_EMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_EMA65', 'LME_Le_Close_bollinger12', 'LME_Le_Close_bollinger125', 'LME_Le_Close_bollinger26', 'LME_Le_Close_bollinger40', 'LME_Le_Close_bollinger65', 'LME_Le_High', 'LME_Le_Low']
Dataset statistic: #examples
Train: 6786 6786 6786
1.7082474 -0.6288155 0.12137239 -0.15229516
Validation: 756 756 756
Testing: 768 768 768
pre-processing time: 0.00046133995056152344
the split date is 2011-07-01
net initializing with time: 0.08549118041992188
preparing training and testing date with time: 4.76837158203125e-07
current epoch: 1
train loss is 0.278111
average val loss: 0.200242, accuracy: 0.2012
average test loss: 0.199808, accuracy: 0.2013
case acc: 0.37892386
case acc: 0.3123871
case acc: 0.03290242
case acc: 0.13088804
case acc: 0.32962975
case acc: 0.022898111
top acc: 0.4032 ::: bot acc: 0.3540
top acc: 0.3349 ::: bot acc: 0.2914
top acc: 0.0179 ::: bot acc: 0.0571
top acc: 0.1509 ::: bot acc: 0.1078
top acc: 0.3548 ::: bot acc: 0.3019
top acc: 0.0253 ::: bot acc: 0.0335
current epoch: 2
train loss is 0.269350
average val loss: 0.150615, accuracy: 0.1509
average test loss: 0.150545, accuracy: 0.1503
case acc: 0.2173462
case acc: 0.15706256
case acc: 0.16943017
case acc: 0.024254683
case acc: 0.17214328
case acc: 0.16126926
top acc: 0.2421 ::: bot acc: 0.1930
top acc: 0.1788 ::: bot acc: 0.1368
top acc: 0.1359 ::: bot acc: 0.2027
top acc: 0.0102 ::: bot acc: 0.0435
top acc: 0.1980 ::: bot acc: 0.1437
top acc: 0.1308 ::: bot acc: 0.1912
current epoch: 3
train loss is 0.156265
average val loss: 0.154923, accuracy: 0.1557
average test loss: 0.155181, accuracy: 0.1560
case acc: 0.27223438
case acc: 0.2184411
case acc: 0.08613959
case acc: 0.04987722
case acc: 0.23269744
case acc: 0.0763997
top acc: 0.2972 ::: bot acc: 0.2482
top acc: 0.2399 ::: bot acc: 0.1985
top acc: 0.0530 ::: bot acc: 0.1192
top acc: 0.0683 ::: bot acc: 0.0296
top acc: 0.2589 ::: bot acc: 0.2042
top acc: 0.0482 ::: bot acc: 0.1053
current epoch: 4
train loss is 0.161445
average val loss: 0.133441, accuracy: 0.1339
average test loss: 0.133325, accuracy: 0.1336
case acc: 0.22130427
case acc: 0.17429832
case acc: 0.10530275
case acc: 0.022109501
case acc: 0.18737194
case acc: 0.09144692
top acc: 0.2463 ::: bot acc: 0.1973
top acc: 0.1957 ::: bot acc: 0.1544
top acc: 0.0715 ::: bot acc: 0.1387
top acc: 0.0354 ::: bot acc: 0.0122
top acc: 0.2136 ::: bot acc: 0.1587
top acc: 0.0620 ::: bot acc: 0.1211
current epoch: 5
train loss is 0.138005
average val loss: 0.130539, accuracy: 0.1314
average test loss: 0.130832, accuracy: 0.1319
case acc: 0.23469868
case acc: 0.19506054
case acc: 0.05955431
case acc: 0.050865926
case acc: 0.20642586
case acc: 0.04453577
top acc: 0.2596 ::: bot acc: 0.2107
top acc: 0.2165 ::: bot acc: 0.1752
top acc: 0.0295 ::: bot acc: 0.0912
top acc: 0.0692 ::: bot acc: 0.0306
top acc: 0.2326 ::: bot acc: 0.1777
top acc: 0.0210 ::: bot acc: 0.0714
current epoch: 6
train loss is 0.131000
average val loss: 0.111572, accuracy: 0.1122
average test loss: 0.111768, accuracy: 0.1125
case acc: 0.19427183
case acc: 0.16175826
case acc: 0.0669364
case acc: 0.031241953
case acc: 0.17160186
case acc: 0.049242456
top acc: 0.2191 ::: bot acc: 0.1702
top acc: 0.1832 ::: bot acc: 0.1419
top acc: 0.0353 ::: bot acc: 0.0993
top acc: 0.0479 ::: bot acc: 0.0145
top acc: 0.1978 ::: bot acc: 0.1428
top acc: 0.0244 ::: bot acc: 0.0769
current epoch: 7
train loss is 0.117351
average val loss: 0.103265, accuracy: 0.1042
average test loss: 0.103207, accuracy: 0.1043
case acc: 0.1842396
case acc: 0.15903242
case acc: 0.04690926
case acc: 0.039451916
case acc: 0.16718033
case acc: 0.02918791
top acc: 0.2091 ::: bot acc: 0.1601
top acc: 0.1805 ::: bot acc: 0.1392
top acc: 0.0207 ::: bot acc: 0.0766
top acc: 0.0572 ::: bot acc: 0.0204
top acc: 0.1934 ::: bot acc: 0.1383
top acc: 0.0139 ::: bot acc: 0.0522
current epoch: 8
train loss is 0.103553
average val loss: 0.090911, accuracy: 0.0918
average test loss: 0.090554, accuracy: 0.0919
case acc: 0.16007286
case acc: 0.14212017
case acc: 0.040658638
case acc: 0.034667864
case acc: 0.14866903
case acc: 0.024964197
top acc: 0.1849 ::: bot acc: 0.1359
top acc: 0.1635 ::: bot acc: 0.1223
top acc: 0.0174 ::: bot acc: 0.0690
top acc: 0.0518 ::: bot acc: 0.0169
top acc: 0.1749 ::: bot acc: 0.1197
top acc: 0.0194 ::: bot acc: 0.0429
current epoch: 9
train loss is 0.093574
average val loss: 0.082485, accuracy: 0.0833
average test loss: 0.081680, accuracy: 0.0834
case acc: 0.14205119
case acc: 0.13149717
case acc: 0.03145487
case acc: 0.035219133
case acc: 0.13637537
case acc: 0.023541752
top acc: 0.1669 ::: bot acc: 0.1179
top acc: 0.1529 ::: bot acc: 0.1118
top acc: 0.0173 ::: bot acc: 0.0553
top acc: 0.0523 ::: bot acc: 0.0173
top acc: 0.1627 ::: bot acc: 0.1073
top acc: 0.0338 ::: bot acc: 0.0287
current epoch: 10
train loss is 0.082137
average val loss: 0.073356, accuracy: 0.0741
average test loss: 0.072271, accuracy: 0.0739
case acc: 0.12056002
case acc: 0.11749661
case acc: 0.02687319
case acc: 0.032478407
case acc: 0.12074585
case acc: 0.024977839
top acc: 0.1454 ::: bot acc: 0.0964
top acc: 0.1388 ::: bot acc: 0.0978
top acc: 0.0227 ::: bot acc: 0.0457
top acc: 0.0492 ::: bot acc: 0.0154
top acc: 0.1472 ::: bot acc: 0.0916
top acc: 0.0430 ::: bot acc: 0.0203
current epoch: 11
train loss is 0.072617
average val loss: 0.066741, accuracy: 0.0675
average test loss: 0.065512, accuracy: 0.0669
case acc: 0.10174307
case acc: 0.106243
case acc: 0.024614472
case acc: 0.031745527
case acc: 0.107843965
case acc: 0.029194698
top acc: 0.1267 ::: bot acc: 0.0777
top acc: 0.1274 ::: bot acc: 0.0866
top acc: 0.0336 ::: bot acc: 0.0341
top acc: 0.0483 ::: bot acc: 0.0149
top acc: 0.1344 ::: bot acc: 0.0787
top acc: 0.0529 ::: bot acc: 0.0140
current epoch: 12
train loss is 0.063508
average val loss: 0.058699, accuracy: 0.0594
average test loss: 0.057412, accuracy: 0.0586
case acc: 0.080480516
case acc: 0.09275676
case acc: 0.025460357
case acc: 0.02854304
case acc: 0.092671536
case acc: 0.03158656
top acc: 0.1054 ::: bot acc: 0.0566
top acc: 0.1138 ::: bot acc: 0.0732
top acc: 0.0419 ::: bot acc: 0.0262
top acc: 0.0444 ::: bot acc: 0.0129
top acc: 0.1193 ::: bot acc: 0.0634
top acc: 0.0570 ::: bot acc: 0.0130
current epoch: 13
train loss is 0.055500
average val loss: 0.052827, accuracy: 0.0534
average test loss: 0.051608, accuracy: 0.0525
case acc: 0.06247869
case acc: 0.08243346
case acc: 0.028632473
case acc: 0.027188655
case acc: 0.080647305
case acc: 0.03343703
top acc: 0.0875 ::: bot acc: 0.0388
top acc: 0.1033 ::: bot acc: 0.0631
top acc: 0.0518 ::: bot acc: 0.0178
top acc: 0.0428 ::: bot acc: 0.0121
top acc: 0.1075 ::: bot acc: 0.0512
top acc: 0.0598 ::: bot acc: 0.0131
current epoch: 14
train loss is 0.048167
average val loss: 0.048172, accuracy: 0.0485
average test loss: 0.047105, accuracy: 0.0475
case acc: 0.04715468
case acc: 0.074229926
case acc: 0.033548504
case acc: 0.026479552
case acc: 0.07059808
case acc: 0.03316103
top acc: 0.0723 ::: bot acc: 0.0237
top acc: 0.0949 ::: bot acc: 0.0550
top acc: 0.0616 ::: bot acc: 0.0131
top acc: 0.0420 ::: bot acc: 0.0117
top acc: 0.0975 ::: bot acc: 0.0413
top acc: 0.0595 ::: bot acc: 0.0129
current epoch: 15
train loss is 0.041786
average val loss: 0.043902, accuracy: 0.0440
average test loss: 0.042906, accuracy: 0.0429
case acc: 0.034637436
case acc: 0.06677893
case acc: 0.038397405
case acc: 0.025388196
case acc: 0.06150814
case acc: 0.03086391
top acc: 0.0592 ::: bot acc: 0.0131
top acc: 0.0874 ::: bot acc: 0.0476
top acc: 0.0697 ::: bot acc: 0.0114
top acc: 0.0406 ::: bot acc: 0.0111
top acc: 0.0883 ::: bot acc: 0.0328
top acc: 0.0560 ::: bot acc: 0.0129
current epoch: 16
train loss is 0.037138
average val loss: 0.042613, accuracy: 0.0426
average test loss: 0.041655, accuracy: 0.0414
case acc: 0.028150424
case acc: 0.0630095
case acc: 0.04510326
case acc: 0.02644093
case acc: 0.05618625
case acc: 0.02946327
top acc: 0.0515 ::: bot acc: 0.0094
top acc: 0.0835 ::: bot acc: 0.0439
top acc: 0.0790 ::: bot acc: 0.0130
top acc: 0.0419 ::: bot acc: 0.0115
top acc: 0.0829 ::: bot acc: 0.0279
top acc: 0.0538 ::: bot acc: 0.0132
current epoch: 17
train loss is 0.034480
average val loss: 0.050301, accuracy: 0.0503
average test loss: 0.049594, accuracy: 0.0494
case acc: 0.031584345
case acc: 0.06993252
case acc: 0.06154379
case acc: 0.03665633
case acc: 0.06176191
case acc: 0.035152733
top acc: 0.0559 ::: bot acc: 0.0111
top acc: 0.0904 ::: bot acc: 0.0508
top acc: 0.0965 ::: bot acc: 0.0274
top acc: 0.0535 ::: bot acc: 0.0189
top acc: 0.0888 ::: bot acc: 0.0329
top acc: 0.0621 ::: bot acc: 0.0135
current epoch: 18
train loss is 0.036746
average val loss: 0.065515, accuracy: 0.0655
average test loss: 0.065034, accuracy: 0.0651
case acc: 0.041929394
case acc: 0.084299356
case acc: 0.08380847
case acc: 0.055253938
case acc: 0.075977005
case acc: 0.04911922
top acc: 0.0673 ::: bot acc: 0.0194
top acc: 0.1048 ::: bot acc: 0.0651
top acc: 0.1189 ::: bot acc: 0.0494
top acc: 0.0729 ::: bot acc: 0.0361
top acc: 0.1035 ::: bot acc: 0.0463
top acc: 0.0784 ::: bot acc: 0.0225
current epoch: 19
train loss is 0.042768
average val loss: 0.075574, accuracy: 0.0755
average test loss: 0.075110, accuracy: 0.0751
case acc: 0.0453519
case acc: 0.092990495
case acc: 0.09841852
case acc: 0.069103464
case acc: 0.08621854
case acc: 0.05838567
top acc: 0.0710 ::: bot acc: 0.0225
top acc: 0.1134 ::: bot acc: 0.0738
top acc: 0.1335 ::: bot acc: 0.0640
top acc: 0.0870 ::: bot acc: 0.0493
top acc: 0.1138 ::: bot acc: 0.0565
top acc: 0.0888 ::: bot acc: 0.0296
current epoch: 20
train loss is 0.051904
average val loss: 0.063254, accuracy: 0.0631
average test loss: 0.062720, accuracy: 0.0626
case acc: 0.02732668
case acc: 0.07835695
case acc: 0.08534597
case acc: 0.060147494
case acc: 0.07521476
case acc: 0.04919228
top acc: 0.0509 ::: bot acc: 0.0089
top acc: 0.0987 ::: bot acc: 0.0593
top acc: 0.1205 ::: bot acc: 0.0509
top acc: 0.0779 ::: bot acc: 0.0407
top acc: 0.1028 ::: bot acc: 0.0455
top acc: 0.0785 ::: bot acc: 0.0226
current epoch: 21
train loss is 0.056309
average val loss: 0.031582, accuracy: 0.0318
average test loss: 0.030517, accuracy: 0.0304
case acc: 0.029304262
case acc: 0.031505823
case acc: 0.038621478
case acc: 0.021318972
case acc: 0.036671977
case acc: 0.024969079
top acc: 0.0144 ::: bot acc: 0.0467
top acc: 0.0517 ::: bot acc: 0.0128
top acc: 0.0702 ::: bot acc: 0.0115
top acc: 0.0353 ::: bot acc: 0.0095
top acc: 0.0615 ::: bot acc: 0.0127
top acc: 0.0440 ::: bot acc: 0.0192
current epoch: 22
train loss is 0.058433
average val loss: 0.040519, accuracy: 0.0412
average test loss: 0.040485, accuracy: 0.0406
case acc: 0.07670057
case acc: 0.029178848
case acc: 0.037182502
case acc: 0.040535454
case acc: 0.025824983
case acc: 0.03441027
top acc: 0.0517 ::: bot acc: 0.0989
top acc: 0.0126 ::: bot acc: 0.0464
top acc: 0.0146 ::: bot acc: 0.0655
top acc: 0.0234 ::: bot acc: 0.0599
top acc: 0.0117 ::: bot acc: 0.0490
top acc: 0.0145 ::: bot acc: 0.0601
current epoch: 23
train loss is 0.041581
average val loss: 0.034610, accuracy: 0.0352
average test loss: 0.034073, accuracy: 0.0346
case acc: 0.060900085
case acc: 0.025270537
case acc: 0.038520113
case acc: 0.03705826
case acc: 0.022022093
case acc: 0.023553655
top acc: 0.0370 ::: bot acc: 0.0826
top acc: 0.0108 ::: bot acc: 0.0415
top acc: 0.0149 ::: bot acc: 0.0674
top acc: 0.0203 ::: bot acc: 0.0562
top acc: 0.0170 ::: bot acc: 0.0404
top acc: 0.0255 ::: bot acc: 0.0375
current epoch: 24
train loss is 0.035330
average val loss: 0.044044, accuracy: 0.0444
average test loss: 0.044113, accuracy: 0.0444
case acc: 0.064546905
case acc: 0.037717257
case acc: 0.056789346
case acc: 0.054001227
case acc: 0.02874121
case acc: 0.024412429
top acc: 0.0404 ::: bot acc: 0.0863
top acc: 0.0182 ::: bot acc: 0.0564
top acc: 0.0262 ::: bot acc: 0.0891
top acc: 0.0362 ::: bot acc: 0.0736
top acc: 0.0112 ::: bot acc: 0.0535
top acc: 0.0212 ::: bot acc: 0.0418
current epoch: 25
train loss is 0.042348
average val loss: 0.057014, accuracy: 0.0572
average test loss: 0.057448, accuracy: 0.0575
case acc: 0.069706365
case acc: 0.05257125
case acc: 0.07658261
case acc: 0.07379986
case acc: 0.041529283
case acc: 0.031022673
top acc: 0.0452 ::: bot acc: 0.0916
top acc: 0.0323 ::: bot acc: 0.0716
top acc: 0.0424 ::: bot acc: 0.1106
top acc: 0.0560 ::: bot acc: 0.0934
top acc: 0.0176 ::: bot acc: 0.0694
top acc: 0.0140 ::: bot acc: 0.0553
current epoch: 26
train loss is 0.068055
average val loss: 0.027359, accuracy: 0.0272
average test loss: 0.025775, accuracy: 0.0253
case acc: 0.017867893
case acc: 0.02005814
case acc: 0.025650417
case acc: 0.014709802
case acc: 0.031162862
case acc: 0.04214219
top acc: 0.0341 ::: bot acc: 0.0141
top acc: 0.0381 ::: bot acc: 0.0056
top acc: 0.0298 ::: bot acc: 0.0397
top acc: 0.0101 ::: bot acc: 0.0279
top acc: 0.0537 ::: bot acc: 0.0119
top acc: 0.0704 ::: bot acc: 0.0177
current epoch: 27
train loss is 0.047838
average val loss: 0.029755, accuracy: 0.0297
average test loss: 0.028427, accuracy: 0.0281
case acc: 0.025703005
case acc: 0.030719794
case acc: 0.02605972
case acc: 0.01373335
case acc: 0.036153637
case acc: 0.03610155
top acc: 0.0489 ::: bot acc: 0.0082
top acc: 0.0508 ::: bot acc: 0.0120
top acc: 0.0443 ::: bot acc: 0.0251
top acc: 0.0186 ::: bot acc: 0.0191
top acc: 0.0607 ::: bot acc: 0.0127
top acc: 0.0630 ::: bot acc: 0.0143
current epoch: 28
train loss is 0.039957
average val loss: 0.031384, accuracy: 0.0314
average test loss: 0.030198, accuracy: 0.0300
case acc: 0.03052913
case acc: 0.038075168
case acc: 0.030799253
case acc: 0.0152496975
case acc: 0.037809283
case acc: 0.027251795
top acc: 0.0550 ::: bot acc: 0.0104
top acc: 0.0584 ::: bot acc: 0.0189
top acc: 0.0566 ::: bot acc: 0.0152
top acc: 0.0245 ::: bot acc: 0.0132
top acc: 0.0628 ::: bot acc: 0.0135
top acc: 0.0500 ::: bot acc: 0.0140
current epoch: 29
train loss is 0.033759
average val loss: 0.039377, accuracy: 0.0395
average test loss: 0.038602, accuracy: 0.0384
case acc: 0.039822098
case acc: 0.051797673
case acc: 0.043921284
case acc: 0.023483645
case acc: 0.04542488
case acc: 0.025836337
top acc: 0.0653 ::: bot acc: 0.0177
top acc: 0.0722 ::: bot acc: 0.0326
top acc: 0.0774 ::: bot acc: 0.0126
top acc: 0.0385 ::: bot acc: 0.0097
top acc: 0.0716 ::: bot acc: 0.0186
top acc: 0.0468 ::: bot acc: 0.0161
current epoch: 30
train loss is 0.031003
average val loss: 0.056803, accuracy: 0.0569
average test loss: 0.056443, accuracy: 0.0566
case acc: 0.054184422
case acc: 0.07245377
case acc: 0.07368639
case acc: 0.044928797
case acc: 0.06167813
case acc: 0.03281281
top acc: 0.0799 ::: bot acc: 0.0316
top acc: 0.0929 ::: bot acc: 0.0532
top acc: 0.1086 ::: bot acc: 0.0393
top acc: 0.0623 ::: bot acc: 0.0265
top acc: 0.0888 ::: bot acc: 0.0331
top acc: 0.0587 ::: bot acc: 0.0130
current epoch: 31
train loss is 0.038864
average val loss: 0.079639, accuracy: 0.0797
average test loss: 0.079357, accuracy: 0.0796
case acc: 0.068406925
case acc: 0.09474569
case acc: 0.107148275
case acc: 0.07240802
case acc: 0.08277667
case acc: 0.05182372
top acc: 0.0942 ::: bot acc: 0.0458
top acc: 0.1152 ::: bot acc: 0.0755
top acc: 0.1421 ::: bot acc: 0.0728
top acc: 0.0904 ::: bot acc: 0.0526
top acc: 0.1103 ::: bot acc: 0.0533
top acc: 0.0811 ::: bot acc: 0.0250
current epoch: 32
train loss is 0.060954
average val loss: 0.037047, accuracy: 0.0371
average test loss: 0.035970, accuracy: 0.0356
case acc: 0.01874556
case acc: 0.044692323
case acc: 0.05818887
case acc: 0.029789198
case acc: 0.039079808
case acc: 0.023391629
top acc: 0.0370 ::: bot acc: 0.0114
top acc: 0.0652 ::: bot acc: 0.0254
top acc: 0.0930 ::: bot acc: 0.0241
top acc: 0.0460 ::: bot acc: 0.0136
top acc: 0.0643 ::: bot acc: 0.0143
top acc: 0.0381 ::: bot acc: 0.0244
current epoch: 33
train loss is 0.050539
average val loss: 0.024964, accuracy: 0.0251
average test loss: 0.023189, accuracy: 0.0228
case acc: 0.026629316
case acc: 0.017844766
case acc: 0.03204694
case acc: 0.013788935
case acc: 0.023387674
case acc: 0.023337603
top acc: 0.0137 ::: bot acc: 0.0430
top acc: 0.0343 ::: bot acc: 0.0069
top acc: 0.0589 ::: bot acc: 0.0144
top acc: 0.0190 ::: bot acc: 0.0187
top acc: 0.0392 ::: bot acc: 0.0179
top acc: 0.0261 ::: bot acc: 0.0365
current epoch: 34
train loss is 0.040443
average val loss: 0.023636, accuracy: 0.0238
average test loss: 0.021686, accuracy: 0.0217
case acc: 0.03056167
case acc: 0.014223218
case acc: 0.025393229
case acc: 0.015581004
case acc: 0.021549879
case acc: 0.023016278
top acc: 0.0146 ::: bot acc: 0.0484
top acc: 0.0225 ::: bot acc: 0.0173
top acc: 0.0403 ::: bot acc: 0.0291
top acc: 0.0090 ::: bot acc: 0.0298
top acc: 0.0323 ::: bot acc: 0.0247
top acc: 0.0332 ::: bot acc: 0.0293
current epoch: 35
train loss is 0.031954
average val loss: 0.024462, accuracy: 0.0246
average test loss: 0.022777, accuracy: 0.0231
case acc: 0.030444456
case acc: 0.01563819
case acc: 0.026829766
case acc: 0.02148417
case acc: 0.0207899
case acc: 0.023547046
top acc: 0.0145 ::: bot acc: 0.0482
top acc: 0.0142 ::: bot acc: 0.0256
top acc: 0.0241 ::: bot acc: 0.0454
top acc: 0.0080 ::: bot acc: 0.0390
top acc: 0.0278 ::: bot acc: 0.0293
top acc: 0.0390 ::: bot acc: 0.0235
current epoch: 36
train loss is 0.026761
average val loss: 0.029654, accuracy: 0.0297
average test loss: 0.028820, accuracy: 0.0293
case acc: 0.034537364
case acc: 0.023370586
case acc: 0.037677363
case acc: 0.035353277
case acc: 0.021998836
case acc: 0.023004506
top acc: 0.0166 ::: bot acc: 0.0533
top acc: 0.0106 ::: bot acc: 0.0389
top acc: 0.0145 ::: bot acc: 0.0663
top acc: 0.0188 ::: bot acc: 0.0544
top acc: 0.0165 ::: bot acc: 0.0406
top acc: 0.0313 ::: bot acc: 0.0313
current epoch: 37
train loss is 0.030824
average val loss: 0.037420, accuracy: 0.0374
average test loss: 0.037268, accuracy: 0.0375
case acc: 0.03716116
case acc: 0.032096557
case acc: 0.052338924
case acc: 0.04990635
case acc: 0.028021667
case acc: 0.02549146
top acc: 0.0181 ::: bot acc: 0.0564
top acc: 0.0143 ::: bot acc: 0.0500
top acc: 0.0231 ::: bot acc: 0.0840
top acc: 0.0320 ::: bot acc: 0.0696
top acc: 0.0109 ::: bot acc: 0.0524
top acc: 0.0180 ::: bot acc: 0.0450
current epoch: 38
train loss is 0.043413
average val loss: 0.025495, accuracy: 0.0253
average test loss: 0.023941, accuracy: 0.0241
case acc: 0.018039305
case acc: 0.015921019
case acc: 0.03490059
case acc: 0.03194172
case acc: 0.020695463
case acc: 0.023069903
top acc: 0.0228 ::: bot acc: 0.0255
top acc: 0.0134 ::: bot acc: 0.0264
top acc: 0.0143 ::: bot acc: 0.0623
top acc: 0.0159 ::: bot acc: 0.0508
top acc: 0.0248 ::: bot acc: 0.0323
top acc: 0.0336 ::: bot acc: 0.0290
current epoch: 39
train loss is 0.045967
average val loss: 0.035920, accuracy: 0.0361
average test loss: 0.035137, accuracy: 0.0352
case acc: 0.047022972
case acc: 0.039386675
case acc: 0.030546747
case acc: 0.017693602
case acc: 0.04028807
case acc: 0.03628446
top acc: 0.0728 ::: bot acc: 0.0245
top acc: 0.0598 ::: bot acc: 0.0202
top acc: 0.0561 ::: bot acc: 0.0155
top acc: 0.0297 ::: bot acc: 0.0101
top acc: 0.0658 ::: bot acc: 0.0149
top acc: 0.0631 ::: bot acc: 0.0146
current epoch: 40
train loss is 0.040946
average val loss: 0.047351, accuracy: 0.0475
average test loss: 0.047042, accuracy: 0.0470
case acc: 0.059145935
case acc: 0.057031512
case acc: 0.04703366
case acc: 0.031627495
case acc: 0.052012064
case acc: 0.035329774
top acc: 0.0849 ::: bot acc: 0.0366
top acc: 0.0775 ::: bot acc: 0.0378
top acc: 0.0813 ::: bot acc: 0.0141
top acc: 0.0480 ::: bot acc: 0.0150
top acc: 0.0786 ::: bot acc: 0.0244
top acc: 0.0618 ::: bot acc: 0.0142
current epoch: 41
train loss is 0.034135
average val loss: 0.059877, accuracy: 0.0600
average test loss: 0.059658, accuracy: 0.0599
case acc: 0.06454948
case acc: 0.07184422
case acc: 0.07219669
case acc: 0.049723953
case acc: 0.063349105
case acc: 0.037745267
top acc: 0.0903 ::: bot acc: 0.0420
top acc: 0.0923 ::: bot acc: 0.0526
top acc: 0.1072 ::: bot acc: 0.0377
top acc: 0.0671 ::: bot acc: 0.0310
top acc: 0.0905 ::: bot acc: 0.0346
top acc: 0.0649 ::: bot acc: 0.0153
current epoch: 42
train loss is 0.042537
average val loss: 0.065220, accuracy: 0.0653
average test loss: 0.065042, accuracy: 0.0653
case acc: 0.059605286
case acc: 0.076195285
case acc: 0.08622067
case acc: 0.06015563
case acc: 0.06790649
case acc: 0.04146232
top acc: 0.0854 ::: bot acc: 0.0370
top acc: 0.0967 ::: bot acc: 0.0569
top acc: 0.1212 ::: bot acc: 0.0518
top acc: 0.0779 ::: bot acc: 0.0408
top acc: 0.0953 ::: bot acc: 0.0388
top acc: 0.0694 ::: bot acc: 0.0175
current epoch: 43
train loss is 0.053542
average val loss: 0.027729, accuracy: 0.0279
average test loss: 0.026161, accuracy: 0.0257
case acc: 0.017245648
case acc: 0.026464071
case acc: 0.039354734
case acc: 0.019574687
case acc: 0.028510524
case acc: 0.02294047
top acc: 0.0286 ::: bot acc: 0.0198
top acc: 0.0462 ::: bot acc: 0.0087
top acc: 0.0711 ::: bot acc: 0.0115
top acc: 0.0330 ::: bot acc: 0.0091
top acc: 0.0495 ::: bot acc: 0.0124
top acc: 0.0306 ::: bot acc: 0.0318
current epoch: 44
train loss is 0.037606
average val loss: 0.024302, accuracy: 0.0244
average test loss: 0.022337, accuracy: 0.0221
case acc: 0.019721668
case acc: 0.018311284
case acc: 0.030770015
case acc: 0.015433487
case acc: 0.025189342
case acc: 0.023332596
top acc: 0.0182 ::: bot acc: 0.0304
top acc: 0.0352 ::: bot acc: 0.0065
top acc: 0.0565 ::: bot acc: 0.0153
top acc: 0.0251 ::: bot acc: 0.0127
top acc: 0.0437 ::: bot acc: 0.0143
top acc: 0.0379 ::: bot acc: 0.0244
current epoch: 45
train loss is 0.031005
average val loss: 0.022821, accuracy: 0.0228
average test loss: 0.020657, accuracy: 0.0206
case acc: 0.022644695
case acc: 0.014570328
case acc: 0.025370128
case acc: 0.013474282
case acc: 0.0229615
case acc: 0.024525138
top acc: 0.0149 ::: bot acc: 0.0364
top acc: 0.0251 ::: bot acc: 0.0146
top acc: 0.0403 ::: bot acc: 0.0291
top acc: 0.0161 ::: bot acc: 0.0216
top acc: 0.0381 ::: bot acc: 0.0189
top acc: 0.0433 ::: bot acc: 0.0191
current epoch: 46
train loss is 0.026213
average val loss: 0.023940, accuracy: 0.0240
average test loss: 0.022203, accuracy: 0.0225
case acc: 0.027055357
case acc: 0.016459065
case acc: 0.028165735
case acc: 0.018837105
case acc: 0.020764954
case acc: 0.02350299
top acc: 0.0137 ::: bot acc: 0.0435
top acc: 0.0126 ::: bot acc: 0.0276
top acc: 0.0198 ::: bot acc: 0.0496
top acc: 0.0075 ::: bot acc: 0.0354
top acc: 0.0282 ::: bot acc: 0.0288
top acc: 0.0392 ::: bot acc: 0.0232
current epoch: 47
train loss is 0.024808
average val loss: 0.030608, accuracy: 0.0306
average test loss: 0.029889, accuracy: 0.0303
case acc: 0.03315539
case acc: 0.02613916
case acc: 0.04220283
case acc: 0.034162927
case acc: 0.022748388
case acc: 0.023232779
top acc: 0.0159 ::: bot acc: 0.0515
top acc: 0.0112 ::: bot acc: 0.0427
top acc: 0.0164 ::: bot acc: 0.0721
top acc: 0.0178 ::: bot acc: 0.0531
top acc: 0.0144 ::: bot acc: 0.0428
top acc: 0.0261 ::: bot acc: 0.0363
current epoch: 48
train loss is 0.031571
average val loss: 0.034477, accuracy: 0.0343
average test loss: 0.034068, accuracy: 0.0343
case acc: 0.03089293
case acc: 0.03009562
case acc: 0.050832324
case acc: 0.04296103
case acc: 0.02595589
case acc: 0.024987709
top acc: 0.0148 ::: bot acc: 0.0486
top acc: 0.0132 ::: bot acc: 0.0476
top acc: 0.0220 ::: bot acc: 0.0823
top acc: 0.0254 ::: bot acc: 0.0625
top acc: 0.0112 ::: bot acc: 0.0492
top acc: 0.0189 ::: bot acc: 0.0438
current epoch: 49
train loss is 0.043006
average val loss: 0.023471, accuracy: 0.0233
average test loss: 0.021468, accuracy: 0.0212
case acc: 0.019489767
case acc: 0.014529
case acc: 0.028066095
case acc: 0.018101165
case acc: 0.0225118
case acc: 0.024391737
top acc: 0.0391 ::: bot acc: 0.0096
top acc: 0.0250 ::: bot acc: 0.0146
top acc: 0.0202 ::: bot acc: 0.0493
top acc: 0.0076 ::: bot acc: 0.0342
top acc: 0.0366 ::: bot acc: 0.0205
top acc: 0.0427 ::: bot acc: 0.0198
current epoch: 50
train loss is 0.040160
average val loss: 0.035184, accuracy: 0.0354
average test loss: 0.034427, accuracy: 0.0346
case acc: 0.047277153
case acc: 0.037523072
case acc: 0.03124131
case acc: 0.020216238
case acc: 0.038854636
case acc: 0.03228324
top acc: 0.0731 ::: bot acc: 0.0248
top acc: 0.0579 ::: bot acc: 0.0183
top acc: 0.0574 ::: bot acc: 0.0149
top acc: 0.0339 ::: bot acc: 0.0091
top acc: 0.0641 ::: bot acc: 0.0141
top acc: 0.0579 ::: bot acc: 0.0130
