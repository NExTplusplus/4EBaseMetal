begin to train
{'generate_norm_params': 'v1', 'generate_tech_params': 'v2', 'generate_strat_params': None, 'deal_with_abnormal_value': 'v2', 'labelling': 'v2', 'process_missing_value': 'v1', 'strategy_signal': None, 'normalize_without_1d_return': None, 'technical_indication': 'v3', 'remove_unused_columns': 'v4', 'price_normalization': None, 'scaling': 'v2', 'construct': 'v1'}
the train date is 2012-01-01
the test date is 2017-01-01
LME_Co_Spot
0.01237793361322046
['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'spot_price']
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Co_Spot']
#####################remove_unused_columns_v4#####################
target LME_Co
Index(['LME_Co_Spot', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low',
       'LME_Co_Close', 'LME_Co_Spot_EMA12', 'LME_Co_Spot_WMA12',
       'LME_Co_Spot_EMA26', 'LME_Co_Spot_WMA26', 'LME_Co_Spot_EMA40',
       'LME_Co_Spot_WMA40', 'LME_Co_Spot_EMA65', 'LME_Co_Spot_WMA65',
       'LME_Co_Spot_EMA125', 'LME_Co_Spot_WMA125', 'LME_Co_Spot_bollinger5',
       'LME_Co_Spot_bollinger10', 'LME_Co_Spot_bollinger15',
       'LME_Co_Spot_bollinger20', 'LME_Co_Spot_bollinger30',
       'LME_Co_Spot_bollinger65', 'LME_Co_Spot_Mom5', 'LME_Co_Spot_Mom10',
       'LME_Co_Spot_Mom15', 'LME_Co_Spot_Mom26', 'LME_Co_Spot_Mom40',
       'LME_Co_Spot_Mom65', 'LME_Co_Spot_Mom125', 'LME_Co_Spot_PPO12',
       'LME_Co_Spot_PPO22', 'LME_Co_Spot_RSI14', 'LME_Co_Spot_RSI26',
       'LME_Co_Spot_RSI40', 'LME_Co_Spot_RSI54', 'LME_Co_Spot_RSI125',
       'LME_Co_Close_EMA12', 'LME_Co_Close_WMA12', 'LME_Co_Close_EMA26',
       'LME_Co_Close_WMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_WMA40',
       'LME_Co_Close_EMA65', 'LME_Co_Close_WMA65', 'LME_Co_Close_EMA125',
       'LME_Co_Close_WMA125', 'LME_Co_Close_bollinger5',
       'LME_Co_Close_bollinger10', 'LME_Co_Close_bollinger15',
       'LME_Co_Close_bollinger20', 'LME_Co_Close_bollinger30',
       'LME_Co_Close_bollinger65', 'LME_Co_Close_Mom5', 'LME_Co_Close_Mom10',
       'LME_Co_Close_Mom15', 'LME_Co_Close_Mom26', 'LME_Co_Close_Mom40',
       'LME_Co_Close_Mom65', 'LME_Co_Close_Mom125', 'LME_Co_Close_PPO12',
       'LME_Co_Close_PPO22', 'LME_Co_Close_RSI14', 'LME_Co_Close_RSI26',
       'LME_Co_Close_RSI40', 'LME_Co_Close_RSI54', 'LME_Co_Close_RSI125',
       'LME_Co_PVT', 'LME_Co_divPVT', 'LME_Co_NATR14', 'LME_Co_NATR26',
       'LME_Co_NATR65', 'LME_Co_NATR125', 'LME_Co_CCI12', 'LME_Co_CCI26',
       'LME_Co_CCI40', 'LME_Co_CCI65', 'LME_Co_CCI125', 'LME_Co_VBM12',
       'LME_Co_VBM22', 'LME_Co_ADX14', 'LME_Co_ADX26', 'LME_Co_ADX40',
       'LME_Co_ADX54', 'LME_Co_ADX125', 'LME_Co_SAR'],
      dtype='object')
LME_Al_Spot
0.01129448756949834
['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'spot_price']
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Al_Spot']
#####################remove_unused_columns_v4#####################
target LME_Al
Index(['LME_Al_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low',
       'LME_Al_Close', 'LME_Al_Spot_EMA12', 'LME_Al_Spot_WMA12',
       'LME_Al_Spot_EMA26', 'LME_Al_Spot_WMA26', 'LME_Al_Spot_EMA40',
       'LME_Al_Spot_WMA40', 'LME_Al_Spot_EMA65', 'LME_Al_Spot_WMA65',
       'LME_Al_Spot_EMA125', 'LME_Al_Spot_WMA125', 'LME_Al_Spot_bollinger5',
       'LME_Al_Spot_bollinger10', 'LME_Al_Spot_bollinger15',
       'LME_Al_Spot_bollinger20', 'LME_Al_Spot_bollinger30',
       'LME_Al_Spot_bollinger65', 'LME_Al_Spot_Mom5', 'LME_Al_Spot_Mom10',
       'LME_Al_Spot_Mom15', 'LME_Al_Spot_Mom26', 'LME_Al_Spot_Mom40',
       'LME_Al_Spot_Mom65', 'LME_Al_Spot_Mom125', 'LME_Al_Spot_PPO12',
       'LME_Al_Spot_PPO22', 'LME_Al_Spot_RSI14', 'LME_Al_Spot_RSI26',
       'LME_Al_Spot_RSI40', 'LME_Al_Spot_RSI54', 'LME_Al_Spot_RSI125',
       'LME_Al_Close_EMA12', 'LME_Al_Close_WMA12', 'LME_Al_Close_EMA26',
       'LME_Al_Close_WMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_WMA40',
       'LME_Al_Close_EMA65', 'LME_Al_Close_WMA65', 'LME_Al_Close_EMA125',
       'LME_Al_Close_WMA125', 'LME_Al_Close_bollinger5',
       'LME_Al_Close_bollinger10', 'LME_Al_Close_bollinger15',
       'LME_Al_Close_bollinger20', 'LME_Al_Close_bollinger30',
       'LME_Al_Close_bollinger65', 'LME_Al_Close_Mom5', 'LME_Al_Close_Mom10',
       'LME_Al_Close_Mom15', 'LME_Al_Close_Mom26', 'LME_Al_Close_Mom40',
       'LME_Al_Close_Mom65', 'LME_Al_Close_Mom125', 'LME_Al_Close_PPO12',
       'LME_Al_Close_PPO22', 'LME_Al_Close_RSI14', 'LME_Al_Close_RSI26',
       'LME_Al_Close_RSI40', 'LME_Al_Close_RSI54', 'LME_Al_Close_RSI125',
       'LME_Al_PVT', 'LME_Al_divPVT', 'LME_Al_NATR14', 'LME_Al_NATR26',
       'LME_Al_NATR65', 'LME_Al_NATR125', 'LME_Al_CCI12', 'LME_Al_CCI26',
       'LME_Al_CCI40', 'LME_Al_CCI65', 'LME_Al_CCI125', 'LME_Al_VBM12',
       'LME_Al_VBM22', 'LME_Al_ADX14', 'LME_Al_ADX26', 'LME_Al_ADX40',
       'LME_Al_ADX54', 'LME_Al_ADX125', 'LME_Al_SAR'],
      dtype='object')
LME_Le_Spot
0.01450751047491933
['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'spot_price']
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Le_Spot']
#####################remove_unused_columns_v4#####################
target LME_Le
Index(['LME_Le_Spot', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low',
       'LME_Le_Close', 'LME_Le_Spot_EMA12', 'LME_Le_Spot_WMA12',
       'LME_Le_Spot_EMA26', 'LME_Le_Spot_WMA26', 'LME_Le_Spot_EMA40',
       'LME_Le_Spot_WMA40', 'LME_Le_Spot_EMA65', 'LME_Le_Spot_WMA65',
       'LME_Le_Spot_EMA125', 'LME_Le_Spot_WMA125', 'LME_Le_Spot_bollinger5',
       'LME_Le_Spot_bollinger10', 'LME_Le_Spot_bollinger15',
       'LME_Le_Spot_bollinger20', 'LME_Le_Spot_bollinger30',
       'LME_Le_Spot_bollinger65', 'LME_Le_Spot_Mom5', 'LME_Le_Spot_Mom10',
       'LME_Le_Spot_Mom15', 'LME_Le_Spot_Mom26', 'LME_Le_Spot_Mom40',
       'LME_Le_Spot_Mom65', 'LME_Le_Spot_Mom125', 'LME_Le_Spot_PPO12',
       'LME_Le_Spot_PPO22', 'LME_Le_Spot_RSI14', 'LME_Le_Spot_RSI26',
       'LME_Le_Spot_RSI40', 'LME_Le_Spot_RSI54', 'LME_Le_Spot_RSI125',
       'LME_Le_Close_EMA12', 'LME_Le_Close_WMA12', 'LME_Le_Close_EMA26',
       'LME_Le_Close_WMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_WMA40',
       'LME_Le_Close_EMA65', 'LME_Le_Close_WMA65', 'LME_Le_Close_EMA125',
       'LME_Le_Close_WMA125', 'LME_Le_Close_bollinger5',
       'LME_Le_Close_bollinger10', 'LME_Le_Close_bollinger15',
       'LME_Le_Close_bollinger20', 'LME_Le_Close_bollinger30',
       'LME_Le_Close_bollinger65', 'LME_Le_Close_Mom5', 'LME_Le_Close_Mom10',
       'LME_Le_Close_Mom15', 'LME_Le_Close_Mom26', 'LME_Le_Close_Mom40',
       'LME_Le_Close_Mom65', 'LME_Le_Close_Mom125', 'LME_Le_Close_PPO12',
       'LME_Le_Close_PPO22', 'LME_Le_Close_RSI14', 'LME_Le_Close_RSI26',
       'LME_Le_Close_RSI40', 'LME_Le_Close_RSI54', 'LME_Le_Close_RSI125',
       'LME_Le_PVT', 'LME_Le_divPVT', 'LME_Le_NATR14', 'LME_Le_NATR26',
       'LME_Le_NATR65', 'LME_Le_NATR125', 'LME_Le_CCI12', 'LME_Le_CCI26',
       'LME_Le_CCI40', 'LME_Le_CCI65', 'LME_Le_CCI125', 'LME_Le_VBM12',
       'LME_Le_VBM22', 'LME_Le_ADX14', 'LME_Le_ADX26', 'LME_Le_ADX40',
       'LME_Le_ADX54', 'LME_Le_ADX125', 'LME_Le_SAR'],
      dtype='object')
LME_Ni_Spot
0.0175158853348449
['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'spot_price']
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Ni_Spot']
#####################remove_unused_columns_v4#####################
target LME_Ni
Index(['LME_Ni_Spot', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low',
       'LME_Ni_Close', 'LME_Ni_Spot_EMA12', 'LME_Ni_Spot_WMA12',
       'LME_Ni_Spot_EMA26', 'LME_Ni_Spot_WMA26', 'LME_Ni_Spot_EMA40',
       'LME_Ni_Spot_WMA40', 'LME_Ni_Spot_EMA65', 'LME_Ni_Spot_WMA65',
       'LME_Ni_Spot_EMA125', 'LME_Ni_Spot_WMA125', 'LME_Ni_Spot_bollinger5',
       'LME_Ni_Spot_bollinger10', 'LME_Ni_Spot_bollinger15',
       'LME_Ni_Spot_bollinger20', 'LME_Ni_Spot_bollinger30',
       'LME_Ni_Spot_bollinger65', 'LME_Ni_Spot_Mom5', 'LME_Ni_Spot_Mom10',
       'LME_Ni_Spot_Mom15', 'LME_Ni_Spot_Mom26', 'LME_Ni_Spot_Mom40',
       'LME_Ni_Spot_Mom65', 'LME_Ni_Spot_Mom125', 'LME_Ni_Spot_PPO12',
       'LME_Ni_Spot_PPO22', 'LME_Ni_Spot_RSI14', 'LME_Ni_Spot_RSI26',
       'LME_Ni_Spot_RSI40', 'LME_Ni_Spot_RSI54', 'LME_Ni_Spot_RSI125',
       'LME_Ni_Close_EMA12', 'LME_Ni_Close_WMA12', 'LME_Ni_Close_EMA26',
       'LME_Ni_Close_WMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_WMA40',
       'LME_Ni_Close_EMA65', 'LME_Ni_Close_WMA65', 'LME_Ni_Close_EMA125',
       'LME_Ni_Close_WMA125', 'LME_Ni_Close_bollinger5',
       'LME_Ni_Close_bollinger10', 'LME_Ni_Close_bollinger15',
       'LME_Ni_Close_bollinger20', 'LME_Ni_Close_bollinger30',
       'LME_Ni_Close_bollinger65', 'LME_Ni_Close_Mom5', 'LME_Ni_Close_Mom10',
       'LME_Ni_Close_Mom15', 'LME_Ni_Close_Mom26', 'LME_Ni_Close_Mom40',
       'LME_Ni_Close_Mom65', 'LME_Ni_Close_Mom125', 'LME_Ni_Close_PPO12',
       'LME_Ni_Close_PPO22', 'LME_Ni_Close_RSI14', 'LME_Ni_Close_RSI26',
       'LME_Ni_Close_RSI40', 'LME_Ni_Close_RSI54', 'LME_Ni_Close_RSI125',
       'LME_Ni_PVT', 'LME_Ni_divPVT', 'LME_Ni_NATR14', 'LME_Ni_NATR26',
       'LME_Ni_NATR65', 'LME_Ni_NATR125', 'LME_Ni_CCI12', 'LME_Ni_CCI26',
       'LME_Ni_CCI40', 'LME_Ni_CCI65', 'LME_Ni_CCI125', 'LME_Ni_VBM12',
       'LME_Ni_VBM22', 'LME_Ni_ADX14', 'LME_Ni_ADX26', 'LME_Ni_ADX40',
       'LME_Ni_ADX54', 'LME_Ni_ADX125', 'LME_Ni_SAR'],
      dtype='object')
LME_Zi_Spot
0.014194559494898463
['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'spot_price']
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Zi_Spot']
#####################remove_unused_columns_v4#####################
target LME_Zi
Index(['LME_Zi_Spot', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low',
       'LME_Zi_Close', 'LME_Zi_Spot_EMA12', 'LME_Zi_Spot_WMA12',
       'LME_Zi_Spot_EMA26', 'LME_Zi_Spot_WMA26', 'LME_Zi_Spot_EMA40',
       'LME_Zi_Spot_WMA40', 'LME_Zi_Spot_EMA65', 'LME_Zi_Spot_WMA65',
       'LME_Zi_Spot_EMA125', 'LME_Zi_Spot_WMA125', 'LME_Zi_Spot_bollinger5',
       'LME_Zi_Spot_bollinger10', 'LME_Zi_Spot_bollinger15',
       'LME_Zi_Spot_bollinger20', 'LME_Zi_Spot_bollinger30',
       'LME_Zi_Spot_bollinger65', 'LME_Zi_Spot_Mom5', 'LME_Zi_Spot_Mom10',
       'LME_Zi_Spot_Mom15', 'LME_Zi_Spot_Mom26', 'LME_Zi_Spot_Mom40',
       'LME_Zi_Spot_Mom65', 'LME_Zi_Spot_Mom125', 'LME_Zi_Spot_PPO12',
       'LME_Zi_Spot_PPO22', 'LME_Zi_Spot_RSI14', 'LME_Zi_Spot_RSI26',
       'LME_Zi_Spot_RSI40', 'LME_Zi_Spot_RSI54', 'LME_Zi_Spot_RSI125',
       'LME_Zi_Close_EMA12', 'LME_Zi_Close_WMA12', 'LME_Zi_Close_EMA26',
       'LME_Zi_Close_WMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_WMA40',
       'LME_Zi_Close_EMA65', 'LME_Zi_Close_WMA65', 'LME_Zi_Close_EMA125',
       'LME_Zi_Close_WMA125', 'LME_Zi_Close_bollinger5',
       'LME_Zi_Close_bollinger10', 'LME_Zi_Close_bollinger15',
       'LME_Zi_Close_bollinger20', 'LME_Zi_Close_bollinger30',
       'LME_Zi_Close_bollinger65', 'LME_Zi_Close_Mom5', 'LME_Zi_Close_Mom10',
       'LME_Zi_Close_Mom15', 'LME_Zi_Close_Mom26', 'LME_Zi_Close_Mom40',
       'LME_Zi_Close_Mom65', 'LME_Zi_Close_Mom125', 'LME_Zi_Close_PPO12',
       'LME_Zi_Close_PPO22', 'LME_Zi_Close_RSI14', 'LME_Zi_Close_RSI26',
       'LME_Zi_Close_RSI40', 'LME_Zi_Close_RSI54', 'LME_Zi_Close_RSI125',
       'LME_Zi_PVT', 'LME_Zi_divPVT', 'LME_Zi_NATR14', 'LME_Zi_NATR26',
       'LME_Zi_NATR65', 'LME_Zi_NATR125', 'LME_Zi_CCI12', 'LME_Zi_CCI26',
       'LME_Zi_CCI40', 'LME_Zi_CCI65', 'LME_Zi_CCI125', 'LME_Zi_VBM12',
       'LME_Zi_VBM22', 'LME_Zi_ADX14', 'LME_Zi_ADX26', 'LME_Zi_ADX40',
       'LME_Zi_ADX54', 'LME_Zi_ADX125', 'LME_Zi_SAR'],
      dtype='object')
LME_Ti_Spot
0.013945830101567672
['LME_Co_Spot', 'LME_Al_Spot', 'LME_Le_Spot', 'LME_Ni_Spot', 'LME_Zi_Spot', 'LME_Ti_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low', 'LME_Al_Close', 'LME_Al_Volume', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low', 'LME_Co_Close', 'LME_Co_Volume', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low', 'LME_Ti_Close', 'LME_Ti_Volume', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low', 'LME_Le_Close', 'LME_Le_Volume', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low', 'LME_Ni_Close', 'LME_Ni_Volume', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low', 'LME_Zi_Close', 'LME_Zi_Volume', 'spot_price']
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Ti_Spot']
#####################remove_unused_columns_v4#####################
target LME_Ti
Index(['LME_Ti_Spot', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low',
       'LME_Ti_Close', 'LME_Ti_Spot_EMA12', 'LME_Ti_Spot_WMA12',
       'LME_Ti_Spot_EMA26', 'LME_Ti_Spot_WMA26', 'LME_Ti_Spot_EMA40',
       'LME_Ti_Spot_WMA40', 'LME_Ti_Spot_EMA65', 'LME_Ti_Spot_WMA65',
       'LME_Ti_Spot_EMA125', 'LME_Ti_Spot_WMA125', 'LME_Ti_Spot_bollinger5',
       'LME_Ti_Spot_bollinger10', 'LME_Ti_Spot_bollinger15',
       'LME_Ti_Spot_bollinger20', 'LME_Ti_Spot_bollinger30',
       'LME_Ti_Spot_bollinger65', 'LME_Ti_Spot_Mom5', 'LME_Ti_Spot_Mom10',
       'LME_Ti_Spot_Mom15', 'LME_Ti_Spot_Mom26', 'LME_Ti_Spot_Mom40',
       'LME_Ti_Spot_Mom65', 'LME_Ti_Spot_Mom125', 'LME_Ti_Spot_PPO12',
       'LME_Ti_Spot_PPO22', 'LME_Ti_Spot_RSI14', 'LME_Ti_Spot_RSI26',
       'LME_Ti_Spot_RSI40', 'LME_Ti_Spot_RSI54', 'LME_Ti_Spot_RSI125',
       'LME_Ti_Close_EMA12', 'LME_Ti_Close_WMA12', 'LME_Ti_Close_EMA26',
       'LME_Ti_Close_WMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_WMA40',
       'LME_Ti_Close_EMA65', 'LME_Ti_Close_WMA65', 'LME_Ti_Close_EMA125',
       'LME_Ti_Close_WMA125', 'LME_Ti_Close_bollinger5',
       'LME_Ti_Close_bollinger10', 'LME_Ti_Close_bollinger15',
       'LME_Ti_Close_bollinger20', 'LME_Ti_Close_bollinger30',
       'LME_Ti_Close_bollinger65', 'LME_Ti_Close_Mom5', 'LME_Ti_Close_Mom10',
       'LME_Ti_Close_Mom15', 'LME_Ti_Close_Mom26', 'LME_Ti_Close_Mom40',
       'LME_Ti_Close_Mom65', 'LME_Ti_Close_Mom125', 'LME_Ti_Close_PPO12',
       'LME_Ti_Close_PPO22', 'LME_Ti_Close_RSI14', 'LME_Ti_Close_RSI26',
       'LME_Ti_Close_RSI40', 'LME_Ti_Close_RSI54', 'LME_Ti_Close_RSI125',
       'LME_Ti_PVT', 'LME_Ti_divPVT', 'LME_Ti_NATR14', 'LME_Ti_NATR26',
       'LME_Ti_NATR65', 'LME_Ti_NATR125', 'LME_Ti_CCI12', 'LME_Ti_CCI26',
       'LME_Ti_CCI40', 'LME_Ti_CCI65', 'LME_Ti_CCI125', 'LME_Ti_VBM12',
       'LME_Ti_VBM22', 'LME_Ti_ADX14', 'LME_Ti_ADX26', 'LME_Ti_ADX40',
       'LME_Ti_ADX54', 'LME_Ti_ADX125', 'LME_Ti_SAR'],
      dtype='object')
Dataset statistic: #examples
Train: 5454 5454 5454
11.425974 -8.434036 2.4565036 -1.7160783
Validation: 612 612 612
Testing: 744 744 744
pre-processing time: 0.00028586387634277344
the split date is 2017-01-01
net initializing with time: 0.015662193298339844
preparing training and testing date with time: 0.00461268424987793
current epoch: 1
train loss is 0.564566
average val loss: 0.268928, accuracy: 0.5441
average test loss: 0.234474, accuracy: 0.5175
case acc: 0.5080645161290323
case acc: 0.47580645161290325
case acc: 0.5645161290322581
case acc: 0.5483870967741935
case acc: 0.5
case acc: 0.5080645161290323
top acc: 0.8049 ::: bot acc: 0.1707
top acc: 0.3171 ::: bot acc: 0.6098
top acc: 1.0000 ::: bot acc: 0.0244
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.3415 ::: bot acc: 0.7561
top acc: 0.9756 ::: bot acc: 0.0488
current epoch: 2
train loss is 0.212685
average val loss: 0.186316, accuracy: 0.4788
average test loss: 0.188225, accuracy: 0.5027
case acc: 0.4838709677419355
case acc: 0.4435483870967742
case acc: 0.532258064516129
case acc: 0.5645161290322581
case acc: 0.4838709677419355
case acc: 0.5080645161290323
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.9756 ::: bot acc: 0.0244
top acc: 0.9512 ::: bot acc: 0.0732
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.0244 ::: bot acc: 1.0000
current epoch: 3
train loss is 0.172116
average val loss: 0.163578, accuracy: 0.4755
average test loss: 0.166339, accuracy: 0.5081
case acc: 0.46774193548387094
case acc: 0.4435483870967742
case acc: 0.532258064516129
case acc: 0.5483870967741935
case acc: 0.4838709677419355
case acc: 0.5725806451612904
top acc: 0.1707 ::: bot acc: 0.7317
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.3171 ::: bot acc: 0.7805
current epoch: 4
train loss is 0.159823
average val loss: 0.157322, accuracy: 0.4886
average test loss: 0.151638, accuracy: 0.5121
case acc: 0.4838709677419355
case acc: 0.4435483870967742
case acc: 0.532258064516129
case acc: 0.5483870967741935
case acc: 0.4838709677419355
case acc: 0.5806451612903226
top acc: 0.5610 ::: bot acc: 0.3659
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.2439 ::: bot acc: 0.8537
current epoch: 5
train loss is 0.150572
average val loss: 0.154692, accuracy: 0.4788
average test loss: 0.149253, accuracy: 0.5067
case acc: 0.47580645161290325
case acc: 0.4435483870967742
case acc: 0.532258064516129
case acc: 0.5564516129032258
case acc: 0.4838709677419355
case acc: 0.5483870967741935
top acc: 0.0732 ::: bot acc: 0.8780
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 1.0000 ::: bot acc: 0.0244
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.2195 ::: bot acc: 0.8537
current epoch: 6
train loss is 0.141859
average val loss: 0.147592, accuracy: 0.4837
average test loss: 0.140608, accuracy: 0.5242
case acc: 0.5241935483870968
case acc: 0.4435483870967742
case acc: 0.532258064516129
case acc: 0.5483870967741935
case acc: 0.5
case acc: 0.5967741935483871
top acc: 0.3415 ::: bot acc: 0.6341
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.0488 ::: bot acc: 1.0000
top acc: 0.3902 ::: bot acc: 0.7805
current epoch: 7
train loss is 0.136827
average val loss: 0.145232, accuracy: 0.4902
average test loss: 0.138374, accuracy: 0.5228
case acc: 0.5241935483870968
case acc: 0.4435483870967742
case acc: 0.532258064516129
case acc: 0.5564516129032258
case acc: 0.4838709677419355
case acc: 0.5967741935483871
top acc: 0.2439 ::: bot acc: 0.7561
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.9756 ::: bot acc: 0.0488
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.2927 ::: bot acc: 0.8537
current epoch: 8
train loss is 0.132800
average val loss: 0.142406, accuracy: 0.4918
average test loss: 0.136597, accuracy: 0.5148
case acc: 0.5
case acc: 0.4435483870967742
case acc: 0.5241935483870968
case acc: 0.5403225806451613
case acc: 0.49193548387096775
case acc: 0.5887096774193549
top acc: 0.2195 ::: bot acc: 0.7805
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.9756 ::: bot acc: 0.0000
top acc: 0.9756 ::: bot acc: 0.0000
top acc: 0.0488 ::: bot acc: 0.9756
top acc: 0.3902 ::: bot acc: 0.8049
current epoch: 9
train loss is 0.129091
average val loss: 0.138770, accuracy: 0.4886
average test loss: 0.130719, accuracy: 0.5215
case acc: 0.49193548387096775
case acc: 0.4435483870967742
case acc: 0.5241935483870968
case acc: 0.5725806451612904
case acc: 0.49193548387096775
case acc: 0.6048387096774194
top acc: 0.2439 ::: bot acc: 0.6829
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.9756 ::: bot acc: 0.0000
top acc: 0.9512 ::: bot acc: 0.1220
top acc: 0.0244 ::: bot acc: 1.0000
top acc: 0.3659 ::: bot acc: 0.7805
current epoch: 10
train loss is 0.123639
average val loss: 0.137597, accuracy: 0.5033
average test loss: 0.130724, accuracy: 0.5296
case acc: 0.49193548387096775
case acc: 0.4435483870967742
case acc: 0.5483870967741935
case acc: 0.5887096774193549
case acc: 0.5080645161290323
case acc: 0.5967741935483871
top acc: 0.1707 ::: bot acc: 0.8049
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.8780 ::: bot acc: 0.1463
top acc: 0.9512 ::: bot acc: 0.1463
top acc: 0.0488 ::: bot acc: 1.0000
top acc: 0.3659 ::: bot acc: 0.7805
current epoch: 11
train loss is 0.121691
average val loss: 0.134788, accuracy: 0.5049
average test loss: 0.127704, accuracy: 0.5215
case acc: 0.4838709677419355
case acc: 0.4435483870967742
case acc: 0.5483870967741935
case acc: 0.5887096774193549
case acc: 0.49193548387096775
case acc: 0.5725806451612904
top acc: 0.1951 ::: bot acc: 0.7561
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.8537 ::: bot acc: 0.1707
top acc: 0.9024 ::: bot acc: 0.1707
top acc: 0.0244 ::: bot acc: 1.0000
top acc: 0.3415 ::: bot acc: 0.7561
current epoch: 12
train loss is 0.117175
average val loss: 0.133629, accuracy: 0.5049
average test loss: 0.126092, accuracy: 0.5282
case acc: 0.4838709677419355
case acc: 0.4435483870967742
case acc: 0.5483870967741935
case acc: 0.6129032258064516
case acc: 0.49193548387096775
case acc: 0.5887096774193549
top acc: 0.1220 ::: bot acc: 0.8293
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.8293 ::: bot acc: 0.2439
top acc: 0.8537 ::: bot acc: 0.2683
top acc: 0.0244 ::: bot acc: 1.0000
top acc: 0.2927 ::: bot acc: 0.8293
current epoch: 13
train loss is 0.116686
average val loss: 0.131670, accuracy: 0.5147
average test loss: 0.123118, accuracy: 0.5215
case acc: 0.46774193548387094
case acc: 0.4435483870967742
case acc: 0.5241935483870968
case acc: 0.5887096774193549
case acc: 0.49193548387096775
case acc: 0.6129032258064516
top acc: 0.1951 ::: bot acc: 0.7317
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.7561 ::: bot acc: 0.2439
top acc: 0.7317 ::: bot acc: 0.3415
top acc: 0.0244 ::: bot acc: 1.0000
top acc: 0.4390 ::: bot acc: 0.7561
current epoch: 14
train loss is 0.115334
average val loss: 0.131202, accuracy: 0.5033
average test loss: 0.122083, accuracy: 0.5188
case acc: 0.47580645161290325
case acc: 0.4435483870967742
case acc: 0.532258064516129
case acc: 0.5806451612903226
case acc: 0.49193548387096775
case acc: 0.5887096774193549
top acc: 0.2195 ::: bot acc: 0.7317
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.7317 ::: bot acc: 0.2683
top acc: 0.6829 ::: bot acc: 0.3659
top acc: 0.0244 ::: bot acc: 1.0000
top acc: 0.3659 ::: bot acc: 0.8049
current epoch: 15
train loss is 0.112505
average val loss: 0.130110, accuracy: 0.5016
average test loss: 0.120625, accuracy: 0.5255
case acc: 0.4838709677419355
case acc: 0.4435483870967742
case acc: 0.5564516129032258
case acc: 0.5806451612903226
case acc: 0.49193548387096775
case acc: 0.5967741935483871
top acc: 0.2195 ::: bot acc: 0.7073
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.7317 ::: bot acc: 0.3415
top acc: 0.6098 ::: bot acc: 0.4146
top acc: 0.0244 ::: bot acc: 1.0000
top acc: 0.4634 ::: bot acc: 0.7317
current epoch: 16
train loss is 0.111385
average val loss: 0.129391, accuracy: 0.5000
average test loss: 0.119467, accuracy: 0.5323
case acc: 0.49193548387096775
case acc: 0.4435483870967742
case acc: 0.5403225806451613
case acc: 0.5645161290322581
case acc: 0.5241935483870968
case acc: 0.6290322580645161
top acc: 0.1707 ::: bot acc: 0.7805
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.7317 ::: bot acc: 0.3415
top acc: 0.5366 ::: bot acc: 0.5366
top acc: 0.0976 ::: bot acc: 1.0000
top acc: 0.5122 ::: bot acc: 0.7561
current epoch: 17
train loss is 0.110243
average val loss: 0.128427, accuracy: 0.5147
average test loss: 0.118012, accuracy: 0.5363
case acc: 0.5
case acc: 0.4435483870967742
case acc: 0.5483870967741935
case acc: 0.5645161290322581
case acc: 0.532258064516129
case acc: 0.6290322580645161
top acc: 0.2195 ::: bot acc: 0.7561
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.7317 ::: bot acc: 0.3659
top acc: 0.5122 ::: bot acc: 0.6098
top acc: 0.1220 ::: bot acc: 0.9756
top acc: 0.5122 ::: bot acc: 0.7561
current epoch: 18
train loss is 0.109855
average val loss: 0.128375, accuracy: 0.5033
average test loss: 0.117505, accuracy: 0.5323
case acc: 0.49193548387096775
case acc: 0.4435483870967742
case acc: 0.532258064516129
case acc: 0.5564516129032258
case acc: 0.5483870967741935
case acc: 0.6209677419354839
top acc: 0.1463 ::: bot acc: 0.8049
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.7073 ::: bot acc: 0.3659
top acc: 0.4878 ::: bot acc: 0.6341
top acc: 0.1463 ::: bot acc: 1.0000
top acc: 0.3659 ::: bot acc: 0.8293
current epoch: 19
train loss is 0.108494
average val loss: 0.127339, accuracy: 0.5065
average test loss: 0.116186, accuracy: 0.5309
case acc: 0.49193548387096775
case acc: 0.4435483870967742
case acc: 0.532258064516129
case acc: 0.5564516129032258
case acc: 0.5403225806451613
case acc: 0.6209677419354839
top acc: 0.2439 ::: bot acc: 0.7073
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.6829 ::: bot acc: 0.3659
top acc: 0.4878 ::: bot acc: 0.6341
top acc: 0.1463 ::: bot acc: 1.0000
top acc: 0.4146 ::: bot acc: 0.7805
current epoch: 20
train loss is 0.107490
average val loss: 0.127749, accuracy: 0.4967
average test loss: 0.116226, accuracy: 0.5188
case acc: 0.4838709677419355
case acc: 0.4435483870967742
case acc: 0.5241935483870968
case acc: 0.5241935483870968
case acc: 0.5483870967741935
case acc: 0.5887096774193549
top acc: 0.2195 ::: bot acc: 0.7561
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.6585 ::: bot acc: 0.3659
top acc: 0.3659 ::: bot acc: 0.6829
top acc: 0.1707 ::: bot acc: 1.0000
top acc: 0.3415 ::: bot acc: 0.8049
current epoch: 21
train loss is 0.107153
average val loss: 0.126164, accuracy: 0.5098
average test loss: 0.114271, accuracy: 0.5323
case acc: 0.5161290322580645
case acc: 0.45161290322580644
case acc: 0.5241935483870968
case acc: 0.5403225806451613
case acc: 0.5483870967741935
case acc: 0.6129032258064516
top acc: 0.3415 ::: bot acc: 0.7073
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.6585 ::: bot acc: 0.3659
top acc: 0.4878 ::: bot acc: 0.6098
top acc: 0.1707 ::: bot acc: 0.9268
top acc: 0.4634 ::: bot acc: 0.7317
current epoch: 22
train loss is 0.106506
average val loss: 0.126564, accuracy: 0.5016
average test loss: 0.114491, accuracy: 0.5215
case acc: 0.5241935483870968
case acc: 0.45161290322580644
case acc: 0.5161290322580645
case acc: 0.5161290322580645
case acc: 0.5403225806451613
case acc: 0.5806451612903226
top acc: 0.3171 ::: bot acc: 0.7317
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.6098 ::: bot acc: 0.4146
top acc: 0.3659 ::: bot acc: 0.6341
top acc: 0.1707 ::: bot acc: 0.9756
top acc: 0.3659 ::: bot acc: 0.7561
current epoch: 23
train loss is 0.107032
average val loss: 0.126329, accuracy: 0.5033
average test loss: 0.114775, accuracy: 0.5215
case acc: 0.532258064516129
case acc: 0.45161290322580644
case acc: 0.5080645161290323
case acc: 0.5080645161290323
case acc: 0.5483870967741935
case acc: 0.5806451612903226
top acc: 0.3659 ::: bot acc: 0.7073
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.6098 ::: bot acc: 0.4146
top acc: 0.3659 ::: bot acc: 0.6098
top acc: 0.1707 ::: bot acc: 1.0000
top acc: 0.4146 ::: bot acc: 0.7561
current epoch: 24
train loss is 0.106397
average val loss: 0.125965, accuracy: 0.5180
average test loss: 0.114745, accuracy: 0.5269
case acc: 0.5161290322580645
case acc: 0.45161290322580644
case acc: 0.5403225806451613
case acc: 0.532258064516129
case acc: 0.5403225806451613
case acc: 0.5806451612903226
top acc: 0.4146 ::: bot acc: 0.6341
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.5854 ::: bot acc: 0.5122
top acc: 0.3902 ::: bot acc: 0.6341
top acc: 0.1463 ::: bot acc: 1.0000
top acc: 0.4146 ::: bot acc: 0.7317
current epoch: 25
train loss is 0.106130
average val loss: 0.125272, accuracy: 0.4951
average test loss: 0.113533, accuracy: 0.5309
case acc: 0.5161290322580645
case acc: 0.45161290322580644
case acc: 0.5403225806451613
case acc: 0.5645161290322581
case acc: 0.532258064516129
case acc: 0.5806451612903226
top acc: 0.4390 ::: bot acc: 0.6098
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.6098 ::: bot acc: 0.4878
top acc: 0.5366 ::: bot acc: 0.5854
top acc: 0.1220 ::: bot acc: 1.0000
top acc: 0.4146 ::: bot acc: 0.7317
current epoch: 26
train loss is 0.104364
average val loss: 0.125457, accuracy: 0.4935
average test loss: 0.113445, accuracy: 0.5242
case acc: 0.5161290322580645
case acc: 0.45161290322580644
case acc: 0.5564516129032258
case acc: 0.5080645161290323
case acc: 0.5241935483870968
case acc: 0.5887096774193549
top acc: 0.3415 ::: bot acc: 0.6585
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.5366 ::: bot acc: 0.6098
top acc: 0.3659 ::: bot acc: 0.6585
top acc: 0.0976 ::: bot acc: 1.0000
top acc: 0.3415 ::: bot acc: 0.8293
current epoch: 27
train loss is 0.105046
average val loss: 0.124528, accuracy: 0.5065
average test loss: 0.113075, accuracy: 0.5403
case acc: 0.5403225806451613
case acc: 0.4435483870967742
case acc: 0.5645161290322581
case acc: 0.5564516129032258
case acc: 0.5241935483870968
case acc: 0.6129032258064516
top acc: 0.3902 ::: bot acc: 0.6341
top acc: 0.0000 ::: bot acc: 0.9756
top acc: 0.5122 ::: bot acc: 0.6098
top acc: 0.3902 ::: bot acc: 0.7073
top acc: 0.0976 ::: bot acc: 1.0000
top acc: 0.4146 ::: bot acc: 0.7805
current epoch: 28
train loss is 0.104979
average val loss: 0.125254, accuracy: 0.4804
average test loss: 0.113435, accuracy: 0.5296
case acc: 0.5161290322580645
case acc: 0.4435483870967742
case acc: 0.5483870967741935
case acc: 0.5564516129032258
case acc: 0.5241935483870968
case acc: 0.5887096774193549
top acc: 0.3902 ::: bot acc: 0.6585
top acc: 0.0000 ::: bot acc: 0.9756
top acc: 0.5366 ::: bot acc: 0.5610
top acc: 0.4390 ::: bot acc: 0.6341
top acc: 0.1707 ::: bot acc: 0.9024
top acc: 0.4878 ::: bot acc: 0.7073
current epoch: 29
train loss is 0.103452
average val loss: 0.124496, accuracy: 0.5065
average test loss: 0.113056, accuracy: 0.5215
case acc: 0.5403225806451613
case acc: 0.4435483870967742
case acc: 0.5403225806451613
case acc: 0.5080645161290323
case acc: 0.5
case acc: 0.5967741935483871
top acc: 0.3659 ::: bot acc: 0.6585
top acc: 0.0000 ::: bot acc: 0.9756
top acc: 0.4634 ::: bot acc: 0.6098
top acc: 0.3415 ::: bot acc: 0.7317
top acc: 0.0732 ::: bot acc: 0.9512
top acc: 0.3902 ::: bot acc: 0.7805
current epoch: 30
train loss is 0.104692
average val loss: 0.124986, accuracy: 0.4837
average test loss: 0.112915, accuracy: 0.5202
case acc: 0.5403225806451613
case acc: 0.4435483870967742
case acc: 0.5564516129032258
case acc: 0.47580645161290325
case acc: 0.5080645161290323
case acc: 0.5967741935483871
top acc: 0.3415 ::: bot acc: 0.7317
top acc: 0.0000 ::: bot acc: 0.9756
top acc: 0.4634 ::: bot acc: 0.6585
top acc: 0.2927 ::: bot acc: 0.7073
top acc: 0.0732 ::: bot acc: 0.9512
top acc: 0.3659 ::: bot acc: 0.8293
current epoch: 31
train loss is 0.103765
average val loss: 0.124534, accuracy: 0.4902
average test loss: 0.112191, accuracy: 0.5121
case acc: 0.5161290322580645
case acc: 0.4435483870967742
case acc: 0.5403225806451613
case acc: 0.5
case acc: 0.5
case acc: 0.5725806451612904
top acc: 0.3171 ::: bot acc: 0.6829
top acc: 0.0000 ::: bot acc: 0.9756
top acc: 0.4634 ::: bot acc: 0.6341
top acc: 0.3415 ::: bot acc: 0.7073
top acc: 0.0976 ::: bot acc: 0.8780
top acc: 0.3415 ::: bot acc: 0.8049
current epoch: 32
train loss is 0.103768
average val loss: 0.124708, accuracy: 0.4869
average test loss: 0.112425, accuracy: 0.5188
case acc: 0.5241935483870968
case acc: 0.4435483870967742
case acc: 0.5080645161290323
case acc: 0.532258064516129
case acc: 0.5161290322580645
case acc: 0.5887096774193549
top acc: 0.3171 ::: bot acc: 0.6829
top acc: 0.0000 ::: bot acc: 0.9756
top acc: 0.3902 ::: bot acc: 0.6341
top acc: 0.3659 ::: bot acc: 0.7561
top acc: 0.0976 ::: bot acc: 0.9268
top acc: 0.3171 ::: bot acc: 0.8537
current epoch: 33
train loss is 0.103529
average val loss: 0.125355, accuracy: 0.4722
average test loss: 0.112928, accuracy: 0.5054
case acc: 0.5161290322580645
case acc: 0.4435483870967742
case acc: 0.5080645161290323
case acc: 0.4838709677419355
case acc: 0.5
case acc: 0.5806451612903226
top acc: 0.3171 ::: bot acc: 0.7317
top acc: 0.0000 ::: bot acc: 0.9756
top acc: 0.3415 ::: bot acc: 0.7073
top acc: 0.3171 ::: bot acc: 0.7317
top acc: 0.0732 ::: bot acc: 0.9268
top acc: 0.3415 ::: bot acc: 0.8293
current epoch: 34
train loss is 0.103877
average val loss: 0.124681, accuracy: 0.4853
average test loss: 0.112128, accuracy: 0.5202
case acc: 0.5080645161290323
case acc: 0.45161290322580644
case acc: 0.5564516129032258
case acc: 0.49193548387096775
case acc: 0.532258064516129
case acc: 0.5806451612903226
top acc: 0.3171 ::: bot acc: 0.6829
top acc: 0.0000 ::: bot acc: 0.9756
top acc: 0.4390 ::: bot acc: 0.6829
top acc: 0.3171 ::: bot acc: 0.7073
top acc: 0.1220 ::: bot acc: 0.9268
top acc: 0.4634 ::: bot acc: 0.7561
current epoch: 35
train loss is 0.103924
average val loss: 0.124597, accuracy: 0.4837
average test loss: 0.112664, accuracy: 0.5054
case acc: 0.5
case acc: 0.4435483870967742
case acc: 0.5161290322580645
case acc: 0.49193548387096775
case acc: 0.5
case acc: 0.5806451612903226
top acc: 0.2683 ::: bot acc: 0.7317
top acc: 0.0000 ::: bot acc: 0.9756
top acc: 0.3171 ::: bot acc: 0.7561
top acc: 0.2927 ::: bot acc: 0.7561
top acc: 0.0488 ::: bot acc: 0.9512
top acc: 0.3171 ::: bot acc: 0.8293
current epoch: 36
train loss is 0.103375
average val loss: 0.124675, accuracy: 0.4820
average test loss: 0.113093, accuracy: 0.5067
case acc: 0.49193548387096775
case acc: 0.4435483870967742
case acc: 0.5080645161290323
case acc: 0.5
case acc: 0.5
case acc: 0.5967741935483871
top acc: 0.2195 ::: bot acc: 0.7561
top acc: 0.0000 ::: bot acc: 0.9756
top acc: 0.2927 ::: bot acc: 0.7805
top acc: 0.2439 ::: bot acc: 0.8293
top acc: 0.0488 ::: bot acc: 0.9512
top acc: 0.3171 ::: bot acc: 0.9024
current epoch: 37
train loss is 0.102962
average val loss: 0.124141, accuracy: 0.4902
average test loss: 0.112126, accuracy: 0.4960
case acc: 0.4838709677419355
case acc: 0.46774193548387094
case acc: 0.4838709677419355
case acc: 0.5
case acc: 0.5
case acc: 0.5403225806451613
top acc: 0.2683 ::: bot acc: 0.6585
top acc: 0.0244 ::: bot acc: 0.9756
top acc: 0.3171 ::: bot acc: 0.6829
top acc: 0.2683 ::: bot acc: 0.8049
top acc: 0.0732 ::: bot acc: 0.9024
top acc: 0.3415 ::: bot acc: 0.7561
current epoch: 38
train loss is 0.102717
average val loss: 0.125196, accuracy: 0.4608
average test loss: 0.113210, accuracy: 0.5094
case acc: 0.49193548387096775
case acc: 0.4596774193548387
case acc: 0.5161290322580645
case acc: 0.5080645161290323
case acc: 0.49193548387096775
case acc: 0.5887096774193549
top acc: 0.1951 ::: bot acc: 0.8049
top acc: 0.0244 ::: bot acc: 0.9756
top acc: 0.2927 ::: bot acc: 0.8293
top acc: 0.2195 ::: bot acc: 0.8780
top acc: 0.0488 ::: bot acc: 0.9024
top acc: 0.2683 ::: bot acc: 0.9268
current epoch: 39
train loss is 0.102658
average val loss: 0.123561, accuracy: 0.5033
average test loss: 0.111219, accuracy: 0.5121
case acc: 0.5
case acc: 0.4596774193548387
case acc: 0.5161290322580645
case acc: 0.5
case acc: 0.532258064516129
case acc: 0.5645161290322581
top acc: 0.3171 ::: bot acc: 0.6829
top acc: 0.0244 ::: bot acc: 0.9756
top acc: 0.3659 ::: bot acc: 0.6585
top acc: 0.2927 ::: bot acc: 0.7805
top acc: 0.2195 ::: bot acc: 0.8537
top acc: 0.4390 ::: bot acc: 0.7317
current epoch: 40
train loss is 0.101729
average val loss: 0.124620, accuracy: 0.4641
average test loss: 0.112393, accuracy: 0.5040
case acc: 0.49193548387096775
case acc: 0.4596774193548387
case acc: 0.5080645161290323
case acc: 0.5080645161290323
case acc: 0.5
case acc: 0.5564516129032258
top acc: 0.1951 ::: bot acc: 0.8293
top acc: 0.0244 ::: bot acc: 0.9756
top acc: 0.2683 ::: bot acc: 0.8049
top acc: 0.2683 ::: bot acc: 0.8293
top acc: 0.0976 ::: bot acc: 0.9024
top acc: 0.2927 ::: bot acc: 0.8537
current epoch: 41
train loss is 0.102648
average val loss: 0.123912, accuracy: 0.4804
average test loss: 0.111948, accuracy: 0.5027
case acc: 0.5080645161290323
case acc: 0.4596774193548387
case acc: 0.49193548387096775
case acc: 0.5241935483870968
case acc: 0.49193548387096775
case acc: 0.5403225806451613
top acc: 0.2195 ::: bot acc: 0.8293
top acc: 0.0244 ::: bot acc: 0.9756
top acc: 0.2683 ::: bot acc: 0.8049
top acc: 0.2927 ::: bot acc: 0.8049
top acc: 0.0732 ::: bot acc: 0.9024
top acc: 0.3171 ::: bot acc: 0.8049
current epoch: 42
train loss is 0.101795
average val loss: 0.124245, accuracy: 0.4739
average test loss: 0.111920, accuracy: 0.5067
case acc: 0.5
case acc: 0.4596774193548387
case acc: 0.5403225806451613
case acc: 0.5080645161290323
case acc: 0.5
case acc: 0.532258064516129
top acc: 0.2195 ::: bot acc: 0.8293
top acc: 0.0244 ::: bot acc: 0.9756
top acc: 0.2927 ::: bot acc: 0.8049
top acc: 0.3415 ::: bot acc: 0.7073
top acc: 0.0976 ::: bot acc: 0.8780
top acc: 0.3171 ::: bot acc: 0.8049
current epoch: 43
train loss is 0.102284
average val loss: 0.124116, accuracy: 0.4788
average test loss: 0.111921, accuracy: 0.5054
case acc: 0.49193548387096775
case acc: 0.4596774193548387
case acc: 0.5241935483870968
case acc: 0.5161290322580645
case acc: 0.5
case acc: 0.5403225806451613
top acc: 0.1951 ::: bot acc: 0.8293
top acc: 0.0244 ::: bot acc: 0.9756
top acc: 0.2927 ::: bot acc: 0.8049
top acc: 0.2927 ::: bot acc: 0.8049
top acc: 0.1220 ::: bot acc: 0.8780
top acc: 0.2927 ::: bot acc: 0.8293
current epoch: 44
train loss is 0.101107
average val loss: 0.124029, accuracy: 0.4804
average test loss: 0.111132, accuracy: 0.5067
case acc: 0.49193548387096775
case acc: 0.45161290322580644
case acc: 0.5241935483870968
case acc: 0.5161290322580645
case acc: 0.5161290322580645
case acc: 0.5403225806451613
top acc: 0.1951 ::: bot acc: 0.8293
top acc: 0.0244 ::: bot acc: 0.9756
top acc: 0.2927 ::: bot acc: 0.7561
top acc: 0.3171 ::: bot acc: 0.7561
top acc: 0.1951 ::: bot acc: 0.8537
top acc: 0.2927 ::: bot acc: 0.8293
current epoch: 45
train loss is 0.101355
average val loss: 0.124137, accuracy: 0.5000
average test loss: 0.111558, accuracy: 0.5067
case acc: 0.49193548387096775
case acc: 0.45161290322580644
case acc: 0.46774193548387094
case acc: 0.5080645161290323
case acc: 0.5161290322580645
case acc: 0.6048387096774194
top acc: 0.1707 ::: bot acc: 0.8293
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.2439 ::: bot acc: 0.7805
top acc: 0.2439 ::: bot acc: 0.8293
top acc: 0.1707 ::: bot acc: 0.8780
top acc: 0.2927 ::: bot acc: 0.9268
current epoch: 46
train loss is 0.101525
average val loss: 0.123834, accuracy: 0.4984
average test loss: 0.111221, accuracy: 0.5067
case acc: 0.49193548387096775
case acc: 0.45161290322580644
case acc: 0.4838709677419355
case acc: 0.5
case acc: 0.5080645161290323
case acc: 0.6048387096774194
top acc: 0.2195 ::: bot acc: 0.8049
top acc: 0.0244 ::: bot acc: 0.9756
top acc: 0.2683 ::: bot acc: 0.7561
top acc: 0.2683 ::: bot acc: 0.8049
top acc: 0.1951 ::: bot acc: 0.8537
top acc: 0.3171 ::: bot acc: 0.9268
current epoch: 47
train loss is 0.102935
average val loss: 0.123479, accuracy: 0.5033
average test loss: 0.111356, accuracy: 0.5148
case acc: 0.5
case acc: 0.46774193548387094
case acc: 0.49193548387096775
case acc: 0.5241935483870968
case acc: 0.5
case acc: 0.6048387096774194
top acc: 0.2683 ::: bot acc: 0.7073
top acc: 0.0244 ::: bot acc: 0.9756
top acc: 0.2439 ::: bot acc: 0.7805
top acc: 0.3659 ::: bot acc: 0.7317
top acc: 0.1463 ::: bot acc: 0.8780
top acc: 0.3902 ::: bot acc: 0.8049
current epoch: 48
train loss is 0.100978
average val loss: 0.124421, accuracy: 0.4918
average test loss: 0.112758, accuracy: 0.5054
case acc: 0.49193548387096775
case acc: 0.45161290322580644
case acc: 0.46774193548387094
case acc: 0.5161290322580645
case acc: 0.49193548387096775
case acc: 0.6129032258064516
top acc: 0.2195 ::: bot acc: 0.7805
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.1220 ::: bot acc: 0.8293
top acc: 0.2927 ::: bot acc: 0.8049
top acc: 0.0732 ::: bot acc: 0.8780
top acc: 0.2683 ::: bot acc: 0.9512
current epoch: 49
train loss is 0.100923
average val loss: 0.123711, accuracy: 0.5000
average test loss: 0.111303, accuracy: 0.5134
case acc: 0.5
case acc: 0.45161290322580644
case acc: 0.5080645161290323
case acc: 0.5161290322580645
case acc: 0.532258064516129
case acc: 0.5725806451612904
top acc: 0.2439 ::: bot acc: 0.7561
top acc: 0.0244 ::: bot acc: 0.9756
top acc: 0.2683 ::: bot acc: 0.7805
top acc: 0.2927 ::: bot acc: 0.8293
top acc: 0.2195 ::: bot acc: 0.8780
top acc: 0.2927 ::: bot acc: 0.8780
current epoch: 50
train loss is 0.101405
average val loss: 0.123527, accuracy: 0.4935
average test loss: 0.111295, accuracy: 0.5081
case acc: 0.5
case acc: 0.45161290322580644
case acc: 0.49193548387096775
case acc: 0.5241935483870968
case acc: 0.5161290322580645
case acc: 0.5645161290322581
top acc: 0.1951 ::: bot acc: 0.8049
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.2195 ::: bot acc: 0.7805
top acc: 0.3171 ::: bot acc: 0.8049
top acc: 0.1707 ::: bot acc: 0.8780
top acc: 0.2683 ::: bot acc: 0.9024
