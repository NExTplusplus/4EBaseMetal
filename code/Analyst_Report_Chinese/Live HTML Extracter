from newspaper import Article
from newspaper import fulltext
import time
import datetime
import pickle
import pandas as pd
import sqlalchemy as sq
from bs4 import BeautifulSoup
from inscriptis import get_text

class html_extracter:
    def __init__(self,conn,build_db_content = False):
        
        self.conn_extracter = conn
        if build_db_content:
            self.build_content_db()
    
    def build_content_db(self):
        # Function: Set up a database to store accuracy with the following setting. 
        # Note that: All functions in this class will follow this setting, pls set up ur database accordingly to avoid error
        self.conn_extracter.execute('CREATE TABLE `Alternative_DB`.`content`(`url` VARCHAR(750) NOT NULL,`id` INT NOT NULL AUTO_INCREMENT,`date` DATETIME NOT NULL,`company` VARCHAR(30) NULL,`type` VARCHAR(45) NULL,`title` TINYTEXT NULL,`content` MEDIUMTEXT NULL,PRIMARY KEY (`url`),KEY(`id`));')
    
    def extract(self,df_news,date):
        # Function: This function will extract content from html
        # Inputs: df_news is the crawled report dataframe gotten from live crawler, date is today date
        # function_content is the fucntion to extract content from specific html style
        '''
        df_news:(html)the html we need to extract the information from the html
        date:(string)the date we need to deal with the html
        '''
        
        # Check whether table in database has been created 
        result = self.conn_extracter.execute("SHOW TABLES LIKE 'content';")
        
        if  not result.first():
            raise Exception('Database not exist, please use build_content_db function')
        
        # Record data that has problems when we try to extract
        
        problem={}
        for news_id,title,type1, name,url,html in zip(df_news['id'],df_news['title'],df_news['type'],df_news['company'],df_news['url'],df_news['html']):
            try:
                new_input = {}
                new_input['date'] = [date]
                new_input['company'] = [name]
                new_input['type'] = [type1]
                new_input['title'] = [title]
                new_input['url'] = [url]
                
                function_content = self.choose_func(url)
                
                #Extract Content
                text = function_content(html)
                if len(text)==0:
                    raise Exception('Empty')
                else:
                    new_input['Content'] = [text]
            
            
                df_input = pd.DataFrame(new_input)
                df_input.to_sql(name='content', con=self.conn_extracter, if_exists='append',index=False)
        
            except Exception as e:
                # If still have problem, record it
                print('Problem found',e)
                if str(e) in problem:
                    problem[str(e)].append(news_id)
                else:
                    problem[str(e)] = [news_id]

                
                continue 
        
        print ('Completed')
        return problem 
    
    def choose_func(self,url):
        # Function: this function will return a suitable function that can extract html accordingly
        fulltext_lst = ['gtaxqh','htfc','szjhqh','btqh','hlqh','fnqh','cnzsqh','ftol','dlqh','cnhtqh','mfc','gzjkqh','shqhgs','zcqh','tqfutures','shcifco','rdqh','jtqh','hhqh','bhfcc']
        keyword = website_link.split('.')[1]
        if keyword in fulltext_lst:
            func = lambda x: fulltext(x, 'zh')
        elif 'bocifco' in keyword:
            func = lambda x: BeautifulSoup(x).find("div", {"class": "contArticle_text"}).text
        elif 'xzfutures' in keyword:
            func = lambda x: BeautifulSoup(x).find("div", {"class": "aboutfont"}).text
        elif 'dyqh' in keyword:
            func = lambda x: BeautifulSoup(x).find("div", {"class": "news-list news-info"}).find("div", {"class": "cont"}).text
        elif 'sdfutures' in keyword:
            func = lambda x: BeautifulSoup(x).find("div", {"class": "mainContent"}).text
        elif 'guosenqh' in keyword:
            func = lambda x: BeautifulSoup(x).find("div", {"class": "jp_yyb_box"}).text
        elif 'gtaxqh' in keyword:
            func = lambda x: BeautifulSoup(x).find("div", {"class": "right_service0"}).text
        elif 'gzf2010' in keyword :
            func = lambda x: BeautifulSoup(x).find("div", {"class": "r right right_all"}).text
        elif 'jxgsqh' in keyword:
            func = lambda x: BeautifulSoup(x).find("li", {"class": "ny_li2"}).text
        elif 'hongyuanqh' in keyword:
            func = lambda x: BeautifulSoup(x).find("div", {"class": "about_text1"}).text
        elif 'thanf' in keyword:
            func = lambda x: BeautifulSoup(x).find("p", {"class": "text-justify"}).text
        else:
            raise Exception('Website not in choose_func please add it accordingly')
        return func

#########################################################################################################################33
#Example

engine = sq.create_engine("mysql+pymysql://root:next++4e@localhost/Alternative_DB?host=localhost?port=3306")
conn = engine.connect()
extracter = html_extracter(conn)
df_crawl = pd.read_sql('Select * from html',conn)
date_list = ['2019-05-28']
for date in date_list:
    extracter.extract(df_crawl,'2019-05-28')
