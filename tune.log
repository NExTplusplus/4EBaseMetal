
		{"drop_out": 0.2, "hidden": 10, "embedding_size": 5, "batch": 512, "lag": 2}
Namespace(action='train', attention_size=2, batch=512, data_configure_file='exp/online_v10.conf', drop_out=0.2, embedding_size=5, epoch=50, ground_truth='LME_Co_Spot', hidden_state=10, interval=1, lag=2, lambd=0, lrate=0.001, model='', save_loss=0, save_prediction=0, source='NExT', split=0.9, steps=5, test=False, version='v26')
{'generate_norm_params': 'v1', 'generate_tech_params': 'v2', 'generate_strat_params': None, 'deal_with_abnormal_value': 'v2', 'labelling': 'v2', 'process_missing_value': 'v1', 'strategy_signal': None, 'normalize_without_1d_return': None, 'technical_indication': 'v3', 'remove_unused_columns': 'v4', 'price_normalization': None, 'scaling': 'v2', 'construct': 'v1'}
LME_Co_Spot
Before Load Data
['2009-07-01', '2014-07-01', '2015-01-01']
0.0329349184544754
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Co_Spot']
#####################remove_unused_columns_v4#####################
target LME_Co
Index(['LME_Co_Spot', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low',
       'LME_Co_Close', 'LME_Co_Spot_EMA12', 'LME_Co_Spot_WMA12',
       'LME_Co_Spot_EMA26', 'LME_Co_Spot_WMA26', 'LME_Co_Spot_EMA40',
       'LME_Co_Spot_WMA40', 'LME_Co_Spot_EMA65', 'LME_Co_Spot_WMA65',
       'LME_Co_Spot_EMA125', 'LME_Co_Spot_WMA125', 'LME_Co_Spot_bollinger5',
       'LME_Co_Spot_bollinger10', 'LME_Co_Spot_bollinger15',
       'LME_Co_Spot_bollinger20', 'LME_Co_Spot_bollinger30',
       'LME_Co_Spot_bollinger65', 'LME_Co_Spot_Mom5', 'LME_Co_Spot_Mom10',
       'LME_Co_Spot_Mom15', 'LME_Co_Spot_Mom26', 'LME_Co_Spot_Mom40',
       'LME_Co_Spot_Mom65', 'LME_Co_Spot_Mom125', 'LME_Co_Spot_PPO12',
       'LME_Co_Spot_PPO22', 'LME_Co_Spot_RSI14', 'LME_Co_Spot_RSI26',
       'LME_Co_Spot_RSI40', 'LME_Co_Spot_RSI54', 'LME_Co_Spot_RSI125',
       'LME_Co_Close_EMA12', 'LME_Co_Close_WMA12', 'LME_Co_Close_EMA26',
       'LME_Co_Close_WMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_WMA40',
       'LME_Co_Close_EMA65', 'LME_Co_Close_WMA65', 'LME_Co_Close_EMA125',
       'LME_Co_Close_WMA125', 'LME_Co_Close_bollinger5',
       'LME_Co_Close_bollinger10', 'LME_Co_Close_bollinger15',
       'LME_Co_Close_bollinger20', 'LME_Co_Close_bollinger30',
       'LME_Co_Close_bollinger65', 'LME_Co_Close_Mom5', 'LME_Co_Close_Mom10',
       'LME_Co_Close_Mom15', 'LME_Co_Close_Mom26', 'LME_Co_Close_Mom40',
       'LME_Co_Close_Mom65', 'LME_Co_Close_Mom125', 'LME_Co_Close_PPO12',
       'LME_Co_Close_PPO22', 'LME_Co_Close_RSI14', 'LME_Co_Close_RSI26',
       'LME_Co_Close_RSI40', 'LME_Co_Close_RSI54', 'LME_Co_Close_RSI125',
       'LME_Co_PVT', 'LME_Co_divPVT', 'LME_Co_NATR14', 'LME_Co_NATR26',
       'LME_Co_NATR65', 'LME_Co_NATR125', 'LME_Co_CCI12', 'LME_Co_CCI26',
       'LME_Co_CCI40', 'LME_Co_CCI65', 'LME_Co_CCI125', 'LME_Co_VBM12',
       'LME_Co_VBM22', 'LME_Co_ADX14', 'LME_Co_ADX26', 'LME_Co_ADX40',
       'LME_Co_ADX54', 'LME_Co_ADX125', 'LME_Co_SAR'],
      dtype='object')
LME_Al_Spot
Before Load Data
['2009-07-01', '2014-07-01', '2015-01-01']
0.030556578378780296
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Al_Spot']
#####################remove_unused_columns_v4#####################
target LME_Al
Index(['LME_Al_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low',
       'LME_Al_Close', 'LME_Al_Spot_EMA12', 'LME_Al_Spot_WMA12',
       'LME_Al_Spot_EMA26', 'LME_Al_Spot_WMA26', 'LME_Al_Spot_EMA40',
       'LME_Al_Spot_WMA40', 'LME_Al_Spot_EMA65', 'LME_Al_Spot_WMA65',
       'LME_Al_Spot_EMA125', 'LME_Al_Spot_WMA125', 'LME_Al_Spot_bollinger5',
       'LME_Al_Spot_bollinger10', 'LME_Al_Spot_bollinger15',
       'LME_Al_Spot_bollinger20', 'LME_Al_Spot_bollinger30',
       'LME_Al_Spot_bollinger65', 'LME_Al_Spot_Mom5', 'LME_Al_Spot_Mom10',
       'LME_Al_Spot_Mom15', 'LME_Al_Spot_Mom26', 'LME_Al_Spot_Mom40',
       'LME_Al_Spot_Mom65', 'LME_Al_Spot_Mom125', 'LME_Al_Spot_PPO12',
       'LME_Al_Spot_PPO22', 'LME_Al_Spot_RSI14', 'LME_Al_Spot_RSI26',
       'LME_Al_Spot_RSI40', 'LME_Al_Spot_RSI54', 'LME_Al_Spot_RSI125',
       'LME_Al_Close_EMA12', 'LME_Al_Close_WMA12', 'LME_Al_Close_EMA26',
       'LME_Al_Close_WMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_WMA40',
       'LME_Al_Close_EMA65', 'LME_Al_Close_WMA65', 'LME_Al_Close_EMA125',
       'LME_Al_Close_WMA125', 'LME_Al_Close_bollinger5',
       'LME_Al_Close_bollinger10', 'LME_Al_Close_bollinger15',
       'LME_Al_Close_bollinger20', 'LME_Al_Close_bollinger30',
       'LME_Al_Close_bollinger65', 'LME_Al_Close_Mom5', 'LME_Al_Close_Mom10',
       'LME_Al_Close_Mom15', 'LME_Al_Close_Mom26', 'LME_Al_Close_Mom40',
       'LME_Al_Close_Mom65', 'LME_Al_Close_Mom125', 'LME_Al_Close_PPO12',
       'LME_Al_Close_PPO22', 'LME_Al_Close_RSI14', 'LME_Al_Close_RSI26',
       'LME_Al_Close_RSI40', 'LME_Al_Close_RSI54', 'LME_Al_Close_RSI125',
       'LME_Al_PVT', 'LME_Al_divPVT', 'LME_Al_NATR14', 'LME_Al_NATR26',
       'LME_Al_NATR65', 'LME_Al_NATR125', 'LME_Al_CCI12', 'LME_Al_CCI26',
       'LME_Al_CCI40', 'LME_Al_CCI65', 'LME_Al_CCI125', 'LME_Al_VBM12',
       'LME_Al_VBM22', 'LME_Al_ADX14', 'LME_Al_ADX26', 'LME_Al_ADX40',
       'LME_Al_ADX54', 'LME_Al_ADX125', 'LME_Al_SAR'],
      dtype='object')
LME_Le_Spot
Before Load Data
['2009-07-01', '2014-07-01', '2015-01-01']
0.04411824347075447
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Le_Spot']
#####################remove_unused_columns_v4#####################
target LME_Le
Index(['LME_Le_Spot', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low',
       'LME_Le_Close', 'LME_Le_Spot_EMA12', 'LME_Le_Spot_WMA12',
       'LME_Le_Spot_EMA26', 'LME_Le_Spot_WMA26', 'LME_Le_Spot_EMA40',
       'LME_Le_Spot_WMA40', 'LME_Le_Spot_EMA65', 'LME_Le_Spot_WMA65',
       'LME_Le_Spot_EMA125', 'LME_Le_Spot_WMA125', 'LME_Le_Spot_bollinger5',
       'LME_Le_Spot_bollinger10', 'LME_Le_Spot_bollinger15',
       'LME_Le_Spot_bollinger20', 'LME_Le_Spot_bollinger30',
       'LME_Le_Spot_bollinger65', 'LME_Le_Spot_Mom5', 'LME_Le_Spot_Mom10',
       'LME_Le_Spot_Mom15', 'LME_Le_Spot_Mom26', 'LME_Le_Spot_Mom40',
       'LME_Le_Spot_Mom65', 'LME_Le_Spot_Mom125', 'LME_Le_Spot_PPO12',
       'LME_Le_Spot_PPO22', 'LME_Le_Spot_RSI14', 'LME_Le_Spot_RSI26',
       'LME_Le_Spot_RSI40', 'LME_Le_Spot_RSI54', 'LME_Le_Spot_RSI125',
       'LME_Le_Close_EMA12', 'LME_Le_Close_WMA12', 'LME_Le_Close_EMA26',
       'LME_Le_Close_WMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_WMA40',
       'LME_Le_Close_EMA65', 'LME_Le_Close_WMA65', 'LME_Le_Close_EMA125',
       'LME_Le_Close_WMA125', 'LME_Le_Close_bollinger5',
       'LME_Le_Close_bollinger10', 'LME_Le_Close_bollinger15',
       'LME_Le_Close_bollinger20', 'LME_Le_Close_bollinger30',
       'LME_Le_Close_bollinger65', 'LME_Le_Close_Mom5', 'LME_Le_Close_Mom10',
       'LME_Le_Close_Mom15', 'LME_Le_Close_Mom26', 'LME_Le_Close_Mom40',
       'LME_Le_Close_Mom65', 'LME_Le_Close_Mom125', 'LME_Le_Close_PPO12',
       'LME_Le_Close_PPO22', 'LME_Le_Close_RSI14', 'LME_Le_Close_RSI26',
       'LME_Le_Close_RSI40', 'LME_Le_Close_RSI54', 'LME_Le_Close_RSI125',
       'LME_Le_PVT', 'LME_Le_divPVT', 'LME_Le_NATR14', 'LME_Le_NATR26',
       'LME_Le_NATR65', 'LME_Le_NATR125', 'LME_Le_CCI12', 'LME_Le_CCI26',
       'LME_Le_CCI40', 'LME_Le_CCI65', 'LME_Le_CCI125', 'LME_Le_VBM12',
       'LME_Le_VBM22', 'LME_Le_ADX14', 'LME_Le_ADX26', 'LME_Le_ADX40',
       'LME_Le_ADX54', 'LME_Le_ADX125', 'LME_Le_SAR'],
      dtype='object')
LME_Ni_Spot
Before Load Data
['2009-07-01', '2014-07-01', '2015-01-01']
0.043506354562139325
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Ni_Spot']
#####################remove_unused_columns_v4#####################
target LME_Ni
Index(['LME_Ni_Spot', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low',
       'LME_Ni_Close', 'LME_Ni_Spot_EMA12', 'LME_Ni_Spot_WMA12',
       'LME_Ni_Spot_EMA26', 'LME_Ni_Spot_WMA26', 'LME_Ni_Spot_EMA40',
       'LME_Ni_Spot_WMA40', 'LME_Ni_Spot_EMA65', 'LME_Ni_Spot_WMA65',
       'LME_Ni_Spot_EMA125', 'LME_Ni_Spot_WMA125', 'LME_Ni_Spot_bollinger5',
       'LME_Ni_Spot_bollinger10', 'LME_Ni_Spot_bollinger15',
       'LME_Ni_Spot_bollinger20', 'LME_Ni_Spot_bollinger30',
       'LME_Ni_Spot_bollinger65', 'LME_Ni_Spot_Mom5', 'LME_Ni_Spot_Mom10',
       'LME_Ni_Spot_Mom15', 'LME_Ni_Spot_Mom26', 'LME_Ni_Spot_Mom40',
       'LME_Ni_Spot_Mom65', 'LME_Ni_Spot_Mom125', 'LME_Ni_Spot_PPO12',
       'LME_Ni_Spot_PPO22', 'LME_Ni_Spot_RSI14', 'LME_Ni_Spot_RSI26',
       'LME_Ni_Spot_RSI40', 'LME_Ni_Spot_RSI54', 'LME_Ni_Spot_RSI125',
       'LME_Ni_Close_EMA12', 'LME_Ni_Close_WMA12', 'LME_Ni_Close_EMA26',
       'LME_Ni_Close_WMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_WMA40',
       'LME_Ni_Close_EMA65', 'LME_Ni_Close_WMA65', 'LME_Ni_Close_EMA125',
       'LME_Ni_Close_WMA125', 'LME_Ni_Close_bollinger5',
       'LME_Ni_Close_bollinger10', 'LME_Ni_Close_bollinger15',
       'LME_Ni_Close_bollinger20', 'LME_Ni_Close_bollinger30',
       'LME_Ni_Close_bollinger65', 'LME_Ni_Close_Mom5', 'LME_Ni_Close_Mom10',
       'LME_Ni_Close_Mom15', 'LME_Ni_Close_Mom26', 'LME_Ni_Close_Mom40',
       'LME_Ni_Close_Mom65', 'LME_Ni_Close_Mom125', 'LME_Ni_Close_PPO12',
       'LME_Ni_Close_PPO22', 'LME_Ni_Close_RSI14', 'LME_Ni_Close_RSI26',
       'LME_Ni_Close_RSI40', 'LME_Ni_Close_RSI54', 'LME_Ni_Close_RSI125',
       'LME_Ni_PVT', 'LME_Ni_divPVT', 'LME_Ni_NATR14', 'LME_Ni_NATR26',
       'LME_Ni_NATR65', 'LME_Ni_NATR125', 'LME_Ni_CCI12', 'LME_Ni_CCI26',
       'LME_Ni_CCI40', 'LME_Ni_CCI65', 'LME_Ni_CCI125', 'LME_Ni_VBM12',
       'LME_Ni_VBM22', 'LME_Ni_ADX14', 'LME_Ni_ADX26', 'LME_Ni_ADX40',
       'LME_Ni_ADX54', 'LME_Ni_ADX125', 'LME_Ni_SAR'],
      dtype='object')
LME_Zi_Spot
Before Load Data
['2009-07-01', '2014-07-01', '2015-01-01']
0.03910240629197017
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Zi_Spot']
#####################remove_unused_columns_v4#####################
target LME_Zi
Index(['LME_Zi_Spot', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low',
       'LME_Zi_Close', 'LME_Zi_Spot_EMA12', 'LME_Zi_Spot_WMA12',
       'LME_Zi_Spot_EMA26', 'LME_Zi_Spot_WMA26', 'LME_Zi_Spot_EMA40',
       'LME_Zi_Spot_WMA40', 'LME_Zi_Spot_EMA65', 'LME_Zi_Spot_WMA65',
       'LME_Zi_Spot_EMA125', 'LME_Zi_Spot_WMA125', 'LME_Zi_Spot_bollinger5',
       'LME_Zi_Spot_bollinger10', 'LME_Zi_Spot_bollinger15',
       'LME_Zi_Spot_bollinger20', 'LME_Zi_Spot_bollinger30',
       'LME_Zi_Spot_bollinger65', 'LME_Zi_Spot_Mom5', 'LME_Zi_Spot_Mom10',
       'LME_Zi_Spot_Mom15', 'LME_Zi_Spot_Mom26', 'LME_Zi_Spot_Mom40',
       'LME_Zi_Spot_Mom65', 'LME_Zi_Spot_Mom125', 'LME_Zi_Spot_PPO12',
       'LME_Zi_Spot_PPO22', 'LME_Zi_Spot_RSI14', 'LME_Zi_Spot_RSI26',
       'LME_Zi_Spot_RSI40', 'LME_Zi_Spot_RSI54', 'LME_Zi_Spot_RSI125',
       'LME_Zi_Close_EMA12', 'LME_Zi_Close_WMA12', 'LME_Zi_Close_EMA26',
       'LME_Zi_Close_WMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_WMA40',
       'LME_Zi_Close_EMA65', 'LME_Zi_Close_WMA65', 'LME_Zi_Close_EMA125',
       'LME_Zi_Close_WMA125', 'LME_Zi_Close_bollinger5',
       'LME_Zi_Close_bollinger10', 'LME_Zi_Close_bollinger15',
       'LME_Zi_Close_bollinger20', 'LME_Zi_Close_bollinger30',
       'LME_Zi_Close_bollinger65', 'LME_Zi_Close_Mom5', 'LME_Zi_Close_Mom10',
       'LME_Zi_Close_Mom15', 'LME_Zi_Close_Mom26', 'LME_Zi_Close_Mom40',
       'LME_Zi_Close_Mom65', 'LME_Zi_Close_Mom125', 'LME_Zi_Close_PPO12',
       'LME_Zi_Close_PPO22', 'LME_Zi_Close_RSI14', 'LME_Zi_Close_RSI26',
       'LME_Zi_Close_RSI40', 'LME_Zi_Close_RSI54', 'LME_Zi_Close_RSI125',
       'LME_Zi_PVT', 'LME_Zi_divPVT', 'LME_Zi_NATR14', 'LME_Zi_NATR26',
       'LME_Zi_NATR65', 'LME_Zi_NATR125', 'LME_Zi_CCI12', 'LME_Zi_CCI26',
       'LME_Zi_CCI40', 'LME_Zi_CCI65', 'LME_Zi_CCI125', 'LME_Zi_VBM12',
       'LME_Zi_VBM22', 'LME_Zi_ADX14', 'LME_Zi_ADX26', 'LME_Zi_ADX40',
       'LME_Zi_ADX54', 'LME_Zi_ADX125', 'LME_Zi_SAR'],
      dtype='object')
LME_Ti_Spot
Before Load Data
['2009-07-01', '2014-07-01', '2015-01-01']
0.03826147452634649
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Ti_Spot']
#####################remove_unused_columns_v4#####################
target LME_Ti
Index(['LME_Ti_Spot', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low',
       'LME_Ti_Close', 'LME_Ti_Spot_EMA12', 'LME_Ti_Spot_WMA12',
       'LME_Ti_Spot_EMA26', 'LME_Ti_Spot_WMA26', 'LME_Ti_Spot_EMA40',
       'LME_Ti_Spot_WMA40', 'LME_Ti_Spot_EMA65', 'LME_Ti_Spot_WMA65',
       'LME_Ti_Spot_EMA125', 'LME_Ti_Spot_WMA125', 'LME_Ti_Spot_bollinger5',
       'LME_Ti_Spot_bollinger10', 'LME_Ti_Spot_bollinger15',
       'LME_Ti_Spot_bollinger20', 'LME_Ti_Spot_bollinger30',
       'LME_Ti_Spot_bollinger65', 'LME_Ti_Spot_Mom5', 'LME_Ti_Spot_Mom10',
       'LME_Ti_Spot_Mom15', 'LME_Ti_Spot_Mom26', 'LME_Ti_Spot_Mom40',
       'LME_Ti_Spot_Mom65', 'LME_Ti_Spot_Mom125', 'LME_Ti_Spot_PPO12',
       'LME_Ti_Spot_PPO22', 'LME_Ti_Spot_RSI14', 'LME_Ti_Spot_RSI26',
       'LME_Ti_Spot_RSI40', 'LME_Ti_Spot_RSI54', 'LME_Ti_Spot_RSI125',
       'LME_Ti_Close_EMA12', 'LME_Ti_Close_WMA12', 'LME_Ti_Close_EMA26',
       'LME_Ti_Close_WMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_WMA40',
       'LME_Ti_Close_EMA65', 'LME_Ti_Close_WMA65', 'LME_Ti_Close_EMA125',
       'LME_Ti_Close_WMA125', 'LME_Ti_Close_bollinger5',
       'LME_Ti_Close_bollinger10', 'LME_Ti_Close_bollinger15',
       'LME_Ti_Close_bollinger20', 'LME_Ti_Close_bollinger30',
       'LME_Ti_Close_bollinger65', 'LME_Ti_Close_Mom5', 'LME_Ti_Close_Mom10',
       'LME_Ti_Close_Mom15', 'LME_Ti_Close_Mom26', 'LME_Ti_Close_Mom40',
       'LME_Ti_Close_Mom65', 'LME_Ti_Close_Mom125', 'LME_Ti_Close_PPO12',
       'LME_Ti_Close_PPO22', 'LME_Ti_Close_RSI14', 'LME_Ti_Close_RSI26',
       'LME_Ti_Close_RSI40', 'LME_Ti_Close_RSI54', 'LME_Ti_Close_RSI125',
       'LME_Ti_PVT', 'LME_Ti_divPVT', 'LME_Ti_NATR14', 'LME_Ti_NATR26',
       'LME_Ti_NATR65', 'LME_Ti_NATR125', 'LME_Ti_CCI12', 'LME_Ti_CCI26',
       'LME_Ti_CCI40', 'LME_Ti_CCI65', 'LME_Ti_CCI125', 'LME_Ti_VBM12',
       'LME_Ti_VBM22', 'LME_Ti_ADX14', 'LME_Ti_ADX26', 'LME_Ti_ADX40',
       'LME_Ti_ADX54', 'LME_Ti_ADX125', 'LME_Ti_SAR'],
      dtype='object')
Dataset statistic: #examples
Train: 5460 5460 5460
9.368199 -8.55829 2.1396859 -1.7377949
Validation: 612 612 612
Testing: 774 774 774
pre-processing time: 7.390975952148438e-05
the split date is 2014-07-01
net initializing with time: 0.024993181228637695
preparing training and testing date with time: 0.0028781890869140625
current epoch: 1
train loss is 0.259796
average val loss: 0.096961, accuracy: 0.5065
average test loss: 0.098308, accuracy: 0.4987
case acc: 0.3643410852713178
case acc: 0.4108527131782946
case acc: 0.4418604651162791
case acc: 0.6356589147286822
case acc: 0.5348837209302325
case acc: 0.6046511627906976
top acc: 0.8605 ::: bot acc: 0.0698
top acc: 0.3953 ::: bot acc: 0.4186
top acc: 0.5814 ::: bot acc: 0.2558
top acc: 0.2093 ::: bot acc: 0.9535
top acc: 0.4186 ::: bot acc: 0.6279
top acc: 0.0000 ::: bot acc: 1.0000
current epoch: 2
train loss is 0.146689
average val loss: 0.075681, accuracy: 0.5196
average test loss: 0.079197, accuracy: 0.4858
case acc: 0.32558139534883723
case acc: 0.3798449612403101
case acc: 0.4263565891472868
case acc: 0.6434108527131783
case acc: 0.5426356589147286
case acc: 0.5968992248062015
top acc: 0.9767 ::: bot acc: 0.0000
top acc: 0.8140 ::: bot acc: 0.0233
top acc: 0.9535 ::: bot acc: 0.0465
top acc: 0.1395 ::: bot acc: 0.9535
top acc: 0.6977 ::: bot acc: 0.3256
top acc: 0.0000 ::: bot acc: 1.0000
current epoch: 3
train loss is 0.126283
average val loss: 0.069985, accuracy: 0.5392
average test loss: 0.080344, accuracy: 0.4884
case acc: 0.32558139534883723
case acc: 0.4418604651162791
case acc: 0.3953488372093023
case acc: 0.6201550387596899
case acc: 0.5581395348837209
case acc: 0.5891472868217055
top acc: 0.9767 ::: bot acc: 0.0000
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.3953 ::: bot acc: 0.7442
top acc: 0.7907 ::: bot acc: 0.2558
top acc: 0.0000 ::: bot acc: 1.0000
current epoch: 4
train loss is 0.127985
average val loss: 0.070432, accuracy: 0.5082
average test loss: 0.067570, accuracy: 0.4806
case acc: 0.32558139534883723
case acc: 0.4186046511627907
case acc: 0.4108527131782946
case acc: 0.6201550387596899
case acc: 0.5193798449612403
case acc: 0.5891472868217055
top acc: 0.9535 ::: bot acc: 0.0233
top acc: 0.9302 ::: bot acc: 0.0000
top acc: 0.9767 ::: bot acc: 0.0465
top acc: 0.0698 ::: bot acc: 0.9070
top acc: 0.6279 ::: bot acc: 0.4419
top acc: 0.0000 ::: bot acc: 1.0000
current epoch: 5
train loss is 0.120808
average val loss: 0.070867, accuracy: 0.5147
average test loss: 0.064375, accuracy: 0.4755
case acc: 0.3333333333333333
case acc: 0.40310077519379844
case acc: 0.4263565891472868
case acc: 0.6124031007751938
case acc: 0.4883720930232558
case acc: 0.5891472868217055
top acc: 0.9535 ::: bot acc: 0.0233
top acc: 0.8837 ::: bot acc: 0.0000
top acc: 0.8837 ::: bot acc: 0.0930
top acc: 0.0233 ::: bot acc: 0.9302
top acc: 0.4186 ::: bot acc: 0.5814
top acc: 0.0000 ::: bot acc: 1.0000
current epoch: 6
train loss is 0.116386
average val loss: 0.067669, accuracy: 0.5131
average test loss: 0.064229, accuracy: 0.4780
case acc: 0.32558139534883723
case acc: 0.4186046511627907
case acc: 0.4186046511627907
case acc: 0.6201550387596899
case acc: 0.49612403100775193
case acc: 0.5891472868217055
top acc: 0.9535 ::: bot acc: 0.0233
top acc: 0.9302 ::: bot acc: 0.0000
top acc: 1.0000 ::: bot acc: 0.0233
top acc: 0.1163 ::: bot acc: 0.8837
top acc: 0.3953 ::: bot acc: 0.6279
top acc: 0.0000 ::: bot acc: 1.0000
current epoch: 7
train loss is 0.115440
average val loss: 0.067186, accuracy: 0.5163
average test loss: 0.062510, accuracy: 0.4832
case acc: 0.3333333333333333
case acc: 0.40310077519379844
case acc: 0.4263565891472868
case acc: 0.6356589147286822
case acc: 0.5116279069767442
case acc: 0.5891472868217055
top acc: 0.9302 ::: bot acc: 0.0233
top acc: 0.8837 ::: bot acc: 0.0000
top acc: 1.0000 ::: bot acc: 0.0698
top acc: 0.1395 ::: bot acc: 0.9070
top acc: 0.3488 ::: bot acc: 0.7442
top acc: 0.0000 ::: bot acc: 1.0000
current epoch: 8
train loss is 0.112305
average val loss: 0.066737, accuracy: 0.5196
average test loss: 0.061323, accuracy: 0.4819
case acc: 0.3333333333333333
case acc: 0.3953488372093023
case acc: 0.4186046511627907
case acc: 0.6356589147286822
case acc: 0.5193798449612403
case acc: 0.5891472868217055
top acc: 0.8837 ::: bot acc: 0.0465
top acc: 0.8837 ::: bot acc: 0.0000
top acc: 0.8605 ::: bot acc: 0.1395
top acc: 0.1628 ::: bot acc: 0.8837
top acc: 0.2791 ::: bot acc: 0.8372
top acc: 0.0000 ::: bot acc: 1.0000
current epoch: 9
train loss is 0.109324
average val loss: 0.065337, accuracy: 0.5196
average test loss: 0.060854, accuracy: 0.4897
case acc: 0.34108527131782945
case acc: 0.3953488372093023
case acc: 0.4418604651162791
case acc: 0.6666666666666666
case acc: 0.5038759689922481
case acc: 0.5891472868217055
top acc: 0.8837 ::: bot acc: 0.0698
top acc: 0.8837 ::: bot acc: 0.0000
top acc: 0.8605 ::: bot acc: 0.1395
top acc: 0.2558 ::: bot acc: 0.8837
top acc: 0.2558 ::: bot acc: 0.8372
top acc: 0.0000 ::: bot acc: 1.0000
current epoch: 10
train loss is 0.108655
average val loss: 0.065622, accuracy: 0.5147
average test loss: 0.059771, accuracy: 0.4961
case acc: 0.3333333333333333
case acc: 0.3953488372093023
case acc: 0.46511627906976744
case acc: 0.6589147286821705
case acc: 0.5348837209302325
case acc: 0.5891472868217055
top acc: 0.8372 ::: bot acc: 0.0698
top acc: 0.8837 ::: bot acc: 0.0233
top acc: 0.7907 ::: bot acc: 0.2093
top acc: 0.2326 ::: bot acc: 0.8837
top acc: 0.2326 ::: bot acc: 0.9302
top acc: 0.0000 ::: bot acc: 1.0000
current epoch: 11
train loss is 0.107042
average val loss: 0.064629, accuracy: 0.5196
average test loss: 0.059217, accuracy: 0.4961
case acc: 0.35658914728682173
case acc: 0.40310077519379844
case acc: 0.4573643410852713
case acc: 0.6589147286821705
case acc: 0.5116279069767442
case acc: 0.5891472868217055
top acc: 0.8372 ::: bot acc: 0.0930
top acc: 0.9070 ::: bot acc: 0.0233
top acc: 0.7442 ::: bot acc: 0.2326
top acc: 0.2558 ::: bot acc: 0.8837
top acc: 0.2093 ::: bot acc: 0.8837
top acc: 0.0000 ::: bot acc: 1.0000
current epoch: 12
train loss is 0.105060
average val loss: 0.063856, accuracy: 0.5180
average test loss: 0.058687, accuracy: 0.5026
case acc: 0.35658914728682173
case acc: 0.4108527131782946
case acc: 0.46511627906976744
case acc: 0.6744186046511628
case acc: 0.5193798449612403
case acc: 0.5891472868217055
top acc: 0.8140 ::: bot acc: 0.1163
top acc: 0.9070 ::: bot acc: 0.0465
top acc: 0.6977 ::: bot acc: 0.2558
top acc: 0.3256 ::: bot acc: 0.8837
top acc: 0.2093 ::: bot acc: 0.8837
top acc: 0.0000 ::: bot acc: 1.0000
current epoch: 13
train loss is 0.103137
average val loss: 0.063798, accuracy: 0.5245
average test loss: 0.058166, accuracy: 0.5090
case acc: 0.37209302325581395
case acc: 0.4186046511627907
case acc: 0.4573643410852713
case acc: 0.6821705426356589
case acc: 0.5348837209302325
case acc: 0.5891472868217055
top acc: 0.7907 ::: bot acc: 0.1860
top acc: 0.9070 ::: bot acc: 0.0698
top acc: 0.6744 ::: bot acc: 0.2558
top acc: 0.3488 ::: bot acc: 0.8837
top acc: 0.2093 ::: bot acc: 0.9070
top acc: 0.0000 ::: bot acc: 1.0000
current epoch: 14
train loss is 0.102347
average val loss: 0.063474, accuracy: 0.5261
average test loss: 0.057830, accuracy: 0.5207
case acc: 0.3875968992248062
case acc: 0.4418604651162791
case acc: 0.4883720930232558
case acc: 0.6821705426356589
case acc: 0.5348837209302325
case acc: 0.5891472868217055
top acc: 0.7674 ::: bot acc: 0.2326
top acc: 0.9070 ::: bot acc: 0.1163
top acc: 0.6512 ::: bot acc: 0.3721
top acc: 0.3256 ::: bot acc: 0.8837
top acc: 0.1860 ::: bot acc: 0.9070
top acc: 0.0000 ::: bot acc: 1.0000
current epoch: 15
train loss is 0.099974
average val loss: 0.062436, accuracy: 0.5327
average test loss: 0.057844, accuracy: 0.5233
case acc: 0.3643410852713178
case acc: 0.4496124031007752
case acc: 0.4883720930232558
case acc: 0.7054263565891473
case acc: 0.5271317829457365
case acc: 0.6046511627906976
top acc: 0.7442 ::: bot acc: 0.1860
top acc: 0.8837 ::: bot acc: 0.1395
top acc: 0.6047 ::: bot acc: 0.3721
top acc: 0.4186 ::: bot acc: 0.8605
top acc: 0.1860 ::: bot acc: 0.9302
top acc: 0.0465 ::: bot acc: 1.0000
current epoch: 16
train loss is 0.099556
average val loss: 0.062327, accuracy: 0.5261
average test loss: 0.057634, accuracy: 0.5284
case acc: 0.3798449612403101
case acc: 0.46511627906976744
case acc: 0.5116279069767442
case acc: 0.6976744186046512
case acc: 0.5116279069767442
case acc: 0.6046511627906976
top acc: 0.7442 ::: bot acc: 0.2093
top acc: 0.8837 ::: bot acc: 0.1860
top acc: 0.5581 ::: bot acc: 0.3953
top acc: 0.3953 ::: bot acc: 0.8605
top acc: 0.1860 ::: bot acc: 0.9302
top acc: 0.0465 ::: bot acc: 1.0000
current epoch: 17
train loss is 0.098534
average val loss: 0.061548, accuracy: 0.5261
average test loss: 0.057440, accuracy: 0.5336
case acc: 0.3798449612403101
case acc: 0.46511627906976744
case acc: 0.5271317829457365
case acc: 0.7054263565891473
case acc: 0.5116279069767442
case acc: 0.6124031007751938
top acc: 0.7442 ::: bot acc: 0.1860
top acc: 0.8837 ::: bot acc: 0.1860
top acc: 0.5349 ::: bot acc: 0.4651
top acc: 0.4186 ::: bot acc: 0.8605
top acc: 0.1628 ::: bot acc: 0.9535
top acc: 0.0698 ::: bot acc: 1.0000
current epoch: 18
train loss is 0.097226
average val loss: 0.060951, accuracy: 0.5245
average test loss: 0.057253, accuracy: 0.5362
case acc: 0.3875968992248062
case acc: 0.46511627906976744
case acc: 0.5271317829457365
case acc: 0.7131782945736435
case acc: 0.5038759689922481
case acc: 0.6201550387596899
top acc: 0.7442 ::: bot acc: 0.2093
top acc: 0.8837 ::: bot acc: 0.1860
top acc: 0.4884 ::: bot acc: 0.5116
top acc: 0.4419 ::: bot acc: 0.8372
top acc: 0.1395 ::: bot acc: 0.9535
top acc: 0.0930 ::: bot acc: 1.0000
current epoch: 19
train loss is 0.095770
average val loss: 0.060624, accuracy: 0.5294
average test loss: 0.057049, accuracy: 0.5413
case acc: 0.3875968992248062
case acc: 0.4806201550387597
case acc: 0.5426356589147286
case acc: 0.7131782945736435
case acc: 0.5038759689922481
case acc: 0.6201550387596899
top acc: 0.7442 ::: bot acc: 0.2093
top acc: 0.8837 ::: bot acc: 0.1860
top acc: 0.4884 ::: bot acc: 0.5349
top acc: 0.4651 ::: bot acc: 0.8372
top acc: 0.1628 ::: bot acc: 0.9535
top acc: 0.0930 ::: bot acc: 1.0000
current epoch: 20
train loss is 0.094393
average val loss: 0.059993, accuracy: 0.5294
average test loss: 0.056909, accuracy: 0.5362
case acc: 0.37209302325581395
case acc: 0.4806201550387597
case acc: 0.5271317829457365
case acc: 0.6976744186046512
case acc: 0.5116279069767442
case acc: 0.627906976744186
top acc: 0.7209 ::: bot acc: 0.1860
top acc: 0.8605 ::: bot acc: 0.1860
top acc: 0.4651 ::: bot acc: 0.5116
top acc: 0.4651 ::: bot acc: 0.8140
top acc: 0.1628 ::: bot acc: 0.9535
top acc: 0.1163 ::: bot acc: 1.0000
current epoch: 21
train loss is 0.093215
average val loss: 0.059747, accuracy: 0.5310
average test loss: 0.056794, accuracy: 0.5388
case acc: 0.37209302325581395
case acc: 0.5038759689922481
case acc: 0.5193798449612403
case acc: 0.6821705426356589
case acc: 0.5193798449612403
case acc: 0.6356589147286822
top acc: 0.6977 ::: bot acc: 0.1860
top acc: 0.8372 ::: bot acc: 0.1860
top acc: 0.4419 ::: bot acc: 0.5349
top acc: 0.4651 ::: bot acc: 0.7907
top acc: 0.1628 ::: bot acc: 0.9535
top acc: 0.1395 ::: bot acc: 1.0000
current epoch: 22
train loss is 0.093208
average val loss: 0.059293, accuracy: 0.5359
average test loss: 0.056769, accuracy: 0.5413
case acc: 0.37209302325581395
case acc: 0.5038759689922481
case acc: 0.5348837209302325
case acc: 0.6744186046511628
case acc: 0.5193798449612403
case acc: 0.6434108527131783
top acc: 0.6977 ::: bot acc: 0.1860
top acc: 0.8372 ::: bot acc: 0.1860
top acc: 0.4419 ::: bot acc: 0.5814
top acc: 0.4884 ::: bot acc: 0.7674
top acc: 0.1628 ::: bot acc: 0.9535
top acc: 0.1628 ::: bot acc: 1.0000
current epoch: 23
train loss is 0.091964
average val loss: 0.058322, accuracy: 0.5425
average test loss: 0.056818, accuracy: 0.5388
case acc: 0.3643410852713178
case acc: 0.5038759689922481
case acc: 0.5426356589147286
case acc: 0.6511627906976745
case acc: 0.5193798449612403
case acc: 0.6511627906976745
top acc: 0.6744 ::: bot acc: 0.1860
top acc: 0.8372 ::: bot acc: 0.1860
top acc: 0.4419 ::: bot acc: 0.5814
top acc: 0.4884 ::: bot acc: 0.7674
top acc: 0.1628 ::: bot acc: 0.9535
top acc: 0.1628 ::: bot acc: 1.0000
current epoch: 24
train loss is 0.091344
average val loss: 0.058200, accuracy: 0.5408
average test loss: 0.056905, accuracy: 0.5413
case acc: 0.3643410852713178
case acc: 0.49612403100775193
case acc: 0.5426356589147286
case acc: 0.6589147286821705
case acc: 0.5193798449612403
case acc: 0.6666666666666666
top acc: 0.6279 ::: bot acc: 0.2093
top acc: 0.7674 ::: bot acc: 0.1860
top acc: 0.4419 ::: bot acc: 0.5814
top acc: 0.5116 ::: bot acc: 0.7674
top acc: 0.1628 ::: bot acc: 0.9535
top acc: 0.2093 ::: bot acc: 1.0000
current epoch: 25
train loss is 0.090344
average val loss: 0.057475, accuracy: 0.5474
average test loss: 0.056743, accuracy: 0.5401
case acc: 0.37209302325581395
case acc: 0.49612403100775193
case acc: 0.5503875968992248
case acc: 0.6434108527131783
case acc: 0.5193798449612403
case acc: 0.6589147286821705
top acc: 0.6279 ::: bot acc: 0.2093
top acc: 0.8372 ::: bot acc: 0.1860
top acc: 0.4419 ::: bot acc: 0.5814
top acc: 0.5116 ::: bot acc: 0.7209
top acc: 0.1628 ::: bot acc: 0.9535
top acc: 0.2326 ::: bot acc: 1.0000
current epoch: 26
train loss is 0.088508
average val loss: 0.057739, accuracy: 0.5343
average test loss: 0.056824, accuracy: 0.5375
case acc: 0.37209302325581395
case acc: 0.4728682170542636
case acc: 0.5426356589147286
case acc: 0.6434108527131783
case acc: 0.5193798449612403
case acc: 0.6744186046511628
top acc: 0.6279 ::: bot acc: 0.2093
top acc: 0.7674 ::: bot acc: 0.1860
top acc: 0.4419 ::: bot acc: 0.5814
top acc: 0.5116 ::: bot acc: 0.7209
top acc: 0.1628 ::: bot acc: 0.9535
top acc: 0.2791 ::: bot acc: 1.0000
current epoch: 27
train loss is 0.088558
average val loss: 0.058014, accuracy: 0.5343
average test loss: 0.057122, accuracy: 0.5375
case acc: 0.3875968992248062
case acc: 0.46511627906976744
case acc: 0.5348837209302325
case acc: 0.6434108527131783
case acc: 0.5193798449612403
case acc: 0.6744186046511628
top acc: 0.6512 ::: bot acc: 0.2558
top acc: 0.6977 ::: bot acc: 0.1860
top acc: 0.4186 ::: bot acc: 0.5814
top acc: 0.5116 ::: bot acc: 0.7209
top acc: 0.1628 ::: bot acc: 0.9535
top acc: 0.3023 ::: bot acc: 0.9767
current epoch: 28
train loss is 0.087826
average val loss: 0.056987, accuracy: 0.5343
average test loss: 0.057220, accuracy: 0.5375
case acc: 0.3875968992248062
case acc: 0.4728682170542636
case acc: 0.5426356589147286
case acc: 0.6201550387596899
case acc: 0.5193798449612403
case acc: 0.6821705426356589
top acc: 0.6744 ::: bot acc: 0.2558
top acc: 0.7209 ::: bot acc: 0.1860
top acc: 0.4419 ::: bot acc: 0.5814
top acc: 0.5116 ::: bot acc: 0.7209
top acc: 0.1628 ::: bot acc: 0.9535
top acc: 0.3023 ::: bot acc: 0.9767
current epoch: 29
train loss is 0.087426
average val loss: 0.056735, accuracy: 0.5376
average test loss: 0.057337, accuracy: 0.5323
case acc: 0.3953488372093023
case acc: 0.46511627906976744
case acc: 0.5271317829457365
case acc: 0.6124031007751938
case acc: 0.5116279069767442
case acc: 0.6821705426356589
top acc: 0.6744 ::: bot acc: 0.2791
top acc: 0.6512 ::: bot acc: 0.2093
top acc: 0.3953 ::: bot acc: 0.5814
top acc: 0.5116 ::: bot acc: 0.6744
top acc: 0.1628 ::: bot acc: 0.9535
top acc: 0.3256 ::: bot acc: 0.9767
current epoch: 30
train loss is 0.085479
average val loss: 0.057249, accuracy: 0.5392
average test loss: 0.057060, accuracy: 0.5310
case acc: 0.40310077519379844
case acc: 0.46511627906976744
case acc: 0.5116279069767442
case acc: 0.6124031007751938
case acc: 0.5116279069767442
case acc: 0.6821705426356589
top acc: 0.6512 ::: bot acc: 0.2791
top acc: 0.6512 ::: bot acc: 0.2326
top acc: 0.3488 ::: bot acc: 0.6047
top acc: 0.5116 ::: bot acc: 0.6744
top acc: 0.1628 ::: bot acc: 0.9535
top acc: 0.3023 ::: bot acc: 0.9767
current epoch: 31
train loss is 0.085818
average val loss: 0.057031, accuracy: 0.5343
average test loss: 0.057410, accuracy: 0.5323
case acc: 0.40310077519379844
case acc: 0.46511627906976744
case acc: 0.5271317829457365
case acc: 0.5968992248062015
case acc: 0.5193798449612403
case acc: 0.6821705426356589
top acc: 0.6744 ::: bot acc: 0.2791
top acc: 0.6047 ::: bot acc: 0.2558
top acc: 0.3488 ::: bot acc: 0.6047
top acc: 0.5116 ::: bot acc: 0.6512
top acc: 0.1628 ::: bot acc: 0.9535
top acc: 0.3488 ::: bot acc: 0.9535
current epoch: 32
train loss is 0.085217
average val loss: 0.056565, accuracy: 0.5359
average test loss: 0.057683, accuracy: 0.5375
case acc: 0.4108527131782946
case acc: 0.4496124031007752
case acc: 0.5348837209302325
case acc: 0.6124031007751938
case acc: 0.5193798449612403
case acc: 0.6976744186046512
top acc: 0.6977 ::: bot acc: 0.2791
top acc: 0.5814 ::: bot acc: 0.2326
top acc: 0.3721 ::: bot acc: 0.6047
top acc: 0.5349 ::: bot acc: 0.6512
top acc: 0.1628 ::: bot acc: 0.9535
top acc: 0.3953 ::: bot acc: 0.9535
current epoch: 33
train loss is 0.084685
average val loss: 0.057328, accuracy: 0.5278
average test loss: 0.057702, accuracy: 0.5323
case acc: 0.3953488372093023
case acc: 0.4496124031007752
case acc: 0.5426356589147286
case acc: 0.5891472868217055
case acc: 0.5193798449612403
case acc: 0.6976744186046512
top acc: 0.6512 ::: bot acc: 0.2791
top acc: 0.5581 ::: bot acc: 0.2558
top acc: 0.3488 ::: bot acc: 0.6512
top acc: 0.4884 ::: bot acc: 0.6512
top acc: 0.1628 ::: bot acc: 0.9535
top acc: 0.3721 ::: bot acc: 0.9767
current epoch: 34
train loss is 0.083654
average val loss: 0.056830, accuracy: 0.5261
average test loss: 0.057883, accuracy: 0.5349
case acc: 0.3953488372093023
case acc: 0.4496124031007752
case acc: 0.5348837209302325
case acc: 0.6201550387596899
case acc: 0.5193798449612403
case acc: 0.689922480620155
top acc: 0.6512 ::: bot acc: 0.2791
top acc: 0.5581 ::: bot acc: 0.2558
top acc: 0.3488 ::: bot acc: 0.6512
top acc: 0.5349 ::: bot acc: 0.6512
top acc: 0.1628 ::: bot acc: 0.9535
top acc: 0.3721 ::: bot acc: 0.9535
current epoch: 35
train loss is 0.082827
average val loss: 0.056244, accuracy: 0.5294
average test loss: 0.058156, accuracy: 0.5388
case acc: 0.4186046511627907
case acc: 0.4496124031007752
case acc: 0.5426356589147286
case acc: 0.6201550387596899
case acc: 0.5116279069767442
case acc: 0.689922480620155
top acc: 0.7209 ::: bot acc: 0.2791
top acc: 0.5581 ::: bot acc: 0.2558
top acc: 0.3488 ::: bot acc: 0.6512
top acc: 0.5814 ::: bot acc: 0.6279
top acc: 0.1395 ::: bot acc: 0.9535
top acc: 0.3953 ::: bot acc: 0.9302
current epoch: 36
train loss is 0.083163
average val loss: 0.057043, accuracy: 0.5163
average test loss: 0.057874, accuracy: 0.5362
case acc: 0.4186046511627907
case acc: 0.4496124031007752
case acc: 0.5348837209302325
case acc: 0.6124031007751938
case acc: 0.5193798449612403
case acc: 0.6821705426356589
top acc: 0.6977 ::: bot acc: 0.2791
top acc: 0.5349 ::: bot acc: 0.2558
top acc: 0.3256 ::: bot acc: 0.6512
top acc: 0.5581 ::: bot acc: 0.6512
top acc: 0.1395 ::: bot acc: 0.9767
top acc: 0.3721 ::: bot acc: 0.9302
current epoch: 37
train loss is 0.081987
average val loss: 0.056558, accuracy: 0.5147
average test loss: 0.057689, accuracy: 0.5375
case acc: 0.43410852713178294
case acc: 0.43410852713178294
case acc: 0.5271317829457365
case acc: 0.6356589147286822
case acc: 0.5038759689922481
case acc: 0.689922480620155
top acc: 0.7209 ::: bot acc: 0.3023
top acc: 0.5349 ::: bot acc: 0.2326
top acc: 0.3023 ::: bot acc: 0.6512
top acc: 0.6047 ::: bot acc: 0.6512
top acc: 0.1395 ::: bot acc: 0.9535
top acc: 0.3721 ::: bot acc: 0.9535
current epoch: 38
train loss is 0.081745
average val loss: 0.056352, accuracy: 0.5049
average test loss: 0.057818, accuracy: 0.5349
case acc: 0.4263565891472868
case acc: 0.43410852713178294
case acc: 0.5193798449612403
case acc: 0.6356589147286822
case acc: 0.5038759689922481
case acc: 0.689922480620155
top acc: 0.7209 ::: bot acc: 0.3023
top acc: 0.5349 ::: bot acc: 0.2093
top acc: 0.3023 ::: bot acc: 0.6512
top acc: 0.6047 ::: bot acc: 0.6744
top acc: 0.1395 ::: bot acc: 0.9535
top acc: 0.3953 ::: bot acc: 0.9302
current epoch: 39
train loss is 0.080744
average val loss: 0.056194, accuracy: 0.5049
average test loss: 0.058025, accuracy: 0.5349
case acc: 0.4418604651162791
case acc: 0.4263565891472868
case acc: 0.5271317829457365
case acc: 0.627906976744186
case acc: 0.5038759689922481
case acc: 0.6821705426356589
top acc: 0.7674 ::: bot acc: 0.3023
top acc: 0.5349 ::: bot acc: 0.2093
top acc: 0.3023 ::: bot acc: 0.6512
top acc: 0.6047 ::: bot acc: 0.6512
top acc: 0.1395 ::: bot acc: 0.9535
top acc: 0.4186 ::: bot acc: 0.8837
current epoch: 40
train loss is 0.080224
average val loss: 0.056638, accuracy: 0.5033
average test loss: 0.058364, accuracy: 0.5362
case acc: 0.4418604651162791
case acc: 0.4418604651162791
case acc: 0.5116279069767442
case acc: 0.6356589147286822
case acc: 0.5038759689922481
case acc: 0.6821705426356589
top acc: 0.7442 ::: bot acc: 0.3256
top acc: 0.5349 ::: bot acc: 0.2326
top acc: 0.2791 ::: bot acc: 0.6512
top acc: 0.6047 ::: bot acc: 0.6744
top acc: 0.1395 ::: bot acc: 0.9535
top acc: 0.4186 ::: bot acc: 0.8837
current epoch: 41
train loss is 0.080248
average val loss: 0.057827, accuracy: 0.4902
average test loss: 0.058270, accuracy: 0.5362
case acc: 0.4418604651162791
case acc: 0.4418604651162791
case acc: 0.5116279069767442
case acc: 0.627906976744186
case acc: 0.5038759689922481
case acc: 0.689922480620155
top acc: 0.7209 ::: bot acc: 0.3256
top acc: 0.5116 ::: bot acc: 0.2558
top acc: 0.2558 ::: bot acc: 0.6512
top acc: 0.5814 ::: bot acc: 0.6744
top acc: 0.1395 ::: bot acc: 0.9535
top acc: 0.3953 ::: bot acc: 0.9302
current epoch: 42
train loss is 0.079195
average val loss: 0.056778, accuracy: 0.4886
average test loss: 0.058408, accuracy: 0.5349
case acc: 0.4418604651162791
case acc: 0.43410852713178294
case acc: 0.5038759689922481
case acc: 0.627906976744186
case acc: 0.5038759689922481
case acc: 0.6976744186046512
top acc: 0.7674 ::: bot acc: 0.3256
top acc: 0.5116 ::: bot acc: 0.2326
top acc: 0.2558 ::: bot acc: 0.6512
top acc: 0.5814 ::: bot acc: 0.6744
top acc: 0.1395 ::: bot acc: 0.9535
top acc: 0.4419 ::: bot acc: 0.9070
current epoch: 43
train loss is 0.078769
average val loss: 0.057973, accuracy: 0.4804
average test loss: 0.059142, accuracy: 0.5388
case acc: 0.4418604651162791
case acc: 0.4418604651162791
case acc: 0.5116279069767442
case acc: 0.6356589147286822
case acc: 0.5038759689922481
case acc: 0.6976744186046512
top acc: 0.7442 ::: bot acc: 0.3256
top acc: 0.4419 ::: bot acc: 0.2791
top acc: 0.2326 ::: bot acc: 0.6512
top acc: 0.6047 ::: bot acc: 0.6744
top acc: 0.1395 ::: bot acc: 0.9535
top acc: 0.4419 ::: bot acc: 0.9070
current epoch: 44
train loss is 0.077053
average val loss: 0.057152, accuracy: 0.4869
average test loss: 0.059279, accuracy: 0.5362
case acc: 0.4573643410852713
case acc: 0.4418604651162791
case acc: 0.5116279069767442
case acc: 0.6201550387596899
case acc: 0.5038759689922481
case acc: 0.6821705426356589
top acc: 0.7907 ::: bot acc: 0.3256
top acc: 0.4884 ::: bot acc: 0.2558
top acc: 0.2558 ::: bot acc: 0.6512
top acc: 0.6512 ::: bot acc: 0.6512
top acc: 0.1395 ::: bot acc: 0.9535
top acc: 0.4419 ::: bot acc: 0.8605
current epoch: 45
train loss is 0.077330
average val loss: 0.058126, accuracy: 0.4722
average test loss: 0.059349, accuracy: 0.5362
case acc: 0.4418604651162791
case acc: 0.4496124031007752
case acc: 0.5116279069767442
case acc: 0.627906976744186
case acc: 0.5038759689922481
case acc: 0.6821705426356589
top acc: 0.6977 ::: bot acc: 0.3256
top acc: 0.4419 ::: bot acc: 0.2791
top acc: 0.2558 ::: bot acc: 0.6512
top acc: 0.6279 ::: bot acc: 0.6512
top acc: 0.1395 ::: bot acc: 0.9535
top acc: 0.4419 ::: bot acc: 0.8605
current epoch: 46
train loss is 0.077076
average val loss: 0.057881, accuracy: 0.4820
average test loss: 0.059244, accuracy: 0.5375
case acc: 0.4496124031007752
case acc: 0.46511627906976744
case acc: 0.5038759689922481
case acc: 0.6124031007751938
case acc: 0.5038759689922481
case acc: 0.689922480620155
top acc: 0.7209 ::: bot acc: 0.3256
top acc: 0.4419 ::: bot acc: 0.2791
top acc: 0.2326 ::: bot acc: 0.6512
top acc: 0.6279 ::: bot acc: 0.6512
top acc: 0.1395 ::: bot acc: 0.9535
top acc: 0.4419 ::: bot acc: 0.8837
current epoch: 47
train loss is 0.075897
average val loss: 0.059090, accuracy: 0.4690
average test loss: 0.059919, accuracy: 0.5401
case acc: 0.4573643410852713
case acc: 0.4883720930232558
case acc: 0.5116279069767442
case acc: 0.5968992248062015
case acc: 0.5116279069767442
case acc: 0.6744186046511628
top acc: 0.7209 ::: bot acc: 0.3256
top acc: 0.4419 ::: bot acc: 0.3488
top acc: 0.2093 ::: bot acc: 0.6512
top acc: 0.5581 ::: bot acc: 0.6279
top acc: 0.1395 ::: bot acc: 0.9767
top acc: 0.3721 ::: bot acc: 0.9070
current epoch: 48
train loss is 0.076507
average val loss: 0.057627, accuracy: 0.4788
average test loss: 0.059863, accuracy: 0.5349
case acc: 0.4418604651162791
case acc: 0.4806201550387597
case acc: 0.49612403100775193
case acc: 0.6046511627906976
case acc: 0.5116279069767442
case acc: 0.6744186046511628
top acc: 0.7674 ::: bot acc: 0.3256
top acc: 0.4419 ::: bot acc: 0.3023
top acc: 0.2093 ::: bot acc: 0.6512
top acc: 0.6279 ::: bot acc: 0.6279
top acc: 0.1395 ::: bot acc: 0.9767
top acc: 0.4186 ::: bot acc: 0.8605
current epoch: 49
train loss is 0.075066
average val loss: 0.059405, accuracy: 0.4771
average test loss: 0.059948, accuracy: 0.5439
case acc: 0.4573643410852713
case acc: 0.49612403100775193
case acc: 0.5193798449612403
case acc: 0.6046511627906976
case acc: 0.5116279069767442
case acc: 0.6744186046511628
top acc: 0.7442 ::: bot acc: 0.3488
top acc: 0.4419 ::: bot acc: 0.3953
top acc: 0.2093 ::: bot acc: 0.6512
top acc: 0.6279 ::: bot acc: 0.6279
top acc: 0.1395 ::: bot acc: 0.9767
top acc: 0.4186 ::: bot acc: 0.8605
current epoch: 50
train loss is 0.074699
average val loss: 0.058871, accuracy: 0.4755
average test loss: 0.059802, accuracy: 0.5401
case acc: 0.4496124031007752
case acc: 0.4883720930232558
case acc: 0.5038759689922481
case acc: 0.6201550387596899
case acc: 0.5116279069767442
case acc: 0.6666666666666666
top acc: 0.7442 ::: bot acc: 0.3256
top acc: 0.4419 ::: bot acc: 0.3488
top acc: 0.2326 ::: bot acc: 0.6512
top acc: 0.6744 ::: bot acc: 0.6279
top acc: 0.1395 ::: bot acc: 0.9767
top acc: 0.4186 ::: bot acc: 0.8605
LME_Co_Spot
Before Load Data
['2010-01-01', '2015-01-01', '2015-07-01']
0.031709819364606276
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Co_Spot']
#####################remove_unused_columns_v4#####################
target LME_Co
Index(['LME_Co_Spot', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low',
       'LME_Co_Close', 'LME_Co_Spot_EMA12', 'LME_Co_Spot_WMA12',
       'LME_Co_Spot_EMA26', 'LME_Co_Spot_WMA26', 'LME_Co_Spot_EMA40',
       'LME_Co_Spot_WMA40', 'LME_Co_Spot_EMA65', 'LME_Co_Spot_WMA65',
       'LME_Co_Spot_EMA125', 'LME_Co_Spot_WMA125', 'LME_Co_Spot_bollinger5',
       'LME_Co_Spot_bollinger10', 'LME_Co_Spot_bollinger15',
       'LME_Co_Spot_bollinger20', 'LME_Co_Spot_bollinger30',
       'LME_Co_Spot_bollinger65', 'LME_Co_Spot_Mom5', 'LME_Co_Spot_Mom10',
       'LME_Co_Spot_Mom15', 'LME_Co_Spot_Mom26', 'LME_Co_Spot_Mom40',
       'LME_Co_Spot_Mom65', 'LME_Co_Spot_Mom125', 'LME_Co_Spot_PPO12',
       'LME_Co_Spot_PPO22', 'LME_Co_Spot_RSI14', 'LME_Co_Spot_RSI26',
       'LME_Co_Spot_RSI40', 'LME_Co_Spot_RSI54', 'LME_Co_Spot_RSI125',
       'LME_Co_Close_EMA12', 'LME_Co_Close_WMA12', 'LME_Co_Close_EMA26',
       'LME_Co_Close_WMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_WMA40',
       'LME_Co_Close_EMA65', 'LME_Co_Close_WMA65', 'LME_Co_Close_EMA125',
       'LME_Co_Close_WMA125', 'LME_Co_Close_bollinger5',
       'LME_Co_Close_bollinger10', 'LME_Co_Close_bollinger15',
       'LME_Co_Close_bollinger20', 'LME_Co_Close_bollinger30',
       'LME_Co_Close_bollinger65', 'LME_Co_Close_Mom5', 'LME_Co_Close_Mom10',
       'LME_Co_Close_Mom15', 'LME_Co_Close_Mom26', 'LME_Co_Close_Mom40',
       'LME_Co_Close_Mom65', 'LME_Co_Close_Mom125', 'LME_Co_Close_PPO12',
       'LME_Co_Close_PPO22', 'LME_Co_Close_RSI14', 'LME_Co_Close_RSI26',
       'LME_Co_Close_RSI40', 'LME_Co_Close_RSI54', 'LME_Co_Close_RSI125',
       'LME_Co_PVT', 'LME_Co_divPVT', 'LME_Co_NATR14', 'LME_Co_NATR26',
       'LME_Co_NATR65', 'LME_Co_NATR125', 'LME_Co_CCI12', 'LME_Co_CCI26',
       'LME_Co_CCI40', 'LME_Co_CCI65', 'LME_Co_CCI125', 'LME_Co_VBM12',
       'LME_Co_VBM22', 'LME_Co_ADX14', 'LME_Co_ADX26', 'LME_Co_ADX40',
       'LME_Co_ADX54', 'LME_Co_ADX125', 'LME_Co_SAR'],
      dtype='object')
LME_Al_Spot
Before Load Data
['2010-01-01', '2015-01-01', '2015-07-01']
0.028915528319485455
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Al_Spot']
#####################remove_unused_columns_v4#####################
target LME_Al
Index(['LME_Al_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low',
       'LME_Al_Close', 'LME_Al_Spot_EMA12', 'LME_Al_Spot_WMA12',
       'LME_Al_Spot_EMA26', 'LME_Al_Spot_WMA26', 'LME_Al_Spot_EMA40',
       'LME_Al_Spot_WMA40', 'LME_Al_Spot_EMA65', 'LME_Al_Spot_WMA65',
       'LME_Al_Spot_EMA125', 'LME_Al_Spot_WMA125', 'LME_Al_Spot_bollinger5',
       'LME_Al_Spot_bollinger10', 'LME_Al_Spot_bollinger15',
       'LME_Al_Spot_bollinger20', 'LME_Al_Spot_bollinger30',
       'LME_Al_Spot_bollinger65', 'LME_Al_Spot_Mom5', 'LME_Al_Spot_Mom10',
       'LME_Al_Spot_Mom15', 'LME_Al_Spot_Mom26', 'LME_Al_Spot_Mom40',
       'LME_Al_Spot_Mom65', 'LME_Al_Spot_Mom125', 'LME_Al_Spot_PPO12',
       'LME_Al_Spot_PPO22', 'LME_Al_Spot_RSI14', 'LME_Al_Spot_RSI26',
       'LME_Al_Spot_RSI40', 'LME_Al_Spot_RSI54', 'LME_Al_Spot_RSI125',
       'LME_Al_Close_EMA12', 'LME_Al_Close_WMA12', 'LME_Al_Close_EMA26',
       'LME_Al_Close_WMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_WMA40',
       'LME_Al_Close_EMA65', 'LME_Al_Close_WMA65', 'LME_Al_Close_EMA125',
       'LME_Al_Close_WMA125', 'LME_Al_Close_bollinger5',
       'LME_Al_Close_bollinger10', 'LME_Al_Close_bollinger15',
       'LME_Al_Close_bollinger20', 'LME_Al_Close_bollinger30',
       'LME_Al_Close_bollinger65', 'LME_Al_Close_Mom5', 'LME_Al_Close_Mom10',
       'LME_Al_Close_Mom15', 'LME_Al_Close_Mom26', 'LME_Al_Close_Mom40',
       'LME_Al_Close_Mom65', 'LME_Al_Close_Mom125', 'LME_Al_Close_PPO12',
       'LME_Al_Close_PPO22', 'LME_Al_Close_RSI14', 'LME_Al_Close_RSI26',
       'LME_Al_Close_RSI40', 'LME_Al_Close_RSI54', 'LME_Al_Close_RSI125',
       'LME_Al_PVT', 'LME_Al_divPVT', 'LME_Al_NATR14', 'LME_Al_NATR26',
       'LME_Al_NATR65', 'LME_Al_NATR125', 'LME_Al_CCI12', 'LME_Al_CCI26',
       'LME_Al_CCI40', 'LME_Al_CCI65', 'LME_Al_CCI125', 'LME_Al_VBM12',
       'LME_Al_VBM22', 'LME_Al_ADX14', 'LME_Al_ADX26', 'LME_Al_ADX40',
       'LME_Al_ADX54', 'LME_Al_ADX125', 'LME_Al_SAR'],
      dtype='object')
LME_Le_Spot
Before Load Data
['2010-01-01', '2015-01-01', '2015-07-01']
0.041192289664352746
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Le_Spot']
#####################remove_unused_columns_v4#####################
target LME_Le
Index(['LME_Le_Spot', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low',
       'LME_Le_Close', 'LME_Le_Spot_EMA12', 'LME_Le_Spot_WMA12',
       'LME_Le_Spot_EMA26', 'LME_Le_Spot_WMA26', 'LME_Le_Spot_EMA40',
       'LME_Le_Spot_WMA40', 'LME_Le_Spot_EMA65', 'LME_Le_Spot_WMA65',
       'LME_Le_Spot_EMA125', 'LME_Le_Spot_WMA125', 'LME_Le_Spot_bollinger5',
       'LME_Le_Spot_bollinger10', 'LME_Le_Spot_bollinger15',
       'LME_Le_Spot_bollinger20', 'LME_Le_Spot_bollinger30',
       'LME_Le_Spot_bollinger65', 'LME_Le_Spot_Mom5', 'LME_Le_Spot_Mom10',
       'LME_Le_Spot_Mom15', 'LME_Le_Spot_Mom26', 'LME_Le_Spot_Mom40',
       'LME_Le_Spot_Mom65', 'LME_Le_Spot_Mom125', 'LME_Le_Spot_PPO12',
       'LME_Le_Spot_PPO22', 'LME_Le_Spot_RSI14', 'LME_Le_Spot_RSI26',
       'LME_Le_Spot_RSI40', 'LME_Le_Spot_RSI54', 'LME_Le_Spot_RSI125',
       'LME_Le_Close_EMA12', 'LME_Le_Close_WMA12', 'LME_Le_Close_EMA26',
       'LME_Le_Close_WMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_WMA40',
       'LME_Le_Close_EMA65', 'LME_Le_Close_WMA65', 'LME_Le_Close_EMA125',
       'LME_Le_Close_WMA125', 'LME_Le_Close_bollinger5',
       'LME_Le_Close_bollinger10', 'LME_Le_Close_bollinger15',
       'LME_Le_Close_bollinger20', 'LME_Le_Close_bollinger30',
       'LME_Le_Close_bollinger65', 'LME_Le_Close_Mom5', 'LME_Le_Close_Mom10',
       'LME_Le_Close_Mom15', 'LME_Le_Close_Mom26', 'LME_Le_Close_Mom40',
       'LME_Le_Close_Mom65', 'LME_Le_Close_Mom125', 'LME_Le_Close_PPO12',
       'LME_Le_Close_PPO22', 'LME_Le_Close_RSI14', 'LME_Le_Close_RSI26',
       'LME_Le_Close_RSI40', 'LME_Le_Close_RSI54', 'LME_Le_Close_RSI125',
       'LME_Le_PVT', 'LME_Le_divPVT', 'LME_Le_NATR14', 'LME_Le_NATR26',
       'LME_Le_NATR65', 'LME_Le_NATR125', 'LME_Le_CCI12', 'LME_Le_CCI26',
       'LME_Le_CCI40', 'LME_Le_CCI65', 'LME_Le_CCI125', 'LME_Le_VBM12',
       'LME_Le_VBM22', 'LME_Le_ADX14', 'LME_Le_ADX26', 'LME_Le_ADX40',
       'LME_Le_ADX54', 'LME_Le_ADX125', 'LME_Le_SAR'],
      dtype='object')
LME_Ni_Spot
Before Load Data
['2010-01-01', '2015-01-01', '2015-07-01']
0.04157474857906271
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Ni_Spot']
#####################remove_unused_columns_v4#####################
target LME_Ni
Index(['LME_Ni_Spot', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low',
       'LME_Ni_Close', 'LME_Ni_Spot_EMA12', 'LME_Ni_Spot_WMA12',
       'LME_Ni_Spot_EMA26', 'LME_Ni_Spot_WMA26', 'LME_Ni_Spot_EMA40',
       'LME_Ni_Spot_WMA40', 'LME_Ni_Spot_EMA65', 'LME_Ni_Spot_WMA65',
       'LME_Ni_Spot_EMA125', 'LME_Ni_Spot_WMA125', 'LME_Ni_Spot_bollinger5',
       'LME_Ni_Spot_bollinger10', 'LME_Ni_Spot_bollinger15',
       'LME_Ni_Spot_bollinger20', 'LME_Ni_Spot_bollinger30',
       'LME_Ni_Spot_bollinger65', 'LME_Ni_Spot_Mom5', 'LME_Ni_Spot_Mom10',
       'LME_Ni_Spot_Mom15', 'LME_Ni_Spot_Mom26', 'LME_Ni_Spot_Mom40',
       'LME_Ni_Spot_Mom65', 'LME_Ni_Spot_Mom125', 'LME_Ni_Spot_PPO12',
       'LME_Ni_Spot_PPO22', 'LME_Ni_Spot_RSI14', 'LME_Ni_Spot_RSI26',
       'LME_Ni_Spot_RSI40', 'LME_Ni_Spot_RSI54', 'LME_Ni_Spot_RSI125',
       'LME_Ni_Close_EMA12', 'LME_Ni_Close_WMA12', 'LME_Ni_Close_EMA26',
       'LME_Ni_Close_WMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_WMA40',
       'LME_Ni_Close_EMA65', 'LME_Ni_Close_WMA65', 'LME_Ni_Close_EMA125',
       'LME_Ni_Close_WMA125', 'LME_Ni_Close_bollinger5',
       'LME_Ni_Close_bollinger10', 'LME_Ni_Close_bollinger15',
       'LME_Ni_Close_bollinger20', 'LME_Ni_Close_bollinger30',
       'LME_Ni_Close_bollinger65', 'LME_Ni_Close_Mom5', 'LME_Ni_Close_Mom10',
       'LME_Ni_Close_Mom15', 'LME_Ni_Close_Mom26', 'LME_Ni_Close_Mom40',
       'LME_Ni_Close_Mom65', 'LME_Ni_Close_Mom125', 'LME_Ni_Close_PPO12',
       'LME_Ni_Close_PPO22', 'LME_Ni_Close_RSI14', 'LME_Ni_Close_RSI26',
       'LME_Ni_Close_RSI40', 'LME_Ni_Close_RSI54', 'LME_Ni_Close_RSI125',
       'LME_Ni_PVT', 'LME_Ni_divPVT', 'LME_Ni_NATR14', 'LME_Ni_NATR26',
       'LME_Ni_NATR65', 'LME_Ni_NATR125', 'LME_Ni_CCI12', 'LME_Ni_CCI26',
       'LME_Ni_CCI40', 'LME_Ni_CCI65', 'LME_Ni_CCI125', 'LME_Ni_VBM12',
       'LME_Ni_VBM22', 'LME_Ni_ADX14', 'LME_Ni_ADX26', 'LME_Ni_ADX40',
       'LME_Ni_ADX54', 'LME_Ni_ADX125', 'LME_Ni_SAR'],
      dtype='object')
LME_Zi_Spot
Before Load Data
['2010-01-01', '2015-01-01', '2015-07-01']
0.037617297591954736
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Zi_Spot']
#####################remove_unused_columns_v4#####################
target LME_Zi
Index(['LME_Zi_Spot', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low',
       'LME_Zi_Close', 'LME_Zi_Spot_EMA12', 'LME_Zi_Spot_WMA12',
       'LME_Zi_Spot_EMA26', 'LME_Zi_Spot_WMA26', 'LME_Zi_Spot_EMA40',
       'LME_Zi_Spot_WMA40', 'LME_Zi_Spot_EMA65', 'LME_Zi_Spot_WMA65',
       'LME_Zi_Spot_EMA125', 'LME_Zi_Spot_WMA125', 'LME_Zi_Spot_bollinger5',
       'LME_Zi_Spot_bollinger10', 'LME_Zi_Spot_bollinger15',
       'LME_Zi_Spot_bollinger20', 'LME_Zi_Spot_bollinger30',
       'LME_Zi_Spot_bollinger65', 'LME_Zi_Spot_Mom5', 'LME_Zi_Spot_Mom10',
       'LME_Zi_Spot_Mom15', 'LME_Zi_Spot_Mom26', 'LME_Zi_Spot_Mom40',
       'LME_Zi_Spot_Mom65', 'LME_Zi_Spot_Mom125', 'LME_Zi_Spot_PPO12',
       'LME_Zi_Spot_PPO22', 'LME_Zi_Spot_RSI14', 'LME_Zi_Spot_RSI26',
       'LME_Zi_Spot_RSI40', 'LME_Zi_Spot_RSI54', 'LME_Zi_Spot_RSI125',
       'LME_Zi_Close_EMA12', 'LME_Zi_Close_WMA12', 'LME_Zi_Close_EMA26',
       'LME_Zi_Close_WMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_WMA40',
       'LME_Zi_Close_EMA65', 'LME_Zi_Close_WMA65', 'LME_Zi_Close_EMA125',
       'LME_Zi_Close_WMA125', 'LME_Zi_Close_bollinger5',
       'LME_Zi_Close_bollinger10', 'LME_Zi_Close_bollinger15',
       'LME_Zi_Close_bollinger20', 'LME_Zi_Close_bollinger30',
       'LME_Zi_Close_bollinger65', 'LME_Zi_Close_Mom5', 'LME_Zi_Close_Mom10',
       'LME_Zi_Close_Mom15', 'LME_Zi_Close_Mom26', 'LME_Zi_Close_Mom40',
       'LME_Zi_Close_Mom65', 'LME_Zi_Close_Mom125', 'LME_Zi_Close_PPO12',
       'LME_Zi_Close_PPO22', 'LME_Zi_Close_RSI14', 'LME_Zi_Close_RSI26',
       'LME_Zi_Close_RSI40', 'LME_Zi_Close_RSI54', 'LME_Zi_Close_RSI125',
       'LME_Zi_PVT', 'LME_Zi_divPVT', 'LME_Zi_NATR14', 'LME_Zi_NATR26',
       'LME_Zi_NATR65', 'LME_Zi_NATR125', 'LME_Zi_CCI12', 'LME_Zi_CCI26',
       'LME_Zi_CCI40', 'LME_Zi_CCI65', 'LME_Zi_CCI125', 'LME_Zi_VBM12',
       'LME_Zi_VBM22', 'LME_Zi_ADX14', 'LME_Zi_ADX26', 'LME_Zi_ADX40',
       'LME_Zi_ADX54', 'LME_Zi_ADX125', 'LME_Zi_SAR'],
      dtype='object')
LME_Ti_Spot
Before Load Data
['2010-01-01', '2015-01-01', '2015-07-01']
0.037443301430493174
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Ti_Spot']
#####################remove_unused_columns_v4#####################
target LME_Ti
Index(['LME_Ti_Spot', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low',
       'LME_Ti_Close', 'LME_Ti_Spot_EMA12', 'LME_Ti_Spot_WMA12',
       'LME_Ti_Spot_EMA26', 'LME_Ti_Spot_WMA26', 'LME_Ti_Spot_EMA40',
       'LME_Ti_Spot_WMA40', 'LME_Ti_Spot_EMA65', 'LME_Ti_Spot_WMA65',
       'LME_Ti_Spot_EMA125', 'LME_Ti_Spot_WMA125', 'LME_Ti_Spot_bollinger5',
       'LME_Ti_Spot_bollinger10', 'LME_Ti_Spot_bollinger15',
       'LME_Ti_Spot_bollinger20', 'LME_Ti_Spot_bollinger30',
       'LME_Ti_Spot_bollinger65', 'LME_Ti_Spot_Mom5', 'LME_Ti_Spot_Mom10',
       'LME_Ti_Spot_Mom15', 'LME_Ti_Spot_Mom26', 'LME_Ti_Spot_Mom40',
       'LME_Ti_Spot_Mom65', 'LME_Ti_Spot_Mom125', 'LME_Ti_Spot_PPO12',
       'LME_Ti_Spot_PPO22', 'LME_Ti_Spot_RSI14', 'LME_Ti_Spot_RSI26',
       'LME_Ti_Spot_RSI40', 'LME_Ti_Spot_RSI54', 'LME_Ti_Spot_RSI125',
       'LME_Ti_Close_EMA12', 'LME_Ti_Close_WMA12', 'LME_Ti_Close_EMA26',
       'LME_Ti_Close_WMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_WMA40',
       'LME_Ti_Close_EMA65', 'LME_Ti_Close_WMA65', 'LME_Ti_Close_EMA125',
       'LME_Ti_Close_WMA125', 'LME_Ti_Close_bollinger5',
       'LME_Ti_Close_bollinger10', 'LME_Ti_Close_bollinger15',
       'LME_Ti_Close_bollinger20', 'LME_Ti_Close_bollinger30',
       'LME_Ti_Close_bollinger65', 'LME_Ti_Close_Mom5', 'LME_Ti_Close_Mom10',
       'LME_Ti_Close_Mom15', 'LME_Ti_Close_Mom26', 'LME_Ti_Close_Mom40',
       'LME_Ti_Close_Mom65', 'LME_Ti_Close_Mom125', 'LME_Ti_Close_PPO12',
       'LME_Ti_Close_PPO22', 'LME_Ti_Close_RSI14', 'LME_Ti_Close_RSI26',
       'LME_Ti_Close_RSI40', 'LME_Ti_Close_RSI54', 'LME_Ti_Close_RSI125',
       'LME_Ti_PVT', 'LME_Ti_divPVT', 'LME_Ti_NATR14', 'LME_Ti_NATR26',
       'LME_Ti_NATR65', 'LME_Ti_NATR125', 'LME_Ti_CCI12', 'LME_Ti_CCI26',
       'LME_Ti_CCI40', 'LME_Ti_CCI65', 'LME_Ti_CCI125', 'LME_Ti_VBM12',
       'LME_Ti_VBM22', 'LME_Ti_ADX14', 'LME_Ti_ADX26', 'LME_Ti_ADX40',
       'LME_Ti_ADX54', 'LME_Ti_ADX125', 'LME_Ti_SAR'],
      dtype='object')
Dataset statistic: #examples
Train: 5460 5460 5460
6.998165 -7.1710863 2.222352 -1.7757674
Validation: 612 612 612
Testing: 744 744 744
pre-processing time: 0.0010089874267578125
the split date is 2015-01-01
net initializing with time: 0.0010030269622802734
preparing training and testing date with time: 0.0019800662994384766
current epoch: 1
train loss is 0.521384
average val loss: 0.225919, accuracy: 0.3987
average test loss: 0.235731, accuracy: 0.4194
case acc: 0.4274193548387097
case acc: 0.4596774193548387
case acc: 0.4032258064516129
case acc: 0.4435483870967742
case acc: 0.45161290322580644
case acc: 0.33064516129032256
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.9512 ::: bot acc: 0.1951
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 2
train loss is 0.142826
average val loss: 0.074368, accuracy: 0.5359
average test loss: 0.112411, accuracy: 0.4597
case acc: 0.5080645161290323
case acc: 0.5241935483870968
case acc: 0.33064516129032256
case acc: 0.49193548387096775
case acc: 0.6048387096774194
case acc: 0.29838709677419356
top acc: 0.1220 ::: bot acc: 0.8780
top acc: 0.2439 ::: bot acc: 0.8049
top acc: 0.6098 ::: bot acc: 0.1220
top acc: 0.0244 ::: bot acc: 0.8293
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.3659 ::: bot acc: 0.2439
current epoch: 3
train loss is 0.142644
average val loss: 0.071763, accuracy: 0.5245
average test loss: 0.106793, accuracy: 0.4691
case acc: 0.4838709677419355
case acc: 0.532258064516129
case acc: 0.3709677419354839
case acc: 0.5
case acc: 0.6048387096774194
case acc: 0.3225806451612903
top acc: 0.1220 ::: bot acc: 0.8537
top acc: 0.3902 ::: bot acc: 0.7073
top acc: 0.8780 ::: bot acc: 0.0488
top acc: 0.0732 ::: bot acc: 0.8049
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.5610 ::: bot acc: 0.1951
current epoch: 4
train loss is 0.121009
average val loss: 0.078410, accuracy: 0.4739
average test loss: 0.113947, accuracy: 0.4530
case acc: 0.43548387096774194
case acc: 0.5080645161290323
case acc: 0.4032258064516129
case acc: 0.4435483870967742
case acc: 0.5967741935483871
case acc: 0.33064516129032256
top acc: 0.5854 ::: bot acc: 0.4390
top acc: 0.9024 ::: bot acc: 0.2195
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.6098 ::: bot acc: 0.3171
top acc: 0.0000 ::: bot acc: 0.9756
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 5
train loss is 0.116379
average val loss: 0.078119, accuracy: 0.4690
average test loss: 0.114893, accuracy: 0.4718
case acc: 0.4435483870967742
case acc: 0.5161290322580645
case acc: 0.4032258064516129
case acc: 0.532258064516129
case acc: 0.6048387096774194
case acc: 0.33064516129032256
top acc: 0.6585 ::: bot acc: 0.3171
top acc: 1.0000 ::: bot acc: 0.1463
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.8537 ::: bot acc: 0.2439
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 6
train loss is 0.113006
average val loss: 0.071522, accuracy: 0.4755
average test loss: 0.107995, accuracy: 0.4637
case acc: 0.4274193548387097
case acc: 0.5241935483870968
case acc: 0.4032258064516129
case acc: 0.49193548387096775
case acc: 0.6048387096774194
case acc: 0.33064516129032256
top acc: 0.3902 ::: bot acc: 0.4634
top acc: 0.9756 ::: bot acc: 0.1951
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.5854 ::: bot acc: 0.3902
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 7
train loss is 0.110818
average val loss: 0.069467, accuracy: 0.4771
average test loss: 0.105738, accuracy: 0.4691
case acc: 0.46774193548387094
case acc: 0.532258064516129
case acc: 0.3951612903225806
case acc: 0.4838709677419355
case acc: 0.6048387096774194
case acc: 0.33064516129032256
top acc: 0.4390 ::: bot acc: 0.5122
top acc: 0.9756 ::: bot acc: 0.2195
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.5122 ::: bot acc: 0.4634
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 8
train loss is 0.108305
average val loss: 0.069570, accuracy: 0.4739
average test loss: 0.106163, accuracy: 0.4731
case acc: 0.4435483870967742
case acc: 0.532258064516129
case acc: 0.3951612903225806
case acc: 0.532258064516129
case acc: 0.6048387096774194
case acc: 0.33064516129032256
top acc: 0.5610 ::: bot acc: 0.3659
top acc: 1.0000 ::: bot acc: 0.1951
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.6829 ::: bot acc: 0.4146
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 9
train loss is 0.106890
average val loss: 0.068977, accuracy: 0.4722
average test loss: 0.105663, accuracy: 0.4745
case acc: 0.4435483870967742
case acc: 0.532258064516129
case acc: 0.3951612903225806
case acc: 0.5403225806451613
case acc: 0.6048387096774194
case acc: 0.33064516129032256
top acc: 0.6098 ::: bot acc: 0.3415
top acc: 1.0000 ::: bot acc: 0.1951
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.7317 ::: bot acc: 0.3659
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 10
train loss is 0.105439
average val loss: 0.067808, accuracy: 0.4771
average test loss: 0.104460, accuracy: 0.4731
case acc: 0.43548387096774194
case acc: 0.532258064516129
case acc: 0.4032258064516129
case acc: 0.532258064516129
case acc: 0.6048387096774194
case acc: 0.33064516129032256
top acc: 0.6098 ::: bot acc: 0.3171
top acc: 1.0000 ::: bot acc: 0.1951
top acc: 1.0000 ::: bot acc: 0.0244
top acc: 0.7073 ::: bot acc: 0.3659
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 11
train loss is 0.104263
average val loss: 0.066967, accuracy: 0.4820
average test loss: 0.103743, accuracy: 0.4758
case acc: 0.4274193548387097
case acc: 0.532258064516129
case acc: 0.4112903225806452
case acc: 0.5483870967741935
case acc: 0.6048387096774194
case acc: 0.33064516129032256
top acc: 0.6341 ::: bot acc: 0.2927
top acc: 1.0000 ::: bot acc: 0.2195
top acc: 1.0000 ::: bot acc: 0.0488
top acc: 0.7317 ::: bot acc: 0.4146
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 12
train loss is 0.102877
average val loss: 0.066358, accuracy: 0.4837
average test loss: 0.103590, accuracy: 0.4879
case acc: 0.4838709677419355
case acc: 0.5403225806451613
case acc: 0.41935483870967744
case acc: 0.5483870967741935
case acc: 0.6048387096774194
case acc: 0.33064516129032256
top acc: 0.8049 ::: bot acc: 0.2927
top acc: 1.0000 ::: bot acc: 0.2195
top acc: 1.0000 ::: bot acc: 0.0488
top acc: 0.7561 ::: bot acc: 0.4146
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 13
train loss is 0.102601
average val loss: 0.065750, accuracy: 0.4837
average test loss: 0.103402, accuracy: 0.4906
case acc: 0.49193548387096775
case acc: 0.5403225806451613
case acc: 0.41935483870967744
case acc: 0.5564516129032258
case acc: 0.6048387096774194
case acc: 0.33064516129032256
top acc: 0.8049 ::: bot acc: 0.2927
top acc: 0.9756 ::: bot acc: 0.2439
top acc: 0.9756 ::: bot acc: 0.0732
top acc: 0.7805 ::: bot acc: 0.3902
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 14
train loss is 0.100430
average val loss: 0.064928, accuracy: 0.4837
average test loss: 0.102971, accuracy: 0.4919
case acc: 0.49193548387096775
case acc: 0.5403225806451613
case acc: 0.4112903225806452
case acc: 0.5725806451612904
case acc: 0.6048387096774194
case acc: 0.33064516129032256
top acc: 0.8293 ::: bot acc: 0.2683
top acc: 0.9756 ::: bot acc: 0.2439
top acc: 0.9512 ::: bot acc: 0.0976
top acc: 0.7561 ::: bot acc: 0.4390
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 15
train loss is 0.099353
average val loss: 0.064632, accuracy: 0.4886
average test loss: 0.103325, accuracy: 0.4919
case acc: 0.47580645161290325
case acc: 0.532258064516129
case acc: 0.43548387096774194
case acc: 0.5725806451612904
case acc: 0.6048387096774194
case acc: 0.33064516129032256
top acc: 0.8537 ::: bot acc: 0.2439
top acc: 0.9756 ::: bot acc: 0.2195
top acc: 0.9512 ::: bot acc: 0.1707
top acc: 0.8049 ::: bot acc: 0.3902
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 16
train loss is 0.097507
average val loss: 0.064236, accuracy: 0.4902
average test loss: 0.103264, accuracy: 0.4933
case acc: 0.47580645161290325
case acc: 0.532258064516129
case acc: 0.43548387096774194
case acc: 0.5725806451612904
case acc: 0.6129032258064516
case acc: 0.33064516129032256
top acc: 0.8780 ::: bot acc: 0.2439
top acc: 0.9756 ::: bot acc: 0.2195
top acc: 0.9512 ::: bot acc: 0.1707
top acc: 0.8049 ::: bot acc: 0.3902
top acc: 0.0244 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 17
train loss is 0.097357
average val loss: 0.063461, accuracy: 0.4918
average test loss: 0.102685, accuracy: 0.4879
case acc: 0.4596774193548387
case acc: 0.5241935483870968
case acc: 0.43548387096774194
case acc: 0.5645161290322581
case acc: 0.6129032258064516
case acc: 0.33064516129032256
top acc: 0.8780 ::: bot acc: 0.2195
top acc: 0.9512 ::: bot acc: 0.2195
top acc: 0.9024 ::: bot acc: 0.2195
top acc: 0.8049 ::: bot acc: 0.3902
top acc: 0.0244 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 18
train loss is 0.096293
average val loss: 0.063105, accuracy: 0.4886
average test loss: 0.102589, accuracy: 0.4839
case acc: 0.4435483870967742
case acc: 0.5241935483870968
case acc: 0.4435483870967742
case acc: 0.5483870967741935
case acc: 0.6129032258064516
case acc: 0.33064516129032256
top acc: 0.8780 ::: bot acc: 0.1707
top acc: 0.9512 ::: bot acc: 0.2195
top acc: 0.8780 ::: bot acc: 0.2683
top acc: 0.8049 ::: bot acc: 0.3415
top acc: 0.0244 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 19
train loss is 0.094687
average val loss: 0.062690, accuracy: 0.4935
average test loss: 0.103171, accuracy: 0.4812
case acc: 0.43548387096774194
case acc: 0.532258064516129
case acc: 0.4435483870967742
case acc: 0.5241935483870968
case acc: 0.6209677419354839
case acc: 0.33064516129032256
top acc: 0.8780 ::: bot acc: 0.1463
top acc: 0.9512 ::: bot acc: 0.2439
top acc: 0.8780 ::: bot acc: 0.2683
top acc: 0.8049 ::: bot acc: 0.2927
top acc: 0.0488 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 20
train loss is 0.094010
average val loss: 0.062119, accuracy: 0.5049
average test loss: 0.103260, accuracy: 0.4839
case acc: 0.4274193548387097
case acc: 0.532258064516129
case acc: 0.45161290322580644
case acc: 0.5241935483870968
case acc: 0.6290322580645161
case acc: 0.3387096774193548
top acc: 0.8780 ::: bot acc: 0.1220
top acc: 0.9512 ::: bot acc: 0.2439
top acc: 0.8780 ::: bot acc: 0.2927
top acc: 0.8049 ::: bot acc: 0.2927
top acc: 0.0732 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 21
train loss is 0.092559
average val loss: 0.061794, accuracy: 0.5016
average test loss: 0.103726, accuracy: 0.4892
case acc: 0.43548387096774194
case acc: 0.5483870967741935
case acc: 0.45161290322580644
case acc: 0.532258064516129
case acc: 0.6290322580645161
case acc: 0.3387096774193548
top acc: 0.9024 ::: bot acc: 0.1220
top acc: 0.9512 ::: bot acc: 0.2683
top acc: 0.8537 ::: bot acc: 0.2927
top acc: 0.8049 ::: bot acc: 0.3171
top acc: 0.0732 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 22
train loss is 0.092690
average val loss: 0.061652, accuracy: 0.5016
average test loss: 0.104572, accuracy: 0.4866
case acc: 0.43548387096774194
case acc: 0.5483870967741935
case acc: 0.4596774193548387
case acc: 0.5241935483870968
case acc: 0.6129032258064516
case acc: 0.3387096774193548
top acc: 0.9024 ::: bot acc: 0.1220
top acc: 0.9512 ::: bot acc: 0.2683
top acc: 0.8537 ::: bot acc: 0.3171
top acc: 0.8293 ::: bot acc: 0.3171
top acc: 0.0732 ::: bot acc: 0.9756
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 23
train loss is 0.091266
average val loss: 0.061378, accuracy: 0.4967
average test loss: 0.104690, accuracy: 0.4798
case acc: 0.4112903225806452
case acc: 0.5564516129032258
case acc: 0.4435483870967742
case acc: 0.5241935483870968
case acc: 0.6129032258064516
case acc: 0.33064516129032256
top acc: 0.9024 ::: bot acc: 0.0488
top acc: 0.9512 ::: bot acc: 0.2927
top acc: 0.8049 ::: bot acc: 0.3415
top acc: 0.8293 ::: bot acc: 0.3171
top acc: 0.0732 ::: bot acc: 0.9756
top acc: 0.9756 ::: bot acc: 0.0000
current epoch: 24
train loss is 0.090714
average val loss: 0.061370, accuracy: 0.5016
average test loss: 0.105330, accuracy: 0.4839
case acc: 0.4112903225806452
case acc: 0.5564516129032258
case acc: 0.45161290322580644
case acc: 0.5241935483870968
case acc: 0.6290322580645161
case acc: 0.33064516129032256
top acc: 0.9024 ::: bot acc: 0.0488
top acc: 0.9512 ::: bot acc: 0.2927
top acc: 0.8293 ::: bot acc: 0.3415
top acc: 0.8293 ::: bot acc: 0.3415
top acc: 0.1220 ::: bot acc: 0.9756
top acc: 0.9756 ::: bot acc: 0.0000
current epoch: 25
train loss is 0.089129
average val loss: 0.061100, accuracy: 0.5114
average test loss: 0.105659, accuracy: 0.4866
case acc: 0.41935483870967744
case acc: 0.5645161290322581
case acc: 0.4596774193548387
case acc: 0.5161290322580645
case acc: 0.6290322580645161
case acc: 0.33064516129032256
top acc: 0.9268 ::: bot acc: 0.0488
top acc: 0.9512 ::: bot acc: 0.2927
top acc: 0.8293 ::: bot acc: 0.3659
top acc: 0.8537 ::: bot acc: 0.3171
top acc: 0.1220 ::: bot acc: 0.9756
top acc: 0.9756 ::: bot acc: 0.0000
current epoch: 26
train loss is 0.088554
average val loss: 0.060952, accuracy: 0.5033
average test loss: 0.107070, accuracy: 0.4798
case acc: 0.4112903225806452
case acc: 0.5645161290322581
case acc: 0.4435483870967742
case acc: 0.5080645161290323
case acc: 0.6209677419354839
case acc: 0.33064516129032256
top acc: 0.9512 ::: bot acc: 0.0244
top acc: 0.9268 ::: bot acc: 0.3171
top acc: 0.8293 ::: bot acc: 0.3171
top acc: 0.8780 ::: bot acc: 0.2683
top acc: 0.1220 ::: bot acc: 0.9512
top acc: 0.9756 ::: bot acc: 0.0000
current epoch: 27
train loss is 0.087409
average val loss: 0.060597, accuracy: 0.5065
average test loss: 0.107759, accuracy: 0.4892
case acc: 0.4112903225806452
case acc: 0.5725806451612904
case acc: 0.45161290322580644
case acc: 0.5403225806451613
case acc: 0.6290322580645161
case acc: 0.33064516129032256
top acc: 0.9512 ::: bot acc: 0.0244
top acc: 0.9024 ::: bot acc: 0.3415
top acc: 0.8293 ::: bot acc: 0.3415
top acc: 0.9024 ::: bot acc: 0.3415
top acc: 0.1463 ::: bot acc: 0.9512
top acc: 0.9756 ::: bot acc: 0.0000
current epoch: 28
train loss is 0.087587
average val loss: 0.060472, accuracy: 0.5082
average test loss: 0.108731, accuracy: 0.4933
case acc: 0.41935483870967744
case acc: 0.5887096774193549
case acc: 0.4596774193548387
case acc: 0.5241935483870968
case acc: 0.6370967741935484
case acc: 0.33064516129032256
top acc: 0.9756 ::: bot acc: 0.0244
top acc: 0.9024 ::: bot acc: 0.3659
top acc: 0.8537 ::: bot acc: 0.3415
top acc: 0.9024 ::: bot acc: 0.2927
top acc: 0.1463 ::: bot acc: 0.9512
top acc: 0.9756 ::: bot acc: 0.0000
current epoch: 29
train loss is 0.086572
average val loss: 0.060595, accuracy: 0.5033
average test loss: 0.109710, accuracy: 0.4987
case acc: 0.41935483870967744
case acc: 0.5967741935483871
case acc: 0.45161290322580644
case acc: 0.5483870967741935
case acc: 0.6451612903225806
case acc: 0.33064516129032256
top acc: 0.9756 ::: bot acc: 0.0244
top acc: 0.9024 ::: bot acc: 0.3659
top acc: 0.8537 ::: bot acc: 0.3171
top acc: 0.9024 ::: bot acc: 0.3415
top acc: 0.1707 ::: bot acc: 0.9512
top acc: 0.9756 ::: bot acc: 0.0000
current epoch: 30
train loss is 0.086597
average val loss: 0.060488, accuracy: 0.5049
average test loss: 0.110289, accuracy: 0.4987
case acc: 0.41935483870967744
case acc: 0.6048387096774194
case acc: 0.46774193548387094
case acc: 0.5403225806451613
case acc: 0.6290322580645161
case acc: 0.33064516129032256
top acc: 0.9756 ::: bot acc: 0.0244
top acc: 0.9024 ::: bot acc: 0.3902
top acc: 0.8780 ::: bot acc: 0.3415
top acc: 0.9024 ::: bot acc: 0.3415
top acc: 0.1707 ::: bot acc: 0.9268
top acc: 0.9756 ::: bot acc: 0.0000
current epoch: 31
train loss is 0.085176
average val loss: 0.060513, accuracy: 0.5016
average test loss: 0.112306, accuracy: 0.4933
case acc: 0.41935483870967744
case acc: 0.5967741935483871
case acc: 0.45161290322580644
case acc: 0.5403225806451613
case acc: 0.6209677419354839
case acc: 0.33064516129032256
top acc: 0.9756 ::: bot acc: 0.0244
top acc: 0.9024 ::: bot acc: 0.3902
top acc: 0.8537 ::: bot acc: 0.3171
top acc: 0.9268 ::: bot acc: 0.3171
top acc: 0.1951 ::: bot acc: 0.9024
top acc: 0.9756 ::: bot acc: 0.0000
current epoch: 32
train loss is 0.084771
average val loss: 0.060329, accuracy: 0.5033
average test loss: 0.112010, accuracy: 0.4946
case acc: 0.41935483870967744
case acc: 0.6209677419354839
case acc: 0.4596774193548387
case acc: 0.5161290322580645
case acc: 0.6209677419354839
case acc: 0.33064516129032256
top acc: 0.9756 ::: bot acc: 0.0244
top acc: 0.9024 ::: bot acc: 0.4390
top acc: 0.8780 ::: bot acc: 0.3171
top acc: 0.8780 ::: bot acc: 0.3171
top acc: 0.1951 ::: bot acc: 0.9024
top acc: 0.9756 ::: bot acc: 0.0000
current epoch: 33
train loss is 0.083711
average val loss: 0.060398, accuracy: 0.5016
average test loss: 0.111546, accuracy: 0.5000
case acc: 0.41935483870967744
case acc: 0.6209677419354839
case acc: 0.4596774193548387
case acc: 0.532258064516129
case acc: 0.6290322580645161
case acc: 0.3387096774193548
top acc: 0.9756 ::: bot acc: 0.0244
top acc: 0.8780 ::: bot acc: 0.4390
top acc: 0.8780 ::: bot acc: 0.3171
top acc: 0.8780 ::: bot acc: 0.3171
top acc: 0.1951 ::: bot acc: 0.9024
top acc: 0.9756 ::: bot acc: 0.0000
current epoch: 34
train loss is 0.083721
average val loss: 0.060609, accuracy: 0.5016
average test loss: 0.113665, accuracy: 0.5000
case acc: 0.41935483870967744
case acc: 0.6209677419354839
case acc: 0.4596774193548387
case acc: 0.5403225806451613
case acc: 0.6209677419354839
case acc: 0.3387096774193548
top acc: 0.9756 ::: bot acc: 0.0244
top acc: 0.9024 ::: bot acc: 0.4390
top acc: 0.8780 ::: bot acc: 0.3171
top acc: 0.9268 ::: bot acc: 0.3415
top acc: 0.1951 ::: bot acc: 0.9024
top acc: 0.9756 ::: bot acc: 0.0000
current epoch: 35
train loss is 0.082191
average val loss: 0.060853, accuracy: 0.4984
average test loss: 0.115365, accuracy: 0.5013
case acc: 0.41935483870967744
case acc: 0.6209677419354839
case acc: 0.45161290322580644
case acc: 0.532258064516129
case acc: 0.6451612903225806
case acc: 0.3387096774193548
top acc: 0.9756 ::: bot acc: 0.0244
top acc: 0.8780 ::: bot acc: 0.4390
top acc: 0.8780 ::: bot acc: 0.2927
top acc: 0.9268 ::: bot acc: 0.3171
top acc: 0.2439 ::: bot acc: 0.9024
top acc: 0.9756 ::: bot acc: 0.0000
current epoch: 36
train loss is 0.081749
average val loss: 0.060843, accuracy: 0.4967
average test loss: 0.115642, accuracy: 0.5067
case acc: 0.41935483870967744
case acc: 0.6370967741935484
case acc: 0.4596774193548387
case acc: 0.5483870967741935
case acc: 0.6451612903225806
case acc: 0.33064516129032256
top acc: 0.9756 ::: bot acc: 0.0244
top acc: 0.8537 ::: bot acc: 0.4878
top acc: 0.8780 ::: bot acc: 0.3171
top acc: 0.9268 ::: bot acc: 0.3415
top acc: 0.2439 ::: bot acc: 0.9024
top acc: 0.9512 ::: bot acc: 0.0000
current epoch: 37
train loss is 0.081976
average val loss: 0.061159, accuracy: 0.4967
average test loss: 0.117681, accuracy: 0.5081
case acc: 0.41935483870967744
case acc: 0.6451612903225806
case acc: 0.4435483870967742
case acc: 0.5483870967741935
case acc: 0.6612903225806451
case acc: 0.33064516129032256
top acc: 0.9756 ::: bot acc: 0.0244
top acc: 0.8537 ::: bot acc: 0.5122
top acc: 0.8537 ::: bot acc: 0.2927
top acc: 0.9268 ::: bot acc: 0.3415
top acc: 0.2927 ::: bot acc: 0.9024
top acc: 0.9512 ::: bot acc: 0.0000
current epoch: 38
train loss is 0.081934
average val loss: 0.060973, accuracy: 0.5033
average test loss: 0.117562, accuracy: 0.5081
case acc: 0.41935483870967744
case acc: 0.6451612903225806
case acc: 0.4435483870967742
case acc: 0.5403225806451613
case acc: 0.6693548387096774
case acc: 0.33064516129032256
top acc: 0.9756 ::: bot acc: 0.0244
top acc: 0.8537 ::: bot acc: 0.5122
top acc: 0.8537 ::: bot acc: 0.2927
top acc: 0.9024 ::: bot acc: 0.3171
top acc: 0.2683 ::: bot acc: 0.9268
top acc: 0.9512 ::: bot acc: 0.0000
current epoch: 39
train loss is 0.081161
average val loss: 0.060970, accuracy: 0.5082
average test loss: 0.118712, accuracy: 0.5134
case acc: 0.4274193548387097
case acc: 0.6612903225806451
case acc: 0.4435483870967742
case acc: 0.5483870967741935
case acc: 0.6693548387096774
case acc: 0.33064516129032256
top acc: 0.9756 ::: bot acc: 0.0488
top acc: 0.8537 ::: bot acc: 0.5610
top acc: 0.8537 ::: bot acc: 0.2927
top acc: 0.9024 ::: bot acc: 0.3415
top acc: 0.2683 ::: bot acc: 0.9268
top acc: 0.9512 ::: bot acc: 0.0000
current epoch: 40
train loss is 0.080235
average val loss: 0.060920, accuracy: 0.5147
average test loss: 0.119046, accuracy: 0.5134
case acc: 0.4274193548387097
case acc: 0.6612903225806451
case acc: 0.4435483870967742
case acc: 0.5483870967741935
case acc: 0.6693548387096774
case acc: 0.33064516129032256
top acc: 0.9756 ::: bot acc: 0.0488
top acc: 0.8537 ::: bot acc: 0.5610
top acc: 0.8537 ::: bot acc: 0.2927
top acc: 0.9024 ::: bot acc: 0.3415
top acc: 0.2683 ::: bot acc: 0.9268
top acc: 0.9512 ::: bot acc: 0.0000
current epoch: 41
train loss is 0.080195
average val loss: 0.061262, accuracy: 0.5131
average test loss: 0.120867, accuracy: 0.5081
case acc: 0.41935483870967744
case acc: 0.6532258064516129
case acc: 0.45161290322580644
case acc: 0.532258064516129
case acc: 0.6612903225806451
case acc: 0.33064516129032256
top acc: 0.9756 ::: bot acc: 0.0244
top acc: 0.8537 ::: bot acc: 0.5366
top acc: 0.8780 ::: bot acc: 0.2927
top acc: 0.9024 ::: bot acc: 0.2927
top acc: 0.2683 ::: bot acc: 0.9268
top acc: 0.9512 ::: bot acc: 0.0000
current epoch: 42
train loss is 0.079486
average val loss: 0.061311, accuracy: 0.5098
average test loss: 0.120177, accuracy: 0.5121
case acc: 0.4274193548387097
case acc: 0.6693548387096774
case acc: 0.45161290322580644
case acc: 0.532258064516129
case acc: 0.6612903225806451
case acc: 0.33064516129032256
top acc: 0.9756 ::: bot acc: 0.0488
top acc: 0.8537 ::: bot acc: 0.5610
top acc: 0.8780 ::: bot acc: 0.2927
top acc: 0.9024 ::: bot acc: 0.2927
top acc: 0.2683 ::: bot acc: 0.9268
top acc: 0.9512 ::: bot acc: 0.0000
current epoch: 43
train loss is 0.078646
average val loss: 0.061180, accuracy: 0.5147
average test loss: 0.120174, accuracy: 0.5175
case acc: 0.4274193548387097
case acc: 0.6854838709677419
case acc: 0.45161290322580644
case acc: 0.5403225806451613
case acc: 0.6693548387096774
case acc: 0.33064516129032256
top acc: 0.9756 ::: bot acc: 0.0488
top acc: 0.8537 ::: bot acc: 0.5854
top acc: 0.8780 ::: bot acc: 0.2927
top acc: 0.8780 ::: bot acc: 0.3171
top acc: 0.2683 ::: bot acc: 0.9268
top acc: 0.9512 ::: bot acc: 0.0000
current epoch: 44
train loss is 0.078678
average val loss: 0.061638, accuracy: 0.5114
average test loss: 0.122783, accuracy: 0.5161
case acc: 0.4274193548387097
case acc: 0.6774193548387096
case acc: 0.45161290322580644
case acc: 0.532258064516129
case acc: 0.6774193548387096
case acc: 0.33064516129032256
top acc: 0.9756 ::: bot acc: 0.0488
top acc: 0.8537 ::: bot acc: 0.5610
top acc: 0.8780 ::: bot acc: 0.2927
top acc: 0.9024 ::: bot acc: 0.2927
top acc: 0.2927 ::: bot acc: 0.9268
top acc: 0.9512 ::: bot acc: 0.0000
current epoch: 45
train loss is 0.077948
average val loss: 0.061697, accuracy: 0.5196
average test loss: 0.122327, accuracy: 0.5188
case acc: 0.4274193548387097
case acc: 0.6854838709677419
case acc: 0.45161290322580644
case acc: 0.5483870967741935
case acc: 0.6693548387096774
case acc: 0.33064516129032256
top acc: 0.9756 ::: bot acc: 0.0488
top acc: 0.8537 ::: bot acc: 0.5854
top acc: 0.8780 ::: bot acc: 0.2927
top acc: 0.9024 ::: bot acc: 0.2927
top acc: 0.2683 ::: bot acc: 0.9268
top acc: 0.9512 ::: bot acc: 0.0000
current epoch: 46
train loss is 0.077075
average val loss: 0.062010, accuracy: 0.5082
average test loss: 0.123860, accuracy: 0.5215
case acc: 0.4274193548387097
case acc: 0.6854838709677419
case acc: 0.45161290322580644
case acc: 0.5564516129032258
case acc: 0.6774193548387096
case acc: 0.33064516129032256
top acc: 0.9756 ::: bot acc: 0.0488
top acc: 0.8537 ::: bot acc: 0.5854
top acc: 0.8780 ::: bot acc: 0.2927
top acc: 0.9024 ::: bot acc: 0.3171
top acc: 0.2927 ::: bot acc: 0.9268
top acc: 0.9512 ::: bot acc: 0.0000
current epoch: 47
train loss is 0.076687
average val loss: 0.062059, accuracy: 0.5163
average test loss: 0.123993, accuracy: 0.5202
case acc: 0.4274193548387097
case acc: 0.6774193548387096
case acc: 0.4435483870967742
case acc: 0.5725806451612904
case acc: 0.6693548387096774
case acc: 0.33064516129032256
top acc: 0.9756 ::: bot acc: 0.0488
top acc: 0.8537 ::: bot acc: 0.5610
top acc: 0.8780 ::: bot acc: 0.2683
top acc: 0.9024 ::: bot acc: 0.3171
top acc: 0.2683 ::: bot acc: 0.9268
top acc: 0.9512 ::: bot acc: 0.0000
current epoch: 48
train loss is 0.075927
average val loss: 0.062474, accuracy: 0.5049
average test loss: 0.126121, accuracy: 0.5188
case acc: 0.4274193548387097
case acc: 0.6774193548387096
case acc: 0.4435483870967742
case acc: 0.5645161290322581
case acc: 0.6693548387096774
case acc: 0.33064516129032256
top acc: 0.9756 ::: bot acc: 0.0488
top acc: 0.8537 ::: bot acc: 0.5610
top acc: 0.8780 ::: bot acc: 0.2683
top acc: 0.9024 ::: bot acc: 0.3171
top acc: 0.2683 ::: bot acc: 0.9268
top acc: 0.9512 ::: bot acc: 0.0000
current epoch: 49
train loss is 0.075610
average val loss: 0.062491, accuracy: 0.5114
average test loss: 0.126130, accuracy: 0.5228
case acc: 0.4274193548387097
case acc: 0.6774193548387096
case acc: 0.45161290322580644
case acc: 0.5725806451612904
case acc: 0.6774193548387096
case acc: 0.33064516129032256
top acc: 0.9756 ::: bot acc: 0.0488
top acc: 0.8537 ::: bot acc: 0.5610
top acc: 0.9024 ::: bot acc: 0.2683
top acc: 0.9024 ::: bot acc: 0.3171
top acc: 0.2683 ::: bot acc: 0.9512
top acc: 0.9512 ::: bot acc: 0.0000
current epoch: 50
train loss is 0.075113
average val loss: 0.062583, accuracy: 0.5114
average test loss: 0.126820, accuracy: 0.5215
case acc: 0.4274193548387097
case acc: 0.6774193548387096
case acc: 0.45161290322580644
case acc: 0.5645161290322581
case acc: 0.6774193548387096
case acc: 0.33064516129032256
top acc: 0.9756 ::: bot acc: 0.0488
top acc: 0.8537 ::: bot acc: 0.5610
top acc: 0.9024 ::: bot acc: 0.2683
top acc: 0.9024 ::: bot acc: 0.3171
top acc: 0.2683 ::: bot acc: 0.9512
top acc: 0.9512 ::: bot acc: 0.0000
LME_Co_Spot
Before Load Data
['2010-07-01', '2015-07-01', '2016-01-01']
0.02991760374030773
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Co_Spot']
#####################remove_unused_columns_v4#####################
target LME_Co
Index(['LME_Co_Spot', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low',
       'LME_Co_Close', 'LME_Co_Spot_EMA12', 'LME_Co_Spot_WMA12',
       'LME_Co_Spot_EMA26', 'LME_Co_Spot_WMA26', 'LME_Co_Spot_EMA40',
       'LME_Co_Spot_WMA40', 'LME_Co_Spot_EMA65', 'LME_Co_Spot_WMA65',
       'LME_Co_Spot_EMA125', 'LME_Co_Spot_WMA125', 'LME_Co_Spot_bollinger5',
       'LME_Co_Spot_bollinger10', 'LME_Co_Spot_bollinger15',
       'LME_Co_Spot_bollinger20', 'LME_Co_Spot_bollinger30',
       'LME_Co_Spot_bollinger65', 'LME_Co_Spot_Mom5', 'LME_Co_Spot_Mom10',
       'LME_Co_Spot_Mom15', 'LME_Co_Spot_Mom26', 'LME_Co_Spot_Mom40',
       'LME_Co_Spot_Mom65', 'LME_Co_Spot_Mom125', 'LME_Co_Spot_PPO12',
       'LME_Co_Spot_PPO22', 'LME_Co_Spot_RSI14', 'LME_Co_Spot_RSI26',
       'LME_Co_Spot_RSI40', 'LME_Co_Spot_RSI54', 'LME_Co_Spot_RSI125',
       'LME_Co_Close_EMA12', 'LME_Co_Close_WMA12', 'LME_Co_Close_EMA26',
       'LME_Co_Close_WMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_WMA40',
       'LME_Co_Close_EMA65', 'LME_Co_Close_WMA65', 'LME_Co_Close_EMA125',
       'LME_Co_Close_WMA125', 'LME_Co_Close_bollinger5',
       'LME_Co_Close_bollinger10', 'LME_Co_Close_bollinger15',
       'LME_Co_Close_bollinger20', 'LME_Co_Close_bollinger30',
       'LME_Co_Close_bollinger65', 'LME_Co_Close_Mom5', 'LME_Co_Close_Mom10',
       'LME_Co_Close_Mom15', 'LME_Co_Close_Mom26', 'LME_Co_Close_Mom40',
       'LME_Co_Close_Mom65', 'LME_Co_Close_Mom125', 'LME_Co_Close_PPO12',
       'LME_Co_Close_PPO22', 'LME_Co_Close_RSI14', 'LME_Co_Close_RSI26',
       'LME_Co_Close_RSI40', 'LME_Co_Close_RSI54', 'LME_Co_Close_RSI125',
       'LME_Co_PVT', 'LME_Co_divPVT', 'LME_Co_NATR14', 'LME_Co_NATR26',
       'LME_Co_NATR65', 'LME_Co_NATR125', 'LME_Co_CCI12', 'LME_Co_CCI26',
       'LME_Co_CCI40', 'LME_Co_CCI65', 'LME_Co_CCI125', 'LME_Co_VBM12',
       'LME_Co_VBM22', 'LME_Co_ADX14', 'LME_Co_ADX26', 'LME_Co_ADX40',
       'LME_Co_ADX54', 'LME_Co_ADX125', 'LME_Co_SAR'],
      dtype='object')
LME_Al_Spot
Before Load Data
['2010-07-01', '2015-07-01', '2016-01-01']
0.027862107915306612
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Al_Spot']
#####################remove_unused_columns_v4#####################
target LME_Al
Index(['LME_Al_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low',
       'LME_Al_Close', 'LME_Al_Spot_EMA12', 'LME_Al_Spot_WMA12',
       'LME_Al_Spot_EMA26', 'LME_Al_Spot_WMA26', 'LME_Al_Spot_EMA40',
       'LME_Al_Spot_WMA40', 'LME_Al_Spot_EMA65', 'LME_Al_Spot_WMA65',
       'LME_Al_Spot_EMA125', 'LME_Al_Spot_WMA125', 'LME_Al_Spot_bollinger5',
       'LME_Al_Spot_bollinger10', 'LME_Al_Spot_bollinger15',
       'LME_Al_Spot_bollinger20', 'LME_Al_Spot_bollinger30',
       'LME_Al_Spot_bollinger65', 'LME_Al_Spot_Mom5', 'LME_Al_Spot_Mom10',
       'LME_Al_Spot_Mom15', 'LME_Al_Spot_Mom26', 'LME_Al_Spot_Mom40',
       'LME_Al_Spot_Mom65', 'LME_Al_Spot_Mom125', 'LME_Al_Spot_PPO12',
       'LME_Al_Spot_PPO22', 'LME_Al_Spot_RSI14', 'LME_Al_Spot_RSI26',
       'LME_Al_Spot_RSI40', 'LME_Al_Spot_RSI54', 'LME_Al_Spot_RSI125',
       'LME_Al_Close_EMA12', 'LME_Al_Close_WMA12', 'LME_Al_Close_EMA26',
       'LME_Al_Close_WMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_WMA40',
       'LME_Al_Close_EMA65', 'LME_Al_Close_WMA65', 'LME_Al_Close_EMA125',
       'LME_Al_Close_WMA125', 'LME_Al_Close_bollinger5',
       'LME_Al_Close_bollinger10', 'LME_Al_Close_bollinger15',
       'LME_Al_Close_bollinger20', 'LME_Al_Close_bollinger30',
       'LME_Al_Close_bollinger65', 'LME_Al_Close_Mom5', 'LME_Al_Close_Mom10',
       'LME_Al_Close_Mom15', 'LME_Al_Close_Mom26', 'LME_Al_Close_Mom40',
       'LME_Al_Close_Mom65', 'LME_Al_Close_Mom125', 'LME_Al_Close_PPO12',
       'LME_Al_Close_PPO22', 'LME_Al_Close_RSI14', 'LME_Al_Close_RSI26',
       'LME_Al_Close_RSI40', 'LME_Al_Close_RSI54', 'LME_Al_Close_RSI125',
       'LME_Al_PVT', 'LME_Al_divPVT', 'LME_Al_NATR14', 'LME_Al_NATR26',
       'LME_Al_NATR65', 'LME_Al_NATR125', 'LME_Al_CCI12', 'LME_Al_CCI26',
       'LME_Al_CCI40', 'LME_Al_CCI65', 'LME_Al_CCI125', 'LME_Al_VBM12',
       'LME_Al_VBM22', 'LME_Al_ADX14', 'LME_Al_ADX26', 'LME_Al_ADX40',
       'LME_Al_ADX54', 'LME_Al_ADX125', 'LME_Al_SAR'],
      dtype='object')
LME_Le_Spot
Before Load Data
['2010-07-01', '2015-07-01', '2016-01-01']
0.03801151778803025
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Le_Spot']
#####################remove_unused_columns_v4#####################
target LME_Le
Index(['LME_Le_Spot', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low',
       'LME_Le_Close', 'LME_Le_Spot_EMA12', 'LME_Le_Spot_WMA12',
       'LME_Le_Spot_EMA26', 'LME_Le_Spot_WMA26', 'LME_Le_Spot_EMA40',
       'LME_Le_Spot_WMA40', 'LME_Le_Spot_EMA65', 'LME_Le_Spot_WMA65',
       'LME_Le_Spot_EMA125', 'LME_Le_Spot_WMA125', 'LME_Le_Spot_bollinger5',
       'LME_Le_Spot_bollinger10', 'LME_Le_Spot_bollinger15',
       'LME_Le_Spot_bollinger20', 'LME_Le_Spot_bollinger30',
       'LME_Le_Spot_bollinger65', 'LME_Le_Spot_Mom5', 'LME_Le_Spot_Mom10',
       'LME_Le_Spot_Mom15', 'LME_Le_Spot_Mom26', 'LME_Le_Spot_Mom40',
       'LME_Le_Spot_Mom65', 'LME_Le_Spot_Mom125', 'LME_Le_Spot_PPO12',
       'LME_Le_Spot_PPO22', 'LME_Le_Spot_RSI14', 'LME_Le_Spot_RSI26',
       'LME_Le_Spot_RSI40', 'LME_Le_Spot_RSI54', 'LME_Le_Spot_RSI125',
       'LME_Le_Close_EMA12', 'LME_Le_Close_WMA12', 'LME_Le_Close_EMA26',
       'LME_Le_Close_WMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_WMA40',
       'LME_Le_Close_EMA65', 'LME_Le_Close_WMA65', 'LME_Le_Close_EMA125',
       'LME_Le_Close_WMA125', 'LME_Le_Close_bollinger5',
       'LME_Le_Close_bollinger10', 'LME_Le_Close_bollinger15',
       'LME_Le_Close_bollinger20', 'LME_Le_Close_bollinger30',
       'LME_Le_Close_bollinger65', 'LME_Le_Close_Mom5', 'LME_Le_Close_Mom10',
       'LME_Le_Close_Mom15', 'LME_Le_Close_Mom26', 'LME_Le_Close_Mom40',
       'LME_Le_Close_Mom65', 'LME_Le_Close_Mom125', 'LME_Le_Close_PPO12',
       'LME_Le_Close_PPO22', 'LME_Le_Close_RSI14', 'LME_Le_Close_RSI26',
       'LME_Le_Close_RSI40', 'LME_Le_Close_RSI54', 'LME_Le_Close_RSI125',
       'LME_Le_PVT', 'LME_Le_divPVT', 'LME_Le_NATR14', 'LME_Le_NATR26',
       'LME_Le_NATR65', 'LME_Le_NATR125', 'LME_Le_CCI12', 'LME_Le_CCI26',
       'LME_Le_CCI40', 'LME_Le_CCI65', 'LME_Le_CCI125', 'LME_Le_VBM12',
       'LME_Le_VBM22', 'LME_Le_ADX14', 'LME_Le_ADX26', 'LME_Le_ADX40',
       'LME_Le_ADX54', 'LME_Le_ADX125', 'LME_Le_SAR'],
      dtype='object')
LME_Ni_Spot
Before Load Data
['2010-07-01', '2015-07-01', '2016-01-01']
0.0388443333878017
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Ni_Spot']
#####################remove_unused_columns_v4#####################
target LME_Ni
Index(['LME_Ni_Spot', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low',
       'LME_Ni_Close', 'LME_Ni_Spot_EMA12', 'LME_Ni_Spot_WMA12',
       'LME_Ni_Spot_EMA26', 'LME_Ni_Spot_WMA26', 'LME_Ni_Spot_EMA40',
       'LME_Ni_Spot_WMA40', 'LME_Ni_Spot_EMA65', 'LME_Ni_Spot_WMA65',
       'LME_Ni_Spot_EMA125', 'LME_Ni_Spot_WMA125', 'LME_Ni_Spot_bollinger5',
       'LME_Ni_Spot_bollinger10', 'LME_Ni_Spot_bollinger15',
       'LME_Ni_Spot_bollinger20', 'LME_Ni_Spot_bollinger30',
       'LME_Ni_Spot_bollinger65', 'LME_Ni_Spot_Mom5', 'LME_Ni_Spot_Mom10',
       'LME_Ni_Spot_Mom15', 'LME_Ni_Spot_Mom26', 'LME_Ni_Spot_Mom40',
       'LME_Ni_Spot_Mom65', 'LME_Ni_Spot_Mom125', 'LME_Ni_Spot_PPO12',
       'LME_Ni_Spot_PPO22', 'LME_Ni_Spot_RSI14', 'LME_Ni_Spot_RSI26',
       'LME_Ni_Spot_RSI40', 'LME_Ni_Spot_RSI54', 'LME_Ni_Spot_RSI125',
       'LME_Ni_Close_EMA12', 'LME_Ni_Close_WMA12', 'LME_Ni_Close_EMA26',
       'LME_Ni_Close_WMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_WMA40',
       'LME_Ni_Close_EMA65', 'LME_Ni_Close_WMA65', 'LME_Ni_Close_EMA125',
       'LME_Ni_Close_WMA125', 'LME_Ni_Close_bollinger5',
       'LME_Ni_Close_bollinger10', 'LME_Ni_Close_bollinger15',
       'LME_Ni_Close_bollinger20', 'LME_Ni_Close_bollinger30',
       'LME_Ni_Close_bollinger65', 'LME_Ni_Close_Mom5', 'LME_Ni_Close_Mom10',
       'LME_Ni_Close_Mom15', 'LME_Ni_Close_Mom26', 'LME_Ni_Close_Mom40',
       'LME_Ni_Close_Mom65', 'LME_Ni_Close_Mom125', 'LME_Ni_Close_PPO12',
       'LME_Ni_Close_PPO22', 'LME_Ni_Close_RSI14', 'LME_Ni_Close_RSI26',
       'LME_Ni_Close_RSI40', 'LME_Ni_Close_RSI54', 'LME_Ni_Close_RSI125',
       'LME_Ni_PVT', 'LME_Ni_divPVT', 'LME_Ni_NATR14', 'LME_Ni_NATR26',
       'LME_Ni_NATR65', 'LME_Ni_NATR125', 'LME_Ni_CCI12', 'LME_Ni_CCI26',
       'LME_Ni_CCI40', 'LME_Ni_CCI65', 'LME_Ni_CCI125', 'LME_Ni_VBM12',
       'LME_Ni_VBM22', 'LME_Ni_ADX14', 'LME_Ni_ADX26', 'LME_Ni_ADX40',
       'LME_Ni_ADX54', 'LME_Ni_ADX125', 'LME_Ni_SAR'],
      dtype='object')
LME_Zi_Spot
Before Load Data
['2010-07-01', '2015-07-01', '2016-01-01']
0.035238518075965806
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Zi_Spot']
#####################remove_unused_columns_v4#####################
target LME_Zi
Index(['LME_Zi_Spot', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low',
       'LME_Zi_Close', 'LME_Zi_Spot_EMA12', 'LME_Zi_Spot_WMA12',
       'LME_Zi_Spot_EMA26', 'LME_Zi_Spot_WMA26', 'LME_Zi_Spot_EMA40',
       'LME_Zi_Spot_WMA40', 'LME_Zi_Spot_EMA65', 'LME_Zi_Spot_WMA65',
       'LME_Zi_Spot_EMA125', 'LME_Zi_Spot_WMA125', 'LME_Zi_Spot_bollinger5',
       'LME_Zi_Spot_bollinger10', 'LME_Zi_Spot_bollinger15',
       'LME_Zi_Spot_bollinger20', 'LME_Zi_Spot_bollinger30',
       'LME_Zi_Spot_bollinger65', 'LME_Zi_Spot_Mom5', 'LME_Zi_Spot_Mom10',
       'LME_Zi_Spot_Mom15', 'LME_Zi_Spot_Mom26', 'LME_Zi_Spot_Mom40',
       'LME_Zi_Spot_Mom65', 'LME_Zi_Spot_Mom125', 'LME_Zi_Spot_PPO12',
       'LME_Zi_Spot_PPO22', 'LME_Zi_Spot_RSI14', 'LME_Zi_Spot_RSI26',
       'LME_Zi_Spot_RSI40', 'LME_Zi_Spot_RSI54', 'LME_Zi_Spot_RSI125',
       'LME_Zi_Close_EMA12', 'LME_Zi_Close_WMA12', 'LME_Zi_Close_EMA26',
       'LME_Zi_Close_WMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_WMA40',
       'LME_Zi_Close_EMA65', 'LME_Zi_Close_WMA65', 'LME_Zi_Close_EMA125',
       'LME_Zi_Close_WMA125', 'LME_Zi_Close_bollinger5',
       'LME_Zi_Close_bollinger10', 'LME_Zi_Close_bollinger15',
       'LME_Zi_Close_bollinger20', 'LME_Zi_Close_bollinger30',
       'LME_Zi_Close_bollinger65', 'LME_Zi_Close_Mom5', 'LME_Zi_Close_Mom10',
       'LME_Zi_Close_Mom15', 'LME_Zi_Close_Mom26', 'LME_Zi_Close_Mom40',
       'LME_Zi_Close_Mom65', 'LME_Zi_Close_Mom125', 'LME_Zi_Close_PPO12',
       'LME_Zi_Close_PPO22', 'LME_Zi_Close_RSI14', 'LME_Zi_Close_RSI26',
       'LME_Zi_Close_RSI40', 'LME_Zi_Close_RSI54', 'LME_Zi_Close_RSI125',
       'LME_Zi_PVT', 'LME_Zi_divPVT', 'LME_Zi_NATR14', 'LME_Zi_NATR26',
       'LME_Zi_NATR65', 'LME_Zi_NATR125', 'LME_Zi_CCI12', 'LME_Zi_CCI26',
       'LME_Zi_CCI40', 'LME_Zi_CCI65', 'LME_Zi_CCI125', 'LME_Zi_VBM12',
       'LME_Zi_VBM22', 'LME_Zi_ADX14', 'LME_Zi_ADX26', 'LME_Zi_ADX40',
       'LME_Zi_ADX54', 'LME_Zi_ADX125', 'LME_Zi_SAR'],
      dtype='object')
LME_Ti_Spot
Before Load Data
['2010-07-01', '2015-07-01', '2016-01-01']
0.03666189867808864
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Ti_Spot']
#####################remove_unused_columns_v4#####################
target LME_Ti
Index(['LME_Ti_Spot', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low',
       'LME_Ti_Close', 'LME_Ti_Spot_EMA12', 'LME_Ti_Spot_WMA12',
       'LME_Ti_Spot_EMA26', 'LME_Ti_Spot_WMA26', 'LME_Ti_Spot_EMA40',
       'LME_Ti_Spot_WMA40', 'LME_Ti_Spot_EMA65', 'LME_Ti_Spot_WMA65',
       'LME_Ti_Spot_EMA125', 'LME_Ti_Spot_WMA125', 'LME_Ti_Spot_bollinger5',
       'LME_Ti_Spot_bollinger10', 'LME_Ti_Spot_bollinger15',
       'LME_Ti_Spot_bollinger20', 'LME_Ti_Spot_bollinger30',
       'LME_Ti_Spot_bollinger65', 'LME_Ti_Spot_Mom5', 'LME_Ti_Spot_Mom10',
       'LME_Ti_Spot_Mom15', 'LME_Ti_Spot_Mom26', 'LME_Ti_Spot_Mom40',
       'LME_Ti_Spot_Mom65', 'LME_Ti_Spot_Mom125', 'LME_Ti_Spot_PPO12',
       'LME_Ti_Spot_PPO22', 'LME_Ti_Spot_RSI14', 'LME_Ti_Spot_RSI26',
       'LME_Ti_Spot_RSI40', 'LME_Ti_Spot_RSI54', 'LME_Ti_Spot_RSI125',
       'LME_Ti_Close_EMA12', 'LME_Ti_Close_WMA12', 'LME_Ti_Close_EMA26',
       'LME_Ti_Close_WMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_WMA40',
       'LME_Ti_Close_EMA65', 'LME_Ti_Close_WMA65', 'LME_Ti_Close_EMA125',
       'LME_Ti_Close_WMA125', 'LME_Ti_Close_bollinger5',
       'LME_Ti_Close_bollinger10', 'LME_Ti_Close_bollinger15',
       'LME_Ti_Close_bollinger20', 'LME_Ti_Close_bollinger30',
       'LME_Ti_Close_bollinger65', 'LME_Ti_Close_Mom5', 'LME_Ti_Close_Mom10',
       'LME_Ti_Close_Mom15', 'LME_Ti_Close_Mom26', 'LME_Ti_Close_Mom40',
       'LME_Ti_Close_Mom65', 'LME_Ti_Close_Mom125', 'LME_Ti_Close_PPO12',
       'LME_Ti_Close_PPO22', 'LME_Ti_Close_RSI14', 'LME_Ti_Close_RSI26',
       'LME_Ti_Close_RSI40', 'LME_Ti_Close_RSI54', 'LME_Ti_Close_RSI125',
       'LME_Ti_PVT', 'LME_Ti_divPVT', 'LME_Ti_NATR14', 'LME_Ti_NATR26',
       'LME_Ti_NATR65', 'LME_Ti_NATR125', 'LME_Ti_CCI12', 'LME_Ti_CCI26',
       'LME_Ti_CCI40', 'LME_Ti_CCI65', 'LME_Ti_CCI125', 'LME_Ti_VBM12',
       'LME_Ti_VBM22', 'LME_Ti_ADX14', 'LME_Ti_ADX26', 'LME_Ti_ADX40',
       'LME_Ti_ADX54', 'LME_Ti_ADX125', 'LME_Ti_SAR'],
      dtype='object')
Dataset statistic: #examples
Train: 5460 5460 5460
7.1049705 -8.132434 2.355482 -1.8136157
Validation: 612 612 612
Testing: 774 774 774
pre-processing time: 0.0010309219360351562
the split date is 2015-07-01
net initializing with time: 0.0008757114410400391
preparing training and testing date with time: 0.002089977264404297
current epoch: 1
train loss is 0.135647
average val loss: 0.126903, accuracy: 0.4918
average test loss: 0.146955, accuracy: 0.4755
case acc: 0.3798449612403101
case acc: 0.4883720930232558
case acc: 0.4728682170542636
case acc: 0.3953488372093023
case acc: 0.6666666666666666
case acc: 0.4496124031007752
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.2791 ::: bot acc: 0.7442
top acc: 0.8837 ::: bot acc: 0.1395
top acc: 1.0000 ::: bot acc: 0.0233
top acc: 0.1628 ::: bot acc: 0.8837
top acc: 0.9070 ::: bot acc: 0.0930
current epoch: 2
train loss is 0.114657
average val loss: 0.135542, accuracy: 0.4706
average test loss: 0.166656, accuracy: 0.4367
case acc: 0.3798449612403101
case acc: 0.4108527131782946
case acc: 0.43410852713178294
case acc: 0.37209302325581395
case acc: 0.5736434108527132
case acc: 0.4496124031007752
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.7442 ::: bot acc: 0.2093
top acc: 0.9767 ::: bot acc: 0.0465
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.5814 ::: bot acc: 0.5116
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 3
train loss is 0.109252
average val loss: 0.128187, accuracy: 0.4820
average test loss: 0.156586, accuracy: 0.4548
case acc: 0.3798449612403101
case acc: 0.4263565891472868
case acc: 0.4418604651162791
case acc: 0.40310077519379844
case acc: 0.6124031007751938
case acc: 0.46511627906976744
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.6047 ::: bot acc: 0.3953
top acc: 0.8837 ::: bot acc: 0.0930
top acc: 1.0000 ::: bot acc: 0.0465
top acc: 0.6279 ::: bot acc: 0.5581
top acc: 1.0000 ::: bot acc: 0.0465
current epoch: 4
train loss is 0.105396
average val loss: 0.130766, accuracy: 0.4739
average test loss: 0.164785, accuracy: 0.4406
case acc: 0.3798449612403101
case acc: 0.4108527131782946
case acc: 0.4573643410852713
case acc: 0.3953488372093023
case acc: 0.5503875968992248
case acc: 0.4496124031007752
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.8140 ::: bot acc: 0.1395
top acc: 0.9535 ::: bot acc: 0.0930
top acc: 1.0000 ::: bot acc: 0.0465
top acc: 0.6512 ::: bot acc: 0.4884
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 5
train loss is 0.102265
average val loss: 0.126611, accuracy: 0.4722
average test loss: 0.161354, accuracy: 0.4328
case acc: 0.3798449612403101
case acc: 0.3875968992248062
case acc: 0.4263565891472868
case acc: 0.40310077519379844
case acc: 0.5581395348837209
case acc: 0.4418604651162791
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.7674 ::: bot acc: 0.1163
top acc: 0.8837 ::: bot acc: 0.0930
top acc: 1.0000 ::: bot acc: 0.0465
top acc: 0.6512 ::: bot acc: 0.5116
top acc: 0.9767 ::: bot acc: 0.0000
current epoch: 6
train loss is 0.099556
average val loss: 0.127543, accuracy: 0.4886
average test loss: 0.166207, accuracy: 0.4419
case acc: 0.3798449612403101
case acc: 0.4108527131782946
case acc: 0.4573643410852713
case acc: 0.40310077519379844
case acc: 0.5426356589147286
case acc: 0.4573643410852713
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.8372 ::: bot acc: 0.0930
top acc: 0.9535 ::: bot acc: 0.0930
top acc: 1.0000 ::: bot acc: 0.0465
top acc: 0.6744 ::: bot acc: 0.5116
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 7
train loss is 0.098269
average val loss: 0.127505, accuracy: 0.4804
average test loss: 0.169459, accuracy: 0.4341
case acc: 0.3798449612403101
case acc: 0.4186046511627907
case acc: 0.4418604651162791
case acc: 0.40310077519379844
case acc: 0.5038759689922481
case acc: 0.4573643410852713
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.8372 ::: bot acc: 0.0698
top acc: 0.9535 ::: bot acc: 0.0698
top acc: 1.0000 ::: bot acc: 0.0465
top acc: 0.6977 ::: bot acc: 0.4186
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 8
train loss is 0.095660
average val loss: 0.125535, accuracy: 0.4771
average test loss: 0.169843, accuracy: 0.4315
case acc: 0.3798449612403101
case acc: 0.4263565891472868
case acc: 0.4418604651162791
case acc: 0.3953488372093023
case acc: 0.4883720930232558
case acc: 0.4573643410852713
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.8837 ::: bot acc: 0.0465
top acc: 0.9535 ::: bot acc: 0.0698
top acc: 1.0000 ::: bot acc: 0.0233
top acc: 0.7209 ::: bot acc: 0.3953
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 9
train loss is 0.094818
average val loss: 0.123761, accuracy: 0.4804
average test loss: 0.169570, accuracy: 0.4276
case acc: 0.3798449612403101
case acc: 0.4186046511627907
case acc: 0.4418604651162791
case acc: 0.3953488372093023
case acc: 0.4728682170542636
case acc: 0.4573643410852713
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.8605 ::: bot acc: 0.0465
top acc: 0.9535 ::: bot acc: 0.0698
top acc: 1.0000 ::: bot acc: 0.0233
top acc: 0.7209 ::: bot acc: 0.3953
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 10
train loss is 0.093762
average val loss: 0.122918, accuracy: 0.4771
average test loss: 0.169872, accuracy: 0.4264
case acc: 0.3798449612403101
case acc: 0.4186046511627907
case acc: 0.4418604651162791
case acc: 0.40310077519379844
case acc: 0.4573643410852713
case acc: 0.4573643410852713
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.8837 ::: bot acc: 0.0465
top acc: 0.9535 ::: bot acc: 0.0698
top acc: 1.0000 ::: bot acc: 0.0465
top acc: 0.7209 ::: bot acc: 0.3721
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 11
train loss is 0.091589
average val loss: 0.120665, accuracy: 0.4771
average test loss: 0.167582, accuracy: 0.4238
case acc: 0.3798449612403101
case acc: 0.4186046511627907
case acc: 0.4263565891472868
case acc: 0.40310077519379844
case acc: 0.46511627906976744
case acc: 0.4496124031007752
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.8837 ::: bot acc: 0.0465
top acc: 0.9302 ::: bot acc: 0.0698
top acc: 1.0000 ::: bot acc: 0.0465
top acc: 0.7209 ::: bot acc: 0.3953
top acc: 0.9767 ::: bot acc: 0.0000
current epoch: 12
train loss is 0.089860
average val loss: 0.118845, accuracy: 0.4755
average test loss: 0.166094, accuracy: 0.4251
case acc: 0.3798449612403101
case acc: 0.4186046511627907
case acc: 0.4418604651162791
case acc: 0.40310077519379844
case acc: 0.4573643410852713
case acc: 0.4496124031007752
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.8837 ::: bot acc: 0.0465
top acc: 0.9302 ::: bot acc: 0.0930
top acc: 1.0000 ::: bot acc: 0.0465
top acc: 0.7209 ::: bot acc: 0.3721
top acc: 0.9767 ::: bot acc: 0.0000
current epoch: 13
train loss is 0.089530
average val loss: 0.118022, accuracy: 0.4755
average test loss: 0.166917, accuracy: 0.4302
case acc: 0.3798449612403101
case acc: 0.4418604651162791
case acc: 0.4496124031007752
case acc: 0.40310077519379844
case acc: 0.4573643410852713
case acc: 0.4496124031007752
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.8837 ::: bot acc: 0.1163
top acc: 0.9302 ::: bot acc: 0.0930
top acc: 1.0000 ::: bot acc: 0.0465
top acc: 0.7209 ::: bot acc: 0.3721
top acc: 0.9767 ::: bot acc: 0.0000
current epoch: 14
train loss is 0.087691
average val loss: 0.117123, accuracy: 0.4771
average test loss: 0.168235, accuracy: 0.4328
case acc: 0.3798449612403101
case acc: 0.4418604651162791
case acc: 0.4573643410852713
case acc: 0.40310077519379844
case acc: 0.46511627906976744
case acc: 0.4496124031007752
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.8837 ::: bot acc: 0.1163
top acc: 0.9302 ::: bot acc: 0.0930
top acc: 1.0000 ::: bot acc: 0.0465
top acc: 0.7442 ::: bot acc: 0.3721
top acc: 0.9767 ::: bot acc: 0.0000
current epoch: 15
train loss is 0.086977
average val loss: 0.115405, accuracy: 0.4820
average test loss: 0.166754, accuracy: 0.4315
case acc: 0.3798449612403101
case acc: 0.4418604651162791
case acc: 0.4418604651162791
case acc: 0.3953488372093023
case acc: 0.4806201550387597
case acc: 0.4496124031007752
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.8837 ::: bot acc: 0.1163
top acc: 0.8837 ::: bot acc: 0.0930
top acc: 1.0000 ::: bot acc: 0.0465
top acc: 0.7907 ::: bot acc: 0.3721
top acc: 0.9767 ::: bot acc: 0.0000
current epoch: 16
train loss is 0.086378
average val loss: 0.114833, accuracy: 0.4820
average test loss: 0.166951, accuracy: 0.4315
case acc: 0.3875968992248062
case acc: 0.4418604651162791
case acc: 0.4418604651162791
case acc: 0.3875968992248062
case acc: 0.4728682170542636
case acc: 0.4573643410852713
top acc: 1.0000 ::: bot acc: 0.0233
top acc: 0.8837 ::: bot acc: 0.1163
top acc: 0.8837 ::: bot acc: 0.1163
top acc: 1.0000 ::: bot acc: 0.0465
top acc: 0.7907 ::: bot acc: 0.3721
top acc: 0.9767 ::: bot acc: 0.0233
current epoch: 17
train loss is 0.085008
average val loss: 0.114424, accuracy: 0.4869
average test loss: 0.168025, accuracy: 0.4289
case acc: 0.3798449612403101
case acc: 0.4418604651162791
case acc: 0.43410852713178294
case acc: 0.3875968992248062
case acc: 0.4728682170542636
case acc: 0.4573643410852713
top acc: 0.9767 ::: bot acc: 0.0233
top acc: 0.8837 ::: bot acc: 0.1163
top acc: 0.8605 ::: bot acc: 0.1163
top acc: 1.0000 ::: bot acc: 0.0465
top acc: 0.7907 ::: bot acc: 0.3721
top acc: 0.9767 ::: bot acc: 0.0233
current epoch: 18
train loss is 0.084403
average val loss: 0.114316, accuracy: 0.4837
average test loss: 0.170691, accuracy: 0.4251
case acc: 0.3798449612403101
case acc: 0.4418604651162791
case acc: 0.4418604651162791
case acc: 0.3875968992248062
case acc: 0.4496124031007752
case acc: 0.4496124031007752
top acc: 0.9767 ::: bot acc: 0.0233
top acc: 0.8837 ::: bot acc: 0.1163
top acc: 0.8837 ::: bot acc: 0.1163
top acc: 1.0000 ::: bot acc: 0.0465
top acc: 0.7907 ::: bot acc: 0.3721
top acc: 0.9767 ::: bot acc: 0.0233
current epoch: 19
train loss is 0.082360
average val loss: 0.112182, accuracy: 0.4918
average test loss: 0.168592, accuracy: 0.4264
case acc: 0.3798449612403101
case acc: 0.4496124031007752
case acc: 0.4496124031007752
case acc: 0.3798449612403101
case acc: 0.4496124031007752
case acc: 0.4496124031007752
top acc: 0.9767 ::: bot acc: 0.0233
top acc: 0.8837 ::: bot acc: 0.1395
top acc: 0.8372 ::: bot acc: 0.1395
top acc: 0.9767 ::: bot acc: 0.0465
top acc: 0.7907 ::: bot acc: 0.3721
top acc: 0.9767 ::: bot acc: 0.0233
current epoch: 20
train loss is 0.083388
average val loss: 0.112062, accuracy: 0.4935
average test loss: 0.170290, accuracy: 0.4238
case acc: 0.3798449612403101
case acc: 0.4418604651162791
case acc: 0.4418604651162791
case acc: 0.3798449612403101
case acc: 0.4496124031007752
case acc: 0.4496124031007752
top acc: 0.9767 ::: bot acc: 0.0233
top acc: 0.8837 ::: bot acc: 0.1163
top acc: 0.8372 ::: bot acc: 0.1395
top acc: 0.9767 ::: bot acc: 0.0465
top acc: 0.8140 ::: bot acc: 0.3721
top acc: 0.9767 ::: bot acc: 0.0233
current epoch: 21
train loss is 0.082556
average val loss: 0.110549, accuracy: 0.4935
average test loss: 0.168505, accuracy: 0.4264
case acc: 0.3798449612403101
case acc: 0.46511627906976744
case acc: 0.4496124031007752
case acc: 0.3798449612403101
case acc: 0.43410852713178294
case acc: 0.4496124031007752
top acc: 0.9767 ::: bot acc: 0.0233
top acc: 0.9070 ::: bot acc: 0.1395
top acc: 0.8372 ::: bot acc: 0.1860
top acc: 0.9767 ::: bot acc: 0.0465
top acc: 0.8140 ::: bot acc: 0.3256
top acc: 0.9535 ::: bot acc: 0.0233
current epoch: 22
train loss is 0.081173
average val loss: 0.109616, accuracy: 0.5000
average test loss: 0.166118, accuracy: 0.4328
case acc: 0.3798449612403101
case acc: 0.46511627906976744
case acc: 0.49612403100775193
case acc: 0.37209302325581395
case acc: 0.4418604651162791
case acc: 0.4418604651162791
top acc: 0.9767 ::: bot acc: 0.0233
top acc: 0.8837 ::: bot acc: 0.1628
top acc: 0.8140 ::: bot acc: 0.2791
top acc: 0.9535 ::: bot acc: 0.0465
top acc: 0.8140 ::: bot acc: 0.3488
top acc: 0.9535 ::: bot acc: 0.0233
current epoch: 23
train loss is 0.080574
average val loss: 0.109154, accuracy: 0.4967
average test loss: 0.165685, accuracy: 0.4341
case acc: 0.3875968992248062
case acc: 0.4728682170542636
case acc: 0.49612403100775193
case acc: 0.37209302325581395
case acc: 0.4418604651162791
case acc: 0.43410852713178294
top acc: 0.9767 ::: bot acc: 0.0465
top acc: 0.8837 ::: bot acc: 0.1628
top acc: 0.7907 ::: bot acc: 0.2791
top acc: 0.9302 ::: bot acc: 0.0465
top acc: 0.8140 ::: bot acc: 0.3488
top acc: 0.9302 ::: bot acc: 0.0233
current epoch: 24
train loss is 0.078950
average val loss: 0.108864, accuracy: 0.5016
average test loss: 0.166284, accuracy: 0.4419
case acc: 0.3953488372093023
case acc: 0.4728682170542636
case acc: 0.5348837209302325
case acc: 0.3798449612403101
case acc: 0.43410852713178294
case acc: 0.43410852713178294
top acc: 0.9767 ::: bot acc: 0.0465
top acc: 0.8605 ::: bot acc: 0.1860
top acc: 0.7907 ::: bot acc: 0.3023
top acc: 0.9302 ::: bot acc: 0.0698
top acc: 0.8140 ::: bot acc: 0.3256
top acc: 0.9302 ::: bot acc: 0.0233
current epoch: 25
train loss is 0.078667
average val loss: 0.109581, accuracy: 0.5000
average test loss: 0.169793, accuracy: 0.4328
case acc: 0.3875968992248062
case acc: 0.4573643410852713
case acc: 0.5116279069767442
case acc: 0.3798449612403101
case acc: 0.4263565891472868
case acc: 0.43410852713178294
top acc: 0.9767 ::: bot acc: 0.0465
top acc: 0.8837 ::: bot acc: 0.1163
top acc: 0.7907 ::: bot acc: 0.2791
top acc: 0.9302 ::: bot acc: 0.0698
top acc: 0.8140 ::: bot acc: 0.3023
top acc: 0.9302 ::: bot acc: 0.0233
current epoch: 26
train loss is 0.078517
average val loss: 0.108465, accuracy: 0.5049
average test loss: 0.168050, accuracy: 0.4432
case acc: 0.3953488372093023
case acc: 0.4806201550387597
case acc: 0.5271317829457365
case acc: 0.3798449612403101
case acc: 0.4263565891472868
case acc: 0.4496124031007752
top acc: 0.9767 ::: bot acc: 0.0465
top acc: 0.8605 ::: bot acc: 0.2093
top acc: 0.7674 ::: bot acc: 0.3256
top acc: 0.9302 ::: bot acc: 0.0930
top acc: 0.8140 ::: bot acc: 0.3023
top acc: 0.9302 ::: bot acc: 0.0698
current epoch: 27
train loss is 0.077751
average val loss: 0.107734, accuracy: 0.5049
average test loss: 0.168172, accuracy: 0.4406
case acc: 0.3953488372093023
case acc: 0.4806201550387597
case acc: 0.5116279069767442
case acc: 0.3798449612403101
case acc: 0.4263565891472868
case acc: 0.4496124031007752
top acc: 0.9535 ::: bot acc: 0.0698
top acc: 0.8605 ::: bot acc: 0.2093
top acc: 0.7209 ::: bot acc: 0.3256
top acc: 0.9070 ::: bot acc: 0.0930
top acc: 0.8140 ::: bot acc: 0.3023
top acc: 0.9070 ::: bot acc: 0.0698
current epoch: 28
train loss is 0.077222
average val loss: 0.108455, accuracy: 0.5016
average test loss: 0.171221, accuracy: 0.4341
case acc: 0.3875968992248062
case acc: 0.4728682170542636
case acc: 0.49612403100775193
case acc: 0.3798449612403101
case acc: 0.43410852713178294
case acc: 0.43410852713178294
top acc: 0.9535 ::: bot acc: 0.0465
top acc: 0.8837 ::: bot acc: 0.1628
top acc: 0.7209 ::: bot acc: 0.3256
top acc: 0.9070 ::: bot acc: 0.0930
top acc: 0.8372 ::: bot acc: 0.3023
top acc: 0.9070 ::: bot acc: 0.0465
current epoch: 29
train loss is 0.076736
average val loss: 0.106593, accuracy: 0.5163
average test loss: 0.165460, accuracy: 0.4432
case acc: 0.3953488372093023
case acc: 0.4883720930232558
case acc: 0.5116279069767442
case acc: 0.3798449612403101
case acc: 0.4263565891472868
case acc: 0.4573643410852713
top acc: 0.9070 ::: bot acc: 0.0930
top acc: 0.8605 ::: bot acc: 0.2558
top acc: 0.6744 ::: bot acc: 0.3721
top acc: 0.8605 ::: bot acc: 0.1395
top acc: 0.8140 ::: bot acc: 0.3023
top acc: 0.9070 ::: bot acc: 0.0930
current epoch: 30
train loss is 0.075940
average val loss: 0.107674, accuracy: 0.5082
average test loss: 0.168593, accuracy: 0.4393
case acc: 0.3953488372093023
case acc: 0.4728682170542636
case acc: 0.5116279069767442
case acc: 0.3798449612403101
case acc: 0.43410852713178294
case acc: 0.4418604651162791
top acc: 0.9302 ::: bot acc: 0.0698
top acc: 0.8605 ::: bot acc: 0.1860
top acc: 0.6744 ::: bot acc: 0.3488
top acc: 0.8837 ::: bot acc: 0.1163
top acc: 0.8372 ::: bot acc: 0.3023
top acc: 0.9070 ::: bot acc: 0.0698
current epoch: 31
train loss is 0.075551
average val loss: 0.106680, accuracy: 0.5114
average test loss: 0.166759, accuracy: 0.4380
case acc: 0.3875968992248062
case acc: 0.4728682170542636
case acc: 0.5038759689922481
case acc: 0.3798449612403101
case acc: 0.43410852713178294
case acc: 0.4496124031007752
top acc: 0.9302 ::: bot acc: 0.0698
top acc: 0.8605 ::: bot acc: 0.2093
top acc: 0.6512 ::: bot acc: 0.3721
top acc: 0.8837 ::: bot acc: 0.1163
top acc: 0.8372 ::: bot acc: 0.3023
top acc: 0.9070 ::: bot acc: 0.0698
current epoch: 32
train loss is 0.075027
average val loss: 0.106682, accuracy: 0.5098
average test loss: 0.169482, accuracy: 0.4444
case acc: 0.3953488372093023
case acc: 0.4728682170542636
case acc: 0.5193798449612403
case acc: 0.3875968992248062
case acc: 0.4263565891472868
case acc: 0.46511627906976744
top acc: 0.9302 ::: bot acc: 0.0930
top acc: 0.8605 ::: bot acc: 0.2093
top acc: 0.6512 ::: bot acc: 0.3953
top acc: 0.8837 ::: bot acc: 0.1395
top acc: 0.8372 ::: bot acc: 0.3023
top acc: 0.9070 ::: bot acc: 0.1163
current epoch: 33
train loss is 0.073231
average val loss: 0.106955, accuracy: 0.5147
average test loss: 0.174833, accuracy: 0.4367
case acc: 0.4108527131782946
case acc: 0.4728682170542636
case acc: 0.49612403100775193
case acc: 0.3643410852713178
case acc: 0.4108527131782946
case acc: 0.46511627906976744
top acc: 0.9535 ::: bot acc: 0.0930
top acc: 0.8605 ::: bot acc: 0.2093
top acc: 0.6279 ::: bot acc: 0.3953
top acc: 0.8837 ::: bot acc: 0.0930
top acc: 0.8372 ::: bot acc: 0.3023
top acc: 0.9070 ::: bot acc: 0.1163
current epoch: 34
train loss is 0.073297
average val loss: 0.106563, accuracy: 0.5229
average test loss: 0.174314, accuracy: 0.4354
case acc: 0.3953488372093023
case acc: 0.4728682170542636
case acc: 0.4883720930232558
case acc: 0.3798449612403101
case acc: 0.4108527131782946
case acc: 0.46511627906976744
top acc: 0.9070 ::: bot acc: 0.1163
top acc: 0.8605 ::: bot acc: 0.2093
top acc: 0.5814 ::: bot acc: 0.3953
top acc: 0.8605 ::: bot acc: 0.1163
top acc: 0.8372 ::: bot acc: 0.3023
top acc: 0.9070 ::: bot acc: 0.1163
current epoch: 35
train loss is 0.072566
average val loss: 0.106779, accuracy: 0.5147
average test loss: 0.172316, accuracy: 0.4393
case acc: 0.40310077519379844
case acc: 0.4728682170542636
case acc: 0.4883720930232558
case acc: 0.3798449612403101
case acc: 0.4186046511627907
case acc: 0.4728682170542636
top acc: 0.8605 ::: bot acc: 0.1628
top acc: 0.8605 ::: bot acc: 0.2093
top acc: 0.5814 ::: bot acc: 0.3953
top acc: 0.8605 ::: bot acc: 0.1163
top acc: 0.8372 ::: bot acc: 0.3023
top acc: 0.9070 ::: bot acc: 0.1163
current epoch: 36
train loss is 0.072168
average val loss: 0.106255, accuracy: 0.5147
average test loss: 0.169621, accuracy: 0.4444
case acc: 0.4186046511627907
case acc: 0.4806201550387597
case acc: 0.4883720930232558
case acc: 0.3875968992248062
case acc: 0.4263565891472868
case acc: 0.46511627906976744
top acc: 0.8605 ::: bot acc: 0.2093
top acc: 0.8605 ::: bot acc: 0.2326
top acc: 0.5814 ::: bot acc: 0.3953
top acc: 0.8605 ::: bot acc: 0.1163
top acc: 0.8372 ::: bot acc: 0.3023
top acc: 0.9070 ::: bot acc: 0.0930
current epoch: 37
train loss is 0.071840
average val loss: 0.106238, accuracy: 0.5245
average test loss: 0.171717, accuracy: 0.4419
case acc: 0.4186046511627907
case acc: 0.4806201550387597
case acc: 0.5038759689922481
case acc: 0.3798449612403101
case acc: 0.4186046511627907
case acc: 0.4496124031007752
top acc: 0.8605 ::: bot acc: 0.2093
top acc: 0.8837 ::: bot acc: 0.2326
top acc: 0.6047 ::: bot acc: 0.3953
top acc: 0.8605 ::: bot acc: 0.0930
top acc: 0.8372 ::: bot acc: 0.2791
top acc: 0.9070 ::: bot acc: 0.0698
current epoch: 38
train loss is 0.070360
average val loss: 0.106756, accuracy: 0.5163
average test loss: 0.172484, accuracy: 0.4457
case acc: 0.4263565891472868
case acc: 0.4883720930232558
case acc: 0.5038759689922481
case acc: 0.3798449612403101
case acc: 0.4186046511627907
case acc: 0.4573643410852713
top acc: 0.8605 ::: bot acc: 0.2093
top acc: 0.8837 ::: bot acc: 0.2326
top acc: 0.6047 ::: bot acc: 0.3953
top acc: 0.8605 ::: bot acc: 0.0930
top acc: 0.8140 ::: bot acc: 0.3023
top acc: 0.9070 ::: bot acc: 0.0698
current epoch: 39
train loss is 0.070427
average val loss: 0.107344, accuracy: 0.5180
average test loss: 0.175294, accuracy: 0.4444
case acc: 0.4108527131782946
case acc: 0.4883720930232558
case acc: 0.5038759689922481
case acc: 0.3798449612403101
case acc: 0.4263565891472868
case acc: 0.4573643410852713
top acc: 0.8605 ::: bot acc: 0.1628
top acc: 0.8837 ::: bot acc: 0.2326
top acc: 0.6047 ::: bot acc: 0.3953
top acc: 0.8605 ::: bot acc: 0.0930
top acc: 0.8372 ::: bot acc: 0.3023
top acc: 0.9070 ::: bot acc: 0.0698
current epoch: 40
train loss is 0.070939
average val loss: 0.106827, accuracy: 0.5229
average test loss: 0.173869, accuracy: 0.4496
case acc: 0.43410852713178294
case acc: 0.49612403100775193
case acc: 0.5038759689922481
case acc: 0.3798449612403101
case acc: 0.4263565891472868
case acc: 0.4573643410852713
top acc: 0.8605 ::: bot acc: 0.2326
top acc: 0.8837 ::: bot acc: 0.2558
top acc: 0.5814 ::: bot acc: 0.4186
top acc: 0.8605 ::: bot acc: 0.0930
top acc: 0.8372 ::: bot acc: 0.3023
top acc: 0.9070 ::: bot acc: 0.0698
current epoch: 41
train loss is 0.069719
average val loss: 0.106912, accuracy: 0.5245
average test loss: 0.172774, accuracy: 0.4509
case acc: 0.4263565891472868
case acc: 0.49612403100775193
case acc: 0.5193798449612403
case acc: 0.3875968992248062
case acc: 0.4186046511627907
case acc: 0.4573643410852713
top acc: 0.8605 ::: bot acc: 0.2093
top acc: 0.8837 ::: bot acc: 0.2558
top acc: 0.6047 ::: bot acc: 0.4186
top acc: 0.8372 ::: bot acc: 0.1395
top acc: 0.8372 ::: bot acc: 0.2791
top acc: 0.8837 ::: bot acc: 0.0930
current epoch: 42
train loss is 0.067918
average val loss: 0.105873, accuracy: 0.5229
average test loss: 0.170459, accuracy: 0.4561
case acc: 0.4573643410852713
case acc: 0.49612403100775193
case acc: 0.5038759689922481
case acc: 0.3953488372093023
case acc: 0.43410852713178294
case acc: 0.4496124031007752
top acc: 0.8372 ::: bot acc: 0.2558
top acc: 0.8372 ::: bot acc: 0.2791
top acc: 0.5814 ::: bot acc: 0.4186
top acc: 0.8372 ::: bot acc: 0.1628
top acc: 0.8372 ::: bot acc: 0.3023
top acc: 0.8605 ::: bot acc: 0.0930
current epoch: 43
train loss is 0.067679
average val loss: 0.108226, accuracy: 0.5131
average test loss: 0.177539, accuracy: 0.4483
case acc: 0.4263565891472868
case acc: 0.49612403100775193
case acc: 0.5193798449612403
case acc: 0.37209302325581395
case acc: 0.4186046511627907
case acc: 0.4573643410852713
top acc: 0.8605 ::: bot acc: 0.1860
top acc: 0.8837 ::: bot acc: 0.2558
top acc: 0.6047 ::: bot acc: 0.4186
top acc: 0.8372 ::: bot acc: 0.1163
top acc: 0.8372 ::: bot acc: 0.2791
top acc: 0.8837 ::: bot acc: 0.0930
current epoch: 44
train loss is 0.068003
average val loss: 0.107996, accuracy: 0.5131
average test loss: 0.178314, accuracy: 0.4535
case acc: 0.43410852713178294
case acc: 0.5116279069767442
case acc: 0.5271317829457365
case acc: 0.3643410852713178
case acc: 0.43410852713178294
case acc: 0.4496124031007752
top acc: 0.8372 ::: bot acc: 0.2326
top acc: 0.8605 ::: bot acc: 0.2791
top acc: 0.6047 ::: bot acc: 0.4186
top acc: 0.8372 ::: bot acc: 0.1163
top acc: 0.8372 ::: bot acc: 0.2791
top acc: 0.8605 ::: bot acc: 0.0930
current epoch: 45
train loss is 0.067096
average val loss: 0.106992, accuracy: 0.5163
average test loss: 0.173453, accuracy: 0.4587
case acc: 0.4573643410852713
case acc: 0.49612403100775193
case acc: 0.5116279069767442
case acc: 0.3953488372093023
case acc: 0.4418604651162791
case acc: 0.4496124031007752
top acc: 0.8372 ::: bot acc: 0.2558
top acc: 0.8372 ::: bot acc: 0.2791
top acc: 0.5581 ::: bot acc: 0.4186
top acc: 0.8372 ::: bot acc: 0.1860
top acc: 0.8140 ::: bot acc: 0.3256
top acc: 0.8372 ::: bot acc: 0.1163
current epoch: 46
train loss is 0.067750
average val loss: 0.108419, accuracy: 0.5131
average test loss: 0.176284, accuracy: 0.4587
case acc: 0.43410852713178294
case acc: 0.49612403100775193
case acc: 0.5271317829457365
case acc: 0.3953488372093023
case acc: 0.4418604651162791
case acc: 0.4573643410852713
top acc: 0.8605 ::: bot acc: 0.2093
top acc: 0.8837 ::: bot acc: 0.2558
top acc: 0.6047 ::: bot acc: 0.4186
top acc: 0.8372 ::: bot acc: 0.1860
top acc: 0.8372 ::: bot acc: 0.3023
top acc: 0.8372 ::: bot acc: 0.1395
current epoch: 47
train loss is 0.065675
average val loss: 0.106888, accuracy: 0.5131
average test loss: 0.172373, accuracy: 0.4599
case acc: 0.4418604651162791
case acc: 0.4883720930232558
case acc: 0.5271317829457365
case acc: 0.3953488372093023
case acc: 0.43410852713178294
case acc: 0.4728682170542636
top acc: 0.8372 ::: bot acc: 0.2093
top acc: 0.8372 ::: bot acc: 0.2791
top acc: 0.6047 ::: bot acc: 0.4186
top acc: 0.8372 ::: bot acc: 0.1860
top acc: 0.8140 ::: bot acc: 0.3023
top acc: 0.8372 ::: bot acc: 0.1860
current epoch: 48
train loss is 0.067247
average val loss: 0.106680, accuracy: 0.5147
average test loss: 0.173207, accuracy: 0.4625
case acc: 0.4418604651162791
case acc: 0.49612403100775193
case acc: 0.5271317829457365
case acc: 0.3953488372093023
case acc: 0.4418604651162791
case acc: 0.4728682170542636
top acc: 0.8372 ::: bot acc: 0.2326
top acc: 0.8605 ::: bot acc: 0.2791
top acc: 0.6047 ::: bot acc: 0.4186
top acc: 0.8372 ::: bot acc: 0.1860
top acc: 0.8372 ::: bot acc: 0.3023
top acc: 0.8372 ::: bot acc: 0.1860
current epoch: 49
train loss is 0.064334
average val loss: 0.107944, accuracy: 0.5082
average test loss: 0.175644, accuracy: 0.4638
case acc: 0.4418604651162791
case acc: 0.49612403100775193
case acc: 0.5271317829457365
case acc: 0.40310077519379844
case acc: 0.4418604651162791
case acc: 0.4728682170542636
top acc: 0.8372 ::: bot acc: 0.2326
top acc: 0.8605 ::: bot acc: 0.2791
top acc: 0.6047 ::: bot acc: 0.4186
top acc: 0.8605 ::: bot acc: 0.1860
top acc: 0.8372 ::: bot acc: 0.3023
top acc: 0.8372 ::: bot acc: 0.1860
current epoch: 50
train loss is 0.065583
average val loss: 0.108301, accuracy: 0.5082
average test loss: 0.174166, accuracy: 0.4716
case acc: 0.46511627906976744
case acc: 0.5193798449612403
case acc: 0.5193798449612403
case acc: 0.3953488372093023
case acc: 0.4418604651162791
case acc: 0.4883720930232558
top acc: 0.8140 ::: bot acc: 0.2558
top acc: 0.8605 ::: bot acc: 0.3023
top acc: 0.5814 ::: bot acc: 0.4419
top acc: 0.8372 ::: bot acc: 0.1860
top acc: 0.8140 ::: bot acc: 0.3256
top acc: 0.8140 ::: bot acc: 0.2558
LME_Co_Spot
Before Load Data
['2011-01-01', '2016-01-01', '2016-07-01']
0.02981507985089216
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Co_Spot']
#####################remove_unused_columns_v4#####################
target LME_Co
Index(['LME_Co_Spot', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low',
       'LME_Co_Close', 'LME_Co_Spot_EMA12', 'LME_Co_Spot_WMA12',
       'LME_Co_Spot_EMA26', 'LME_Co_Spot_WMA26', 'LME_Co_Spot_EMA40',
       'LME_Co_Spot_WMA40', 'LME_Co_Spot_EMA65', 'LME_Co_Spot_WMA65',
       'LME_Co_Spot_EMA125', 'LME_Co_Spot_WMA125', 'LME_Co_Spot_bollinger5',
       'LME_Co_Spot_bollinger10', 'LME_Co_Spot_bollinger15',
       'LME_Co_Spot_bollinger20', 'LME_Co_Spot_bollinger30',
       'LME_Co_Spot_bollinger65', 'LME_Co_Spot_Mom5', 'LME_Co_Spot_Mom10',
       'LME_Co_Spot_Mom15', 'LME_Co_Spot_Mom26', 'LME_Co_Spot_Mom40',
       'LME_Co_Spot_Mom65', 'LME_Co_Spot_Mom125', 'LME_Co_Spot_PPO12',
       'LME_Co_Spot_PPO22', 'LME_Co_Spot_RSI14', 'LME_Co_Spot_RSI26',
       'LME_Co_Spot_RSI40', 'LME_Co_Spot_RSI54', 'LME_Co_Spot_RSI125',
       'LME_Co_Close_EMA12', 'LME_Co_Close_WMA12', 'LME_Co_Close_EMA26',
       'LME_Co_Close_WMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_WMA40',
       'LME_Co_Close_EMA65', 'LME_Co_Close_WMA65', 'LME_Co_Close_EMA125',
       'LME_Co_Close_WMA125', 'LME_Co_Close_bollinger5',
       'LME_Co_Close_bollinger10', 'LME_Co_Close_bollinger15',
       'LME_Co_Close_bollinger20', 'LME_Co_Close_bollinger30',
       'LME_Co_Close_bollinger65', 'LME_Co_Close_Mom5', 'LME_Co_Close_Mom10',
       'LME_Co_Close_Mom15', 'LME_Co_Close_Mom26', 'LME_Co_Close_Mom40',
       'LME_Co_Close_Mom65', 'LME_Co_Close_Mom125', 'LME_Co_Close_PPO12',
       'LME_Co_Close_PPO22', 'LME_Co_Close_RSI14', 'LME_Co_Close_RSI26',
       'LME_Co_Close_RSI40', 'LME_Co_Close_RSI54', 'LME_Co_Close_RSI125',
       'LME_Co_PVT', 'LME_Co_divPVT', 'LME_Co_NATR14', 'LME_Co_NATR26',
       'LME_Co_NATR65', 'LME_Co_NATR125', 'LME_Co_CCI12', 'LME_Co_CCI26',
       'LME_Co_CCI40', 'LME_Co_CCI65', 'LME_Co_CCI125', 'LME_Co_VBM12',
       'LME_Co_VBM22', 'LME_Co_ADX14', 'LME_Co_ADX26', 'LME_Co_ADX40',
       'LME_Co_ADX54', 'LME_Co_ADX125', 'LME_Co_SAR'],
      dtype='object')
LME_Al_Spot
Before Load Data
['2011-01-01', '2016-01-01', '2016-07-01']
0.02695224407968044
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Al_Spot']
#####################remove_unused_columns_v4#####################
target LME_Al
Index(['LME_Al_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low',
       'LME_Al_Close', 'LME_Al_Spot_EMA12', 'LME_Al_Spot_WMA12',
       'LME_Al_Spot_EMA26', 'LME_Al_Spot_WMA26', 'LME_Al_Spot_EMA40',
       'LME_Al_Spot_WMA40', 'LME_Al_Spot_EMA65', 'LME_Al_Spot_WMA65',
       'LME_Al_Spot_EMA125', 'LME_Al_Spot_WMA125', 'LME_Al_Spot_bollinger5',
       'LME_Al_Spot_bollinger10', 'LME_Al_Spot_bollinger15',
       'LME_Al_Spot_bollinger20', 'LME_Al_Spot_bollinger30',
       'LME_Al_Spot_bollinger65', 'LME_Al_Spot_Mom5', 'LME_Al_Spot_Mom10',
       'LME_Al_Spot_Mom15', 'LME_Al_Spot_Mom26', 'LME_Al_Spot_Mom40',
       'LME_Al_Spot_Mom65', 'LME_Al_Spot_Mom125', 'LME_Al_Spot_PPO12',
       'LME_Al_Spot_PPO22', 'LME_Al_Spot_RSI14', 'LME_Al_Spot_RSI26',
       'LME_Al_Spot_RSI40', 'LME_Al_Spot_RSI54', 'LME_Al_Spot_RSI125',
       'LME_Al_Close_EMA12', 'LME_Al_Close_WMA12', 'LME_Al_Close_EMA26',
       'LME_Al_Close_WMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_WMA40',
       'LME_Al_Close_EMA65', 'LME_Al_Close_WMA65', 'LME_Al_Close_EMA125',
       'LME_Al_Close_WMA125', 'LME_Al_Close_bollinger5',
       'LME_Al_Close_bollinger10', 'LME_Al_Close_bollinger15',
       'LME_Al_Close_bollinger20', 'LME_Al_Close_bollinger30',
       'LME_Al_Close_bollinger65', 'LME_Al_Close_Mom5', 'LME_Al_Close_Mom10',
       'LME_Al_Close_Mom15', 'LME_Al_Close_Mom26', 'LME_Al_Close_Mom40',
       'LME_Al_Close_Mom65', 'LME_Al_Close_Mom125', 'LME_Al_Close_PPO12',
       'LME_Al_Close_PPO22', 'LME_Al_Close_RSI14', 'LME_Al_Close_RSI26',
       'LME_Al_Close_RSI40', 'LME_Al_Close_RSI54', 'LME_Al_Close_RSI125',
       'LME_Al_PVT', 'LME_Al_divPVT', 'LME_Al_NATR14', 'LME_Al_NATR26',
       'LME_Al_NATR65', 'LME_Al_NATR125', 'LME_Al_CCI12', 'LME_Al_CCI26',
       'LME_Al_CCI40', 'LME_Al_CCI65', 'LME_Al_CCI125', 'LME_Al_VBM12',
       'LME_Al_VBM22', 'LME_Al_ADX14', 'LME_Al_ADX26', 'LME_Al_ADX40',
       'LME_Al_ADX54', 'LME_Al_ADX125', 'LME_Al_SAR'],
      dtype='object')
LME_Le_Spot
Before Load Data
['2011-01-01', '2016-01-01', '2016-07-01']
0.036896707418412604
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Le_Spot']
#####################remove_unused_columns_v4#####################
target LME_Le
Index(['LME_Le_Spot', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low',
       'LME_Le_Close', 'LME_Le_Spot_EMA12', 'LME_Le_Spot_WMA12',
       'LME_Le_Spot_EMA26', 'LME_Le_Spot_WMA26', 'LME_Le_Spot_EMA40',
       'LME_Le_Spot_WMA40', 'LME_Le_Spot_EMA65', 'LME_Le_Spot_WMA65',
       'LME_Le_Spot_EMA125', 'LME_Le_Spot_WMA125', 'LME_Le_Spot_bollinger5',
       'LME_Le_Spot_bollinger10', 'LME_Le_Spot_bollinger15',
       'LME_Le_Spot_bollinger20', 'LME_Le_Spot_bollinger30',
       'LME_Le_Spot_bollinger65', 'LME_Le_Spot_Mom5', 'LME_Le_Spot_Mom10',
       'LME_Le_Spot_Mom15', 'LME_Le_Spot_Mom26', 'LME_Le_Spot_Mom40',
       'LME_Le_Spot_Mom65', 'LME_Le_Spot_Mom125', 'LME_Le_Spot_PPO12',
       'LME_Le_Spot_PPO22', 'LME_Le_Spot_RSI14', 'LME_Le_Spot_RSI26',
       'LME_Le_Spot_RSI40', 'LME_Le_Spot_RSI54', 'LME_Le_Spot_RSI125',
       'LME_Le_Close_EMA12', 'LME_Le_Close_WMA12', 'LME_Le_Close_EMA26',
       'LME_Le_Close_WMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_WMA40',
       'LME_Le_Close_EMA65', 'LME_Le_Close_WMA65', 'LME_Le_Close_EMA125',
       'LME_Le_Close_WMA125', 'LME_Le_Close_bollinger5',
       'LME_Le_Close_bollinger10', 'LME_Le_Close_bollinger15',
       'LME_Le_Close_bollinger20', 'LME_Le_Close_bollinger30',
       'LME_Le_Close_bollinger65', 'LME_Le_Close_Mom5', 'LME_Le_Close_Mom10',
       'LME_Le_Close_Mom15', 'LME_Le_Close_Mom26', 'LME_Le_Close_Mom40',
       'LME_Le_Close_Mom65', 'LME_Le_Close_Mom125', 'LME_Le_Close_PPO12',
       'LME_Le_Close_PPO22', 'LME_Le_Close_RSI14', 'LME_Le_Close_RSI26',
       'LME_Le_Close_RSI40', 'LME_Le_Close_RSI54', 'LME_Le_Close_RSI125',
       'LME_Le_PVT', 'LME_Le_divPVT', 'LME_Le_NATR14', 'LME_Le_NATR26',
       'LME_Le_NATR65', 'LME_Le_NATR125', 'LME_Le_CCI12', 'LME_Le_CCI26',
       'LME_Le_CCI40', 'LME_Le_CCI65', 'LME_Le_CCI125', 'LME_Le_VBM12',
       'LME_Le_VBM22', 'LME_Le_ADX14', 'LME_Le_ADX26', 'LME_Le_ADX40',
       'LME_Le_ADX54', 'LME_Le_ADX125', 'LME_Le_SAR'],
      dtype='object')
LME_Ni_Spot
Before Load Data
['2011-01-01', '2016-01-01', '2016-07-01']
0.038591501995276
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Ni_Spot']
#####################remove_unused_columns_v4#####################
target LME_Ni
Index(['LME_Ni_Spot', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low',
       'LME_Ni_Close', 'LME_Ni_Spot_EMA12', 'LME_Ni_Spot_WMA12',
       'LME_Ni_Spot_EMA26', 'LME_Ni_Spot_WMA26', 'LME_Ni_Spot_EMA40',
       'LME_Ni_Spot_WMA40', 'LME_Ni_Spot_EMA65', 'LME_Ni_Spot_WMA65',
       'LME_Ni_Spot_EMA125', 'LME_Ni_Spot_WMA125', 'LME_Ni_Spot_bollinger5',
       'LME_Ni_Spot_bollinger10', 'LME_Ni_Spot_bollinger15',
       'LME_Ni_Spot_bollinger20', 'LME_Ni_Spot_bollinger30',
       'LME_Ni_Spot_bollinger65', 'LME_Ni_Spot_Mom5', 'LME_Ni_Spot_Mom10',
       'LME_Ni_Spot_Mom15', 'LME_Ni_Spot_Mom26', 'LME_Ni_Spot_Mom40',
       'LME_Ni_Spot_Mom65', 'LME_Ni_Spot_Mom125', 'LME_Ni_Spot_PPO12',
       'LME_Ni_Spot_PPO22', 'LME_Ni_Spot_RSI14', 'LME_Ni_Spot_RSI26',
       'LME_Ni_Spot_RSI40', 'LME_Ni_Spot_RSI54', 'LME_Ni_Spot_RSI125',
       'LME_Ni_Close_EMA12', 'LME_Ni_Close_WMA12', 'LME_Ni_Close_EMA26',
       'LME_Ni_Close_WMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_WMA40',
       'LME_Ni_Close_EMA65', 'LME_Ni_Close_WMA65', 'LME_Ni_Close_EMA125',
       'LME_Ni_Close_WMA125', 'LME_Ni_Close_bollinger5',
       'LME_Ni_Close_bollinger10', 'LME_Ni_Close_bollinger15',
       'LME_Ni_Close_bollinger20', 'LME_Ni_Close_bollinger30',
       'LME_Ni_Close_bollinger65', 'LME_Ni_Close_Mom5', 'LME_Ni_Close_Mom10',
       'LME_Ni_Close_Mom15', 'LME_Ni_Close_Mom26', 'LME_Ni_Close_Mom40',
       'LME_Ni_Close_Mom65', 'LME_Ni_Close_Mom125', 'LME_Ni_Close_PPO12',
       'LME_Ni_Close_PPO22', 'LME_Ni_Close_RSI14', 'LME_Ni_Close_RSI26',
       'LME_Ni_Close_RSI40', 'LME_Ni_Close_RSI54', 'LME_Ni_Close_RSI125',
       'LME_Ni_PVT', 'LME_Ni_divPVT', 'LME_Ni_NATR14', 'LME_Ni_NATR26',
       'LME_Ni_NATR65', 'LME_Ni_NATR125', 'LME_Ni_CCI12', 'LME_Ni_CCI26',
       'LME_Ni_CCI40', 'LME_Ni_CCI65', 'LME_Ni_CCI125', 'LME_Ni_VBM12',
       'LME_Ni_VBM22', 'LME_Ni_ADX14', 'LME_Ni_ADX26', 'LME_Ni_ADX40',
       'LME_Ni_ADX54', 'LME_Ni_ADX125', 'LME_Ni_SAR'],
      dtype='object')
LME_Zi_Spot
Before Load Data
['2011-01-01', '2016-01-01', '2016-07-01']
0.03357536293703594
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Zi_Spot']
#####################remove_unused_columns_v4#####################
target LME_Zi
Index(['LME_Zi_Spot', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low',
       'LME_Zi_Close', 'LME_Zi_Spot_EMA12', 'LME_Zi_Spot_WMA12',
       'LME_Zi_Spot_EMA26', 'LME_Zi_Spot_WMA26', 'LME_Zi_Spot_EMA40',
       'LME_Zi_Spot_WMA40', 'LME_Zi_Spot_EMA65', 'LME_Zi_Spot_WMA65',
       'LME_Zi_Spot_EMA125', 'LME_Zi_Spot_WMA125', 'LME_Zi_Spot_bollinger5',
       'LME_Zi_Spot_bollinger10', 'LME_Zi_Spot_bollinger15',
       'LME_Zi_Spot_bollinger20', 'LME_Zi_Spot_bollinger30',
       'LME_Zi_Spot_bollinger65', 'LME_Zi_Spot_Mom5', 'LME_Zi_Spot_Mom10',
       'LME_Zi_Spot_Mom15', 'LME_Zi_Spot_Mom26', 'LME_Zi_Spot_Mom40',
       'LME_Zi_Spot_Mom65', 'LME_Zi_Spot_Mom125', 'LME_Zi_Spot_PPO12',
       'LME_Zi_Spot_PPO22', 'LME_Zi_Spot_RSI14', 'LME_Zi_Spot_RSI26',
       'LME_Zi_Spot_RSI40', 'LME_Zi_Spot_RSI54', 'LME_Zi_Spot_RSI125',
       'LME_Zi_Close_EMA12', 'LME_Zi_Close_WMA12', 'LME_Zi_Close_EMA26',
       'LME_Zi_Close_WMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_WMA40',
       'LME_Zi_Close_EMA65', 'LME_Zi_Close_WMA65', 'LME_Zi_Close_EMA125',
       'LME_Zi_Close_WMA125', 'LME_Zi_Close_bollinger5',
       'LME_Zi_Close_bollinger10', 'LME_Zi_Close_bollinger15',
       'LME_Zi_Close_bollinger20', 'LME_Zi_Close_bollinger30',
       'LME_Zi_Close_bollinger65', 'LME_Zi_Close_Mom5', 'LME_Zi_Close_Mom10',
       'LME_Zi_Close_Mom15', 'LME_Zi_Close_Mom26', 'LME_Zi_Close_Mom40',
       'LME_Zi_Close_Mom65', 'LME_Zi_Close_Mom125', 'LME_Zi_Close_PPO12',
       'LME_Zi_Close_PPO22', 'LME_Zi_Close_RSI14', 'LME_Zi_Close_RSI26',
       'LME_Zi_Close_RSI40', 'LME_Zi_Close_RSI54', 'LME_Zi_Close_RSI125',
       'LME_Zi_PVT', 'LME_Zi_divPVT', 'LME_Zi_NATR14', 'LME_Zi_NATR26',
       'LME_Zi_NATR65', 'LME_Zi_NATR125', 'LME_Zi_CCI12', 'LME_Zi_CCI26',
       'LME_Zi_CCI40', 'LME_Zi_CCI65', 'LME_Zi_CCI125', 'LME_Zi_VBM12',
       'LME_Zi_VBM22', 'LME_Zi_ADX14', 'LME_Zi_ADX26', 'LME_Zi_ADX40',
       'LME_Zi_ADX54', 'LME_Zi_ADX125', 'LME_Zi_SAR'],
      dtype='object')
LME_Ti_Spot
Before Load Data
['2011-01-01', '2016-01-01', '2016-07-01']
0.035540828293523626
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Ti_Spot']
#####################remove_unused_columns_v4#####################
target LME_Ti
Index(['LME_Ti_Spot', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low',
       'LME_Ti_Close', 'LME_Ti_Spot_EMA12', 'LME_Ti_Spot_WMA12',
       'LME_Ti_Spot_EMA26', 'LME_Ti_Spot_WMA26', 'LME_Ti_Spot_EMA40',
       'LME_Ti_Spot_WMA40', 'LME_Ti_Spot_EMA65', 'LME_Ti_Spot_WMA65',
       'LME_Ti_Spot_EMA125', 'LME_Ti_Spot_WMA125', 'LME_Ti_Spot_bollinger5',
       'LME_Ti_Spot_bollinger10', 'LME_Ti_Spot_bollinger15',
       'LME_Ti_Spot_bollinger20', 'LME_Ti_Spot_bollinger30',
       'LME_Ti_Spot_bollinger65', 'LME_Ti_Spot_Mom5', 'LME_Ti_Spot_Mom10',
       'LME_Ti_Spot_Mom15', 'LME_Ti_Spot_Mom26', 'LME_Ti_Spot_Mom40',
       'LME_Ti_Spot_Mom65', 'LME_Ti_Spot_Mom125', 'LME_Ti_Spot_PPO12',
       'LME_Ti_Spot_PPO22', 'LME_Ti_Spot_RSI14', 'LME_Ti_Spot_RSI26',
       'LME_Ti_Spot_RSI40', 'LME_Ti_Spot_RSI54', 'LME_Ti_Spot_RSI125',
       'LME_Ti_Close_EMA12', 'LME_Ti_Close_WMA12', 'LME_Ti_Close_EMA26',
       'LME_Ti_Close_WMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_WMA40',
       'LME_Ti_Close_EMA65', 'LME_Ti_Close_WMA65', 'LME_Ti_Close_EMA125',
       'LME_Ti_Close_WMA125', 'LME_Ti_Close_bollinger5',
       'LME_Ti_Close_bollinger10', 'LME_Ti_Close_bollinger15',
       'LME_Ti_Close_bollinger20', 'LME_Ti_Close_bollinger30',
       'LME_Ti_Close_bollinger65', 'LME_Ti_Close_Mom5', 'LME_Ti_Close_Mom10',
       'LME_Ti_Close_Mom15', 'LME_Ti_Close_Mom26', 'LME_Ti_Close_Mom40',
       'LME_Ti_Close_Mom65', 'LME_Ti_Close_Mom125', 'LME_Ti_Close_PPO12',
       'LME_Ti_Close_PPO22', 'LME_Ti_Close_RSI14', 'LME_Ti_Close_RSI26',
       'LME_Ti_Close_RSI40', 'LME_Ti_Close_RSI54', 'LME_Ti_Close_RSI125',
       'LME_Ti_PVT', 'LME_Ti_divPVT', 'LME_Ti_NATR14', 'LME_Ti_NATR26',
       'LME_Ti_NATR65', 'LME_Ti_NATR125', 'LME_Ti_CCI12', 'LME_Ti_CCI26',
       'LME_Ti_CCI40', 'LME_Ti_CCI65', 'LME_Ti_CCI125', 'LME_Ti_VBM12',
       'LME_Ti_VBM22', 'LME_Ti_ADX14', 'LME_Ti_ADX26', 'LME_Ti_ADX40',
       'LME_Ti_ADX54', 'LME_Ti_ADX125', 'LME_Ti_SAR'],
      dtype='object')
Dataset statistic: #examples
Train: 5460 5460 5460
9.346831 -14.815535 1.2495481 -1.0459785
Validation: 612 612 612
Testing: 750 750 750
pre-processing time: 0.0008990764617919922
the split date is 2016-01-01
net initializing with time: 0.000743865966796875
preparing training and testing date with time: 0.0020818710327148438
current epoch: 1
train loss is 0.168296
average val loss: 0.153382, accuracy: 0.4722
average test loss: 0.144302, accuracy: 0.4973
case acc: 0.4
case acc: 0.528
case acc: 0.408
case acc: 0.536
case acc: 0.552
case acc: 0.56
top acc: 0.2195 ::: bot acc: 0.6341
top acc: 0.7805 ::: bot acc: 0.1463
top acc: 0.2683 ::: bot acc: 0.6829
top acc: 0.9512 ::: bot acc: 0.0000
top acc: 0.5610 ::: bot acc: 0.4634
top acc: 0.7317 ::: bot acc: 0.4146
current epoch: 2
train loss is 0.114715
average val loss: 0.148686, accuracy: 0.5359
average test loss: 0.149874, accuracy: 0.4733
case acc: 0.424
case acc: 0.512
case acc: 0.416
case acc: 0.536
case acc: 0.456
case acc: 0.496
top acc: 0.1463 ::: bot acc: 0.8049
top acc: 0.7073 ::: bot acc: 0.2195
top acc: 0.0488 ::: bot acc: 0.8537
top acc: 0.9512 ::: bot acc: 0.0000
top acc: 0.2927 ::: bot acc: 0.6585
top acc: 0.4634 ::: bot acc: 0.5610
current epoch: 3
train loss is 0.113437
average val loss: 0.150824, accuracy: 0.4526
average test loss: 0.138958, accuracy: 0.4947
case acc: 0.408
case acc: 0.56
case acc: 0.44
case acc: 0.56
case acc: 0.504
case acc: 0.496
top acc: 0.2683 ::: bot acc: 0.5610
top acc: 0.8537 ::: bot acc: 0.0976
top acc: 0.3902 ::: bot acc: 0.6098
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.6585 ::: bot acc: 0.1220
top acc: 0.6585 ::: bot acc: 0.2195
current epoch: 4
train loss is 0.104382
average val loss: 0.144956, accuracy: 0.4967
average test loss: 0.139149, accuracy: 0.4853
case acc: 0.44
case acc: 0.52
case acc: 0.432
case acc: 0.56
case acc: 0.472
case acc: 0.488
top acc: 0.1951 ::: bot acc: 0.7805
top acc: 0.8049 ::: bot acc: 0.0976
top acc: 0.2195 ::: bot acc: 0.8049
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.3415 ::: bot acc: 0.5122
top acc: 0.5854 ::: bot acc: 0.3659
current epoch: 5
train loss is 0.101680
average val loss: 0.147583, accuracy: 0.4592
average test loss: 0.136329, accuracy: 0.4880
case acc: 0.424
case acc: 0.56
case acc: 0.448
case acc: 0.56
case acc: 0.448
case acc: 0.488
top acc: 0.2439 ::: bot acc: 0.6585
top acc: 0.8537 ::: bot acc: 0.0976
top acc: 0.3902 ::: bot acc: 0.6829
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.4878 ::: bot acc: 0.2195
top acc: 0.6098 ::: bot acc: 0.2927
current epoch: 6
train loss is 0.099340
average val loss: 0.148123, accuracy: 0.4444
average test loss: 0.135762, accuracy: 0.4867
case acc: 0.44
case acc: 0.568
case acc: 0.456
case acc: 0.56
case acc: 0.416
case acc: 0.48
top acc: 0.2439 ::: bot acc: 0.6829
top acc: 0.8537 ::: bot acc: 0.0976
top acc: 0.3902 ::: bot acc: 0.7073
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.4878 ::: bot acc: 0.1707
top acc: 0.6098 ::: bot acc: 0.2683
current epoch: 7
train loss is 0.096724
average val loss: 0.148487, accuracy: 0.4444
average test loss: 0.135265, accuracy: 0.4827
case acc: 0.448
case acc: 0.568
case acc: 0.44
case acc: 0.56
case acc: 0.4
case acc: 0.48
top acc: 0.2439 ::: bot acc: 0.7073
top acc: 0.8537 ::: bot acc: 0.0976
top acc: 0.3415 ::: bot acc: 0.7073
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.4146 ::: bot acc: 0.1951
top acc: 0.5854 ::: bot acc: 0.2927
current epoch: 8
train loss is 0.095906
average val loss: 0.151646, accuracy: 0.4216
average test loss: 0.134314, accuracy: 0.4947
case acc: 0.44
case acc: 0.576
case acc: 0.488
case acc: 0.56
case acc: 0.432
case acc: 0.472
top acc: 0.2439 ::: bot acc: 0.6341
top acc: 0.8780 ::: bot acc: 0.0488
top acc: 0.4390 ::: bot acc: 0.7073
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.5122 ::: bot acc: 0.1707
top acc: 0.5610 ::: bot acc: 0.2439
current epoch: 9
train loss is 0.093203
average val loss: 0.152340, accuracy: 0.4052
average test loss: 0.134240, accuracy: 0.4880
case acc: 0.432
case acc: 0.584
case acc: 0.48
case acc: 0.56
case acc: 0.424
case acc: 0.448
top acc: 0.2439 ::: bot acc: 0.6098
top acc: 0.8780 ::: bot acc: 0.0732
top acc: 0.3902 ::: bot acc: 0.7317
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.4878 ::: bot acc: 0.1707
top acc: 0.5122 ::: bot acc: 0.2683
current epoch: 10
train loss is 0.091939
average val loss: 0.154901, accuracy: 0.4036
average test loss: 0.133303, accuracy: 0.4880
case acc: 0.424
case acc: 0.584
case acc: 0.488
case acc: 0.56
case acc: 0.416
case acc: 0.456
top acc: 0.2683 ::: bot acc: 0.5610
top acc: 0.8780 ::: bot acc: 0.0732
top acc: 0.4634 ::: bot acc: 0.7073
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.5366 ::: bot acc: 0.0976
top acc: 0.5122 ::: bot acc: 0.2439
current epoch: 11
train loss is 0.090202
average val loss: 0.155138, accuracy: 0.4036
average test loss: 0.133176, accuracy: 0.4813
case acc: 0.424
case acc: 0.592
case acc: 0.472
case acc: 0.56
case acc: 0.4
case acc: 0.44
top acc: 0.2439 ::: bot acc: 0.6098
top acc: 0.9024 ::: bot acc: 0.0732
top acc: 0.3902 ::: bot acc: 0.7317
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.5366 ::: bot acc: 0.0976
top acc: 0.5122 ::: bot acc: 0.2195
current epoch: 12
train loss is 0.090008
average val loss: 0.157002, accuracy: 0.3922
average test loss: 0.132747, accuracy: 0.4960
case acc: 0.448
case acc: 0.616
case acc: 0.48
case acc: 0.56
case acc: 0.432
case acc: 0.44
top acc: 0.2683 ::: bot acc: 0.6098
top acc: 0.9268 ::: bot acc: 0.1220
top acc: 0.3902 ::: bot acc: 0.6585
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.5854 ::: bot acc: 0.1220
top acc: 0.5366 ::: bot acc: 0.1951
current epoch: 13
train loss is 0.087701
average val loss: 0.158570, accuracy: 0.3954
average test loss: 0.133055, accuracy: 0.4973
case acc: 0.464
case acc: 0.632
case acc: 0.488
case acc: 0.56
case acc: 0.416
case acc: 0.424
top acc: 0.2683 ::: bot acc: 0.6341
top acc: 0.9268 ::: bot acc: 0.1707
top acc: 0.3659 ::: bot acc: 0.7073
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.5610 ::: bot acc: 0.1220
top acc: 0.4878 ::: bot acc: 0.1951
current epoch: 14
train loss is 0.087084
average val loss: 0.159212, accuracy: 0.3938
average test loss: 0.133307, accuracy: 0.5080
case acc: 0.496
case acc: 0.64
case acc: 0.504
case acc: 0.56
case acc: 0.424
case acc: 0.424
top acc: 0.3171 ::: bot acc: 0.6585
top acc: 0.9512 ::: bot acc: 0.1707
top acc: 0.4390 ::: bot acc: 0.6829
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.5610 ::: bot acc: 0.1463
top acc: 0.4878 ::: bot acc: 0.1707
current epoch: 15
train loss is 0.084994
average val loss: 0.159231, accuracy: 0.3889
average test loss: 0.134096, accuracy: 0.5027
case acc: 0.504
case acc: 0.616
case acc: 0.52
case acc: 0.56
case acc: 0.392
case acc: 0.424
top acc: 0.3171 ::: bot acc: 0.7073
top acc: 0.8780 ::: bot acc: 0.1951
top acc: 0.4390 ::: bot acc: 0.7317
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.5122 ::: bot acc: 0.1220
top acc: 0.4878 ::: bot acc: 0.1707
current epoch: 16
train loss is 0.084443
average val loss: 0.159477, accuracy: 0.3922
average test loss: 0.134673, accuracy: 0.4987
case acc: 0.496
case acc: 0.616
case acc: 0.528
case acc: 0.56
case acc: 0.376
case acc: 0.416
top acc: 0.3171 ::: bot acc: 0.7073
top acc: 0.8780 ::: bot acc: 0.1951
top acc: 0.4390 ::: bot acc: 0.7317
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.4878 ::: bot acc: 0.0976
top acc: 0.4634 ::: bot acc: 0.1707
current epoch: 17
train loss is 0.084150
average val loss: 0.158717, accuracy: 0.3938
average test loss: 0.134483, accuracy: 0.4987
case acc: 0.504
case acc: 0.608
case acc: 0.512
case acc: 0.56
case acc: 0.392
case acc: 0.416
top acc: 0.3415 ::: bot acc: 0.6829
top acc: 0.8293 ::: bot acc: 0.2195
top acc: 0.4146 ::: bot acc: 0.7317
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.4878 ::: bot acc: 0.1707
top acc: 0.4634 ::: bot acc: 0.1707
current epoch: 18
train loss is 0.081669
average val loss: 0.159222, accuracy: 0.3938
average test loss: 0.134314, accuracy: 0.4987
case acc: 0.496
case acc: 0.624
case acc: 0.512
case acc: 0.56
case acc: 0.408
case acc: 0.392
top acc: 0.3415 ::: bot acc: 0.6585
top acc: 0.8780 ::: bot acc: 0.2439
top acc: 0.4634 ::: bot acc: 0.7073
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.5366 ::: bot acc: 0.1707
top acc: 0.4634 ::: bot acc: 0.0976
current epoch: 19
train loss is 0.081295
average val loss: 0.160278, accuracy: 0.3954
average test loss: 0.134145, accuracy: 0.4987
case acc: 0.496
case acc: 0.632
case acc: 0.504
case acc: 0.56
case acc: 0.416
case acc: 0.384
top acc: 0.3415 ::: bot acc: 0.6585
top acc: 0.8537 ::: bot acc: 0.2683
top acc: 0.4634 ::: bot acc: 0.6829
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.5610 ::: bot acc: 0.1707
top acc: 0.4634 ::: bot acc: 0.0976
current epoch: 20
train loss is 0.080988
average val loss: 0.160240, accuracy: 0.4069
average test loss: 0.134378, accuracy: 0.5067
case acc: 0.504
case acc: 0.64
case acc: 0.504
case acc: 0.56
case acc: 0.416
case acc: 0.416
top acc: 0.3171 ::: bot acc: 0.7073
top acc: 0.8537 ::: bot acc: 0.2927
top acc: 0.4146 ::: bot acc: 0.7073
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.5122 ::: bot acc: 0.2195
top acc: 0.4634 ::: bot acc: 0.1951
current epoch: 21
train loss is 0.079732
average val loss: 0.161561, accuracy: 0.3971
average test loss: 0.134519, accuracy: 0.4960
case acc: 0.488
case acc: 0.632
case acc: 0.496
case acc: 0.544
case acc: 0.416
case acc: 0.4
top acc: 0.3415 ::: bot acc: 0.6341
top acc: 0.8537 ::: bot acc: 0.2683
top acc: 0.4634 ::: bot acc: 0.6585
top acc: 0.9756 ::: bot acc: 0.0000
top acc: 0.5122 ::: bot acc: 0.2195
top acc: 0.4878 ::: bot acc: 0.1463
current epoch: 22
train loss is 0.078922
average val loss: 0.161059, accuracy: 0.4085
average test loss: 0.134750, accuracy: 0.5027
case acc: 0.496
case acc: 0.64
case acc: 0.504
case acc: 0.536
case acc: 0.416
case acc: 0.424
top acc: 0.3171 ::: bot acc: 0.6829
top acc: 0.8537 ::: bot acc: 0.2927
top acc: 0.4390 ::: bot acc: 0.6829
top acc: 0.9512 ::: bot acc: 0.0000
top acc: 0.4878 ::: bot acc: 0.2683
top acc: 0.4634 ::: bot acc: 0.2195
current epoch: 23
train loss is 0.078232
average val loss: 0.161481, accuracy: 0.4003
average test loss: 0.133951, accuracy: 0.5040
case acc: 0.488
case acc: 0.648
case acc: 0.504
case acc: 0.536
case acc: 0.432
case acc: 0.416
top acc: 0.3415 ::: bot acc: 0.6585
top acc: 0.8780 ::: bot acc: 0.2927
top acc: 0.4390 ::: bot acc: 0.6829
top acc: 0.9512 ::: bot acc: 0.0000
top acc: 0.4878 ::: bot acc: 0.3415
top acc: 0.4634 ::: bot acc: 0.1951
current epoch: 24
train loss is 0.077253
average val loss: 0.159844, accuracy: 0.4085
average test loss: 0.133475, accuracy: 0.5027
case acc: 0.512
case acc: 0.64
case acc: 0.504
case acc: 0.536
case acc: 0.416
case acc: 0.408
top acc: 0.3415 ::: bot acc: 0.7073
top acc: 0.8537 ::: bot acc: 0.3171
top acc: 0.4146 ::: bot acc: 0.7073
top acc: 0.9512 ::: bot acc: 0.0000
top acc: 0.4878 ::: bot acc: 0.3415
top acc: 0.4390 ::: bot acc: 0.1951
current epoch: 25
train loss is 0.077296
average val loss: 0.159631, accuracy: 0.4101
average test loss: 0.133174, accuracy: 0.5000
case acc: 0.504
case acc: 0.632
case acc: 0.512
case acc: 0.536
case acc: 0.408
case acc: 0.408
top acc: 0.3415 ::: bot acc: 0.7073
top acc: 0.8537 ::: bot acc: 0.3171
top acc: 0.4146 ::: bot acc: 0.7317
top acc: 0.9512 ::: bot acc: 0.0000
top acc: 0.4390 ::: bot acc: 0.3659
top acc: 0.4634 ::: bot acc: 0.1951
current epoch: 26
train loss is 0.076167
average val loss: 0.158286, accuracy: 0.4134
average test loss: 0.134134, accuracy: 0.5027
case acc: 0.512
case acc: 0.632
case acc: 0.52
case acc: 0.536
case acc: 0.408
case acc: 0.408
top acc: 0.3415 ::: bot acc: 0.7073
top acc: 0.8537 ::: bot acc: 0.3171
top acc: 0.4146 ::: bot acc: 0.7317
top acc: 0.9268 ::: bot acc: 0.0000
top acc: 0.4146 ::: bot acc: 0.3659
top acc: 0.4634 ::: bot acc: 0.1951
current epoch: 27
train loss is 0.074873
average val loss: 0.159293, accuracy: 0.4085
average test loss: 0.134093, accuracy: 0.4960
case acc: 0.496
case acc: 0.624
case acc: 0.512
case acc: 0.544
case acc: 0.384
case acc: 0.416
top acc: 0.3415 ::: bot acc: 0.6829
top acc: 0.8537 ::: bot acc: 0.3171
top acc: 0.3902 ::: bot acc: 0.7317
top acc: 0.9268 ::: bot acc: 0.0000
top acc: 0.3659 ::: bot acc: 0.3659
top acc: 0.4634 ::: bot acc: 0.1951
current epoch: 28
train loss is 0.075658
average val loss: 0.159981, accuracy: 0.4150
average test loss: 0.134202, accuracy: 0.4933
case acc: 0.488
case acc: 0.624
case acc: 0.512
case acc: 0.544
case acc: 0.392
case acc: 0.4
top acc: 0.3415 ::: bot acc: 0.6829
top acc: 0.8293 ::: bot acc: 0.3415
top acc: 0.3902 ::: bot acc: 0.7317
top acc: 0.9268 ::: bot acc: 0.0000
top acc: 0.3659 ::: bot acc: 0.3902
top acc: 0.4390 ::: bot acc: 0.1951
current epoch: 29
train loss is 0.074941
average val loss: 0.159398, accuracy: 0.4167
average test loss: 0.134007, accuracy: 0.4960
case acc: 0.48
case acc: 0.632
case acc: 0.512
case acc: 0.552
case acc: 0.408
case acc: 0.392
top acc: 0.3415 ::: bot acc: 0.6585
top acc: 0.8293 ::: bot acc: 0.3659
top acc: 0.3902 ::: bot acc: 0.6829
top acc: 0.9268 ::: bot acc: 0.0244
top acc: 0.4390 ::: bot acc: 0.3659
top acc: 0.4390 ::: bot acc: 0.1707
current epoch: 30
train loss is 0.073790
average val loss: 0.159229, accuracy: 0.4199
average test loss: 0.134062, accuracy: 0.5053
case acc: 0.48
case acc: 0.648
case acc: 0.528
case acc: 0.544
case acc: 0.424
case acc: 0.408
top acc: 0.3659 ::: bot acc: 0.6585
top acc: 0.8293 ::: bot acc: 0.4146
top acc: 0.4146 ::: bot acc: 0.6829
top acc: 0.9268 ::: bot acc: 0.0244
top acc: 0.4390 ::: bot acc: 0.4146
top acc: 0.4146 ::: bot acc: 0.2439
current epoch: 31
train loss is 0.073140
average val loss: 0.160571, accuracy: 0.4183
average test loss: 0.134714, accuracy: 0.5053
case acc: 0.488
case acc: 0.648
case acc: 0.52
case acc: 0.536
case acc: 0.424
case acc: 0.416
top acc: 0.3659 ::: bot acc: 0.6585
top acc: 0.8293 ::: bot acc: 0.3902
top acc: 0.4146 ::: bot acc: 0.6585
top acc: 0.9268 ::: bot acc: 0.0000
top acc: 0.4146 ::: bot acc: 0.4146
top acc: 0.4634 ::: bot acc: 0.2195
current epoch: 32
train loss is 0.073500
average val loss: 0.157823, accuracy: 0.4216
average test loss: 0.134809, accuracy: 0.5000
case acc: 0.48
case acc: 0.664
case acc: 0.52
case acc: 0.528
case acc: 0.424
case acc: 0.384
top acc: 0.3415 ::: bot acc: 0.6829
top acc: 0.7805 ::: bot acc: 0.4634
top acc: 0.3902 ::: bot acc: 0.6829
top acc: 0.9268 ::: bot acc: 0.0244
top acc: 0.4146 ::: bot acc: 0.4634
top acc: 0.4146 ::: bot acc: 0.2439
current epoch: 33
train loss is 0.073816
average val loss: 0.157667, accuracy: 0.4199
average test loss: 0.134873, accuracy: 0.4933
case acc: 0.464
case acc: 0.664
case acc: 0.52
case acc: 0.528
case acc: 0.4
case acc: 0.384
top acc: 0.3415 ::: bot acc: 0.6829
top acc: 0.7805 ::: bot acc: 0.4634
top acc: 0.3659 ::: bot acc: 0.6829
top acc: 0.9268 ::: bot acc: 0.0488
top acc: 0.3659 ::: bot acc: 0.4390
top acc: 0.4146 ::: bot acc: 0.2439
current epoch: 34
train loss is 0.071786
average val loss: 0.157900, accuracy: 0.4216
average test loss: 0.135899, accuracy: 0.4853
case acc: 0.464
case acc: 0.64
case acc: 0.512
case acc: 0.52
case acc: 0.384
case acc: 0.392
top acc: 0.3415 ::: bot acc: 0.6829
top acc: 0.7805 ::: bot acc: 0.4146
top acc: 0.3659 ::: bot acc: 0.6829
top acc: 0.9268 ::: bot acc: 0.0488
top acc: 0.3659 ::: bot acc: 0.3902
top acc: 0.4146 ::: bot acc: 0.2439
current epoch: 35
train loss is 0.072136
average val loss: 0.157191, accuracy: 0.4216
average test loss: 0.136504, accuracy: 0.4893
case acc: 0.464
case acc: 0.632
case acc: 0.52
case acc: 0.536
case acc: 0.392
case acc: 0.392
top acc: 0.3415 ::: bot acc: 0.6829
top acc: 0.7317 ::: bot acc: 0.4634
top acc: 0.3659 ::: bot acc: 0.7073
top acc: 0.9024 ::: bot acc: 0.0976
top acc: 0.2683 ::: bot acc: 0.4878
top acc: 0.3659 ::: bot acc: 0.3171
current epoch: 36
train loss is 0.070920
average val loss: 0.157195, accuracy: 0.4232
average test loss: 0.136677, accuracy: 0.4880
case acc: 0.448
case acc: 0.64
case acc: 0.504
case acc: 0.544
case acc: 0.392
case acc: 0.4
top acc: 0.3415 ::: bot acc: 0.6098
top acc: 0.7561 ::: bot acc: 0.4146
top acc: 0.3902 ::: bot acc: 0.6585
top acc: 0.9024 ::: bot acc: 0.1220
top acc: 0.3659 ::: bot acc: 0.3902
top acc: 0.4390 ::: bot acc: 0.2439
current epoch: 37
train loss is 0.070841
average val loss: 0.158919, accuracy: 0.4265
average test loss: 0.137250, accuracy: 0.4947
case acc: 0.456
case acc: 0.632
case acc: 0.512
case acc: 0.552
case acc: 0.424
case acc: 0.392
top acc: 0.3415 ::: bot acc: 0.6585
top acc: 0.7073 ::: bot acc: 0.4634
top acc: 0.3659 ::: bot acc: 0.6829
top acc: 0.9024 ::: bot acc: 0.1463
top acc: 0.3171 ::: bot acc: 0.5610
top acc: 0.3659 ::: bot acc: 0.3171
current epoch: 38
train loss is 0.070751
average val loss: 0.159093, accuracy: 0.4216
average test loss: 0.137180, accuracy: 0.4907
case acc: 0.44
case acc: 0.648
case acc: 0.504
case acc: 0.536
case acc: 0.416
case acc: 0.4
top acc: 0.3415 ::: bot acc: 0.6098
top acc: 0.7317 ::: bot acc: 0.4634
top acc: 0.3659 ::: bot acc: 0.6829
top acc: 0.9024 ::: bot acc: 0.0976
top acc: 0.3171 ::: bot acc: 0.5366
top acc: 0.3902 ::: bot acc: 0.3171
current epoch: 39
train loss is 0.070066
average val loss: 0.159539, accuracy: 0.4248
average test loss: 0.137561, accuracy: 0.4853
case acc: 0.424
case acc: 0.648
case acc: 0.496
case acc: 0.536
case acc: 0.408
case acc: 0.4
top acc: 0.3415 ::: bot acc: 0.5610
top acc: 0.7317 ::: bot acc: 0.4634
top acc: 0.3659 ::: bot acc: 0.6829
top acc: 0.9024 ::: bot acc: 0.0976
top acc: 0.2927 ::: bot acc: 0.5366
top acc: 0.4146 ::: bot acc: 0.2927
current epoch: 40
train loss is 0.070443
average val loss: 0.159923, accuracy: 0.4281
average test loss: 0.137642, accuracy: 0.4813
case acc: 0.44
case acc: 0.624
case acc: 0.512
case acc: 0.528
case acc: 0.408
case acc: 0.376
top acc: 0.3659 ::: bot acc: 0.5854
top acc: 0.7073 ::: bot acc: 0.4390
top acc: 0.3659 ::: bot acc: 0.6829
top acc: 0.8780 ::: bot acc: 0.0732
top acc: 0.3171 ::: bot acc: 0.5122
top acc: 0.3659 ::: bot acc: 0.2927
current epoch: 41
train loss is 0.069575
average val loss: 0.161421, accuracy: 0.4281
average test loss: 0.138214, accuracy: 0.4920
case acc: 0.456
case acc: 0.616
case acc: 0.504
case acc: 0.544
case acc: 0.432
case acc: 0.4
top acc: 0.3902 ::: bot acc: 0.5610
top acc: 0.7317 ::: bot acc: 0.3902
top acc: 0.3659 ::: bot acc: 0.6829
top acc: 0.9024 ::: bot acc: 0.1220
top acc: 0.3415 ::: bot acc: 0.5610
top acc: 0.4390 ::: bot acc: 0.2927
current epoch: 42
train loss is 0.069042
average val loss: 0.160864, accuracy: 0.4265
average test loss: 0.139103, accuracy: 0.4893
case acc: 0.432
case acc: 0.616
case acc: 0.512
case acc: 0.544
case acc: 0.432
case acc: 0.4
top acc: 0.3415 ::: bot acc: 0.5610
top acc: 0.7317 ::: bot acc: 0.3902
top acc: 0.3659 ::: bot acc: 0.6829
top acc: 0.8537 ::: bot acc: 0.1463
top acc: 0.2927 ::: bot acc: 0.6098
top acc: 0.4390 ::: bot acc: 0.2683
current epoch: 43
train loss is 0.068362
average val loss: 0.160977, accuracy: 0.4265
average test loss: 0.139705, accuracy: 0.4827
case acc: 0.448
case acc: 0.592
case acc: 0.504
case acc: 0.536
case acc: 0.44
case acc: 0.376
top acc: 0.3415 ::: bot acc: 0.6098
top acc: 0.7073 ::: bot acc: 0.3902
top acc: 0.3415 ::: bot acc: 0.6829
top acc: 0.8537 ::: bot acc: 0.1463
top acc: 0.2927 ::: bot acc: 0.6341
top acc: 0.3902 ::: bot acc: 0.2683
current epoch: 44
train loss is 0.068146
average val loss: 0.161021, accuracy: 0.4363
average test loss: 0.139548, accuracy: 0.4907
case acc: 0.472
case acc: 0.608
case acc: 0.512
case acc: 0.544
case acc: 0.432
case acc: 0.376
top acc: 0.3902 ::: bot acc: 0.5854
top acc: 0.7317 ::: bot acc: 0.3902
top acc: 0.3659 ::: bot acc: 0.6829
top acc: 0.8780 ::: bot acc: 0.1220
top acc: 0.3171 ::: bot acc: 0.5854
top acc: 0.3902 ::: bot acc: 0.2683
current epoch: 45
train loss is 0.068181
average val loss: 0.162884, accuracy: 0.4314
average test loss: 0.140995, accuracy: 0.4947
case acc: 0.472
case acc: 0.608
case acc: 0.512
case acc: 0.544
case acc: 0.44
case acc: 0.392
top acc: 0.3659 ::: bot acc: 0.5854
top acc: 0.7317 ::: bot acc: 0.4390
top acc: 0.3415 ::: bot acc: 0.6829
top acc: 0.8780 ::: bot acc: 0.1220
top acc: 0.2927 ::: bot acc: 0.6585
top acc: 0.3902 ::: bot acc: 0.2927
current epoch: 46
train loss is 0.068246
average val loss: 0.164058, accuracy: 0.4346
average test loss: 0.141995, accuracy: 0.4893
case acc: 0.456
case acc: 0.6
case acc: 0.504
case acc: 0.552
case acc: 0.432
case acc: 0.392
top acc: 0.3659 ::: bot acc: 0.5610
top acc: 0.7317 ::: bot acc: 0.3902
top acc: 0.3659 ::: bot acc: 0.6341
top acc: 0.9024 ::: bot acc: 0.1220
top acc: 0.2927 ::: bot acc: 0.6098
top acc: 0.4146 ::: bot acc: 0.2439
current epoch: 47
train loss is 0.067736
average val loss: 0.160470, accuracy: 0.4281
average test loss: 0.142262, accuracy: 0.4893
case acc: 0.464
case acc: 0.6
case acc: 0.52
case acc: 0.544
case acc: 0.432
case acc: 0.376
top acc: 0.3659 ::: bot acc: 0.6098
top acc: 0.7317 ::: bot acc: 0.4390
top acc: 0.3415 ::: bot acc: 0.7073
top acc: 0.8537 ::: bot acc: 0.1463
top acc: 0.2683 ::: bot acc: 0.6585
top acc: 0.3902 ::: bot acc: 0.2683
current epoch: 48
train loss is 0.067283
average val loss: 0.160959, accuracy: 0.4199
average test loss: 0.143037, accuracy: 0.4893
case acc: 0.472
case acc: 0.616
case acc: 0.52
case acc: 0.56
case acc: 0.4
case acc: 0.368
top acc: 0.3902 ::: bot acc: 0.6098
top acc: 0.7317 ::: bot acc: 0.4390
top acc: 0.3415 ::: bot acc: 0.7073
top acc: 0.8537 ::: bot acc: 0.1951
top acc: 0.2439 ::: bot acc: 0.5854
top acc: 0.3902 ::: bot acc: 0.2683
current epoch: 49
train loss is 0.067305
average val loss: 0.164477, accuracy: 0.4232
average test loss: 0.142910, accuracy: 0.4893
case acc: 0.456
case acc: 0.616
case acc: 0.52
case acc: 0.56
case acc: 0.416
case acc: 0.368
top acc: 0.3902 ::: bot acc: 0.5610
top acc: 0.7317 ::: bot acc: 0.4146
top acc: 0.3659 ::: bot acc: 0.6341
top acc: 0.8780 ::: bot acc: 0.1707
top acc: 0.2927 ::: bot acc: 0.5854
top acc: 0.3902 ::: bot acc: 0.2439
current epoch: 50
train loss is 0.066280
average val loss: 0.163556, accuracy: 0.4183
average test loss: 0.143802, accuracy: 0.4987
case acc: 0.48
case acc: 0.624
case acc: 0.528
case acc: 0.568
case acc: 0.416
case acc: 0.376
top acc: 0.3659 ::: bot acc: 0.6098
top acc: 0.7317 ::: bot acc: 0.4634
top acc: 0.3415 ::: bot acc: 0.7073
top acc: 0.8780 ::: bot acc: 0.1951
top acc: 0.2439 ::: bot acc: 0.6585
top acc: 0.3659 ::: bot acc: 0.2927
LME_Co_Spot
Before Load Data
['2011-07-01', '2016-07-01', '2017-01-01']
0.029121474242381942
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Co_Spot']
#####################remove_unused_columns_v4#####################
target LME_Co
Index(['LME_Co_Spot', 'LME_Co_Open', 'LME_Co_High', 'LME_Co_Low',
       'LME_Co_Close', 'LME_Co_Spot_EMA12', 'LME_Co_Spot_WMA12',
       'LME_Co_Spot_EMA26', 'LME_Co_Spot_WMA26', 'LME_Co_Spot_EMA40',
       'LME_Co_Spot_WMA40', 'LME_Co_Spot_EMA65', 'LME_Co_Spot_WMA65',
       'LME_Co_Spot_EMA125', 'LME_Co_Spot_WMA125', 'LME_Co_Spot_bollinger5',
       'LME_Co_Spot_bollinger10', 'LME_Co_Spot_bollinger15',
       'LME_Co_Spot_bollinger20', 'LME_Co_Spot_bollinger30',
       'LME_Co_Spot_bollinger65', 'LME_Co_Spot_Mom5', 'LME_Co_Spot_Mom10',
       'LME_Co_Spot_Mom15', 'LME_Co_Spot_Mom26', 'LME_Co_Spot_Mom40',
       'LME_Co_Spot_Mom65', 'LME_Co_Spot_Mom125', 'LME_Co_Spot_PPO12',
       'LME_Co_Spot_PPO22', 'LME_Co_Spot_RSI14', 'LME_Co_Spot_RSI26',
       'LME_Co_Spot_RSI40', 'LME_Co_Spot_RSI54', 'LME_Co_Spot_RSI125',
       'LME_Co_Close_EMA12', 'LME_Co_Close_WMA12', 'LME_Co_Close_EMA26',
       'LME_Co_Close_WMA26', 'LME_Co_Close_EMA40', 'LME_Co_Close_WMA40',
       'LME_Co_Close_EMA65', 'LME_Co_Close_WMA65', 'LME_Co_Close_EMA125',
       'LME_Co_Close_WMA125', 'LME_Co_Close_bollinger5',
       'LME_Co_Close_bollinger10', 'LME_Co_Close_bollinger15',
       'LME_Co_Close_bollinger20', 'LME_Co_Close_bollinger30',
       'LME_Co_Close_bollinger65', 'LME_Co_Close_Mom5', 'LME_Co_Close_Mom10',
       'LME_Co_Close_Mom15', 'LME_Co_Close_Mom26', 'LME_Co_Close_Mom40',
       'LME_Co_Close_Mom65', 'LME_Co_Close_Mom125', 'LME_Co_Close_PPO12',
       'LME_Co_Close_PPO22', 'LME_Co_Close_RSI14', 'LME_Co_Close_RSI26',
       'LME_Co_Close_RSI40', 'LME_Co_Close_RSI54', 'LME_Co_Close_RSI125',
       'LME_Co_PVT', 'LME_Co_divPVT', 'LME_Co_NATR14', 'LME_Co_NATR26',
       'LME_Co_NATR65', 'LME_Co_NATR125', 'LME_Co_CCI12', 'LME_Co_CCI26',
       'LME_Co_CCI40', 'LME_Co_CCI65', 'LME_Co_CCI125', 'LME_Co_VBM12',
       'LME_Co_VBM22', 'LME_Co_ADX14', 'LME_Co_ADX26', 'LME_Co_ADX40',
       'LME_Co_ADX54', 'LME_Co_ADX125', 'LME_Co_SAR'],
      dtype='object')
LME_Al_Spot
Before Load Data
['2011-07-01', '2016-07-01', '2017-01-01']
0.026370266024077417
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Al_Spot']
#####################remove_unused_columns_v4#####################
target LME_Al
Index(['LME_Al_Spot', 'LME_Al_Open', 'LME_Al_High', 'LME_Al_Low',
       'LME_Al_Close', 'LME_Al_Spot_EMA12', 'LME_Al_Spot_WMA12',
       'LME_Al_Spot_EMA26', 'LME_Al_Spot_WMA26', 'LME_Al_Spot_EMA40',
       'LME_Al_Spot_WMA40', 'LME_Al_Spot_EMA65', 'LME_Al_Spot_WMA65',
       'LME_Al_Spot_EMA125', 'LME_Al_Spot_WMA125', 'LME_Al_Spot_bollinger5',
       'LME_Al_Spot_bollinger10', 'LME_Al_Spot_bollinger15',
       'LME_Al_Spot_bollinger20', 'LME_Al_Spot_bollinger30',
       'LME_Al_Spot_bollinger65', 'LME_Al_Spot_Mom5', 'LME_Al_Spot_Mom10',
       'LME_Al_Spot_Mom15', 'LME_Al_Spot_Mom26', 'LME_Al_Spot_Mom40',
       'LME_Al_Spot_Mom65', 'LME_Al_Spot_Mom125', 'LME_Al_Spot_PPO12',
       'LME_Al_Spot_PPO22', 'LME_Al_Spot_RSI14', 'LME_Al_Spot_RSI26',
       'LME_Al_Spot_RSI40', 'LME_Al_Spot_RSI54', 'LME_Al_Spot_RSI125',
       'LME_Al_Close_EMA12', 'LME_Al_Close_WMA12', 'LME_Al_Close_EMA26',
       'LME_Al_Close_WMA26', 'LME_Al_Close_EMA40', 'LME_Al_Close_WMA40',
       'LME_Al_Close_EMA65', 'LME_Al_Close_WMA65', 'LME_Al_Close_EMA125',
       'LME_Al_Close_WMA125', 'LME_Al_Close_bollinger5',
       'LME_Al_Close_bollinger10', 'LME_Al_Close_bollinger15',
       'LME_Al_Close_bollinger20', 'LME_Al_Close_bollinger30',
       'LME_Al_Close_bollinger65', 'LME_Al_Close_Mom5', 'LME_Al_Close_Mom10',
       'LME_Al_Close_Mom15', 'LME_Al_Close_Mom26', 'LME_Al_Close_Mom40',
       'LME_Al_Close_Mom65', 'LME_Al_Close_Mom125', 'LME_Al_Close_PPO12',
       'LME_Al_Close_PPO22', 'LME_Al_Close_RSI14', 'LME_Al_Close_RSI26',
       'LME_Al_Close_RSI40', 'LME_Al_Close_RSI54', 'LME_Al_Close_RSI125',
       'LME_Al_PVT', 'LME_Al_divPVT', 'LME_Al_NATR14', 'LME_Al_NATR26',
       'LME_Al_NATR65', 'LME_Al_NATR125', 'LME_Al_CCI12', 'LME_Al_CCI26',
       'LME_Al_CCI40', 'LME_Al_CCI65', 'LME_Al_CCI125', 'LME_Al_VBM12',
       'LME_Al_VBM22', 'LME_Al_ADX14', 'LME_Al_ADX26', 'LME_Al_ADX40',
       'LME_Al_ADX54', 'LME_Al_ADX125', 'LME_Al_SAR'],
      dtype='object')
LME_Le_Spot
Before Load Data
['2011-07-01', '2016-07-01', '2017-01-01']
0.0357585312970694
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Le_Spot']
#####################remove_unused_columns_v4#####################
target LME_Le
Index(['LME_Le_Spot', 'LME_Le_Open', 'LME_Le_High', 'LME_Le_Low',
       'LME_Le_Close', 'LME_Le_Spot_EMA12', 'LME_Le_Spot_WMA12',
       'LME_Le_Spot_EMA26', 'LME_Le_Spot_WMA26', 'LME_Le_Spot_EMA40',
       'LME_Le_Spot_WMA40', 'LME_Le_Spot_EMA65', 'LME_Le_Spot_WMA65',
       'LME_Le_Spot_EMA125', 'LME_Le_Spot_WMA125', 'LME_Le_Spot_bollinger5',
       'LME_Le_Spot_bollinger10', 'LME_Le_Spot_bollinger15',
       'LME_Le_Spot_bollinger20', 'LME_Le_Spot_bollinger30',
       'LME_Le_Spot_bollinger65', 'LME_Le_Spot_Mom5', 'LME_Le_Spot_Mom10',
       'LME_Le_Spot_Mom15', 'LME_Le_Spot_Mom26', 'LME_Le_Spot_Mom40',
       'LME_Le_Spot_Mom65', 'LME_Le_Spot_Mom125', 'LME_Le_Spot_PPO12',
       'LME_Le_Spot_PPO22', 'LME_Le_Spot_RSI14', 'LME_Le_Spot_RSI26',
       'LME_Le_Spot_RSI40', 'LME_Le_Spot_RSI54', 'LME_Le_Spot_RSI125',
       'LME_Le_Close_EMA12', 'LME_Le_Close_WMA12', 'LME_Le_Close_EMA26',
       'LME_Le_Close_WMA26', 'LME_Le_Close_EMA40', 'LME_Le_Close_WMA40',
       'LME_Le_Close_EMA65', 'LME_Le_Close_WMA65', 'LME_Le_Close_EMA125',
       'LME_Le_Close_WMA125', 'LME_Le_Close_bollinger5',
       'LME_Le_Close_bollinger10', 'LME_Le_Close_bollinger15',
       'LME_Le_Close_bollinger20', 'LME_Le_Close_bollinger30',
       'LME_Le_Close_bollinger65', 'LME_Le_Close_Mom5', 'LME_Le_Close_Mom10',
       'LME_Le_Close_Mom15', 'LME_Le_Close_Mom26', 'LME_Le_Close_Mom40',
       'LME_Le_Close_Mom65', 'LME_Le_Close_Mom125', 'LME_Le_Close_PPO12',
       'LME_Le_Close_PPO22', 'LME_Le_Close_RSI14', 'LME_Le_Close_RSI26',
       'LME_Le_Close_RSI40', 'LME_Le_Close_RSI54', 'LME_Le_Close_RSI125',
       'LME_Le_PVT', 'LME_Le_divPVT', 'LME_Le_NATR14', 'LME_Le_NATR26',
       'LME_Le_NATR65', 'LME_Le_NATR125', 'LME_Le_CCI12', 'LME_Le_CCI26',
       'LME_Le_CCI40', 'LME_Le_CCI65', 'LME_Le_CCI125', 'LME_Le_VBM12',
       'LME_Le_VBM22', 'LME_Le_ADX14', 'LME_Le_ADX26', 'LME_Le_ADX40',
       'LME_Le_ADX54', 'LME_Le_ADX125', 'LME_Le_SAR'],
      dtype='object')
LME_Ni_Spot
Before Load Data
['2011-07-01', '2016-07-01', '2017-01-01']
0.03787968544741786
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Ni_Spot']
#####################remove_unused_columns_v4#####################
target LME_Ni
Index(['LME_Ni_Spot', 'LME_Ni_Open', 'LME_Ni_High', 'LME_Ni_Low',
       'LME_Ni_Close', 'LME_Ni_Spot_EMA12', 'LME_Ni_Spot_WMA12',
       'LME_Ni_Spot_EMA26', 'LME_Ni_Spot_WMA26', 'LME_Ni_Spot_EMA40',
       'LME_Ni_Spot_WMA40', 'LME_Ni_Spot_EMA65', 'LME_Ni_Spot_WMA65',
       'LME_Ni_Spot_EMA125', 'LME_Ni_Spot_WMA125', 'LME_Ni_Spot_bollinger5',
       'LME_Ni_Spot_bollinger10', 'LME_Ni_Spot_bollinger15',
       'LME_Ni_Spot_bollinger20', 'LME_Ni_Spot_bollinger30',
       'LME_Ni_Spot_bollinger65', 'LME_Ni_Spot_Mom5', 'LME_Ni_Spot_Mom10',
       'LME_Ni_Spot_Mom15', 'LME_Ni_Spot_Mom26', 'LME_Ni_Spot_Mom40',
       'LME_Ni_Spot_Mom65', 'LME_Ni_Spot_Mom125', 'LME_Ni_Spot_PPO12',
       'LME_Ni_Spot_PPO22', 'LME_Ni_Spot_RSI14', 'LME_Ni_Spot_RSI26',
       'LME_Ni_Spot_RSI40', 'LME_Ni_Spot_RSI54', 'LME_Ni_Spot_RSI125',
       'LME_Ni_Close_EMA12', 'LME_Ni_Close_WMA12', 'LME_Ni_Close_EMA26',
       'LME_Ni_Close_WMA26', 'LME_Ni_Close_EMA40', 'LME_Ni_Close_WMA40',
       'LME_Ni_Close_EMA65', 'LME_Ni_Close_WMA65', 'LME_Ni_Close_EMA125',
       'LME_Ni_Close_WMA125', 'LME_Ni_Close_bollinger5',
       'LME_Ni_Close_bollinger10', 'LME_Ni_Close_bollinger15',
       'LME_Ni_Close_bollinger20', 'LME_Ni_Close_bollinger30',
       'LME_Ni_Close_bollinger65', 'LME_Ni_Close_Mom5', 'LME_Ni_Close_Mom10',
       'LME_Ni_Close_Mom15', 'LME_Ni_Close_Mom26', 'LME_Ni_Close_Mom40',
       'LME_Ni_Close_Mom65', 'LME_Ni_Close_Mom125', 'LME_Ni_Close_PPO12',
       'LME_Ni_Close_PPO22', 'LME_Ni_Close_RSI14', 'LME_Ni_Close_RSI26',
       'LME_Ni_Close_RSI40', 'LME_Ni_Close_RSI54', 'LME_Ni_Close_RSI125',
       'LME_Ni_PVT', 'LME_Ni_divPVT', 'LME_Ni_NATR14', 'LME_Ni_NATR26',
       'LME_Ni_NATR65', 'LME_Ni_NATR125', 'LME_Ni_CCI12', 'LME_Ni_CCI26',
       'LME_Ni_CCI40', 'LME_Ni_CCI65', 'LME_Ni_CCI125', 'LME_Ni_VBM12',
       'LME_Ni_VBM22', 'LME_Ni_ADX14', 'LME_Ni_ADX26', 'LME_Ni_ADX40',
       'LME_Ni_ADX54', 'LME_Ni_ADX125', 'LME_Ni_SAR'],
      dtype='object')
LME_Zi_Spot
Before Load Data
['2011-07-01', '2016-07-01', '2017-01-01']
0.0329719414016907
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Zi_Spot']
#####################remove_unused_columns_v4#####################
target LME_Zi
Index(['LME_Zi_Spot', 'LME_Zi_Open', 'LME_Zi_High', 'LME_Zi_Low',
       'LME_Zi_Close', 'LME_Zi_Spot_EMA12', 'LME_Zi_Spot_WMA12',
       'LME_Zi_Spot_EMA26', 'LME_Zi_Spot_WMA26', 'LME_Zi_Spot_EMA40',
       'LME_Zi_Spot_WMA40', 'LME_Zi_Spot_EMA65', 'LME_Zi_Spot_WMA65',
       'LME_Zi_Spot_EMA125', 'LME_Zi_Spot_WMA125', 'LME_Zi_Spot_bollinger5',
       'LME_Zi_Spot_bollinger10', 'LME_Zi_Spot_bollinger15',
       'LME_Zi_Spot_bollinger20', 'LME_Zi_Spot_bollinger30',
       'LME_Zi_Spot_bollinger65', 'LME_Zi_Spot_Mom5', 'LME_Zi_Spot_Mom10',
       'LME_Zi_Spot_Mom15', 'LME_Zi_Spot_Mom26', 'LME_Zi_Spot_Mom40',
       'LME_Zi_Spot_Mom65', 'LME_Zi_Spot_Mom125', 'LME_Zi_Spot_PPO12',
       'LME_Zi_Spot_PPO22', 'LME_Zi_Spot_RSI14', 'LME_Zi_Spot_RSI26',
       'LME_Zi_Spot_RSI40', 'LME_Zi_Spot_RSI54', 'LME_Zi_Spot_RSI125',
       'LME_Zi_Close_EMA12', 'LME_Zi_Close_WMA12', 'LME_Zi_Close_EMA26',
       'LME_Zi_Close_WMA26', 'LME_Zi_Close_EMA40', 'LME_Zi_Close_WMA40',
       'LME_Zi_Close_EMA65', 'LME_Zi_Close_WMA65', 'LME_Zi_Close_EMA125',
       'LME_Zi_Close_WMA125', 'LME_Zi_Close_bollinger5',
       'LME_Zi_Close_bollinger10', 'LME_Zi_Close_bollinger15',
       'LME_Zi_Close_bollinger20', 'LME_Zi_Close_bollinger30',
       'LME_Zi_Close_bollinger65', 'LME_Zi_Close_Mom5', 'LME_Zi_Close_Mom10',
       'LME_Zi_Close_Mom15', 'LME_Zi_Close_Mom26', 'LME_Zi_Close_Mom40',
       'LME_Zi_Close_Mom65', 'LME_Zi_Close_Mom125', 'LME_Zi_Close_PPO12',
       'LME_Zi_Close_PPO22', 'LME_Zi_Close_RSI14', 'LME_Zi_Close_RSI26',
       'LME_Zi_Close_RSI40', 'LME_Zi_Close_RSI54', 'LME_Zi_Close_RSI125',
       'LME_Zi_PVT', 'LME_Zi_divPVT', 'LME_Zi_NATR14', 'LME_Zi_NATR26',
       'LME_Zi_NATR65', 'LME_Zi_NATR125', 'LME_Zi_CCI12', 'LME_Zi_CCI26',
       'LME_Zi_CCI40', 'LME_Zi_CCI65', 'LME_Zi_CCI125', 'LME_Zi_VBM12',
       'LME_Zi_VBM22', 'LME_Zi_ADX14', 'LME_Zi_ADX26', 'LME_Zi_ADX40',
       'LME_Zi_ADX54', 'LME_Zi_ADX125', 'LME_Zi_SAR'],
      dtype='object')
LME_Ti_Spot
Before Load Data
['2011-07-01', '2016-07-01', '2017-01-01']
0.03437046930765069
====================================technical indicator_v3========================================
LME_Al_Close+LME_Al_Volume=>LME_Al_PVT+LME_Al_divPVT
LME_Co_Close+LME_Co_Volume=>LME_Co_PVT+LME_Co_divPVT
LME_Ti_Close+LME_Ti_Volume=>LME_Ti_PVT+LME_Ti_divPVT
LME_Le_Close+LME_Le_Volume=>LME_Le_PVT+LME_Le_divPVT
LME_Ni_Close+LME_Ni_Volume=>LME_Ni_PVT+LME_Ni_divPVT
LME_Zi_Close+LME_Zi_Volume=>LME_Zi_PVT+LME_Zi_divPVT
Remove Columns Version4
ground_truth ['LME_Ti_Spot']
#####################remove_unused_columns_v4#####################
target LME_Ti
Index(['LME_Ti_Spot', 'LME_Ti_Open', 'LME_Ti_High', 'LME_Ti_Low',
       'LME_Ti_Close', 'LME_Ti_Spot_EMA12', 'LME_Ti_Spot_WMA12',
       'LME_Ti_Spot_EMA26', 'LME_Ti_Spot_WMA26', 'LME_Ti_Spot_EMA40',
       'LME_Ti_Spot_WMA40', 'LME_Ti_Spot_EMA65', 'LME_Ti_Spot_WMA65',
       'LME_Ti_Spot_EMA125', 'LME_Ti_Spot_WMA125', 'LME_Ti_Spot_bollinger5',
       'LME_Ti_Spot_bollinger10', 'LME_Ti_Spot_bollinger15',
       'LME_Ti_Spot_bollinger20', 'LME_Ti_Spot_bollinger30',
       'LME_Ti_Spot_bollinger65', 'LME_Ti_Spot_Mom5', 'LME_Ti_Spot_Mom10',
       'LME_Ti_Spot_Mom15', 'LME_Ti_Spot_Mom26', 'LME_Ti_Spot_Mom40',
       'LME_Ti_Spot_Mom65', 'LME_Ti_Spot_Mom125', 'LME_Ti_Spot_PPO12',
       'LME_Ti_Spot_PPO22', 'LME_Ti_Spot_RSI14', 'LME_Ti_Spot_RSI26',
       'LME_Ti_Spot_RSI40', 'LME_Ti_Spot_RSI54', 'LME_Ti_Spot_RSI125',
       'LME_Ti_Close_EMA12', 'LME_Ti_Close_WMA12', 'LME_Ti_Close_EMA26',
       'LME_Ti_Close_WMA26', 'LME_Ti_Close_EMA40', 'LME_Ti_Close_WMA40',
       'LME_Ti_Close_EMA65', 'LME_Ti_Close_WMA65', 'LME_Ti_Close_EMA125',
       'LME_Ti_Close_WMA125', 'LME_Ti_Close_bollinger5',
       'LME_Ti_Close_bollinger10', 'LME_Ti_Close_bollinger15',
       'LME_Ti_Close_bollinger20', 'LME_Ti_Close_bollinger30',
       'LME_Ti_Close_bollinger65', 'LME_Ti_Close_Mom5', 'LME_Ti_Close_Mom10',
       'LME_Ti_Close_Mom15', 'LME_Ti_Close_Mom26', 'LME_Ti_Close_Mom40',
       'LME_Ti_Close_Mom65', 'LME_Ti_Close_Mom125', 'LME_Ti_Close_PPO12',
       'LME_Ti_Close_PPO22', 'LME_Ti_Close_RSI14', 'LME_Ti_Close_RSI26',
       'LME_Ti_Close_RSI40', 'LME_Ti_Close_RSI54', 'LME_Ti_Close_RSI125',
       'LME_Ti_PVT', 'LME_Ti_divPVT', 'LME_Ti_NATR14', 'LME_Ti_NATR26',
       'LME_Ti_NATR65', 'LME_Ti_NATR125', 'LME_Ti_CCI12', 'LME_Ti_CCI26',
       'LME_Ti_CCI40', 'LME_Ti_CCI65', 'LME_Ti_CCI125', 'LME_Ti_VBM12',
       'LME_Ti_VBM22', 'LME_Ti_ADX14', 'LME_Ti_ADX26', 'LME_Ti_ADX40',
       'LME_Ti_ADX54', 'LME_Ti_ADX125', 'LME_Ti_SAR'],
      dtype='object')
Dataset statistic: #examples
Train: 5472 5472 5472
5.728738 -6.7451596 1.273029 -1.0815955
Validation: 612 612 612
Testing: 768 768 768
pre-processing time: 0.0009219646453857422
the split date is 2016-07-01
net initializing with time: 0.0012028217315673828
preparing training and testing date with time: 0.0020558834075927734
current epoch: 1
train loss is 0.224434
average val loss: 0.135752, accuracy: 0.5327
average test loss: 0.130842, accuracy: 0.5586
case acc: 0.53125
case acc: 0.453125
case acc: 0.53125
case acc: 0.5390625
case acc: 0.640625
case acc: 0.65625
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.1190 ::: bot acc: 0.8095
top acc: 0.3095 ::: bot acc: 0.9048
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.7619 ::: bot acc: 0.4048
top acc: 1.0000 ::: bot acc: 0.0000
current epoch: 2
train loss is 0.119983
average val loss: 0.131422, accuracy: 0.4820
average test loss: 0.140927, accuracy: 0.4779
case acc: 0.5546875
case acc: 0.46875
case acc: 0.46875
case acc: 0.5390625
case acc: 0.34375
case acc: 0.4921875
top acc: 0.5952 ::: bot acc: 0.3810
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.3095 ::: bot acc: 0.9286
current epoch: 3
train loss is 0.112488
average val loss: 0.121610, accuracy: 0.5131
average test loss: 0.129900, accuracy: 0.4922
case acc: 0.5546875
case acc: 0.46875
case acc: 0.46875
case acc: 0.5390625
case acc: 0.3515625
case acc: 0.5703125
top acc: 0.9524 ::: bot acc: 0.1190
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.0238 ::: bot acc: 1.0000
top acc: 0.8095 ::: bot acc: 0.1905
current epoch: 4
train loss is 0.105490
average val loss: 0.124262, accuracy: 0.4967
average test loss: 0.129569, accuracy: 0.4844
case acc: 0.5546875
case acc: 0.46875
case acc: 0.46875
case acc: 0.5390625
case acc: 0.3515625
case acc: 0.5234375
top acc: 0.9762 ::: bot acc: 0.0952
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.0476 ::: bot acc: 0.9762
top acc: 0.7143 ::: bot acc: 0.1667
current epoch: 5
train loss is 0.102341
average val loss: 0.126710, accuracy: 0.4951
average test loss: 0.129100, accuracy: 0.4779
case acc: 0.5390625
case acc: 0.46875
case acc: 0.46875
case acc: 0.5390625
case acc: 0.34375
case acc: 0.5078125
top acc: 0.9762 ::: bot acc: 0.0476
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.0476 ::: bot acc: 0.7857
top acc: 0.6429 ::: bot acc: 0.1905
current epoch: 6
train loss is 0.101496
average val loss: 0.124896, accuracy: 0.5033
average test loss: 0.126127, accuracy: 0.4844
case acc: 0.53125
case acc: 0.46875
case acc: 0.46875
case acc: 0.5390625
case acc: 0.3671875
case acc: 0.53125
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.0952 ::: bot acc: 0.6667
top acc: 0.7381 ::: bot acc: 0.1190
current epoch: 7
train loss is 0.099609
average val loss: 0.124725, accuracy: 0.4951
average test loss: 0.126035, accuracy: 0.4740
case acc: 0.5390625
case acc: 0.46875
case acc: 0.46875
case acc: 0.5390625
case acc: 0.359375
case acc: 0.46875
top acc: 1.0000 ::: bot acc: 0.0238
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.0714 ::: bot acc: 0.6905
top acc: 0.5952 ::: bot acc: 0.1905
current epoch: 8
train loss is 0.098654
average val loss: 0.124785, accuracy: 0.4771
average test loss: 0.126247, accuracy: 0.4688
case acc: 0.5703125
case acc: 0.46875
case acc: 0.46875
case acc: 0.5390625
case acc: 0.34375
case acc: 0.421875
top acc: 0.9762 ::: bot acc: 0.1429
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.0714 ::: bot acc: 0.7381
top acc: 0.4762 ::: bot acc: 0.2381
current epoch: 9
train loss is 0.097101
average val loss: 0.123974, accuracy: 0.4820
average test loss: 0.125583, accuracy: 0.4727
case acc: 0.5703125
case acc: 0.46875
case acc: 0.46875
case acc: 0.5390625
case acc: 0.3515625
case acc: 0.4375
top acc: 0.9762 ::: bot acc: 0.1429
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.0714 ::: bot acc: 0.7143
top acc: 0.4524 ::: bot acc: 0.3095
current epoch: 10
train loss is 0.096139
average val loss: 0.124262, accuracy: 0.4755
average test loss: 0.125607, accuracy: 0.4740
case acc: 0.578125
case acc: 0.46875
case acc: 0.46875
case acc: 0.5390625
case acc: 0.3671875
case acc: 0.421875
top acc: 0.9524 ::: bot acc: 0.1905
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.0952 ::: bot acc: 0.6905
top acc: 0.3571 ::: bot acc: 0.3810
current epoch: 11
train loss is 0.095338
average val loss: 0.124032, accuracy: 0.4837
average test loss: 0.125084, accuracy: 0.4740
case acc: 0.6015625
case acc: 0.46875
case acc: 0.46875
case acc: 0.5390625
case acc: 0.375
case acc: 0.390625
top acc: 0.9762 ::: bot acc: 0.2381
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 1.0000 ::: bot acc: 0.0000
top acc: 0.0952 ::: bot acc: 0.6667
top acc: 0.3333 ::: bot acc: 0.3810
current epoch: 12
train loss is 0.094119
average val loss: 0.123846, accuracy: 0.4902
average test loss: 0.124763, accuracy: 0.4727
case acc: 0.609375
case acc: 0.46875
case acc: 0.46875
case acc: 0.5234375
case acc: 0.3671875
case acc: 0.3984375
top acc: 0.9524 ::: bot acc: 0.3095
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.9762 ::: bot acc: 0.0000
top acc: 0.0952 ::: bot acc: 0.6429
top acc: 0.3333 ::: bot acc: 0.4524
current epoch: 13
train loss is 0.093577
average val loss: 0.123713, accuracy: 0.4804
average test loss: 0.124610, accuracy: 0.4740
case acc: 0.625
case acc: 0.46875
case acc: 0.46875
case acc: 0.5234375
case acc: 0.3671875
case acc: 0.390625
top acc: 0.8810 ::: bot acc: 0.3810
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.9524 ::: bot acc: 0.0714
top acc: 0.0952 ::: bot acc: 0.6429
top acc: 0.3333 ::: bot acc: 0.5238
current epoch: 14
train loss is 0.092470
average val loss: 0.123853, accuracy: 0.4869
average test loss: 0.124431, accuracy: 0.4661
case acc: 0.609375
case acc: 0.46875
case acc: 0.46875
case acc: 0.5234375
case acc: 0.359375
case acc: 0.3671875
top acc: 0.9048 ::: bot acc: 0.3810
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.9286 ::: bot acc: 0.1667
top acc: 0.1190 ::: bot acc: 0.5714
top acc: 0.2857 ::: bot acc: 0.5238
current epoch: 15
train loss is 0.091276
average val loss: 0.123838, accuracy: 0.4902
average test loss: 0.124608, accuracy: 0.4674
case acc: 0.6015625
case acc: 0.46875
case acc: 0.46875
case acc: 0.546875
case acc: 0.359375
case acc: 0.359375
top acc: 0.8333 ::: bot acc: 0.4048
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.8333 ::: bot acc: 0.3571
top acc: 0.1190 ::: bot acc: 0.5714
top acc: 0.2619 ::: bot acc: 0.5476
current epoch: 16
train loss is 0.091294
average val loss: 0.123858, accuracy: 0.4853
average test loss: 0.124512, accuracy: 0.4674
case acc: 0.5859375
case acc: 0.46875
case acc: 0.46875
case acc: 0.5625
case acc: 0.3671875
case acc: 0.3515625
top acc: 0.8095 ::: bot acc: 0.4048
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.7143 ::: bot acc: 0.5000
top acc: 0.1429 ::: bot acc: 0.5714
top acc: 0.2381 ::: bot acc: 0.5714
current epoch: 17
train loss is 0.089820
average val loss: 0.124168, accuracy: 0.4951
average test loss: 0.124586, accuracy: 0.4714
case acc: 0.609375
case acc: 0.46875
case acc: 0.46875
case acc: 0.5546875
case acc: 0.375
case acc: 0.3515625
top acc: 0.7857 ::: bot acc: 0.5000
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.6190 ::: bot acc: 0.5714
top acc: 0.1667 ::: bot acc: 0.5714
top acc: 0.2381 ::: bot acc: 0.5952
current epoch: 18
train loss is 0.089077
average val loss: 0.124825, accuracy: 0.5033
average test loss: 0.125095, accuracy: 0.4674
case acc: 0.59375
case acc: 0.46875
case acc: 0.4609375
case acc: 0.546875
case acc: 0.375
case acc: 0.359375
top acc: 0.7381 ::: bot acc: 0.5476
top acc: 0.0000 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 0.9762
top acc: 0.5476 ::: bot acc: 0.6429
top acc: 0.1667 ::: bot acc: 0.5714
top acc: 0.2381 ::: bot acc: 0.6190
current epoch: 19
train loss is 0.088903
average val loss: 0.124542, accuracy: 0.5016
average test loss: 0.124777, accuracy: 0.4714
case acc: 0.6015625
case acc: 0.4765625
case acc: 0.4609375
case acc: 0.5625
case acc: 0.375
case acc: 0.3515625
top acc: 0.7857 ::: bot acc: 0.5238
top acc: 0.0238 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 0.9762
top acc: 0.5476 ::: bot acc: 0.6905
top acc: 0.1905 ::: bot acc: 0.5476
top acc: 0.2381 ::: bot acc: 0.5952
current epoch: 20
train loss is 0.087863
average val loss: 0.125249, accuracy: 0.5082
average test loss: 0.125060, accuracy: 0.4701
case acc: 0.6015625
case acc: 0.4765625
case acc: 0.4609375
case acc: 0.546875
case acc: 0.3828125
case acc: 0.3515625
top acc: 0.7857 ::: bot acc: 0.5238
top acc: 0.0238 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 0.9762
top acc: 0.5000 ::: bot acc: 0.7381
top acc: 0.2143 ::: bot acc: 0.5476
top acc: 0.2381 ::: bot acc: 0.5952
current epoch: 21
train loss is 0.086943
average val loss: 0.125701, accuracy: 0.5098
average test loss: 0.125169, accuracy: 0.4688
case acc: 0.6015625
case acc: 0.4765625
case acc: 0.4609375
case acc: 0.5546875
case acc: 0.3671875
case acc: 0.3515625
top acc: 0.7857 ::: bot acc: 0.5476
top acc: 0.0238 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 0.9762
top acc: 0.5000 ::: bot acc: 0.7381
top acc: 0.2143 ::: bot acc: 0.5238
top acc: 0.2381 ::: bot acc: 0.5952
current epoch: 22
train loss is 0.087052
average val loss: 0.125995, accuracy: 0.5098
average test loss: 0.125090, accuracy: 0.4701
case acc: 0.6015625
case acc: 0.4765625
case acc: 0.4453125
case acc: 0.5625
case acc: 0.3828125
case acc: 0.3515625
top acc: 0.7619 ::: bot acc: 0.5714
top acc: 0.0238 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 0.9524
top acc: 0.5000 ::: bot acc: 0.7619
top acc: 0.2381 ::: bot acc: 0.5238
top acc: 0.2381 ::: bot acc: 0.5952
current epoch: 23
train loss is 0.086037
average val loss: 0.126497, accuracy: 0.5131
average test loss: 0.125100, accuracy: 0.4701
case acc: 0.6015625
case acc: 0.4765625
case acc: 0.4453125
case acc: 0.5546875
case acc: 0.390625
case acc: 0.3515625
top acc: 0.7619 ::: bot acc: 0.5714
top acc: 0.0238 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 0.9524
top acc: 0.4762 ::: bot acc: 0.7619
top acc: 0.2381 ::: bot acc: 0.5238
top acc: 0.2381 ::: bot acc: 0.5952
current epoch: 24
train loss is 0.085076
average val loss: 0.127006, accuracy: 0.5196
average test loss: 0.125728, accuracy: 0.4740
case acc: 0.6328125
case acc: 0.4765625
case acc: 0.4453125
case acc: 0.5625
case acc: 0.375
case acc: 0.3515625
top acc: 0.7619 ::: bot acc: 0.6429
top acc: 0.0238 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 0.9524
top acc: 0.4762 ::: bot acc: 0.7619
top acc: 0.2143 ::: bot acc: 0.5714
top acc: 0.2381 ::: bot acc: 0.5952
current epoch: 25
train loss is 0.085211
average val loss: 0.127089, accuracy: 0.5310
average test loss: 0.125634, accuracy: 0.4661
case acc: 0.6015625
case acc: 0.4765625
case acc: 0.4453125
case acc: 0.5625
case acc: 0.3671875
case acc: 0.34375
top acc: 0.6905 ::: bot acc: 0.6429
top acc: 0.0238 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 0.9524
top acc: 0.4286 ::: bot acc: 0.7619
top acc: 0.1905 ::: bot acc: 0.5952
top acc: 0.2143 ::: bot acc: 0.5952
current epoch: 26
train loss is 0.084248
average val loss: 0.127906, accuracy: 0.5261
average test loss: 0.126031, accuracy: 0.4661
case acc: 0.609375
case acc: 0.4765625
case acc: 0.4453125
case acc: 0.5625
case acc: 0.359375
case acc: 0.34375
top acc: 0.6667 ::: bot acc: 0.6905
top acc: 0.0238 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 0.9524
top acc: 0.4286 ::: bot acc: 0.7619
top acc: 0.1905 ::: bot acc: 0.5952
top acc: 0.1905 ::: bot acc: 0.6429
current epoch: 27
train loss is 0.083513
average val loss: 0.128041, accuracy: 0.5229
average test loss: 0.125951, accuracy: 0.4674
case acc: 0.6171875
case acc: 0.4765625
case acc: 0.4453125
case acc: 0.5546875
case acc: 0.359375
case acc: 0.3515625
top acc: 0.6667 ::: bot acc: 0.7143
top acc: 0.0238 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 0.9524
top acc: 0.4286 ::: bot acc: 0.7619
top acc: 0.1905 ::: bot acc: 0.5952
top acc: 0.1905 ::: bot acc: 0.6667
current epoch: 28
train loss is 0.082782
average val loss: 0.128446, accuracy: 0.5229
average test loss: 0.125809, accuracy: 0.4661
case acc: 0.6171875
case acc: 0.4765625
case acc: 0.4453125
case acc: 0.5390625
case acc: 0.3671875
case acc: 0.3515625
top acc: 0.6667 ::: bot acc: 0.7143
top acc: 0.0238 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 0.9524
top acc: 0.4286 ::: bot acc: 0.7619
top acc: 0.1905 ::: bot acc: 0.5952
top acc: 0.1905 ::: bot acc: 0.6429
current epoch: 29
train loss is 0.082844
average val loss: 0.129812, accuracy: 0.5196
average test loss: 0.126702, accuracy: 0.4635
case acc: 0.6328125
case acc: 0.4765625
case acc: 0.4453125
case acc: 0.515625
case acc: 0.359375
case acc: 0.3515625
top acc: 0.6667 ::: bot acc: 0.7619
top acc: 0.0238 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 0.9524
top acc: 0.3571 ::: bot acc: 0.7619
top acc: 0.1429 ::: bot acc: 0.6429
top acc: 0.1905 ::: bot acc: 0.6429
current epoch: 30
train loss is 0.082366
average val loss: 0.130455, accuracy: 0.5212
average test loss: 0.126898, accuracy: 0.4635
case acc: 0.6484375
case acc: 0.4765625
case acc: 0.4453125
case acc: 0.5
case acc: 0.359375
case acc: 0.3515625
top acc: 0.6667 ::: bot acc: 0.7857
top acc: 0.0238 ::: bot acc: 1.0000
top acc: 0.0000 ::: bot acc: 0.9286
top acc: 0.3095 ::: bot acc: 0.7619
top acc: 0.1429 ::: bot acc: 0.6429
top acc: 0.1905 ::: bot acc: 0.6429
current epoch: 31
train loss is 0.081555
average val loss: 0.130804, accuracy: 0.5196
average test loss: 0.126587, accuracy: 0.4648
case acc: 0.6640625
case acc: 0.4765625
case acc: 0.453125
case acc: 0.484375
case acc: 0.3671875
case acc: 0.34375
top acc: 0.6667 ::: bot acc: 0.8333
top acc: 0.0238 ::: bot acc: 1.0000
top acc: 0.0238 ::: bot acc: 0.9286
top acc: 0.2619 ::: bot acc: 0.7619
top acc: 0.1429 ::: bot acc: 0.6429
top acc: 0.1905 ::: bot acc: 0.6190
current epoch: 32
train loss is 0.080906
average val loss: 0.131057, accuracy: 0.5212
average test loss: 0.126346, accuracy: 0.4648
case acc: 0.6484375
case acc: 0.4765625
case acc: 0.4375
case acc: 0.5234375
case acc: 0.3671875
case acc: 0.3359375
top acc: 0.6429 ::: bot acc: 0.8095
top acc: 0.0238 ::: bot acc: 1.0000
top acc: 0.0238 ::: bot acc: 0.9048
top acc: 0.3571 ::: bot acc: 0.7857
top acc: 0.1429 ::: bot acc: 0.6429
top acc: 0.2143 ::: bot acc: 0.5714
current epoch: 33
train loss is 0.080233
average val loss: 0.131642, accuracy: 0.5196
average test loss: 0.126898, accuracy: 0.4609
case acc: 0.640625
case acc: 0.4765625
case acc: 0.4453125
case acc: 0.5078125
case acc: 0.359375
case acc: 0.3359375
top acc: 0.5952 ::: bot acc: 0.8095
top acc: 0.0238 ::: bot acc: 1.0000
top acc: 0.0714 ::: bot acc: 0.8810
top acc: 0.3095 ::: bot acc: 0.7857
top acc: 0.1429 ::: bot acc: 0.6905
top acc: 0.1905 ::: bot acc: 0.5952
current epoch: 34
train loss is 0.079592
average val loss: 0.131882, accuracy: 0.5163
average test loss: 0.126634, accuracy: 0.4609
case acc: 0.65625
case acc: 0.484375
case acc: 0.4453125
case acc: 0.484375
case acc: 0.359375
case acc: 0.3359375
top acc: 0.6429 ::: bot acc: 0.8095
top acc: 0.0238 ::: bot acc: 1.0000
top acc: 0.0714 ::: bot acc: 0.8810
top acc: 0.2381 ::: bot acc: 0.7857
top acc: 0.1429 ::: bot acc: 0.6905
top acc: 0.2143 ::: bot acc: 0.5714
current epoch: 35
train loss is 0.078921
average val loss: 0.131583, accuracy: 0.5196
average test loss: 0.125924, accuracy: 0.4688
case acc: 0.6484375
case acc: 0.5
case acc: 0.453125
case acc: 0.4921875
case acc: 0.3828125
case acc: 0.3359375
top acc: 0.6429 ::: bot acc: 0.7857
top acc: 0.0476 ::: bot acc: 1.0000
top acc: 0.0714 ::: bot acc: 0.8810
top acc: 0.2619 ::: bot acc: 0.7857
top acc: 0.1429 ::: bot acc: 0.6905
top acc: 0.2381 ::: bot acc: 0.5000
current epoch: 36
train loss is 0.078737
average val loss: 0.133579, accuracy: 0.5131
average test loss: 0.126861, accuracy: 0.4688
case acc: 0.6484375
case acc: 0.5078125
case acc: 0.453125
case acc: 0.4921875
case acc: 0.3671875
case acc: 0.34375
top acc: 0.6429 ::: bot acc: 0.7857
top acc: 0.0476 ::: bot acc: 1.0000
top acc: 0.0714 ::: bot acc: 0.8571
top acc: 0.2381 ::: bot acc: 0.8095
top acc: 0.1429 ::: bot acc: 0.7143
top acc: 0.2143 ::: bot acc: 0.5476
current epoch: 37
train loss is 0.078191
average val loss: 0.133211, accuracy: 0.5147
average test loss: 0.126162, accuracy: 0.4688
case acc: 0.640625
case acc: 0.515625
case acc: 0.4453125
case acc: 0.4921875
case acc: 0.375
case acc: 0.34375
top acc: 0.6190 ::: bot acc: 0.7857
top acc: 0.0476 ::: bot acc: 1.0000
top acc: 0.0714 ::: bot acc: 0.8333
top acc: 0.2381 ::: bot acc: 0.8095
top acc: 0.1429 ::: bot acc: 0.7143
top acc: 0.2619 ::: bot acc: 0.4524
current epoch: 38
train loss is 0.077677
average val loss: 0.133853, accuracy: 0.5131
average test loss: 0.126464, accuracy: 0.4740
case acc: 0.6484375
case acc: 0.5390625
case acc: 0.4453125
case acc: 0.4921875
case acc: 0.375
case acc: 0.34375
top acc: 0.6190 ::: bot acc: 0.8095
top acc: 0.0476 ::: bot acc: 1.0000
top acc: 0.0714 ::: bot acc: 0.8333
top acc: 0.2619 ::: bot acc: 0.7857
top acc: 0.1429 ::: bot acc: 0.7143
top acc: 0.2143 ::: bot acc: 0.5000
current epoch: 39
train loss is 0.076800
average val loss: 0.134401, accuracy: 0.5114
average test loss: 0.126038, accuracy: 0.4740
case acc: 0.6484375
case acc: 0.546875
case acc: 0.4375
case acc: 0.4921875
case acc: 0.375
case acc: 0.34375
top acc: 0.6190 ::: bot acc: 0.7857
top acc: 0.0952 ::: bot acc: 1.0000
top acc: 0.0714 ::: bot acc: 0.8095
top acc: 0.2619 ::: bot acc: 0.7857
top acc: 0.1429 ::: bot acc: 0.7143
top acc: 0.2857 ::: bot acc: 0.4048
current epoch: 40
train loss is 0.077122
average val loss: 0.135917, accuracy: 0.5065
average test loss: 0.126678, accuracy: 0.4727
case acc: 0.6484375
case acc: 0.5625
case acc: 0.4375
case acc: 0.4921875
case acc: 0.3515625
case acc: 0.34375
top acc: 0.6190 ::: bot acc: 0.7857
top acc: 0.1429 ::: bot acc: 1.0000
top acc: 0.0714 ::: bot acc: 0.8095
top acc: 0.2619 ::: bot acc: 0.7857
top acc: 0.1429 ::: bot acc: 0.7143
top acc: 0.3095 ::: bot acc: 0.4048
current epoch: 41
train loss is 0.075649
average val loss: 0.136338, accuracy: 0.5016
average test loss: 0.126488, accuracy: 0.4779
case acc: 0.6484375
case acc: 0.5625
case acc: 0.4375
case acc: 0.5
case acc: 0.359375
case acc: 0.359375
top acc: 0.6190 ::: bot acc: 0.7857
top acc: 0.1667 ::: bot acc: 0.9762
top acc: 0.0714 ::: bot acc: 0.8095
top acc: 0.2857 ::: bot acc: 0.7857
top acc: 0.1429 ::: bot acc: 0.7143
top acc: 0.3333 ::: bot acc: 0.3810
current epoch: 42
train loss is 0.075723
average val loss: 0.136196, accuracy: 0.5016
average test loss: 0.125972, accuracy: 0.4766
case acc: 0.640625
case acc: 0.546875
case acc: 0.4296875
case acc: 0.4921875
case acc: 0.3671875
case acc: 0.3828125
top acc: 0.6190 ::: bot acc: 0.7857
top acc: 0.1667 ::: bot acc: 0.9286
top acc: 0.0714 ::: bot acc: 0.7857
top acc: 0.2857 ::: bot acc: 0.7619
top acc: 0.1429 ::: bot acc: 0.7143
top acc: 0.3810 ::: bot acc: 0.3571
current epoch: 43
train loss is 0.075221
average val loss: 0.134999, accuracy: 0.5000
average test loss: 0.125337, accuracy: 0.4818
case acc: 0.640625
case acc: 0.5390625
case acc: 0.4296875
case acc: 0.484375
case acc: 0.3671875
case acc: 0.4296875
top acc: 0.6190 ::: bot acc: 0.7857
top acc: 0.1667 ::: bot acc: 0.9048
top acc: 0.0714 ::: bot acc: 0.7857
top acc: 0.2857 ::: bot acc: 0.7619
top acc: 0.1429 ::: bot acc: 0.7143
top acc: 0.5000 ::: bot acc: 0.3571
current epoch: 44
train loss is 0.074161
average val loss: 0.136122, accuracy: 0.5000
average test loss: 0.125973, accuracy: 0.4805
case acc: 0.640625
case acc: 0.5390625
case acc: 0.4375
case acc: 0.484375
case acc: 0.359375
case acc: 0.421875
top acc: 0.6190 ::: bot acc: 0.7857
top acc: 0.1667 ::: bot acc: 0.9048
top acc: 0.0714 ::: bot acc: 0.8095
top acc: 0.2857 ::: bot acc: 0.7619
top acc: 0.1190 ::: bot acc: 0.7619
top acc: 0.4762 ::: bot acc: 0.3571
current epoch: 45
train loss is 0.073386
average val loss: 0.139066, accuracy: 0.5000
average test loss: 0.126913, accuracy: 0.4805
case acc: 0.640625
case acc: 0.5234375
case acc: 0.4375
case acc: 0.5
case acc: 0.359375
case acc: 0.421875
top acc: 0.6190 ::: bot acc: 0.7857
top acc: 0.1667 ::: bot acc: 0.8571
top acc: 0.0714 ::: bot acc: 0.8095
top acc: 0.2857 ::: bot acc: 0.7857
top acc: 0.1190 ::: bot acc: 0.7619
top acc: 0.4762 ::: bot acc: 0.3571
current epoch: 46
train loss is 0.074247
average val loss: 0.136983, accuracy: 0.5065
average test loss: 0.125468, accuracy: 0.4792
case acc: 0.640625
case acc: 0.5234375
case acc: 0.4375
case acc: 0.4765625
case acc: 0.3671875
case acc: 0.4296875
top acc: 0.6190 ::: bot acc: 0.7857
top acc: 0.1667 ::: bot acc: 0.8571
top acc: 0.0952 ::: bot acc: 0.8095
top acc: 0.2857 ::: bot acc: 0.7619
top acc: 0.1190 ::: bot acc: 0.7857
top acc: 0.5238 ::: bot acc: 0.3333
current epoch: 47
train loss is 0.073613
average val loss: 0.138835, accuracy: 0.5000
average test loss: 0.126569, accuracy: 0.4792
case acc: 0.640625
case acc: 0.5234375
case acc: 0.4296875
case acc: 0.484375
case acc: 0.359375
case acc: 0.4375
top acc: 0.6190 ::: bot acc: 0.7857
top acc: 0.1667 ::: bot acc: 0.8571
top acc: 0.0714 ::: bot acc: 0.8095
top acc: 0.2857 ::: bot acc: 0.7619
top acc: 0.1190 ::: bot acc: 0.7857
top acc: 0.5238 ::: bot acc: 0.3571
current epoch: 48
train loss is 0.073979
average val loss: 0.139942, accuracy: 0.5000
average test loss: 0.126509, accuracy: 0.4870
case acc: 0.640625
case acc: 0.515625
case acc: 0.4375
case acc: 0.484375
case acc: 0.359375
case acc: 0.484375
top acc: 0.6429 ::: bot acc: 0.7619
top acc: 0.2143 ::: bot acc: 0.8095
top acc: 0.0952 ::: bot acc: 0.8095
top acc: 0.2857 ::: bot acc: 0.7619
top acc: 0.1190 ::: bot acc: 0.8095
top acc: 0.6190 ::: bot acc: 0.3333
current epoch: 49
train loss is 0.071756
average val loss: 0.140607, accuracy: 0.5000
average test loss: 0.127142, accuracy: 0.4779
case acc: 0.625
case acc: 0.515625
case acc: 0.4296875
case acc: 0.4921875
case acc: 0.34375
case acc: 0.4609375
top acc: 0.6190 ::: bot acc: 0.7381
top acc: 0.2143 ::: bot acc: 0.8095
top acc: 0.0714 ::: bot acc: 0.8095
top acc: 0.2857 ::: bot acc: 0.7619
top acc: 0.0714 ::: bot acc: 0.8095
top acc: 0.5714 ::: bot acc: 0.3333
current epoch: 50
train loss is 0.072227
average val loss: 0.137223, accuracy: 0.5147
average test loss: 0.125444, accuracy: 0.4883
case acc: 0.6328125
case acc: 0.5
case acc: 0.421875
case acc: 0.5078125
case acc: 0.3515625
case acc: 0.515625
top acc: 0.6429 ::: bot acc: 0.7381
top acc: 0.2381 ::: bot acc: 0.7619
top acc: 0.0952 ::: bot acc: 0.7619
top acc: 0.3333 ::: bot acc: 0.7619
top acc: 0.1190 ::: bot acc: 0.7857
top acc: 0.6429 ::: bot acc: 0.3095
